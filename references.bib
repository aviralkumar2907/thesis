@string{JMLR = "Journal of Machine Learning Research"}
%@string{JMLR = "JMLR"}

@string{BMVC = "BMVC"}

@string{PAMI = "TPAMI"}
%@string{PAMI = "IEEE Trans. on Pattern Analysis and Machine Intelligence"}

@string{TPAMI = "PAMI"}
@string{TPAMI = "IEEE Trans. on Pattern Analysis and Machine Intelligence"}

@string{CVIU = "Computer Vision and Image Understanding"}
@string{CVIU = "CVIU"}

@string{WACV = "WACV"}
@string{WACV = "IEEE Winter Conference on Applications of Computer Vision"}

@string{PR = "Pattern Recognition"}
@string{PR = "PR"}

@string{ICCV = "ICCV"}
@string{ICCV = "International Conference on Computer Vision"}

@string{CVPR = "CVPR"}
@string{CVPR = "IEEE Conference on Computer Vision and Pattern Recognition"}

@string{IJCV = "IJCV"}
@string{IJCV = "International Journal of Computer Vision"}

@string{ICML = "ICML"}
@string{ICML = "International Conference on Machine Learning"}

@string{ECCV = "ECCV"}
@string{ECCV = "European Conference on Computer Vision"}

@string{ACCV = "ACCV"}

@string{NIPS = "NIPS"}
@string{NIPS = "Advances in Neural Information Processing Systems"}

@string{IJCAI = "International Joint Conference on Artificial Intelligence"}

@string{RA = "IEEE Trans. on Robotics and Automation"}

@string{CACM = "Communications of the ACM"}

@string{CVGIP = "Computer Vision, Graphics, and Image Processing"}

@string{AI = "Artificial Intelligence"}

@string{JAIR = "Journal of Artificial Intelligence Research"}

@string{AISTATS = "International Conference on Artificial Intelligence and Statistics"}

@string{IEEEPUB = "IEEE Computer Society"}


%% Category Shapes References %%
@article{nandakumar2011little,
  title={How little do we need for 3-D shape perception?},
  author={Nandakumar, Chetan and Torralba, Antonio and Malik, Jitendra},
  journal={Perception-London},
  year={2011}
}

@article{pascal-voc-2012, 
   author = "Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.", 
   title = "The Pascal Visual Object Classes (VOC) Challenge", 
   journal = IJCV, 
   year = {2010} 
}

@inproceedings{arbelaez2014multiscale,
  title={Multiscale Combinatorial Grouping},
  author={Arbel{\'a}ez, Pablo and Pont-Tuset, Jordi and Barron, Jonathan T and Marques, Ferran and Malik, Jitendra},
  year={2014},
  booktitle=CVPR
}

@inproceedings{carreira_cvpr10,
  author = {J. Carreira and C. Sminchisescu},
  title = {Constrained Parametric Min-Cuts for Automatic Object Segmentation},
  booktitle = CVPR,
  year = {2010}
}

@incollection{BharathECCV2014,
  author       = "Bharath Hariharan and Pablo Arbel\'{a}ez and Ross Girshick and Jitendra Malik",
  title        = "Simultaneous Detection and Segmentation",
  booktitle    = ECCV,
  year         = {2014},
}

@incollection{ShubhamPose,
  author = {Shubham Tulsiani and Jitendra Malik},
  title = {Viewpoints and Keypoints},
  booktitle = CVPR,
  year = {2015},
}

@inproceedings{Lecun89,
title = {Backpropagation applied to hand-written zip code recognition},
booktitle = {Neural Computation},
author = {Yang LeCun and B. Boser and J.S. Denker and D. Henderson and R. E. Howard and W. Hubbard and L. D. Jackel},
year = {1989}
}

@inproceedings{Krizhevsky,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle=NIPS,
  year={2012}
}

@incollection{what_alexe_10,
	author = {B. Alexe and T. Deselaers and V. Ferrari},
	title = {What is an object?},
	booktitle = CVPR,
	year = {2010}
}

@incollection{endres_proposal_eccv2010,
  author = {Ian Endres and Andrew Hoiem},
  title = {Category Independent Object Proposals},
  booktitle = ECCV,
  year = {2010}
}

@inproceedings{van2011segmentation,
  title={Segmentation as selective search for object recognition},
  author={Van de Sande, Koen EA and Uijlings, Jasper RR and Gevers, Theo and Smeulders, Arnold WM},
  booktitle=ICCV,
  year={2011}
}

@inproceedings{blanz1999morphable,
  title={A morphable model for the synthesis of 3D faces},
  author={Blanz, Volker and Vetter, Thomas},
  booktitle={Computer Graphics and Interactive Techniques},
  year={1999}
}

@article{Everingham10, 
   author = "Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.", 
   title = "The Pascal Visual Object Classes (VOC) Challenge", 
   journal = IJCV, 
   year = {2010} 
}

@inproceedings{carvi14,
  title={Reconstructing PASCAL VOC},
  author={Vicente, Sara and Carreira, Joao and Agapito, Lourdes and Batista, Jorge},
  booktitle=CVPR,
  year={2014}
}

@inproceedings{kemelmacher2011internet,
  title={Internet based morphable model},
  author={Kemelmacher-Shlizerman, Ira},
  booktitle=ICCV,
  year={2011}
}

@incollection{movingFace:eccv14,
	year={2014},
	booktitle=ECCV,
	title={Total Moving Face Reconstruction},
	author={Suwajanakorn, Supasorn and Kemelmacher-Shlizerman, Ira and Seitz, StevenM.}
}

@article{nevatia1977description,
  title={Description and recognition of curved objects},
  author={Nevatia, Ramakant and Binford, Thomas O},
  journal={Artificial Intelligence},
  year={1977}
}

@incollection{gupta2010blocks,
  title={Blocks world revisited: Image understanding using qualitative geometry and mechanics},
  author={Gupta, Abhinav and Efros, Alexei A and Hebert, Martial},
  booktitle=ECCV,
  year={2010}
}

@inproceedings{xiao2012localizing,
  title={Localizing 3D cuboids in single-view images},
  author={Xiao, Jianxiong and Russell, Bryan and Torralba, Antonio},
  booktitle=NIPS,
  year={2012}
}

@phdthesis{roberts1963machine,
  title={Machine Perception of Three-Dimensional Solids},
  author={Roberts, Lawrence Gilman},
  year={1963},
  school={Massachusetts Institute of Technology}
}

@inproceedings{limparsing,
  title={Parsing IKEA Objects: Fine Pose Estimation},
  author={Lim, Joseph J and Pirsiavash, Hamed and Torralba, Antonio},
  booktitle=ICCV,
  year={2013}
}

@article{satkin20143dnn,
  title={3DNN: 3D Nearest Neighbor},
  author={Satkin, Scott and Rashid, Maheen and Lin, Jason and Hebert, Martial},
  journal=IJCV,
  year={2014}
}

@inproceedings{Anguelov:SCAPE2005,
  title={Scape: Shape Completion and Animation of People},
  author={Anguelov, D. and Srinivasan, P. and Koller, D. and Thrun, S. and Rodgers, J. and Davis, J.},
  booktitle = {ACM Transactions on Graphics (TOG)},
  year={2005}
 }

@article{zia2013detailed,
  title={Detailed 3d representations for object recognition and modeling},
  author={Zia, M Zeeshan and Stark, Michael and Schiele, Bernt and Schindler, Konrad},
  journal=PAMI,
  year={2013}
}

@article{koenderink1992surface,
  title={Surface perception in pictures},
  author={Koenderink, Jan J and Van Doorn, Andrea J and Kappers, Astrid ML},
  journal={Perception \& Psychophysics},
  year={1992}
}

@inproceedings{eccv_12,
  author = {J. Carreira and R. Caseiro and J. Batista and C. Sminchisescu},
  title = {Semantic Segmentation with Second-Order Pooling},
  year = {2012},
  booktitle = ECCV
}

@article{barronPAMI13, 
Author = {Jonathan T Barron and Jitendra Malik},
Title = {Shape, Illumination, and Reflectance from Shading},
journal=PAMI,
year={2015}, 
}

@article{blanz2003face,
  title={Face Recognition based on fitting a 3D morphable model},
  author={Blanz, Volker and Vetter, Thomas},
  journal=PAMI,
  year={2003},
}

@incollection{cootes1998active,
  title={Active appearance models},
  author={Cootes, Timothy F and Edwards, Gareth J and Taylor, Christopher J},
  booktitle=ECCV,
  year={1998}
}

@inproceedings{BharathICCV2011,
author = "Bharath Hariharan and Pablo Arbelaez and Lubomir Bourdev and Subhransu Maji and Jitendra Malik",
title = "Semantic Contours from Inverse Detectors",
booktitle = ICCV,
year = "2011",
}

@ARTICLE{felzens_latent_pami10,
  author = {Pedro F. Felzenszwalb and Ross B. Girshick and David McAllester and Deva Ramanan},
  title = {Object Detection with Discriminatively Trained Part-Based Models},
  journal = PAMI,
  year = {2010}
}

@inproceedings{DPMsCNNs,
  Author    = {Ross Girshick and
               Forrest Iandola and
               Trevor Darrell and
               Jitendra Malik},
  Title     = {Deformable Part Models are
               Convolutional Neural Networks},
  Booktitle = CVPR,
  Year      = {2015}
}

@article{huttenlocher1990recognizing,
  title={Recognizing solid objects by alignment with an image},
  author={Huttenlocher, Daniel P and Ullman, Shimon},
  journal=IJCV,
  year={1990},
}

@inproceedings{pascal3d,
  author = {Xiang, Yu and Mottaghi, Roozbeh and Savarese, Silvio},
  title = {Beyond PASCAL: A Benchmark for 3D Object Detection in the Wild},
  booktitle={WACV},
  year={2014}
}

@inproceedings {pepik12dpm,
	title = {Teaching 3D Geometry to Deformable Part Models},
	booktitle = CVPR,
	year = {2012},
	author = {Pepik, Bojan and Michael Stark and Peter Gehler and Schiele, Bernt}
}

@inproceedings{ghodrati14viewpoint,
	title = {Is 2D Information Enough For Viewpoint Estimation?},
	author = {Ghodrati, Amir and Pedersoli, Marco and Tuytelaars, Tinne},
	year = {2014},
	booktitle = BMVC
}

@inproceedings{imagenet_cvpr09,
    AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
    TITLE = {ImageNet: A Large-Scale Hierarchical Image Database},
    BOOKTITLE = CVPR,
    YEAR = {2009},
}

@Article{Simonyan14c,
    author       = "Simonyan, K. and Zisserman, A.",
    title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    journal      = "CoRR",
    volume       = "abs/1409.1556",
    year         = {2014}
}

@article{jia2014caffe,
  Author = {Jia, Yangqing and Shelhamer, Evan and Donahue, Jeff and Karayev, Sergey and Long, Jonathan and Girshick, Ross and Guadarrama, Sergio and Darrell, Trevor},
  Journal = {arXiv preprint arXiv:1408.5093},
  Title = {Caffe: Convolutional Architecture for Fast Feature Embedding},
  Year = {2014}
}

@inproceedings{hoiem2012diagnosing,
	title={Diagnosing error in object detectors},
	author={Hoiem, Derek and Chodpathumwan, Yodsawalai and Dai, Qieyun},
	booktitle=ECCV,
	year={2012}
}

@INPROCEEDINGS{Bregler2000, 
author={Bregler, C. and Hertzmann, A. and Biermann, H.}, 
booktitle=CVPR, 
title={Recovering non-rigid 3D shape from image streams}, 
year={2000}
}

@INPROCEEDINGS{nrsfm_priors, 
author={Bartoli, A. and Gay-Bellile, V. and Castellani, U. and Peyras, J. and Olsen, S. and Sayd, P.}, 
booktitle=CVPR, 
title={Coarse-to-fine low-rank structure-from-motion}, 
year={2008},
}

@Article{Torresani2008NRSFM,
  Author         = {L. Torresani and A. Hertzmann and C. Bregler.},
  Title          = "Non-Rigid Structure-From-Motion: Estimating Shape and
                   Motion with Hierarchical Priors.",
  Journal        = PAMI,
  year           = {2008}
}

@InProceedings{varnrsfm2013,
author = {Ravi Garg and Anastasios Roussos and Lourdes Agapito},
title = {Dense Variational Reconstruction of Non-rigid Surfaces from Monocular Video},
booktitle = CVPR,
year = {2013},
}

@inproceedings{prasad2010finding,
  title={Finding nemo: Deformable object class modelling using curve matching},
  author={Prasad, Mukta and Fitzgibbon, Andrew and Zisserman, Andrew and Van Gool, Luc},
  booktitle=CVPR,
  year={2010}
}

@inproceedings{Zhu_ModelEvolution:2010,
  author = {Shengqi Zhu  and Li Zhang and Brandon Smith},
  booktitle = CVPR,
  title = {Model evolution: An incremental approach to non-rigid structure from motion.},
  year = {2010}
}

@inproceedings{HejratiR12,
  author    = {Mohsen Hejrati and Deva Ramanan},
  title     = {Analyzing 3D Objects in Cluttered Images},
  booktitle = NIPS,
  year      = {2012}
}

@INPROCEEDINGS{Brand2005, 
author={Brand, M.}, 
booktitle=CVPR, 
title={A direct method for 3D factorization of nonrigid motion observed in 2D}, 
year={2005}, 
}

@inproceedings{balloonshapes,
  author = {Vicente, Sara and de Agapito, Lourdes},
  booktitle = {3DV},
  title = {Balloon Shapes: Reconstructing and Deforming Objects with Volume from Images},
  year = {2013}
}

@article{esteban2004snake,
 author = {Esteban, Carlos Hern\'{a}ndez and Schmitt, Francis},
 title = {Silhouette and Stereo Fusion for 3D Object Modeling},
 journal = CVIU,
 year = {2004},
}

@inproceedings{twarog2012playing,
  title={Playing with Puffball: simple scale-invariant inflation for use in vision and graphics},
  author={Twarog, Nathaniel R and Tappen, Marshall F and Adelson, Edward H},
  booktitle={ACM Symposium on Applied Perception},
  year={2012},
}

@article{Barron2012B,
author = {Jonathan T Barron and Jitendra Malik},
title = {Color Constancy, Intrinsic Images, and Shape Estimation},
journal = ECCV,
year = {2012},
}

@InProceedings{Karsch2013,
author = {Kevin Karsch and Zicheng Liao and Jason Rock and Jonathan T. Barron and Derek Hoiem},
title = {Boundary Cues for 3D Object Shape Recovery},
BookTitle=CVPR,
year = {2013},
}

@InProceedings{bourdevECCV10,
	author       = {Lubomir Bourdev and Subhransu Maji and Thomas Brox and Jitendra Malik},
	title        = "Detecting People Using Mutually Consistent Poselet Activations",
	booktitle    = ECCV,
	year         = {2010}
}

@inproceedings{aspert2002mesh,
  title={Mesh: Measuring errors between surfaces using the hausdorff distance},
  author={Aspert, Nicolas and Santa-Cruz, Diego and Ebrahimi, Touradj},
  booktitle={ICME},
  year={2002}
}

@incollection{wu20143d,
  title={3D ShapeNets: A Deep Representation for Volumetric Shape Modeling},
  author={Wu, Zhirong and Song, Shuran and Khosla, Aditya and Yu, F and Zhang, L and Tang, Xiaoou and Xiao, Jianxiong},
  booktitle = CVPR,
  year = {2015},
}

@inproceedings{SavareseF07,
  author = {Savarese, Silvio and Li, Fei-Fei},
  booktitle = ICCV,
  title = {3D generic object categorization, localization and pose estimation.},
  year = {2007}
}

@inproceedings{fidler20123d,
  title={3D Object Detection and Viewpoint Estimation with a Deformable 3D Cuboid Model},
  author={Fidler, Sanja and Dickinson, Sven J and Urtasun, Raquel},
  booktitle=NIPS,
  year={2012}
}

@ARTICLE{laurentini1994hull, 
author={Laurentini, A.}, 
journal=PAMI, 
title={The Visual Hull Concept for Silhouette-based Image Understanding}, 
year={1994}, 
}

@incollection{yusuf2006snake,
year={2006},
booktitle={Multimedia Content Representation, Classification and Security},
title={A Surface Deformation Framework for 3D Shape Recovery},
author={Sahillioğlu, Yusuf and Yemez, Yücel},
}

@ARTICLE{cashman2013dolphins, 
author={Cashman, T.J. and Fitzgibbon, A.W.}, 
journal=PAMI,
title={What Shape Are Dolphins? Building 3D Morphable Models from 2D Images},
year={2013}, 
}

@inproceedings{chen20123d,
 author = {Chen, Yu and Kim, Tae-Kyun and Cipolla, Roberto},
 title = {Inferring 3D Shapes and Deformations from Single Views},
 booktitle = ECCV,
 year = {2010},
} 

@inproceedings{mcg2014,
  author = {Arbel\'{a}ez, P. and Pont-Tuset, J. and Barron, J. and Marques, F. and Malik, J.},
  title = {Multiscale Combinatorial Grouping},
  booktitle = CVPR,
  year = {2014}
}

@article{Kalogerakis:2012:ShapeSynthesis,
  Author    = {Evangelos Kalogerakis and Siddhartha Chaudhuri and Daphne Koller and Vladlen Koltun},
  Title     = {A {P}robabilistic {M}odel of {C}omponent-{B}ased {S}hape {S}ynthesis},
  Journal   = {ACM Transactions on Graphics},
  Year = {2012},
}

@article{saxena2009make3d,
  title={Make3d: Learning 3d scene structure from a single still image},
  author={Saxena, Ashutosh and Sun, Min and Ng, Andrew Y},
  journal={PAMI},
  year={2009}
}

@article{hoiem2005automatic,
  title={Automatic photo pop-up},
  author={Hoiem, Derek and Efros, Alexei A and Hebert, Martial},
  journal={ACM Transactions on Graphics (TOG)},
  year={2005}
}

@MASTERSTHESIS{HORNThesis1970,
  author = {B.K.P. Horn},
  title = {Shape from shading: A method for obtaining the shape of a smooth opaque object from one view},
  school = {Massachusetts Inst. of Technology},
  year = {1970},
  type = "{PhD} thesis",
}

@article{neocognitron,
  author = {Fukushima, Kunihiko},
  journal = {Biological Cybernetics},
  pages = {193--202},
  title = {{N}eocognitron: {A} Self-Organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position},
year = {1980}
}

@article{huang2015single,
  title={Single-view reconstruction via joint analysis of image and shape collections},
  author={Huang, Qixing and Wang, Hai and Koltun, Vladlen},
  journal={ACM Transactions on Graphics (TOG)},
  volume={34},
  year={2015},
  publisher={ACM}
}

@article{su2014estimating,
  title={Estimating image depth using shape collections},
  author={Su, Hao and Huang, Qixing and Mitra, Niloy J and Li, Yangyan and Guibas, Leonidas},
  journal={ACM Transactions on Graphics (TOG)},
  volume={33},
  year={2014},
  publisher={ACM}
}

@inproceedings{wang2015designing,
  title={Designing Deep Networks for Surface Normal Estimation},
  author={Wang, Xiaolong and Fouhey, David and Gupta, Abhinav},
  booktitle=CVPR,
  year={2015}
}

@inproceedings{eigen2015predicting,
  title={Predicting depth, surface normals and semantic labels with a common multi-scale convolutional architecture},
  author={Eigen, David and Fergus, Rob},
  booktitle=ICCV,
  year={2015}
}

@inproceedings{eigennips14,
  title={Depth Map Prediction from a Single Image using a Multi-Scale Deep Network},
  author={Eigen, David and Puhrsch, Christian and Fergus, Rob},
  booktitle=NIPS,
  year={2014}
}

@incollection{categoryShapesKar15,
author = {Abhishek Kar and 
Shubham Tulsiani and 
Jo{\~{a}}o Carreira and 
Jitendra Malik},
title = {Category-Specific Object 
Reconstruction from a Single Image},
booktitle = CVPR,
year = {2015},
}

@inproceedings{BharathCVPR2015,
  author       = {Bharath Hariharan and Pablo Arbel{\'{a}}ez and Ross Girshick and Jitendra Malik},
  title        = "Hypercolumns for Object Segmentation and Fine-grained Localization",
  booktitle    = CVPR,
  year         = "2015",
}

@inproceedings {Pepik_2015_CVPR_Workshops,
    title = {3D Object Class Detection in the Wild},
    booktitle= {Workshop on 3D from a Single Image (3DSI)  (in conjunction with CVPR{\textquoteright}15)},
    year = {2015},
    author = {Pepik, Bojan and Michael Stark and Peter Gehler and Tobias Ritschel and Schiele, Bernt}
}

@article{rothganger20063d,
  title={3d object modeling and recognition using local affine-invariant image descriptors and multi-view spatial constraints},
  author={Rothganger, Fred and Lazebnik, Svetlana and Schmid, Cordelia and Ponce, Jean},
  journal=IJCV,
  pages={231--259},
  year={2006},
  publisher={Springer}
}

@incollection{gordon2006and,
  title={What and where: 3D object recognition with accurate pose},
  author={Gordon, Iryna and Lowe, David G},
  booktitle={Toward category-level object recognition},
  pages={67--82},
  year={2006},
  publisher={Springer}
}

@incollection{savarese2008view,
  title={View synthesis for recognizing unseen poses of object classes},
  author={Savarese, Silvio and Fei-Fei, Li},
  booktitle=ECCV,
  year={2008},
  publisher={Springer}
}

@incollection{xiao2008structuring,
  title={Structuring visual words in 3D for arbitrary-view object localization},
  author={Xiao, Jianxiong and Chen, Jingni and Yeung, Dit-Yan and Quan, Long},
  booktitle=ECCV,
  year={2008},
  publisher={Springer}
}

@incollection{gu2010discriminative,
  title={Discriminative mixture-of-templates for viewpoint classification},
  author={Gu, Chunhui and Ren, Xiaofeng},
  booktitle=ECCV,
  year={2010},
  publisher={Springer}
}

@inproceedings{ozuysal2009pose,
  title={Pose estimation for category specific multiview object localization},
  author={Ozuysal, Mustafa and Lepetit, Vincent and Fua, Pascal},
  booktitle=CVPR,
  year={2009},
  organization={IEEE}
}

@article{sung2015data,
  title={Data-driven structural priors for shape completion},
  author={Sung, Minhyuk and Kim, Vladimir G and Angst, Roland and Guibas, Leonidas},
  journal={ACM Transactions on Graphics (TOG)},
  year={2015},
  publisher={ACM}
}

%% Amodal references %%
@incollection{amodalKarTCM15,
author = {Abhishek Kar and
Shubham Tulsiani and
Jo{\~{a}}o Carreira and
Jitendra Malik},
title = {Amodal Completion and
Size Constancy in Natural Scenes},
booktitle = ICCV,
year = {2015},
}

@book{palmer1999vision,
  title={Vision science: Photons to phenomenology},
  author={Palmer, Stephen E},
  year={1999},
  publisher={MIT press Cambridge, MA}
}

@book{Hoiem:book,
  title={Representations and techniques for 3D object recognition and scene interpretation},
  author={Hoiem, D. and Savarese, S.},
  year={2011},
  publisher={Morgan \& Claypool Publishers}
}

@article{burton45, 
author = {Harry Edwin Burton}, 
journal = {J. Opt. Soc. Am.}, 
title = {The Optics of Euclid},
year = {1945}
}

@article{hoiem2008putting,
  title={Putting objects in perspective},
  author={Hoiem, Derek and Efros, Alexei A and Hebert, Martial},
  journal=IJCV,
  year={2008}
}

@inproceedings{gupta2010blocks,
  title={Blocks world revisited: Image understanding using qualitative geometry and mechanics},
  author={Gupta, Abhinav and Efros, Alexei A and Hebert, Martial},
  booktitle=ECCV,
  year={2010}
}

@article{zia2013detailed,
  title={Detailed 3d representations for object recognition and modeling},
  author={Zia, M Zeeshan and Stark, Michael and Schiele, Bernt and Schindler, Konrad},
  journal=TPAMI,
  year={2013}
}

@inproceedings{lalonde2007photo,
  title={Photo clip art},
  author={Lalonde, Jean-Fran{\c{c}}ois and Hoiem, Derek and Efros, Alexei A and Rother, Carsten and Winn, John and Criminisi, Antonio},
  booktitle={ACM Transactions on Graphics (TOG)},
  year={2007}
}

@inproceedings{russell2009building,
  title={Building a database of 3d scenes from user annotations},
  author={Russell, Bryan C and Torralba, Antonio},
  booktitle= CVPR,
  year={2009}
}

@Book{Hartley2004,
  title={Multiple view geometry in computer vision},
  author={Hartley, Richard and Zisserman, Andrew},
  year={2003},
  publisher={Cambridge university press}
}

@book{shipley2001fragments,
  title={From fragments to objects: Segmentation and grouping in vision},
  author={Shipley, Thomas F and Kellman, Philip J},
  volume={130},
  year={2001},
  publisher={Elsevier}
}

@book{kanizsa1979organization,
  title={Organization in vision: Essays on Gestalt perception},
  author={Kanizsa, Gaetano},
  year={1979},
  publisher={Praeger Publishers}
}

@article{breckon2005amodal,
  title={Amodal volume completion: 3D visual completion},
  author={Breckon, Toby P and Fisher, Robert B},
  journal={Computer Vision and Image Understanding},
  year={2005}
}

@inproceedings{pascal3d,
  author = {Xiang, Yu and Mottaghi, Roozbeh and Savarese, Silvio},
  title = {Beyond PASCAL: A Benchmark for 3D Object Detection in the Wild},
  booktitle=WACV,
  year={2014}
}

@Article{simonyan2014very,
    author       = "Simonyan, K. and Zisserman, A.",
    title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    journal      = "CoRR",
    volume       = "abs/1409.1556",
    year         = "2014"
}

@article{neocognitron,
  author = {Fukushima, Kunihiko},
  journal = {Biological Cybernetics},
  title = {{N}eocognitron: {A} Self-Organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position},
  year = {1980}
}


@inproceedings{ghiasi2014parsing,
  title={Parsing occluded people},
  author={Ghiasi, Golnaz and Yang, Yi and Ramanan, Deva and Fowlkes, Charless C},
  booktitle=CVPR,
  year={2014}
}

@InProceedings{xiang_cvpr15,
  author       = {Yu Xiang and Wongun Choi and Yuanqing Lin and Silvio Savarese},
  title        = {Data-Driven 3D Voxel Patterns for Object Category Recognition},
  booktitle    = CVPR,
  year         = {2015}
}

@inproceedings{zia2014cars,
  title={Are cars just 3D boxes? Jointly estimating the 3D shape of multiple objects},
  author={Zia, Muhammad Zeeshan and Stark, Michael and Schindler, Konrad},
  booktitle=CVPR,
  year={2014}
}

@article{zia2014towards,
  title={Towards Scene Understanding with Detailed 3D Object Representations},
  author={Zia, M Zeeshan and Stark, Michael and Schindler, Konrad},
  journal = IJCV,
  year={2014}
}

@ARTICLE{felzens_latent_pami10,
  author = {Pedro F. Felzenszwalb and Ross B. Girshick and David McAllester and
	Deva Ramanan},
  title = {Object Detection with Discriminatively Trained Part-Based Models},
  journal = PAMI,
  year = {2010}
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle=NIPS,
  year={2012}
}

@inproceedings{girshick2013rich,
author = {Ross Girshick and
Jeff Donahue and
Trevor Darrell and
Jitendra Malik},
title = {Rich feature hierarchies for accurate
object detection and semantic segmentation},
booktitle = CVPR,
year = {2014}
} 


@article{ittelson1951size,
  title={Size as a cue to distance: Static localization},
  author={Ittelson, William H},
  journal={The American Journal of Psychology},
  year={1951}
}

@article{baird1963retinal,
  title={Retinal and assumed size cues as determinants of size and distance perception.},
  author={Baird, JC},
  journal={Journal of Experimental Psychology},
  year={1963}
}

@article{epstein1963influence,
  title={The influence of assumed size on apparent distance},
  author={Epstein, William},
  journal={The American Journal of Psychology},
  year={1963}
}

@article{konkle2011canonical,
  title={Canonical visual size for real-world objects.},
  author={Konkle, Talia and Oliva, Aude},
  journal={Journal of Experimental Psychology: human perception and performance},
  year={2011}
}

@inproceedings{imagenet_cvpr09,
        AUTHOR = {Deng, J. and Dong, W. and Socher, R. and Li, L.-J. and Li, K. and Fei-Fei, L.},
        TITLE = {ImageNet: A Large-Scale Hierarchical Image Database},
        BOOKTITLE = CVPR,
        YEAR = {2009}
        }
        
@article{zhang2000flexible,
  title={A flexible new technique for camera calibration},
  author={Zhang, Zhengyou},
  journal=TPAMI,
  year={2000}
}

@misc{pascal-voc-2012,
	author = "Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.",
	title = "The {PASCAL} {V}isual {O}bject {C}lasses {C}hallenge 2012 {(VOC2012)} {R}esults",
	howpublished = "http://www.pascal-network.org/challenges/VOC/voc2012/workshop/index.html"
}

@incollection{triggs2000bundle,
  title={Bundle adjustment -- a modern synthesis},
  author={Triggs, Bill and McLauchlan, Philip F and Hartley, Richard I and Fitzgibbon, Andrew W},
  booktitle={Vision algorithms: theory and practice},
  year={2000},
  publisher={Springer}
}

@inproceedings{zhou2014learning,
  title={Learning deep features for scene recognition using places database},
  author={Zhou, Bolei and Lapedriza, Agata and Xiao, Jianxiong and Torralba, Antonio and Oliva, Aude},
  booktitle=NIPS,
  year={2014}
}

@article{wang1991camera,
  title={Camera calibration by vanishing lines for 3-D computer vision},
  author={Wang, Ling-Ling and Tsai, Wen-Hsiang},
  journal=TPAMI,
  year={1991}
}

@article{caprile1990using,
  title={Using vanishing points for camera calibration},
  author={Caprile, Bruno and Torre, Vincent},
  journal=IJCV,
  year={1990}
}

%% LSM References %%

@inproceedings{spatialtrans_nips2015,
title={Spatial Transformer Networks},
author={Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and Kavukcuoglu, Koray},
booktitle={Neural Information Processing Systems (NIPS)},
year = {2015}
}

@inproceedings{kanade1995development,
  title={Development of a video-rate stereo machine},
  author={Kanade, T and Kano, H and Kimura, S and Yoshida, A and Oda, K},
  booktitle={International Conference on Intelligent Robots and Systems (IROS)},
  year={1995}
}

@inproceedings{seitz2006comparison,
  title={A comparison and evaluation of multi-view stereo reconstruction algorithms},
  author={Seitz, Steven M and Curless, Brian and Diebel, James and Scharstein, Daniel and Szeliski, Richard},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2006}
}

@article{becker1992self,
  title={Self-organizing neural network that discovers surfaces in random-dot stereograms},
  author={Becker, Suzanna and Hinton, Geoffrey E},
  journal={Nature},
  year={1992}
}

@inproceedings{kendall2017end,
  title={End-to-End Learning of Geometry and Context for Deep Stereo Regression},
  author={Kendall, Alex and Martirosyan, Hayk and Dasgupta, Saumitro and Henry, Peter and Kennedy, Ryan and Bachrach, Abraham and Bry, Adam},
  booktitle = {International Conference on Computer Vision (ICCV)},
  year={2017}
}

@inproceedings{choy20163d,
  title={3d-r2n2: A unified approach for single and multi-view 3d object reconstruction},
  author={Choy, Christopher B and Xu, Danfei and Gwak, JunYoung and Chen, Kevin and Savarese, Silvio},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2016}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  year={1997}
}


@incollection{marr1976cooperative,
  title={Cooperative computation of stereo disparity},
  author={Marr, David and Poggio, Tomaso},
  booktitle={From the Retina to the Neocortex},
  pages={239-243},
  year={1976}
}

@article{scharstein2002taxonomy,
  title={A taxonomy and evaluation of dense two-frame stereo correspondence algorithms},
  author={Scharstein, Daniel and Szeliski, Richard},
  journal={International Journal of Computer Vision (IJCV)},
  volume={47},
  number={1-3},
  pages={7--42},
  year={2002}
}

@article{kutulakos2000theory,
  title={A theory of shape by space carving},
  author={Kutulakos, Kiriakos N and Seitz, Steven M},
  journal={International Journal of Computer Vision (IJCV)},
  volume={38},
  number={3},
  pages={199--218},
  year={2000}
}

@inproceedings{vogiatzis2005multi,
  title={Multi-view stereo via volumetric graph-cuts},
  author={Vogiatzis, George and Torr, Philip HS and Cipolla, Roberto},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2005}
}

@inproceedings{sinha2007multi,
  title={Multi-view stereo via graph cuts on the dual of an adaptive tetrahedral mesh},
  author={Sinha, Sudipta N and Mordohai, Philippos and Pollefeys, Marc},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2007}
}

@article{cremers2011multiview,
  title={Multiview stereo and silhouette consistency via convex functionals over convex domains},
  author={Cremers, Daniel and Kolev, Kalin},
  journal={Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  volume={33},
  number={6},
  pages={1161--1174},
  year={2011}
}

@inproceedings{gargallo2007minimizing,
  title={Minimizing the reprojection error in surface reconstruction from images},
  author={Gargallo, Pau and Prados, Emmanuel and Sturm, Peter},
  booktitle={International Conference on Computer Vision (ICCV)},
  pages={1--8},
  year={2007}
}

@inproceedings{pollard2007change,
  title={Change detection in a 3-d world},
  author={Pollard, Thomas and Mundy, Joseph L},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2007}
}

@article{liu2014statistical,
  title={Statistical inverse ray tracing for image-based 3d modeling},
  author={Liu, Shubao and Cooper, David B},
  journal={Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  volume={36},
  number={10},
  pages={2074--2088},
  year={2014}
}

@inproceedings{ulusoy2015towards,
  title={Towards probabilistic volumetric reconstruction using ray potentials},
  author={Ulusoy, Ali Osman and Geiger, Andreas and Black, Michael J},
  booktitle={International Conference on 3D Vision (3DV)},
  year={2015}
}

@inproceedings{collins1996space,
  title={A space-sweep approach to true multi-image matching},
  author={Collins, Robert T},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={1996}
}

@inproceedings{yang2003real,
  title={Real-Time Consensus-Based Scene Reconstruction Using Commodity Graphics Hardware},
  author={Yang, Ruigang and Welch, Greg and Bishop, Gary},
  booktitle={Computer Graphics Forum},
  year={2003}
}

@article{pollefeys2004visual,
  title={Visual modeling with a hand-held camera},
  author={Pollefeys, Marc and Van Gool, Luc and Vergauwen, Maarten and Verbiest, Frank and Cornelis, Kurt and Tops, Jan and Koch, Reinhard},
  journal={International Journal of Computer Vision (IJCV)},
  volume={59},
  number={3},
  pages={207--232},
  year={2004}
}

@article{pollefeys2008detailed,
  title={Detailed real-time urban 3d reconstruction from video},
  author={Pollefeys, Marc and Nist{\'e}r, David and Frahm, J-M and Akbarzadeh, Amir and Mordohai, Philippos and Clipp, Brian and Engels, Chris and Gallup, David and Kim, S-J and Merrell, Paul and Salmi, C. and Sinha, S. and Talton, B. and Wang, L. and Yang, Q. and Stewenius, H. and Yang, R. and Welch, G. and Towles, H.},
  journal={International Journal of Computer Vision (IJCV)},
  volume={78},
  number={2},
  pages={143--167},
  year={2008}
}

@inproceedings{merrell2007real,
  title={Real-time visibility-based fusion of depth maps},
  author={Merrell, Paul and Akbarzadeh, Amir and Wang, Liang and Mordohai, Philippos and Frahm, Jan-Michael and Yang, Ruigang and Nist{\'e}r, David and Pollefeys, Marc},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2007}
}

@inproceedings{curless1996volumetric,
  title={A volumetric method for building complex models from range images},
  author={Curless, Brian and Levoy, Marc},
  booktitle={Conference on Computer Graphics and Interactive Techniques},
  year={1996}
}

@inproceedings{lempitsky2007global,
  title={Global optimization for shape fitting},
  author={Lempitsky, Victor and Boykov, Yuri},
  booktitle={Conference on Computer Vision and Pattern Recognition, (CVPR)},
  year={2007}
}

@inproceedings{zach2007globally,
  title={A globally optimal algorithm for robust TV-L 1 range image integration},
  author={Zach, Christopher and Pock, Thomas and Bischof, Horst},
  booktitle={International Conference on Computer Vision, (ICCV)},
  year={2007}
}

@inproceedings{labatut2007efficient,
  title={Efficient multi-view reconstruction of large-scale scenes using interest points, delaunay triangulation and graph cuts},
  author={Labatut, Patrick and Pons, Jean-Philippe and Keriven, Renaud},
  booktitle={International Conference on Computer Vision, (ICCV)},
  year={2007}
}

@article{lhuillier2005quasi,
  title={A quasi-dense approach to surface reconstruction from uncalibrated images},
  author={Lhuillier, Maxime and Quan, Long},
  journal={Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  year={2005}
}

@inproceedings{blanz1999morphable,
  title={A morphable model for the synthesis of 3D faces},
  author={Blanz, Volker and Vetter, Thomas},
  booktitle={Conference on Computer Graphics and Interactive Techniques},
  year={1999}
}

@inproceedings{dame2013dense,
  title={Dense reconstruction using 3D object shape priors},
  author={Dame, Amaury and Prisacariu, Victor A and Ren, Carl Y and Reid, Ian},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2013}
}

@inproceedings{yingze2013dense,
  title={Dense object reconstruction with semantic priors},
  author={Yingze Bao, Sid and Chandraker, Manmohan and Lin, Yuanqing and Savarese, Silvio},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2013}
}

@inproceedings{hane2014class,
  title={Class specific 3d object shape priors using surface normals},
  author={H{\"a}ne, Christian and Savinov, Nikolay and Pollefeys, Marc},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2014}
}

@inproceedings{hane2013joint,
  title={Joint 3D scene reconstruction and class segmentation},
  author={H{\"a}ne, Christian and Zach, Christopher and Cohen, Andrea and Angst, Roland and Pollefeys, Marc},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2013}
}

@article{haene2016dense,
  title={Dense Semantic 3D Reconstruction},
  author={Haene, Christian and Zach, Christopher and Cohen, Andrea and Pollefeys, Marc},
  journal={Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  year={2016}
}

@inproceedings{kar2015category,
  title={Category-specific object reconstruction from a single image},
  author={Kar, Abhishek and Tulsiani, Shubham and Carreira, Joao and Malik, Jitendra},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2015}
}

@inproceedings{saxena2007depth,
  title={Depth Estimation Using Monocular and Stereo Cues.},
  author={Saxena, Ashutosh and Schulte, Jamie and Ng, Andrew Y},
  booktitle={Neural Information Processing Systems (NIPS)},
  year={2005}
}

@inproceedings{ladicky2014pulling,
  title={Pulling things out of perspective},
  author={Ladicky, Lubor and Shi, Jianbo and Pollefeys, Marc},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2014}
}

@inproceedings{garg2016unsupervised,
  title={Unsupervised CNN for single view depth estimation: Geometry to the rescue},
  author={Garg, Ravi and Carneiro, Gustavo and Reid, Ian},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2016}
}

@inproceedings{girdhar2016learning,
  title={Learning a predictable and generative vector representation for objects},
  author={Girdhar, Rohit and Fouhey, David F and Rodriguez, Mikel and Gupta, Abhinav},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2016},
}

@inproceedings{sinha2016deep,
  title={Deep learning 3D shape surfaces using geometry images},
  author={Sinha, Ayan and Bai, Jing and Ramani, Karthik},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2016}
}

@inproceedings{fan2016point,
  title={A Point Set Generation Network for 3D Object Reconstruction from a Single Image},
  author={Fan, Haoqiang and Su, Hao and Guibas, Leonidas},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}

@inproceedings{yan2016perspective,
  title={Perspective transformer nets: Learning single-view 3d object reconstruction without 3d supervision},
  author={Yan, Xinchen and Yang, Jimei and Yumer, Ersin and Guo, Yijie and Lee, Honglak},
  booktitle={Neural Information Processing Systems (NIPS)},
  year={2016}
}

@inproceedings{tulsiani2017multi,
  title={Multi-view supervision for single-view reconstruction via differentiable ray consistency},
  author={Tulsiani, Shubham and Zhou, Tinghui and Efros, Alexei A and Malik, Jitendra},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2017}
}

@inproceedings{rezende2016unsupervised,
  title={Unsupervised learning of 3d structure from images},
  author={Rezende, Danilo Jimenez and Eslami, SM Ali and Mohamed, Shakir and Battaglia, Peter and Jaderberg, Max and Heess, Nicolas},
  booktitle={Neural Information Processing Systems (NIPS)},
  year={2016}
}

@inproceedings{tatarchenko2016multi,
  title={Multi-view 3d models from single images with a convolutional network},
  author={Tatarchenko, Maxim and Dosovitskiy, Alexey and Brox, Thomas},
  booktitle={European Conference on Computer Vision (ECCV)},
  year={2016}
}

@inproceedings{unet_2015,
  author       = "O. Ronneberger and P.Fischer and T. Brox",
  title        = "U-Net: Convolutional Networks for Biomedical Image Segmentation",
  booktitle    = "Medical Image Computing and Computer-Assisted Intervention (MICCAI)",
  year         = "2015"
}

@inproceedings{chogru_2014,
  title={Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation},
  author={Cho, Kyunghyun and van Merrienboer, Bart and Gulcehre, Caglar and Bougares, Fethi and Schwenk, Holger and Bengio, Yoshua},
  booktitle={Conference on Empirical Methods in Natural Language Processing (EMNLP 2014)},
  year={2014}
}

@inproceedings{debevec2012light,
  title={The light stages and their applications to photoreal digital actors},
  author={Debevec, Paul},
  booktitle={{SIGGRAPH} {Asia}},
    year = {2012},
}

@inproceedings{hane2014real,
  title={Real-time direct dense matching on fisheye images using plane-sweeping stereo},
  author={H{\"a}ne, Christian and Heng, Lionel and Lee, Gim Hee and Sizov, Alexey and Pollefeys, Marc},
  booktitle={International Conference on 3D Vision (3DV)},
  year={2014}
}

@inproceedings{flynn2016deepstereo,
  title={DeepStereo: Learning to predict new views from the world's imagery},
  author={Flynn, John and Neulander, Ivan and Philbin, James and Snavely, Noah},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016}
}

@article{shapenet2015,
  title={ShapeNet: An Information-Rich 3D Model Repository},
  author={Chang, Angel X. and Funkhouser, Thomas and Guibas, Leonidas and Hanrahan, Pat and Huang, Qixing and Li, Zimo and Savarese, Silvio and Savva, Manolis and Song, Shuran and Su, Hao and Xiao, Jianxiong and Yi, Li and Yu, Fisher},
  journal={arXiv preprint arXiv:1512.03012},
  year= {2015}
}

@article{dosovitskiy2017learning,
  title={Learning to generate chairs, tables and cars with convolutional networks},
  author={Dosovitskiy, Alexey and Springenberg, Jost Tobias and Tatarchenko, Maxim and Brox, Thomas},
  journal={Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  year={2017}
}

@inproceedings{riegler2017octnetfusion,
  title={OctNetFusion: Learning Depth Fusion from Data},
  author={Riegler, Gernot and Ulusoy, Ali Osman and Bischof, Horst and Geiger, Andreas},
  booktitle={International Conference on 3D Vision (3DV)},
  year={2017}
}

@inproceedings{hane2017hierarchical,
  title={Hierarchical Surface Prediction for 3D Object Reconstruction},
  author={H{\"a}ne, Christian and Tulsiani, Shubham and Malik, Jitendra},
  booktitle={International Conference on 3D Vision (3DV)},
  year={2017}
}

@article{Ba2016LayerN,
  title={Layer Normalization},
  author={Jimmy Ba and Jamie Ryan Kiros and Geoffrey E. Hinton},
  journal={CoRR},
  year={2016},
  volume={abs/1607.06450}
}

@article{zbontar2016stereo,
  title={Stereo matching by training a convolutional neural network to compare image patches},
  author={Zbontar, Jure and LeCun, Yann},
  journal={Journal of Machine Learning Research (JMLR)},
  volume={17},
  number={1-32},
  pages={2},
  year={2016}
}

@InProceedings{Han_2015_CVPR,
author = {Han, Xufeng and Leung, Thomas and Jia, Yangqing and Sukthankar, Rahul and Berg, Alexander C.},
title = {MatchNet: Unifying Feature and Metric Learning for Patch-Based Matching},
booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
year = {2015}
} 

@inproceedings{mayer2016large,
  title={A large dataset to train convolutional networks for disparity, optical flow, and scene flow estimation},
  author={Mayer, Nikolaus and Ilg, Eddy and Hausser, Philip and Fischer, Philipp and Cremers, Daniel and Dosovitskiy, Alexey and Brox, Thomas},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016}
}

@inproceedings{zhou2017unsupervised,
    author = {Zhou, Tinghui and Brown, Matthew and Snavely, Noah and Lowe, David G.},
    title = {Unsupervised Learning of Depth and Ego-Motion from Video},
    booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
    year = {2017}
}

@inproceedings{hartmann2017multi,
  author    = {Wilfried Hartmann and
               Silvano Galliani and
               Michal Havlena and
               Konrad Schindler and
               Luc Van Gool},
  title     = {Learned Multi-patch Similarity},
  booktitle={International Conference on Computer Vision, (ICCV)},
  year      = {2017}
}

@article{FuruPMVS2010,
  author    = "Yasutaka Furukawa and Jean Ponce",
  title     = "Accurate, Dense, and Robust Multi-View Stereopsis",
  journal={Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},
  year = "2010"
}

@inproceedings{savinov2016semantic,
  title={Semantic 3d reconstruction with continuous regularization and ray potentials using a visibility consistency constraint},
  author={Savinov, Nikolay and H\"ane, Christian and Ladicky, Lubor and Pollefeys, Marc},
  booktitle={Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016}
}

@article{pamishapeTulsianiKCM15,
author = {Shubham Tulsiani and
Abhishek Kar and
Jo{\~{a}}o Carreira and
Jitendra Malik},
title = {Learning Category-Specific Deformable 3D
Models for Object Reconstruction},
journal=TPAMI
year = {2017},
}

%% Additional refs
@article{TomasiKanade92,
 author = {Tomasi, Carlo and Kanade, Takeo},
 title = {Shape and Motion from Image Streams Under Orthography: A Factorization Method},
 journal = IJCV,
 issue_date = {Nov. 1992},
 volume = {9},
 number = {2},
 year = {1992},
 issn = {0920-5691},
 pages = {137--154},
 numpages = {18},
 url = {http://dx.doi.org/10.1007/BF00129684},
 doi = {10.1007/BF00129684},
 acmid = {144403},
 publisher = {Kluwer Academic Publishers},
 address = {Hingham, MA, USA},
}

@misc{louis1960methods,
  title={Methods and apparatus for correlating corresponding points in two images},
  author={Louis, H.G.},
  url={http://www.google.com.pg/patents/US2964642},
  year={1960},
  month=dec # "~13",
  publisher={Google Patents},
  note={US Patent 2,964,642}
}

@article{longuet1981computer,
  title={A computer algorithm for reconstructing a scene from two projections},
  author={Longuet-Higgins, H Christopher},
  journal={Nature},
  volume={293},
  number={5828},
  pages={133--135},
  year={1981},
  publisher={Springer}
}

@article{17kruppa1913,
    author = {Kruppa, E.},
    citeulike-article-id = {7923374},
    journal = {Sitzungsberichte der Mathematisch Naturwissenschaftlichen Kaiserlichen Akademie der Wissenschaften},
    keywords = {adjustment, book-chapter, bundle},
    pages = {1939--1948},
    posted-at = {2010-09-29 12:11:55},
    priority = {0},
    title = {{Zur Ermittlung eines Objektes aus zwei Perspektiven mit innerer Orientierung}},
    volume = {122},
    year = {1913}
}

@article{agarwal2011building,
  title={Building rome in a day},
  author={Agarwal, Sameer and Furukawa, Yasutaka and Snavely, Noah and Simon, Ian and Curless, Brian and Seitz, Steven M and Szeliski, Richard},
  journal={Communications of the ACM},
  volume={54},
  number={10},
  pages={105--112},
  year={2011},
  publisher={ACM}
}

@article{furukawa2015multi,
  title={Multi-view stereo: A tutorial},
  author={Furukawa, Yasutaka and Hern{\'a}ndez, Carlos and others},
  journal={Foundations and Trends{\textregistered} in Computer Graphics and Vision},
  volume={9},
  number={1-2},
  pages={1--148},
  year={2015},
  publisher={Now Publishers, Inc.}
}

@inproceedings{kushal2012photo,
  title={Photo tours},
  author={Kushal, Avanish and Self, Ben and Furukawa, Yasutaka and Gallup, David and Hernandez, Carlos and Curless, Brian and Seitz, Steven M},
  booktitle={3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), 2012 Second International Conference on},
  pages={57--64},
  year={2012},
  organization={IEEE}
}

@inproceedings{thies2016face,
  author = {Thies, J. and Zollh{\"o}fer, M. and Stamminger, M. and Theobalt, C. and Nie{\ss}ner, M.},
  title = {Face2Face: Real-time Face Capture and Reenactment of RGB Videos},
  booktitle = CVPR,
  year = {2016}
}

@incollection{lsmKarHM2017,
  author = {Abhishek Kar and
  Christian H\"ane and
  Jitendra Malik},
  title = {Learning a Multi-View Stereo Machine},
  booktitle = NIPS,
  year = {2017},
  }

  @inProceedings{abstractionTulsiani17,
  title={Learning Shape Abstractions by Assembling Volumetric Primitives},
  author = {Shubham Tulsiani
  and Hao Su
  and Leonidas J. Guibas
  and Alexei A. Efros
  and Jitendra Malik},
  booktitle={Computer Vision and Pattern Regognition (CVPR)},
  year={2017}
}

@article{finn2016end,
  author  = {S. Levine and C. Finn and T. Darrell and P. Abbeel},
  title   = {End-to-End Training of Deep Visuomotor Policies},
  journal = {Journal of Machine Learning Research (JMLR)},
  year    = {2016},
}


@incollection{mnih2013atari,
  title = {Playing Atari With Deep Reinforcement Learning},
  author = {Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
  booktitle = {NIPS Deep Learning Workshop},
  year = {2013}
}

@MISC{Schaal99isimitation,
    author = {Stefan Schaal},
    title = {Is imitation learning the route to humanoid robots?},
    year = {1999}
}

@inproceedings{laroche2019spibb,
  title={Safe Policy Improvement with Baseline Bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Des Combes, Remi Tachet},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2019}
}

@article{mahmood2015emphatic,
  title={Emphatic temporal-difference learning},
  author={Mahmood, A Rupam and Yu, Huizhen and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1507.01569},
  year={2015}
}

@INPROCEEDINGS{antos07value, 
author={Andr\"as {Antos} and Csaa {Szepesvari} and Remi {Munos}}, 
booktitle={2007 IEEE International Symposium on Approximate Dynamic Programming and Reinforcement Learning}, 
title={Value-Iteration Based Fitted Policy Iteration: Learning with a Single Trajectory}, 
year={2007}, 
volume={}, 
number={}, 
pages={330-337}, 
keywords={continuous systems;iterative methods;learning (artificial intelligence);Markov processes;policy iteration;single trajectory;batch reinforcement learning;continuous space;discounted-reward Markovian decision problem;action-value function;approximate value iteration;Learning;Training data;Algorithm design and analysis;Dynamic programming;Automation;Polynomials;State-space methods;Control systems;Interleaved codes;Extraterrestrial measurements}, 
doi={10.1109/ADPRL.2007.368207}, 
ISSN={2325-1824}, 
month={April},}


@inproceedings{impala2018,
  title={IMPALA: Scalable Distributed Deep-RL with Importance Weighted Actor-Learner Architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  booktitle={Proceedings of the International Conference on Machine Learning (ICML)},
  year={2018}
}

@InProceedings{kalashnikov18qtopt,
  title = 	 {Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  author = 	 {Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and Levine, Sergey},
  booktitle = 	 {Proceedings of The 2nd Conference on Robot Learning},
  pages = 	 {651--673},
  year = 	 {2018},
  editor = 	 {},
  volume = 	 {87},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v87/kalashnikov18a/kalashnikov18a.pdf},
  url = 	 {},
  abstract = 	 {In this paper, we study the problem of learning vision-based dynamic manipulation skills using a scalable reinforcement learning approach. We study this problem in the context of grasping, a longstanding challenge in robotic manipulation. In contrast to static learning behaviors that choose a grasp point and then execute the desired grasp, our method enables closed-loop vision-based control, whereby the robot continuously updates its grasp strategy based on the most recent observations to optimize long-horizon grasp success. To that end, we introduce QT-Opt, a scalable self-supervised vision-based reinforcement learning framework that can leverage over 580k real-world grasp attempts to train a deep neural network Q-function with over 1.2M parameters to perform closed-loop, real-world grasping that generalizes to 96% grasp success on unseen objects. Aside from attaining a very high success rate, our method exhibits behaviors that are quite distinct from more standard grasping systems: using only RGB vision-based perception from an over-the-shoulder camera, our method automatically learns regrasping strategies, probes objects to find the most effective grasps, learns to reposition objects and perform other non-prehensile pre-grasp manipulations, and responds dynamically to disturbances and perturbations. }
}

@article{lillicrap2015ddpg,
  title={Continuous control with deep reinforcement learning},
  author={Timothy P. Lillicrap and Jonathan J. Hunt and Alexander Pritzel and Nicolas Heess and Tom Erez and Yuval Tassa and David Silver and Daan Wierstra},
  journal={CoRR},
  year={2015},
  volume={abs/1509.02971}
}

@incollection{anots08fitted,
title = {Fitted Q-iteration in continuous action-space MDPs},
author = {Andr\'{a}s Antos and Csaba Szepesv\'{a}ri and R\'{e}mi Munos},
booktitle = {Advances in Neural Information Processing Systems 20},
editor = {},
pages = {9--16},
year = {2008},
publisher = {Curran Associates, Inc.},
url = {}
}


@article{Schaul2016PrioritizedER,
  title={Prioritized Experience Replay},
  author={Tom Schaul and John Quan and Ioannis Antonoglou and David Silver},
  journal={CoRR},
  year={2016},
  volume={abs/1511.05952}
}

@article{gretton2012kernel,
 author = {Gretton, Arthur and Borgwardt, Karsten M. and Rasch, Malte J. and Sch\"{o}lkopf, Bernhard and Smola, Alexander},
 title = {A Kernel Two-sample Test},
 journal = {J. Mach. Learn. Res.},
 issue_date = {3/1/2012},
 volume = {13},
 month = mar,
 year = {2012},
 issn = {1532-4435},
 pages = {723--773},
 numpages = {51},
 url = {http://dl.acm.org/citation.cfm?id=2188385.2188410},
 acmid = {2188410},
 publisher = {JMLR.org},
 keywords = {hypothesis testing, integral probability metric, kernel methods, schema matching, two-sample test, uniform convergence bounds},
} 

@inproceedings{goodfellow2015advexamples,
title	= {Explaining and Harnessing Adversarial Examples},
author	= {Ian Goodfellow and Jonathon Shlens and Christian Szegedy},
year	= {2015},
URL	= {http://arxiv.org/abs/1412.6572},
booktitle	= {International Conference on Learning Representations}
}

@inproceedings{bennett2007netflix,
  title={The netflix prize},
  author={Bennett, James and Lanning, Stan and others},
  year={2007}
}

@inproceedings{DBLP:conf/iclr/GaoXLYLD18,
  author    = {Yang Gao and
               Huazhe Xu and
               Ji Lin and
               Fisher Yu and
               Sergey Levine and
               Trevor Darrell},
  title     = {Reinforcement Learning from Imperfect Demonstrations},
  booktitle = {{ICLR} (Workshop)},
  publisher = {OpenReview.net},
  year      = {2018}
}


@article{yu2018bdd,
  author    = {Fisher Yu and
               Wenqi Xian and
               Yingying Chen and
               Fangchen Liu and
               Mike Liao and
               Vashisht Madhavan and
               Trevor Darrell},
  title     = {{BDD100K:} {A} Diverse Driving Video Database with Scalable Annotation
               Tooling},
  journal   = {CoRR},
  volume    = {abs/1805.04687},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.04687},
  archivePrefix = {arXiv},
  eprint    = {1805.04687},
  timestamp = {Mon, 13 Aug 2018 16:47:46 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1805-04687},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{devlin2018bert,
  title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{imagenet_cvpr09,
        AUTHOR = {Deng, Jia and Dong, Wei and Socher, Richard S. and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
        TITLE = {{ImageNet: A Large-Scale Hierarchical Image Database}},
        BOOKTITLE = {CVPR09},
        YEAR = {2009},
}

@article{he2016resnet,
  title={Deep Residual Learning for Image Recognition},
  author={Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  journal={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2016},
  pages={770-778}
}

@article{levine2018rlasinference,
  author    = {Sergey Levine},
  title     = {Reinforcement Learning and Control as Probabilistic Inference: Tutorial
               and Review},
  journal   = {CoRR},
  volume    = {abs/1805.00909},
  year      = {2018},
  url       = {http://arxiv.org/abs/1805.00909},
  archivePrefix = {arXiv},
  eprint    = {1805.00909},
  timestamp = {Mon, 13 Aug 2018 16:47:19 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1805-00909},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
grau-moya2018soft,
title={Soft Q-Learning with Mutual-Information Regularization},
author={Jordi Grau-Moya and Felix Leibfried and Peter Vrancx},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HyEtjoCqFX},
}

@article{bruno2015approximate,
  author  = {Bruno Scherrer and Mohammad Ghavamzadeh and Victor Gabillon and Boris Lesner and Matthieu Geist},
  title   = {Approximate Modified Policy Iteration and its Application to the Game of Tetris},
  journal = {Journal of Machine Learning Research},
  year    = {2015},
  volume  = {16},
  pages   = {1629-1676},
  url     = {http://jmlr.org/papers/v16/scherrer15a.html}
}


@book{suttonrlbook,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  edition = {Second}
}

@InProceedings{fujimoto18addressing,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1587--1596},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {},
  month = 	 {},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/fujimoto18a/fujimoto18a.pdf},
  url = 	 {},
  abstract = 	 {In value-based reinforcement learning methods such as deep Q-learning, function approximation errors are known to lead to overestimated value estimates and suboptimal policies. We show that this problem persists in an actor-critic setting and propose novel mechanisms to minimize its effects on both the actor and the critic. Our algorithm builds on Double Q-learning, by taking the minimum value between a pair of critics to limit overestimation. We draw the connection between target networks and overestimation bias, and suggest delaying policy updates to reduce per-update error and further improve performance. We evaluate our method on the suite of OpenAI gym tasks, outperforming the state of the art in every environment tested.}
}

@article{burda2018rnd,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@article{stadie2015incentivizing,
  title={Incentivizing exploration in reinforcement learning with deep predictive models},
  author={Stadie, Bradly C and Levine, Sergey and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1507.00814},
  year={2015}
}

@inproceedings{houthooft2016vime,
  title={Vime: Variational information maximizing exploration},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1109--1117},
  year={2016}
}

@inproceedings{tang2017exploration,
  title={\# Exploration: A study of count-based exploration for deep reinforcement learning},
  author={Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, OpenAI Xi and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
  booktitle={Advances in neural information processing systems},
  pages={2753--2762},
  year={2017}
}

@inproceedings{fu2017ex2,
  title={Ex2: Exploration with exemplar models for deep reinforcement learning},
  author={Fu, Justin and Co-Reyes, John and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2577--2587},
  year={2017}
}

@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1471--1479},
  year={2016}
}

@inproceedings{precup2001offpol,
author = {Precup, Doina and Sutton, Richard S. and Dasgupta, Sanjoy},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Off-policy temporal-difference learning with function approximation}},
year = {2001}
}

@article{sutton2016etd,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@book{bertsekas1996ndp,
  title={Neuro-dynamic programming},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  publisher={Athena Scientific},
  year={1996}
}

@inproceedings{Baird1995,
annote = {Residual gradient = differentiating through target},
author = {Baird, Leemon},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Residual Algorithms : Reinforcement Learning with Function Approximation}},
year = {1995}
}


@article{majdik2017zurich,
  title={The Zurich urban micro aerial vehicle dataset},
  author={Majdik, Andr{\'a}s L and Till, Charles and Scaramuzza, Davide},
  journal={The International Journal of Robotics Research},
  volume={36},
  number={3},
  pages={269--273},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{levine2018handeye,
  title={Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection},
  author={Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Ibarz, Julian and Quillen, Deirdre},
  journal={The International Journal of Robotics Research},
  volume={37},
  number={4-5},
  pages={421--436},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}


@InProceedings{hallak2017coptd,
  title = 	 {Consistent On-Line Off-Policy Evaluation},
  author = 	 {Assaf Hallak and Shie Mannor},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1372--1383},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/hallak17a/hallak17a.pdf},
  url = 	 {http://proceedings.mlr.press/v70/hallak17a.html},
  abstract = 	 {The problem of on-line off-policy evaluation (OPE) has been actively studied in the last decade due to its importance both as a stand-alone problem and as a module in a policy improvement scheme. However, most Temporal Difference (TD) based solutions ignore the discrepancy between the stationary distribution of the behavior and target policies and its effect on the convergence limit when function approximation is applied. In this paper we propose the Consistent Off-Policy Temporal Difference (COP-TD($\lambda$, $\beta$)) algorithm that addresses this issue and reduces this bias at some computational expense. We show that COP-TD($\lambda$, $\beta$) can be designed to converge to the same value that would have been obtained by using on-policy TD($\lambda$) with the target policy. Subsequently, the proposed scheme leads to a related and promising heuristic we call log-COP-TD($\lambda$, $\beta$). Both algorithms have favorable empirical results to the current state of the art on-line OPE algorithms. Finally, our formulation sheds some new light on the recently proposed Emphatic TD learning.}
}

@article{gelada2019off,
  author    = {Carles Gelada and
               Marc G. Bellemare},
  title     = {Off-Policy Deep Reinforcement Learning by Bootstrapping the Covariate
               Shift},
  journal   = {CoRR},
  volume    = {abs/1901.09455},
  year      = {2019},
  url       = {},
  archivePrefix = {arXiv},
  eprint    = {1901.09455},
  timestamp = {Sat, 02 Feb 2019 16:56:00 +0100},
  biburl    = {},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{hester2018dqfd,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@inproceedings{antos07fitted,
 author = {Antos, Andr\'{a}s and Munos, R{\'e}mi and Szepesv\'{a}ri, Csaba},
 title = {Fitted Q-iteration in Continuous Action-space MDPs},
 booktitle = {Proceedings of the 20th International Conference on Neural Information Processing Systems},
 series = {NIPS'07},
 year = {2007},
 isbn = {978-1-60560-352-0},
 location = {Vancouver, British Columbia, Canada},
 pages = {9--16},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=2981562.2981564},
 acmid = {2981564},
 publisher = {Curran Associates Inc.},
 address = {USA},
} 


@inproceedings{deBruin2015importance,
author = {de Bruin, Tim and Kober, Jens and Tuyls, Karl and Babuska, Robert},
year = {2015},
month = {01},
pages = {},
title = {The importance of experience replay database composition in deep reinforcement learning}
}

@article{gu2016qprop,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}

@article{haarnoja2018sac,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@inproceedings{henderson2018deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{fu2019diagnosing,
  title={Diagnosing Bottlenecks in Deep Q-learning Algorithms},
  author={Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  journal={arXiv preprint arXiv:1902.10250},
  year={2019}
}

@article{fujimoto2018off,
  title={Off-Policy Deep Reinforcement Learning without Exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1054--1062},
  year={2016}
}

@inproceedings{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={568--576},
  year={2010}
}

@inproceedings{munos2003errorapi,
  title={Error bounds for approximate policy iteration},
  author={Munos, R{\'e}mi},
  booktitle={Proceedings of the Twentieth International Conference on International Conference on Machine Learning},
  pages={560--567},
  year={2003},
  organization={AAAI Press}
}

@inproceedings{munos2005erroravi,
  title={Error bounds for approximate value iteration},
  author={Munos, R{\'e}mi},
  year={2005},
  booktitle={Proceedings of the National Conference on Artificial Intelligence}
}

@inproceedings{ross2011dagger,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={Proceedings of the fourteenth international conference on artificial intelligence and statistics},
  pages={627--635},
  year={2011}
}

@inproceedings{kakade2002cpi,
  title={Approximately Optimal Approximate Reinforcement Learning},
  author={Kakade, Sham and Langford, John},
  booktitle={Proceedings of the Nineteenth International Conference on Machine Learning},
  pages={267--274},
  year={2002},
  organization={Morgan Kaufmann Publishers Inc.}
}

@incollection{watters2017vin,
    title = {Visual Interaction Networks: Learning a Physics Simulator from Video},
    author = {Watters, Nicholas and Zoran, Daniel and Weber, Theophane and Battaglia, Peter and Pascanu, Razvan and Tacchetti, Andrea},
    booktitle = {NIPS},
    year = {2017}
}

@inproceedings{wu2017vda,
  title={Learning to See Physics via Visual De-animation},
  author={Wu, Jiajun and Lu, Erika and Kohli, Pushmeet and Freeman, William T and Tenenbaum, Joshua B},
  booktitle={Advances in Neural Information Processing Systems},
  year={2017}
}

@inproceedings{fragkiadaki2016billiards,
  title={Learning Visual Predictive Models of Physics for Playing Billiards},
  author={Katerina Fragkiadaki and
              Pulkit Agrawal and
              Sergey Levine and
              Jitendra Malik},
  booktitle={International Conference on Learning Representations},
  year={2016}
}

@article{lee2018savp,
  title={Stochastic Adversarial Video Prediction},
  author={Alex X. Lee and Richard Zhang and Frederik Ebert and Pieter Abbeel and Chelsea Finn and Sergey Levine},
  journal={arXiv preprint arXiv:1804.01523},
  year={2018}
}

@inproceedings{wu2017nsd,
  title={Neural Scene De-rendering},
  author={Wu, Jiajun and Tenenbaum, Joshua B and Kohli, Pushmeet},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition},
  year={2017}
}

@inproceedings{chang2016npe,
    title={A Compositional Object-Based Approach to Learning Physical Dynamics},
    author={Chang, Michael B and Ullman, Tomer and Torralba, Antonio and Tenenbaum, Joshua B},
    booktitle={ICLR},
    year={2016}
}

@inproceedings{hamrick2011physics,
  title={Internal physics models guide probabilistic judgments about object dynamics},
  author={Hamrick, Jessica B. and Battaglia, Peter and Tenenbaum, Joshua B.},
  booktitle={Proceedings of the 33rd annual conference of the cognitive science society},
  year={2011}
}

@inproceedings{lerer2016physnet,
 author = {Lerer, Adam and Gross, Sam and Fergus, Rob},
 title = {Learning Physical Intuition of Block Towers by Example},
 booktitle = {ICML},
 year={2016}
} 

@inproceedings{babaeizadeh2018sv2p,
    title={Stochastic Variational Video Prediction},
    author={Mohammad Babaeizadeh and Chelsea Finn and Dumitru Erhan and Roy H. Campbell and Sergey Levine},
    booktitle={ICLR},
    year={2018}
}

@article{ha2018worldmodels,
  author = {Ha, D. and Schmidhuber, J.},
  title  = {World Models},
  eprint = {arXiv:1803.10122},
  year   = {2018}
}

@inproceedings{higgins2017betavae,
    title={{$\beta$}-{VAE}: Learning Basic Visual Concepts with a Constrained Variational Framework},
    author={Irina Higgins and Loic Matthey and Arka Pal and Christopher Burgess and Xavier Glorot and Matthew Botvinick and Shakir Mohamed and Alexander Lerchner},
    booktitle={International Conference on Learning Representations},
    year={2017}
}

@inproceedings{chen2016infogan,
  title={InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets},
  author={Xi Chen and Yan Duan and Rein Houthooft and John Schulman and Ilya Sutskever and Pieter Abbeel},
  booktitle={Advances in Neural Information Processing Systems},
  year={2016}
}

@inproceedings{kulkarni2015dcign,
    author = {Kulkarni, Tejas D. and Whitney, William F. and Kohli, Pushmeet and Tenenbaum, Joshua B.},
    title = {Deep Convolutional Inverse Graphics Network},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2015}
}

@incollection{goodfellow2014gan,
    title = {Generative Adversarial Nets},
    author = {Goodfellow, Ian and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
    booktitle = {Advances in Neural Information Processing Systems},
    year = {2014}
}

@article{kingma2013vae,
  author    = {Diederik P. Kingma and
              Max Welling},
  title     = {Auto-Encoding Variational Bayes},
  journal   = {CoRR},
  volume    = {abs/1312.6114},
  year      = {2013}
}

@article{spelke2007core,
    author = {Spelke, Elizabeth S. and Kinzler, Katherine D.},
    title = {Core knowledge},
    journal = {Developmental Science},
    volume = {10},
    number = {1},
    pages = {89-96},
    year = {2007}
}

@phdthesis{winston1970structural,
	author = "Winston, Patrick Henry",
	year = "1970",
	title = "Learning structural descriptions from examples",
	institution = "Department of Electrical Engineering and Computer Science, 		
		Massachusetts Institute of Technology",
	type = "Technical Report",
	number = "MAC-TR-76"
}

@article{finn2017foresight,
  title={Deep visual foresight for planning robot motion},
  author={Chelsea Finn and Sergey Levine},
  journal={IEEE International Conference on Robotics and Automation},
  year={2017},
  pages={2786-2793}
}


@InProceedings{kansky2017schema,
  title = 	 {Schema Networks: Zero-shot Transfer with a Generative Causal Model of Intuitive Physics},
  author = 	 {Ken Kansky and Tom Silver and David A. M{\'e}ly and Mohamed Eldawy and Miguel L{\'a}zaro-Gredilla and Xinghua Lou and Nimrod Dorfman and Szymon Sidor and Scott Phoenix and Dileep George},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  year = 	 {2017},
}

@inproceedings{diuk2008oomdp,
     author = {Diuk, Carlos and Cohen, Andre and Littman, Michael L.},
     title = {An Object-oriented Representation for Efficient Reinforcement Learning},
     booktitle = {Proceedings of the 25th International Conference on Machine Learning},
     year = {2008},
} 

@incollection{zaheer2017deepsets,
    title = {Deep Sets},
    author = {Zaheer, Manzil and Kottur, Satwik and Ravanbakhsh, Siamak and Poczos, Barnabas and Salakhutdinov, Ruslan R and Smola, Alexander J},
    year = {2017}
}

@incollection{santoro2017clevr,
    title = {A simple neural network module for relational reasoning},
    author = {Santoro, Adam and Raposo, David and Barrett, David G and Malinowski, Mateusz and Pascanu, Razvan and Battaglia, Peter and Lillicrap, Tim},
    year = {2017}
}

@inproceedings{johnson2016perceptual,
  title={Perceptual losses for real-time style transfer and super-resolution},
  author={Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle={ECCV},
  year={2016}
}

@inproceedings{ba2015adam,
  author    = {Kingma, Diederik P. and Ba, Jimmy},
  title     = {Adam: A Method for Stochastic Optimization},
  booktitle = {International Conference on Learning Representations},
  year      = {2015},
}

@inproceedings{gupta2010blocks,
   author="Abhinav Gupta and Alexei A. Efros and Martial Hebert", 
   title="Blocks World Revisited: Image Understanding Using Qualitative Geometry and Mechanics", 
   booktitle="European Conference on Computer Vision(ECCV)", 
   year="2010", 
}

@inproceedings{mottaghi2016newtonian,
    author = {Mottaghi, Roozbeh and Bagherinezhad, Hessam and Rastegari, Mohammad and Farhadi, Ali},
    title = {Newtonian Scene Understanding: Unfolding the Dynamics of Objects in Static Images},
    booktitle = {IEEE Conference on Computer Vision and Pattern Recognition},
    year = {2016}
}

@inproceedings{li2017stability, 
    author={W. Li and A. Leonardis and M. Fritz}, 
    booktitle={IEEE International Conference on Robotics and Automation}, 
    title={Visual stability prediction for robotic manipulation}, 
    year={2017}, 
}

@ARTICLE{jia2015reasoning, 
    author={Z. Jia and A. C. Gallagher and A. Saxena and T. Chen}, 
    journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
    title={3D Reasoning from Blocks to Stability}, 
    year={2015}, 
}

@article{mottaghi2016what_happens_if,
  author    = {Roozbeh Mottaghi and
               Mohammad Rastegari and
               Abhinav Gupta and
               Ali Farhadi},
  title     = {"What happens if..." Learning to Predict the Effect of Forces
               in Images},
  journal   = {CoRR},
  volume    = {abs/1603.05600},
  year      = {2016}
}

@article{shao2014cuboid,
  title   = "Imagining the Unseen: Stability-based Cuboid Arrangements for Scene Understanding", 
  author  = "Tianjia Shao and Aron Monszpart and Youyi Zheng and Bongjin Koo and Weiwei Xu and Kun Zhou 
             and Niloy Mitra",
  year    = {2014},
  journal = {ACM SIGGRAPH Asia 2014},
  note    = {* Joint first authors}
}

@article{zheng2014safety,
  title={Scene Understanding by Reasoning Stability and Safety},
  author={Bo Zheng and Yibiao Zhao and Joey C. Yu and Katsushi Ikeuchi and Song-Chun Zhu},
  journal={International Journal of Computer Vision},
  year={2014}
}

@article{ehrhardt2017heightfields,
   author = {{S\'ebastien} Ehrhardt and Aron Monszpart and Niloy {J. Mitra} and Andrea Vedaldi},
    title = "{Taking Visual Motion Prediction To New Heightfields}",
  journal = {arXiv preprint arXiv:1712.09448},
archivePrefix = "arXiv",
     year = 2017
}

@incollection{eslami2016air,
    title = {Attend, Infer, Repeat: Fast Scene Understanding with Generative Models},
    author = {Eslami, S. M. Ali and Heess, Nicolas and Weber, Theophane and Tassa, Yuval and Szepesvari, David and Kavukcuoglu, Koray and Hinton, Geoffrey E},
    booktitle = {Advances in Neural Information Processing Systems 29},
    year = {2016}
}

@article{thomas2017factors,
  author    = {Valentin Thomas and
               Jules Pondard and
               Emmanuel Bengio and
               Marc Sarfati and
               Philippe Beaudoin and
               Marie{-}Jean Meurs and
               Joelle Pineau and
               Doina Precup and
               Yoshua Bengio},
  title     = {Independently Controllable Factors},
  journal   = {CoRR},
  volume    = {abs/1708.01289},
  year      = {2017},
  url       = {http://arxiv.org/abs/1708.01289},
  archivePrefix = {arXiv},
  eprint    = {1708.01289},
  timestamp = {Mon, 13 Aug 2018 16:49:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-01289},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@incollection{greff2017nem,
    title = {Neural Expectation Maximization},
    author = {Greff, Klaus and van Steenkiste, Sjoerd and Schmidhuber, J\"{u}rgen},
    booktitle = {Advances in Neural Information Processing Systems 30},
    editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
    year = {2017},
}

@inproceedings{guestrin2003relational,
     author = {Guestrin, Carlos and Koller, Daphne and Gearhart, Chris and Kanodia, Neal},
     title = {Generalizing Plans to New Environments in Relational MDPs},
     booktitle = {Proceedings of the 18th International Joint Conference on Artificial Intelligence},
     year = {2003}
} 

@article{brunskill2018soorl,
  title={Strategic Object Oriented Reinforcement Learning},
  author={Ramtin Keramati and Jay Whang and Patrick Cho and Emma Brunskill},
  journal={arXiv preprint arXiv:1806.00175},
  year={2018}
}

@inproceedings{wingate2014physicsmdp,
      title = 	 {A Physics-Based Model Prior for Object-Oriented MDPs},
      author = 	 {Jonathan Scholz and Martin Levihn and Charles Isbell and David Wingate},
      booktitle = 	 {Proceedings of the 31st International Conference on Machine Learning},
      year = 	 {2014}
}

@article{devin2017deepobjects,
  title={Deep Object-Centric Representations for Generalizable Robot Learning},
  author={Coline Devin and Pieter Abbeel and Trevor Darrell and Sergey Levine},
  journal={CoRR},
  year={2017},
  volume={abs/1708.04225}
}

@article{goel2018segmentation,
  title={Unsupervised Video Object Segmentation for Deep Reinforcement Learning},
  author={Vik Goel and Jameson Weng and Pascal Poupart},
  journal={CoRR},
  year={2018},
  volume={abs/1805.07780}
}

@book{roberts1963thesis,
  author = {Roberts, Lawrence G.},
  series = {Outstanding Dissertations in the Computer Sciences},
  title = {Machine Perception of Three-Dimensional Solids},
  year = 1963
}

@InProceedings{wu19domain,
  title = 	 {Domain Adaptation with Asymmetrically-Relaxed Distribution Alignment},
  author = 	 {Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  booktitle = 	 {ICML 2019},
  abstract = 	 {Domain adaptation addresses the common situation in which the target distribution generating our test data differs from the source distribution generating our training data. While absent assumptions, domain adaptation is impossible, strict conditions, e.g. covariate or label shift, enable principled algorithms. Recently-proposed domain-adversarial approaches consist of aligning source and target encodings, an approach often motivated as minimizing two (of three) terms in a theoretical bound on target error. Unfortunately, this minimization can cause arbitrary increases in the third term, a problem guaranteed to arise under shifting label distributions. We propose asymmetrically-relaxed distribution alignment, a new approach that overcomes some limitations of standard domain-adversarial algorithms. Moreover, we characterize precise assumptions under which our algorithm is theoretically principled and demonstrate empirical benefits on both synthetic and real datasets.}
}

@article{jacques19way,
  author    = {Natasha Jaques and
               Asma Ghandeharioun and
               Judy Hanwen Shen and
               Craig Ferguson and
               {\`{A}}gata Lapedriza and
               Noah Jones and
               Shixiang Gu and
               Rosalind W. Picard},
  title     = {Way Off-Policy Batch Deep Reinforcement Learning of Implicit Human
               Preferences in Dialog},
  journal   = {CoRR},
  volume    = {abs/1907.00456},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.00456},
  archivePrefix = {arXiv},
  eprint    = {1907.00456},
  timestamp = {Mon, 08 Jul 2019 14:12:33 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1907-00456},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@book{cem,
 author = {Rubinstein, Reuven Y. and Kroese, Dirk P.},
 title = {The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, Monte-carlo Simulation (Information Science and Statistics)},
 year = {2004},
 isbn = {038721240X},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 

@article{wang2019random,
  author    = {Ruohan Wang and
               Carlo Ciliberto and
               Pierluigi Vito Amadori and
               Yiannis Demiris},
  title     = {Random Expert Distillation: Imitation Learning via Expert Policy Support
               Estimation},
  journal   = {CoRR},
  volume    = {abs/1905.06750},
  year      = {2019},
  url       = {http://arxiv.org/abs/1905.06750},
  archivePrefix = {arXiv},
  eprint    = {1905.06750},
  timestamp = {Tue, 28 May 2019 12:48:08 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1905-06750},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{mujoco,
  author = {Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle = {IROS},
  pages = {5026-5033},
  title = {{MuJoCo}: A physics engine for model-based control.},
  year = 2012
}

@Article{vgg,
    author       = "Simonyan, K. and Zisserman, A.",
    title        = "Very Deep Convolutional Networks for Large-Scale Image Recognition",
    journal      = "CoRR",
    volume       = "abs/1409.1556",
    year         = "2014"
}

@inproceedings{
    van2018relational,
    title={Relational Neural Expectation Maximization: Unsupervised Discovery of Objects and their Interactions},
    author={Sjoerd van Steenkiste and Michael Chang and Klaus Greff and Jürgen Schmidhuber},
    booktitle={ICLR},
    year={2018},
}

@article{levine2016visuomotor,
 author = {Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {1334--1373},
 numpages = {40},
 acmid = {2946684},
 publisher = {JMLR.org},
 keywords = {neural networks, optimal control, reinforcement learning, vision},
} 


@article{mnih2015humanlevel,
  added-at = {2015-08-26T14:46:40.000+0200},
  author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
  biburl = {https://www.bibsonomy.org/bibtex/2fb15f4471c81dc2b9edf2304cb2f7083/hotho},
  description = {Human-level control through deep reinforcement learning - nature14236.pdf},
  interhash = {eac59980357d99db87b341b61ef6645f},
  intrahash = {fb15f4471c81dc2b9edf2304cb2f7083},
  issn = {00280836},
  journal = {Nature},
  keywords = {deep learning toread},
  month = feb,
  number = 7540,
  pages = {529--533},
  publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
  timestamp = {2015-08-26T14:46:40.000+0200},
  title = {Human-level control through deep reinforcement learning},
  volume = 518,
  year = 2015
}

@article{schulman2017ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017}
}

@InProceedings{schulman2015trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {John Schulman and Sergey Levine and Pieter Abbeel and Michael Jordan and Philipp Moritz},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1889--1897},
  year = 	 {2015},
  editor = 	 {Francis Bach and David Blei},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher = 	 {PMLR},
}


@article{lake2016building,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J.},
  biburl = {https://www.bibsonomy.org/bibtex/2576ae0ad88cf063408fafc9a55a961f3/dblp},
  ee = {http://arxiv.org/abs/1604.00289},
  interhash = {c8d2eb567dd89fc6f03c07b9db9490ac},
  intrahash = {576ae0ad88cf063408fafc9a55a961f3},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T12:23:49.000+0200},
  title = {Building Machines That Learn and Think Like People.},
  volume = {abs/1604.00289},
  year = 2016
}

@incollection{watter2015embed,
title = {Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images},
author = {Watter, Manuel and Springenberg, Jost and Boedecker, Joschka and Riedmiller, Martin},
booktitle = {Advances in Neural Information Processing Systems 28},
editor = {C. Cortes and N. D. Lawrence and D. D. Lee and M. Sugiyama and R. Garnett},
pages = {2746--2754},
year = {2015},
publisher = {Curran Associates, Inc.},
}

@article{kumar2016optimal,
  title={Optimal control with learned local models: Application to dexterous manipulation},
  author={Vikash Kumar and Emanuel Todorov and Sergey Levine},
  journal={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2016},
  pages={378-383}
}

@article{chua2018pets,
  title={Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models},
  author={Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey Levine},
  journal={CoRR},
  year={2018},
  volume={abs/1805.12114}
}

@inproceedings{
kurutach2018modelensemble,
title={Model-Ensemble Trust-Region Policy Optimization},
author={Thanard Kurutach and Ignasi Clavera and Yan Duan and Aviv Tamar and Pieter Abbeel},
booktitle={International Conference on Learning Representations},
year={2018},
}

@article{feinberg2018mve,
  author    = {Vladimir Feinberg and
               Alvin Wan and
               Ion Stoica and
               Michael I. Jordan and
               Joseph E. Gonzalez and
               Sergey Levine},
  title     = {Model-Based Value Estimation for Efficient Model-Free Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1803.00101},
  year      = {2018}
}


@incollection{i2a,
title = {Imagination-Augmented Agents for Deep Reinforcement Learning},
author = {Racani\`{e}re, S\'{e}bastien and Weber, Theophane and Reichert, David and Buesing, Lars and Guez, Arthur and Jimenez Rezende, Danilo and Puigdom\`{e}nech Badia, Adri\`{a} and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and Pascanu, Razvan and Battaglia, Peter and Hassabis, Demis and Silver, David and Wierstra, Daan},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {5690--5701},
year = {2017},
publisher = {Curran Associates, Inc.},
}

@InProceedings{gu2016mba,
  title = 	 {Continuous Deep Q-Learning with Model-based Acceleration},
  author = 	 {Shixiang Gu and Timothy Lillicrap and Ilya Sutskever and Sergey Levine},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {2829--2838},
  year = 	 {2016},
  editor = 	 {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher = 	 {PMLR},
}

@article{agarwal19striving,
  author    = {Rishabh Agarwal and
               Dale Schuurmans and
               Mohammad Norouzi},
  title     = {Striving for Simplicity in Off-policy Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1907.04543},
  year      = {2019},
  url       = {http://arxiv.org/abs/1907.04543},
  archivePrefix = {arXiv},
  eprint    = {1907.04543},
  timestamp = {Wed, 17 Jul 2019 10:27:36 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1907-04543},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{sutton1990dyna,
  title={Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
  author={Richard S. Sutton},
  booktitle={ML},
  year={1990}
}

@InProceedings{byrd19is,
  title = 	 {What is the Effect of Importance Weighting in Deep Learning?},
  author = 	 {Byrd, Jonathon and Lipton, Zachary},
  booktitle = 	 {ICML 2019},
}

% @InProceedings{sac,
%   title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
%   author = 	 {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
%   booktitle = 	 {ICML 2018},
% }

@article{alphagozero,
  author    = {David Silver and
               Thomas Hubert and
               Julian Schrittwieser and
               Ioannis Antonoglou and
               Matthew Lai and
               Arthur Guez and
               Marc Lanctot and
               Laurent Sifre and
               Dharshan Kumaran and
               Thore Graepel and
               Timothy P. Lillicrap and
               Karen Simonyan and
               Demis Hassabis},
  title     = {Mastering Chess and Shogi by Self-Play with a General Reinforcement
               Learning Algorithm},
  journal   = {CoRR},
  volume    = {abs/1712.01815},
  year      = {2017}
}

@article{kaelbling,
    author = "Leslie Pack Kaelbling and Michael L. Littman and Andrew P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
}

@article{haarnoja18sac,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
  timestamp = {Mon, 13 Aug 2018 16:48:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1801-01290},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={International Conference on machine learning (ICML)},
  pages={465--472},
  year={2011}
}

@article{asadi2018lipschitz,
  title={Lipschitz continuity in model-based reinforcement learning},
  author={Asadi, Kavosh and Misra, Dipendra and Littman, Michael L},
  journal={arXiv preprint arXiv:1804.07193},
  year={2018}
}

@inproceedings{
daskalakis2018training,
title={Training {GAN}s with Optimism},
author={Constantinos Daskalakis and Andrew Ilyas and Vasilis Syrgkanis and Haoyang Zeng},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJJySbbAZ},
}

@inproceedings{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  year={2010}
}

@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  number={3},
  pages={185--202},
  year={1994},
  publisher={Springer}
}

@inproceedings{
yaz2018the,
title={The Unusual Effectiveness of Averaging in {GAN} Training},
author={Yasin Yaz{\i}c{\i} and Chuan-Sheng Foo and Stefan Winkler and Kim-Hui Yap and Georgios Piliouras and Vijay Chandrasekhar},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SJgw_sRqFQ},
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2018}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@inproceedings{Kakade2002,
author = {Kakade, Sham and Langford, John},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Approximately Optimal Approximate Reinforcement Learning}},
year = {2002}
}

@inproceedings{Maei2010,
author = {Maei, Hamid Reza and Szepesv{\'{a}}ri, Csaba and Bhatnagar, Shalabh and Sutton, Richard S},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Toward off-policy learning control with function approximation}},
year = {2010}
}

@inproceedings{Baird1995,
annote = {Residual gradient = differentiating through target},
author = {Baird, Leemon},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Residual Algorithms : Reinforcement Learning with Function Approximation}},
year = {1995}
}

@article{Mnih2015,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
issn = {0028-0836},
journal = {Nature},
month = {feb},
number = {7540},
pages = {529--533},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
title = {{Human-level control through deep reinforcement learning}},
volume = {518},
year = {2015}
}

@article{Lillicrap2015,
author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
journal = {International Conference on Learning Representations (ICLR)},
title = {{Continuous control with deep reinforcement learning}},
year = {2015}
}

@inproceedings{Schulman2015,
author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael I. and Abbeel, Pieter},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Trust Region Policy Optimization}},
year = {2015}
}

@inproceedings{Precup2001,
author = {Precup, Doina and Sutton, Richard S. and Dasgupta, Sanjoy},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Off-policy temporal-difference learning with function approximation}},
year = {2001}
}

@article{Schulman2017,
  author    = {John Schulman and
               Pieter Abbeel and
               Xi Chen},
  title     = {Equivalence Between Policy Gradients and Soft Q-Learning},
  journal   = {ArXiv Preprint},
  volume    = {abs/1704.06440},
  year      = {2017},
}

@article{Gu2016,
  author    = {Shixiang Gu and
               Ethan Holly and
               Timothy Lillicrap and
               Sergey Levine},
  title     = {Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  journal   = {IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2017},
}

@article{Watkins92,
  author    = {Christopher J.C.H. Watkins and Peter Dayan},
  title     = {Q-learning},
  journal   = {Machine Learning},
  year      = {1992},
  volume    = {8},
  pages     = {279-292},
  issue     = {3},
}

@incollection{Kakade2001,
title = {A Natural Policy Gradient},
author = {Sham M. Kakade},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2001},
}

@incollection{Munos2016,
title = {Safe and Efficient Off-policy Reinforcement Learning},
author = {Remi Munos and Thomas Stepleton and Anna Harutyunyan and Marc G. Bellemare},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2016},
}

@inproceedings{Sutton09a,
title = {A Convergent O(n) Temporal-difference Algorithm for Off-policy Learning with Linear Function Approximation},
author = {Sutton, Richard S. and Hamid Reza Maei and Csaba Szepesv\'{a}ri},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2009},
}

@inproceedings{Sutton09b,
title = {Fast Gradient-Descent Methods for Temporal-Difference Learning
with Linear Function Approximation},
author = {
Richard S. Sutton and Hamid Reza Maei and Doina Precup and Shalabh Bhatnagar and David Silver and Csaba Szepesv\'{a}ri and
Eric Wiewiora},
booktitle = {International Conference on Machine Learning (ICML)},
year = {2009},
}

@article{Bertsekas96,
title = {Neuro-Dynamic Programming},
author = {Bertsekas, Dimitri P., and Tsitsiklis, John N.},
journal = {Athena Scientific},
year = {1996},
}


@inproceedings{Haarnoja2017,
author = {Tuomas Haarnoja and
               Haoran Tang and
               Pieter Abbeel and
               Sergey Levine},
booktitle = {International Conference on Machine Learning (ICML)},
title = {Reinforcement Learning with Deep Energy-Based Policies},
year = {2017}
}

@inproceedings{Hausknecht2016,
author = {Matthew Hausknecht and Peter Stone},
booktitle = {Deep Reinforcement Learning: Frontiers and Challenges Workshop, IJCAI},
title = {On-Policy vs. Off-Policy Updates for Deep Reinforcement Learning},
year = {2016}
}

@inproceedings{Farrell95,
author = {Jay A. Farrell and T. Berger},
booktitle = {American Control Conference},
title = {On the effects of the training sample density in passive learning control},
year = {1995}
}

@inproceedings{Boyan94,
author = {Justin A. Boyan and Andrew W. Moore},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
title = {Generalization in Reinforcement Learning:
Safely Approximating the Value Function},
year = {1994}
}

@article{Haarnoja18,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
}

@inproceedings{kalashnikov18,
  author    = {Dmitry Kalashnikov and
               Alex Irpan and
               Peter Pastor and
               Julian Ibarz and
               Alexander Herzog and
               Eric Jang and
               Deirdre Quillen and
               Ethan Holly and
               Mrinal Kalakrishnan and
               Vincent Vanhoucke and
               Sergey Levine},
  title     = {QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  booktitle = {CoRL},
  series    = {Proceedings of Machine Learning Research},
  volume    = {87},
  pages     = {651--673},
  publisher = {{PMLR}},
  year      = {2018}
}

@article{Ernst05,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@book{suttonrlbook,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  edition = {Second}
}

@inproceedings{Dai2018,
  title={Sbeed: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  booktitle={International Conference on Machine Learning},
  pages={1133--1142},
  year={2018}
}

@article{VanHesselt2018,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@inproceedings{Tsitsiklis1997,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1075--1081},
  year={1997}
}

@article{Hallak2017,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  journal={arXiv preprint arXiv:1702.07121},
  year={2017}
}

@article{Sutton2016,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{Riedmiller2005,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}

@article{Watkins1992,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{Gu2017,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@misc{gym,
  Author = {Matthias Plappert and Marcin Andrychowicz and Alex Ray and Bob McGrew and Bowen Baker and Glenn Powell and Jonas Schneider and Josh Tobin and Maciek Chociej and Peter Welinder and Vikash Kumar and Wojciech Zaremba},
  Title = {Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research},
  Year = {2018},
  Eprint = {arXiv:1802.09464},
}

@article{Schaul2015,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={International Conference on Learning Representations (ICLR)},
  year={2015}
}

@inproceedings{prabhakar2022multi,
  title={Multi-objective Optimization of Notifications Using Offline Reinforcement Learning},
  author={Prabhakar, Prakruthi and Yuan, Yiping and Yang, Guangyu and Sun, Wensheng and Muralidharan, Ajith},
  booktitle={Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
  pages={3752--3760},
  year={2022}
}

@article{killian2023risk,
  title={Risk Sensitive Dead-end Identification in Safety-Critical Offline Reinforcement Learning},
  author={Killian, Taylor W and Parbhoo, Sonali and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:2301.05664},
  year={2023}
}


@article{singh2022offline,
  title={Offline rl with realistic datasets: Heteroskedasticity and support constraints},
  author={Singh, Anikait and Kumar, Aviral and Vuong, Quan and Chebotar, Yevgen and Levine, Sergey},
  journal={arXiv preprint arXiv:2211.01052},
  year={2022}
}

@book{Shalev2014,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@incollection{NIPS2017_6913,
title = {Is the Bellman residual a bad proxy?},
author = {Geist, Matthieu and Piot, Bilal and Pietquin, Olivier},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
pages = {3205--3214},
year = {2017},
}

@inproceedings{Pritzel2017,
  title={Neural Episodic Control},
  author={Pritzel, Alexander and Uria, Benigno and Srinivasan, Sriram and Badia, Adri{\`a} Puigdom{\`e}nech and Vinyals, Oriol and Hassabis, Demis and Wierstra, Daan and Blundell, Charles},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2827--2836},
  year={2017}
}

@InProceedings{pmlr-v80-fujimoto18a,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@inproceedings{Gu2017ipg,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={3846--3855},
  year={2017}
}

@inproceedings{maillard2010finite,
  title={Finite-sample analysis of Bellman residual minimization},
  author={Maillard, Odalric-Ambrym and Munos, R{\'e}mi and Lazaric, Alessandro and Ghavamzadeh, Mohammad},
  booktitle={Asian Conference on Machine Learning (ACML)},
  pages={299--314},
  year={2010}
}

@inproceedings{munos2005error,
  title={Error bounds for approximate value iteration},
  author={Munos, R{\'e}mi},
  booktitle={AAAI Conference on Artificial intelligence (AAAI)},
  pages={1006--1011},
  year={2005},
  organization={AAAI Press}
}

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{zhang2018deeper,
  author    = {Shangtong Zhang and
               Richard S. Sutton},
  title     = {A Deeper Look at Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1712.01275},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.01275},
  archivePrefix = {arXiv},
  eprint    = {1712.01275},
  timestamp = {Mon, 13 Aug 2018 16:46:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1712-01275},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{antos2007fitted,
 author = {Antos, Andr\'{a}s and Munos, R{\'e}mi and Szepesv\'{a}ri, Csaba},
 title = {Fitted Q-iteration in Continuous Action-space MDPs},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 series = {NIPS'07},
 year = {2007},
 location = {Vancouver, British Columbia, Canada},
} 

@phdthesis{de2002alp,
  title={The linear programming approach to approximate dynamic programming: Theory and application},
  author={De Farias, Daniela Pucci},
  year={2002}
}

@article{antos2008concentrability,
  title={Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Machine Learning},
  volume={71},
  number={1},
  pages={89--129},
  year={2008},
  publisher={Springer}
}

@inproceedings{munos2005erroravi,
  title={Error bounds for approximate value iteration},
  author={Munos, R{\'e}mi},
  booktitle={AAI Conference on Artificial intelligence (AAAI)},
  pages={1006--1011},
  year={2005},
  organization={AAAI Press}
}

@article{metelli2018nips,
  author    = {Alberto Maria Metelli and
               Matteo Papini and
               Francesco Faccio and
               Marcello Restelli},
  title     = {Policy Optimization via Importance Sampling},
  journal   = {CoRR},
  volume    = {abs/1809.06098},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.06098},
  archivePrefix = {arXiv},
  eprint    = {1809.06098},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1809-06098},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{pmlr-v70-arjovsky17a,
  title = 	 {{W}asserstein Generative Adversarial Networks},
  author = 	 {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {214--223},
  year = 	 {2017},
}

@techreport{haarnoja2018sacapps,
  title={Soft Actor-Critic Algorithms and Applications},
  author={Tuomas Haarnoja, Aurick Zhou, Kristian Hartikainen, George Tucker, Sehoon Ha, Jie Tan, Vikash Kumar, Henry Zhu, Abhishek Gupta, Pieter Abbeel, and Sergey Levine},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{hazan2018,
  title={Provably Efficient Maximum Entropy Exploration},
  author={Hazan, Elad and Kakade, Sham M and Singh, Karan and Van Soest, Abby},
  journal={arXiv preprint arXiv:1812.02690},
  year={2018}
}

@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@inproceedings{scherrer2010residual,
  title={Should one compute the temporal difference fix point or minimize the Bellman Residual? The unified oblique projection view},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={959--966},
  year={2010},
}

@inproceedings{tosatto2017boosted,
  title={Boosted fitted q-iteration},
  author={Tosatto, Samuele and Pirotta, Matteo and D'Eramo, Carlo and Restelli, Marcello},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={3434--3443},
  year={2017},
  organization={JMLR. org}
}

@article{lin1992replay,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1054--1062},
  year={2016}
}

@article{sriperum2009ipms,
  author    = {Bharath K. Sriperumbudur and
               Arthur Gretton and
               Kenji Fukumizu and
               Gert R. G. Lanckriet and
               Bernhard Sch{\"{o}}lkopf},
  title     = {A note on integral probability metrics and {\textdollar}{\textbackslash}phi{\textdollar}-divergences},
  journal   = {CoRR},
  volume    = {abs/0901.2698},
  year      = {2009},
  url       = {http://arxiv.org/abs/0901.2698},
  archivePrefix = {arXiv},
  eprint    = {0901.2698},
  timestamp = {Mon, 13 Aug 2018 16:48:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-0901-2698},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{precup2001offpol,
  title={Off-Policy Temporal Difference Learning with Function Approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={417--424},
  year={2001},
}

@inproceedings{hausknecht2016policy,
  title={On-policy vs. off-policy updates for deep reinforcement learning},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={Deep Reinforcement Learning: Frontiers and Challenges, IJCAI},
  year={2016}
}

@article{martha2018sparse,
  author    = {Vincent Liu and
               Raksha Kumaraswamy and
               Lei Le and
               Martha White},
  title     = {The Utility of Sparse Representations for Control in Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1811.06626},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.06626},
  archivePrefix = {arXiv},
  eprint    = {1811.06626},
  timestamp = {Sun, 25 Nov 2018 18:57:12 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-06626},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{shani2005recommender,
  title={An MDP-based recommender system},
  author={Shani, Guy and Heckerman, David and Brafman, Ronen I},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Sep},
  pages={1265--1295},
  year={2005}
}

@inproceedings{szepesvari1998asymptotic,
  title={The asymptotic convergence-rate of Q-learning},
  author={Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1064--1070},
  year={1998}
}

@book{koller_friedman,
 author = {Koller, D. and Friedman, N.},
 title = {Probabilistic Graphical Models: Principles and Techniques},
 year = {2009},
 isbn = {0262013193, 9780262013192},
 publisher = {The MIT Press},
} 

@inproceedings{chebotar2019closing,
  title={Closing the sim-to-real loop: Adapting simulation randomization with real world experience},
  author={Chebotar, Yevgen and Handa, Ankur and Makoviychuk, Viktor and Macklin, Miles and Issac, Jan and Ratliff, Nathan and Fox, Dieter},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8973--8979},
  year={2019},
  organization={IEEE}
}

@article{tan2018sim,
  title={Sim-to-real: Learning agile locomotion for quadruped robots},
  author={Tan, Jie and Zhang, Tingnan and Coumans, Erwin and Iscen, Atil and Bai, Yunfei and Hafner, Danijar and Bohez, Steven and Vanhoucke, Vincent},
  journal={arXiv preprint arXiv:1804.10332},
  year={2018}
}

@inproceedings{sadeghi2016cad2rl,
  title={{CAD2RL}: Real single-image flight without a single real image},
  author={Sadeghi, Fereshteh and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2017}
}

@inproceedings{gae,
title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
author = {J. Schulman and P. Moritz and S. Levine and M. Jordan and P. Abbeel},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2016
}

@misc{kumar_blog,
title = {Data-Driven Deep Reinforcement Learning},
author = {Aviral Kumar},
note = {{BAIR} Blog},
year = {2019},
howpublished  = {\url{https://bair.berkeley.edu/blog/2019/12/05/bear/}}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2013}
}

@article{luo2019learning,
  title={Learning self-correctable policies and value functions from demonstrations with negative sampling},
  author={Luo, Yuping and Xu, Huazhe and Ma, Tengyu},
  journal={arXiv preprint arXiv:1907.05634},
  year={2019}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@inproceedings{kakade2002natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  booktitle={Advances in neural information processing systems},
  pages={1531--1538},
  year={2002}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@InProceedings{thomas,
  title = 	 {Bias in Natural Actor-Critic Algorithms},
  author = 	 {Philip Thomas},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2014},
  month = 	 {22--24 Jun},
}

@inproceedings{toussaint06,
 author = {Toussaint, M. and Storkey, A.},
 title = {Probabilistic Inference for Solving Discrete and Continuous State Markov Decision Processes},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2006},
} 

@INPROCEEDINGS{attias,
    author = {H. Attias},
    title = {Planning by Probabilistic Inference},
    booktitle = {Proceedings of the 9th International Workshop on Artificial Intelligence and Statistics},
    year = {2003}
}

@article{hafner2011reinforcement,
  title={Reinforcement learning in feedback control},
  author={Hafner, Roland and Riedmiller, Martin},
  journal={Machine learning},
  volume={84},
  number={1-2},
  pages={137--169},
  year={2011},
  publisher={Springer}
}

@article{tesauro1994td,
  title={{TD-Gammon}, a self-teaching backgammon program, achieves master-level play},
  author={Tesauro, Gerald},
  journal={Neural computation},
  volume={6},
  number={2},
  pages={215--219},
  year={1994},
  publisher={MIT Press}
}

@InProceedings{ebrl,
  title = 	 {Actor-Critic Reinforcement Learning with Energy-Based Policies},
  author = 	 {N. Heess and D. Silver and Y. W. Teh},
  booktitle = 	 {European Workshop on Reinforcement Learning (EWRL)},
  year = 	 {2013},
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={627--635},
  year={2011}
}

@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={661--668},
  year={2010}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={International Conference on Machine Learning (ICML)},
  volume={2},
  year={2002}
}

@inproceedings{ep,
 author = {Minka, T. P.},
 title = {Expectation Propagation for Approximate Bayesian Inference},
 booktitle = {Uncertainty in Artificial Intelligence (UAI)},
 year = {2001},
}

@inproceedings{mpo,
title = {Maximum a Posteriori Policy Optimisation},
author = {A. Abdolmaleki and J. T. Springenberg and Y. Tassa and R. Munos and N. Heess and M. Riedmiller},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2018
}

@article{williams,
 author = {Williams, R. J.},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 journal = {Machine Learning},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 pages = {229--256}
} 

@article{WilliamsPeng91,
  author = {Williams, R. J. and Peng, J.},
  journal = {Connection Science},
  number = 3,
  pages = {241-268},
  title = {Function optimization using connectionist reinforcement learning
	algorithms},
  volume = 3,
  year = 1991
}

@book{sb-irl-98,
 author = {Sutton, R. S. and Barto, A. G.},
 title = {Introduction to Reinforcement Learning},
 year = {1998},
 isbn = {0262193981},
 edition = {1st},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@INPROCEEDINGS{suttonadp,
    author = {R. S. Sutton},
    title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {1990},
}

@inproceedings{pgq,
author = {O'Donoghue, B. and Munos, R. and Kavukcuoglu, K. and Mnih, V.},
year = {2017},
title = {PGQ: Combining policy gradient and Q-learning},
booktitle = {International Conference on Learning Representations (ICLR)}
}

@article{sallans,
 author = {Sallans, B. and Hinton, G. E.},
 title = {Reinforcement Learning with Factored States and Actions},
 journal = {Journal of Machine Learning Research},
 volume = {5},
 month = dec,
 year = {2004}
 },

@article{KLMSurvey,
    author = "L. P. Kaelbling and M. L. Littman and A. P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
url={http://people.csail.mit.edu/lpk/papers/rl-survey.ps}}

@inproceedings{todorov_kalman_duality, 
author={E. Todorov}, 
booktitle={Conference on Decision and Control (CDC)},
title={General duality between optimal control and estimation}, 
year={2008},
}

@inproceedings{covariant,
author = {J. A. Bagnell and J. Schneider},
title = {Covariant Policy Search},
booktitle = {International Joint Conference on Artifical Intelligence (IJCAI)},
year = {2003},
}

@InProceedings{reps,
  author =       "Peters, J. and  M{\"u}lling, K. and Alt{\"u}n, Y.",
  title =        "Relative Entropy Policy Search",
  booktitle =    "AAAI Conference on Artificial Intelligence (AAAI)",
  year =         "2010",
}

@inproceedings{mfgps,
title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
author = {Levine, S. and Abbeel, P.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{lmdp_policy,
  author    = {E. Todorov},
  title     = {Policy gradients in linearly-solvable MDPs},
  booktitle = {Neural Information Processing Systems (NIPS)},
  year      = {2010},
}

@inproceedings{ldmp_irl,
 author = {Dvijotham, K. and Todorov, E.},
 title = {Inverse Optimal Control with Linearly-solvable MDPs},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2010},
} 

@inproceedings{bear,
title = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
author = {Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
booktitle = {Neural Information Processing Systems (NeurIPS)},
year = {2019}
}

@article{lerer2016learning,
  title={Learning physical intuition of block towers by example},
  author={Lerer, Adam and Gross, Sam and Fergus, Rob},
  journal={arXiv preprint arXiv:1603.01312},
  year={2016}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@inproceedings{battaglia2016interaction,
  title={Interaction networks for learning about objects, relations and physics},
  author={Battaglia, Peter and Pascanu, Razvan and Lai, Matthew and Rezende, Danilo Jimenez and others},
  booktitle={Advances in neural information processing systems},
  pages={4502--4510},
  year={2016}
}

@inproceedings{sagawa2019distributionally,
  title={Distributionally Robust Neural Networks},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1907.02893},
  year={2019}
}

@article{sinha2017certifying,
  title={Certifying some distributional robustness with principled adversarial training},
  author={Sinha, Aman and Namkoong, Hongseok and Duchi, John},
  journal={arXiv preprint arXiv:1710.10571},
  year={2017}
}

@inproceedings{kingma2014semi,
  title={Semi-supervised learning with deep generative models},
  author={Kingma, Durk P and Mohamed, Shakir and Rezende, Danilo Jimenez and Welling, Max},
  booktitle={Advances in neural information processing systems},
  pages={3581--3589},
  year={2014}
}

@inproceedings{kendall2017uncertainties,
  title={What uncertainties do we need in bayesian deep learning for computer vision?},
  author={Kendall, Alex and Gal, Yarin},
  booktitle={Advances in neural information processing systems},
  pages={5574--5584},
  year={2017}
}

@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016}
}

@article{scholkopf2019causality,
  title={Causality for Machine Learning},
  author={Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:1911.10500},
  year={2019}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{van2018deep,
  title={Deep reinforcement learning and the deadly triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@inproceedings{pi2,
  title = {Learning Policy Improvements with Path Integrals},
  author = {Theodorou, E. A. and Buchli, J. and Schaal, S.},
  booktitle = {International Conference on  Artificial Intelligence and Statistics (AISTATS 2010)},
  year = {2010},
}

@InProceedings{trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {J. Schulman and S. Levine and P. Moritz and M. I. Jordan and P. Abbeel},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2015},
}

@phdthesis{levine_thesis,
author = {Levine, S.},
title = {Motor skill learning with local trajectory methods},
school = {Stanford University},
year = {2014},
}

@phdthesis{ziebart_thesis,
author = {Ziebart, B.},
title = {Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
school = {Carnegie Mellon University},
year = {2010},
}

@article{kappen_oc,
  author    = {H. J. Kappen},
  title     = {Optimal control theory and the linear bellman equation},
  journal   = {Inference and Learning in Dynamic Models},
  year      = {2011},
  pages     = {363-387},
}

@inproceedings{heess2015learning,
  title={Learning continuous control policies by stochastic value gradients},
  author={Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Timothy and Erez, Tom and Tassa, Yuval},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2944--2952},
  year={2015}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1352--1361},
  year={2017},
  organization={JMLR. org}
}

@article{kappen_pgm,
  author    = {H. J. Kappen and
               V. G{\'o}mez and
               M. Opper},
  title     = {Optimal control as a graphical model inference problem},
  journal   = {Machine Learning},
  volume    = {87},
  number    = {2},
  year      = {2012},
  pages     = {159-182},
}

@inproceedings{rawlik_soc,
  author    = {K. Rawlik and
               M. Toussaint and
               S. Vijayakumar},
  title     = {On Stochastic Optimal Control and Reinforcement Learning
               by Approximate Inference},
  year = {2013},
  booktitle = {Robotics: Science and Systems (RSS)},
}

@inproceedings{toussaint_soc,
  author    = {M. Toussaint},
  title     = {Robot trajectory optimization using approximate inference},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2009},
}

@inproceedings{toussaint_pgm,
  title={Hierarchical POMDP Controller Optimization by Likelihood Maximization},
  author={Toussaint, M. and Charlin, L. and Poupart, P.},
  booktitle={Uncertainty in Artificial Intelligence (UAI)},
  volume={24},
  pages={562--570},
  year={2008}
}

@article{kalman_filter,
  author={R. Kalman},
  title={A new approach to linear filtering and prediction problems},
  journal={ASME Transactions journal of basic engineering},
  volume={82},
  number={1},
  pages={35-45},
  year={1960}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}

@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{todorov_lmdp,
  author    = {E. Todorov},
  title     = {Linearly-solvable Markov decision problems},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2006},
}

@inproceedings{rwr,
 author = {Peters, J. and Schaal, S.},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2007},
} 


@inproceedings{neumann,
  author    = {G. Neumann},
  title     = {Variational Inference for Policy Search in changing situations},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2011},
}

@inproceedings{levine_vgps,
  author    = {S. Levine and V. Koltun},
  title     = {Variational policy search via trajectory optimization},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2013},
}

@inproceedings{em_policy_search,
  title = {Efficient Sample Reuse in EM-Based Policy Search},
  author = {Hachiya, H. and Peters, J. and Sugiyama, M.},
  booktitle = {European Conference on Machine Learning (ECML)},
  year = {2009},
}

@article{vmp,
    title={Variational message passing},
    author={Winn, J. and Bishop, C.},
    journal={Journal of Machine Learning Research},
    volume={6},
    year={2005},
    pages={661-694}
}

@inproceedings{haarnoja,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, T. and Tang, H. and Abbeel, P. and Levine, S.},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{sac,
title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
author  = {T. Haarnoja and A. Zhou and P. Abbeel and S. Levine},
year  = {2018},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1801.01290.pdf}
}

@inproceedings{d4rl,
title = {D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
author  = {J. Fu and A. Kumar and O. Nachum and G. Tucker and S. Levine},
year  = {2020},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/2004.07219}
}

@inproceedings{pcl,
title = {Bridging the Gap Between Value and Policy Based Reinforcement Learning},
author  = {O. Nachum and M. Norouzi and K. Xu and D. Schuurmans},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1702.08892.pdf}
}

@inproceedings{gps,
 author = {Levine, S. and Koltun, V.},
 title = {Guided Policy Search},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2013},
} 

@inproceedings{maxentirl,
 author = {Ziebart, B. D. and Maas, A. and Bagnell, J. A. and Dey, A. K.},
 title = {Maximum Entropy Inverse Reinforcement Learning},
 booktitle = {International Conference on Artificial Intelligence (AAAI)},
 year = {2008},
} 

@inproceedings{haarnoja_composable,
author = {Haarnjoa, T. and Pong, V. and Zhou, A. and Dalal, M. and Abbeel, P. and Levine, S.},
title = {Composable Deep Reinforcement Learning for Robotic Manipulation},
booktitle = {International Conference on Robotics and Automation (ICRA)},
year = {2018},
}

@article{trust_pcl,
  author    = {O. Nachum and
               M. Norouzi and
               K. Xu and
               D. Schuurmans},
  title     = {Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1707.01891},
  year      = {2017},
}

@inproceedings{gpirl,
 author = {Levine, S. and Popovi\'{c}, Z. and Koltun, V.},
 title = {Nonlinear Inverse Reinforcement Learning with Gaussian Processes},
 booktitle = {Neural Information Processing Systems (NIPS)},
 year = {2011},
}

@inproceedings{localioc,
    author = {S. Levine and V. Koltun},
    title = {Continuous Inverse Optimal Control with Locally Optimal Examples},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2012},
}

@inproceedings{legibility,
  author    = {A. D. Dragan and
               K. C. T. Lee and
               S. S. Srinivasa},
  title     = {Legibility and predictability of robot motion},
  booktitle = {International Conference on Human-Robot Interaction (HRI)},
  year      = {2013},
}

@inproceedings{maxentdeepirl,
author = {M. Wulfmeier and
P. Ondruska and
I. Posner},
title = {Maximum Entropy Deep Inverse Reinforcement Learning},
Booktitle = {Neural Information Processing Systems Conference, Deep Reinforcement Learning Workshop},
year = {2015},
}

@inproceedings{maxcausalent,
  author    = {B. D. Ziebart and
               J. A. Bagnell and
               A. K. Dey},
  title     = {Modeling Interaction via the Principle of Maximum Causal Entropy},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2010},
}

@inproceedings{kitani1,
  author    = {D. Huang and
               K. M. Kitani},
  title     = {Action-Reaction: Forecasting the Dynamics of Human Interaction},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2014},
}

@inproceedings{kitani2,
  author    = {D. Huang and
               A. Farahmand and
               K. M. Kitani and
               J. A. Bagnell},
  title     = {Approximate {MaxEnt} Inverse Optimal Control and Its Application for
               Mental Simulation of Human Interactions},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2015},
}

@article{realnvp,
title={Latent Space Policies for Hierarchical Reinforcement Learning},
author={T. Haarnoja and K. Hartikainen and P. Abbeel and S. Levine},
journal   = {CoRR},
volume    = {abs/1804.02808},
year      = {2018},
}

@inproceedings{Javdani, 
    AUTHOR    = {S. Javdani and S. Srinivasa and J. A. Bagnell}, 
    TITLE     = {Shared Autonomy via Hindsight Optimization}, 
    BOOKTITLE = {Robotics: Science and Systems (RSS)}, 
    YEAR      = {2015}, 
}

@inproceedings{airl,
title={Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
author={Fu, J. and Luo, K. and Levine, S.},
}

@inproceedings{hausman,
title={Learning an Embedding Space for Transferable Robot Skills},
author={K. Hausman and J. T. Springenberg and Z. Wang and N. Heess and M. Riedmiller},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
}

@article{learning_to_explore,
  author    = {A. Gupta and
               R. Mendonca and
               Y. Liu and
               P. Abbeel and
               S. Levine},
  title     = {Meta-Reinforcement Learning of Structured Exploration Strategies},
  journal   = {CoRR},
  volume    = {abs/1802.07245},
  year      = {2018},
}

@article{endtoend,
 author = {Levine, S. and Finn, C. and Darrell, T. and Abbeel, P.},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {Journal of Machine Learning Research},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
} 

@inproceedings{cgps,
    author = {Sergey Levine and Vladlen Koltun},
    title = {Learning Complex Neural Network Policies with Trajectory Optimization},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2014},
}
@inproceedings{schulman,
title = {Equivalence Between Policy Gradients and Soft Q-Learning},
author  = {J. Schulman and X. Chen and P. Abbeel},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1704.06440}
}

@inproceedings{nvil,
  author    = {A. Mnih and
               K. Gregor},
  title     = {Neural Variational Inference and Learning in Belief Networks},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2014}
}

@inproceedings{gcl,
  author    = {Chelsea Finn and
               Sergey Levine and
               Pieter Abbeel},
  title     = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
    booktitle   = {International Conference on Machine Learning (ICML)},
  year      = {2016},
}

@inproceedings{gan,
title = {Generative Adversarial Nets},
author = {Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{gail,
title = {Generative Adversarial Imitation Learning},
author = {Ho, J. and Ermon, S.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2016},
}

@article{finn_adversarial,
  author    = {Chelsea Finn and
               Paul Christiano and
               Pieter Abbeel and
               Sergey Levine},
  title     = {A Connection between Generative Adversarial Networks, Inverse Reinforcement
               Learning, and Energy-Based Models},
  journal   = {CoRR},
  volume    = {abs/1611.03852},
  year      = {2016},
}

@inproceedings{bornschein2016bidirectional,
  title={Bidirectional helmholtz machines},
  author={Bornschein, Jorg and Shabanian, Samira and Fischer, Asja and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={2511--2519},
  year={2016}
}

@article{marino2018iterative,
  title={Iterative amortized inference},
  author={Marino, Joseph and Yue, Yisong and Mandt, Stephan},
  journal={arXiv preprint arXiv:1807.09356},
  year={2018}
}

@inproceedings{rasmus2015semi,
  title={Semi-supervised learning with ladder networks},
  author={Rasmus, Antti and Berglund, Mathias and Honkala, Mikko and Valpola, Harri and Raiko, Tapani},
  booktitle={Advances in neural information processing systems},
  pages={3546--3554},
  year={2015}
}

@inproceedings{sonderby2016ladder,
  title={Ladder variational autoencoders},
  author={S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
  booktitle={Advances in neural information processing systems},
  pages={3738--3746},
  year={2016}
}

@inproceedings{zhao2017learning,
  title={Learning hierarchical features from deep generative models},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={4091--4099},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{hsu2017unsupervised,
  title={Unsupervised learning of disentangled and interpretable representations from sequential data},
  author={Hsu, Wei-Ning and Zhang, Yu and Glass, James},
  booktitle={Advances in neural information processing systems},
  pages={1878--1889},
  year={2017}
}


@inproceedings{kalashnikov2018qtopt,
  title={Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  pages={651--673},
  year={2018}
}

@article{cabi2019framework,
  title={A Framework for Data-Driven Robotics},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and {\.Z}o{\l}na, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

 @article{Mo18AdobeIndoorNav,
        Author = {Kaichun Mo and Haoxiang Li and Zhe Lin and Joon-Young Lee},
        Title = {The AdobeIndoorNav Dataset: Towards Deep Reinforcement Learning based Real-world Indoor Robot Visual Navigation},
        Year = {2018},
        Eprint = {arXiv:1802.08824},
    }
    
@article{kandasamy2017batch,
  title={Batch policy gradient methods for improving neural conversation models},
  author={Kandasamy, Kirthevasan and Bachrach, Yoram and Tomioka, Ryota and Tarlow, Daniel and Carter, David},
  journal={arXiv preprint arXiv:1702.03334},
  year={2017}
}

@inproceedings{sun2018fast,
  title={A fast integrated planning and control framework for autonomous driving via imitation learning},
  author={Sun, Liting and Peng, Cheng and Zhan, Wei and Tomizuka, Masayoshi},
  booktitle={Dynamic Systems and Control Conference},
  volume={51913},
  pages={V003T37A012},
  year={2018},
  organization={American Society of Mechanical Engineers}
}

@article{zhou2017end,
  title={End-to-end offline goal-oriented dialog policy learning via policy gradient},
  author={Zhou, Li and Small, Kevin and Rokhlenko, Oleg and Elkan, Charles},
  journal={arXiv preprint arXiv:1712.02838},
  year={2017}
}

@article{pan2017agile,
  title={Agile autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{nie2019learning,
  title={Learning when-to-treat policies},
  author={Nie, Xinkun and Brunskill, Emma and Wager, Stefan},
  journal={arXiv preprint arXiv:1905.09751},
  year={2019}
}

@article{bojarski2016end,
  title={End to end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}

@article{yu2018bdd100k,
  title={Bdd100k: A diverse driving video database with scalable annotation tooling},
  author={Yu, Fisher and Xian, Wenqi and Chen, Yingying and Liu, Fangchen and Liao, Mike and Madhavan, Vashisht and Darrell, Trevor},
  journal={arXiv preprint arXiv:1805.04687},
  year={2018}
}

@article{sallab2017deep,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}

@article{yurtsever2020survey,
  title={A survey of autonomous driving: Common practices and emerging technologies},
  author={Yurtsever, Ekim and Lambert, Jacob and Carballo, Alexander and Takeda, Kazuya},
  journal={IEEE Access},
  year={2020},
  publisher={IEEE}
}

@inproceedings{kendall2019learning,
  title={Learning to drive in a day},
  author={Kendall, Alex and Hawke, Jeffrey and Janz, David and Mazur, Przemyslaw and Reda, Daniele and Allen, John-Mark and Lam, Vinh-Dieu and Bewley, Alex and Shah, Amar},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8248--8254},
  year={2019},
  organization={IEEE}
}

@article{maddern2017robotcar,
  title={1 year, 1000 km: The Oxford RobotCar dataset},
  author={Maddern, Will and Pascoe, Geoffrey and Linegar, Chris and Newman, Paul},
  journal={The International Journal of Robotics Research},
  volume={36},
  number={1},
  pages={3--15},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{codevilla2018end,
  title={End-to-end driving via conditional imitation learning},
  author={Codevilla, Felipe and Miiller, Matthias and L{\'o}pez, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1--9},
  year={2018},
  organization={IEEE}
}

@inproceedings{tassa2012synthesis,
  title={Synthesis and stabilization of complex behaviors through online trajectory optimization},
  author={Tassa, Yuval and Erez, Tom and Todorov, Emanuel},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={4906--4913},
  year={2012},
  organization={IEEE}
}

@inproceedings{pets,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4754--4765},
  year={2018}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{pietquin2011sample,
  title={Sample-efficient batch reinforcement learning for dialogue management optimization},
  author={Pietquin, Olivier and Geist, Matthieu and Chandramohan, Senthilkumar and Frezza-Buet, Herv{\'e}},
  journal={ACM Transactions on Speech and Language Processing (TSLP)},
  volume={7},
  number={3},
  pages={1--21},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@article{gottesman2019guidelines,
  title={Guidelines for reinforcement learning in healthcare},
  author={Gottesman, Omer and Johansson, Fredrik and Komorowski, Matthieu and Faisal, Aldo and Sontag, David and Doshi-Velez, Finale and Celi, Leo Anthony},
  journal={Nat Med},
  volume={25},
  number={1},
  pages={16--18},
  year={2019}
}

@inproceedings{swaminathan2015self,
  title={The self-normalized estimator for counterfactual learning},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={advances in neural information processing systems},
  pages={3231--3239},
  year={2015}
}

@book{rockafellar1970convex,
  title={Convex analysis},
  author={Rockafellar, R Tyrrell},
  number={28},
  year={1970},
  publisher={Princeton university press}
}

@article{nachum2020reinforcement,
  title={Reinforcement Learning via Fenchel-Rockafellar Duality},
  author={Nachum, Ofir and Dai, Bo},
  journal={arXiv preprint arXiv:2001.01866},
  year={2020}
}

@inproceedings{nachum2019dualdice,
  title={Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections},
  author={Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2315--2325},
  year={2019}
}

@article{eysenbach2017leave,
  title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
  author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.06782},
  year={2017}
}

@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@inproceedings{osband2018randomized,
  title={Randomized prior functions for deep reinforcement learning},
  author={Osband, Ian and Aslanides, John and Cassirer, Albin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8617--8629},
  year={2018}
}

@article{agarwal2019optimistic,
  title={An Optimistic Perspective on Offline Reinforcement Learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  year={2019}
}

@inproceedings{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Advances in neural information processing systems},
  pages={6402--6413},
  year={2017}
}

@article{achiam2019towards,
  title={Towards characterizing divergence in deep q-learning},
  author={Achiam, Joshua and Knight, Ethan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1903.08894},
  year={2019}
}

@article{gupta2019relay,
  title={Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:1910.11956},
  year={2019}
}

@inproceedings{osband2016deep,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={4026--4034},
  year={2016}
}

@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={Journal of machine learning research},
  volume={4},
  number={Dec},
  pages={1107--1149},
  year={2003}
}

@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM Sigart Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011}
}

@article{johnson2016mimic,
  title={MIMIC-III, a freely accessible critical care database},
  author={Johnson, Alistair EW and Pollard, Tom J and Shen, Lu and Li-wei, H Lehman and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Celi, Leo Anthony and Mark, Roger G},
  journal={Scientific data},
  volume={3},
  pages={160035},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{guez2008adaptive,
  title={Adaptive Treatment of Epilepsy via Batch-mode Reinforcement Learning.},
  author={Guez, Arthur and Vincent, Robert D and Avoli, Massimo and Pineau, Joelle},
  booktitle={AAAI},
  pages={1671--1678},
  year={2008}
}

@article{pipps,
  title={PIPPS: Flexible model-based policy search robust to the curse of chaos},
  author={Parmas, Paavo and Rasmussen, Carl Edward and Peters, Jan and Doya, Kenji},
  journal={arXiv preprint arXiv:1902.01240},
  year={2019}
}

@article{simpl,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@inproceedings{mbpo,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12498--12509},
  year={2019}
}

@article{raghu2017deep,
  title={Deep reinforcement learning for sepsis treatment},
  author={Raghu, Aniruddh and Komorowski, Matthieu and Ahmed, Imran and Celi, Leo and Szolovits, Peter and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:1711.09602},
  year={2017}
}

@article{prasad2017reinforcement,
  title={A reinforcement learning approach to weaning of mechanical ventilation in intensive care units},
  author={Prasad, Niranjani and Cheng, Li-Fang and Chivers, Corey and Draugelis, Michael and Engelhardt, Barbara E},
  journal={arXiv preprint arXiv:1704.06300},
  year={2017}
}

@inproceedings{swaminathan2017off,
  title={Off-policy evaluation for slate recommendation},
  author={Swaminathan, Adith and Krishnamurthy, Akshay and Agarwal, Alekh and Dudik, Miro and Langford, John and Jose, Damien and Zitouni, Imed},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3632--3642},
  year={2017}
}

@article{wu2019behavior,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@inproceedings{osband2017posterior,
  title={Why is posterior sampling better than optimism for reinforcement learning?},
  author={Osband, Ian and Van Roy, Benjamin},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2701--2710},
  year={2017},
  organization={JMLR. org}
}

@article{peng2019awr,
  title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{sriperumbudur2009integral,
  title={On integral probability metrics,$\backslash$phi-divergences and binary classification},
  author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG},
  journal={arXiv preprint arXiv:0901.2698},
  year={2009}
}

@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}

@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11761--11771},
  year={2019}
}

@article{siegel2020keep,
  title={Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning},
  author={Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Riedmiller, Martin},
  journal={arXiv preprint arXiv:2002.08396},
  year={2020}
}

@inproceedings{nowozin2016f,
  title={f-gan: Training generative neural samplers using variational divergence minimization},
  author={Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
  booktitle={Advances in neural information processing systems},
  pages={271--279},
  year={2016}
}

@article{wu2019domain,
  title={Domain adaptation with asymmetrically-relaxed distribution alignment},
  author={Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  journal={arXiv preprint arXiv:1903.01689},
  year={2019}
}

@inproceedings{sutton2009fastgtd,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={993--1000},
  year={2009}
}

@article{levine2020offline,
  title={Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{alphastar,
  title={Mastering the Real-Time Strategy Game StarCraft II},
  author={AlphaStar, DeepMind},
  journal={URL: https://deepmind. com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii}
}

@article{lu2018general,
  title={A General Family of Robust Stochastic Operators for Reinforcement Learning},
  author={Lu, Yingdong and Squillante, Mark S and Wu, Chai Wah},
  journal={arXiv preprint arXiv:1805.08122},
  year={2018}
}

@inproceedings{
Zhang2020GenDICE:,
title={GenDICE: Generalized Offline Estimation of Stationary Values},
author={Ruiyi Zhang and Bo Dai and Lihong Li and Dale Schuurmans},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HkxlcnVFwB}
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{bellemare2016increasing,
  title={Increasing the action gap: New operators for reinforcement learning},
  author={Bellemare, Marc G and Ostrovski, Georg and Guez, Arthur and Thomas, Philip S and Munos, R{\'e}mi},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{rajeswaran2018dapg,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2018}
}

@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@misc{
sachdeva2020offpolicy,
title={Off-policy Bandits with Deficient Support},
author={Noveen Sachdeva and Yi Su and Thorsten Joachims},
year={2020},
url={https://openreview.net/forum?id=SklcyJBtvB}
}

@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 19th international conference on World wide web},
  pages={661--670},
  year={2010}
}

@article{o2018variational,
  title={Variational Bayesian reinforcement learning with regret bounds},
  author={O'Donoghue, Brendan},
  journal={arXiv preprint arXiv:1807.09647},
  year={2018}
}

@inproceedings{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado V},
  booktitle={Advances in neural information processing systems},
  pages={2613--2621},
  year={2010}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@InProceedings{fujimoto2018addressing,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@incollection{ntk,
title = {Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
booktitle = {Advances in Neural Information Processing Systems 31},
year = {2018},
url = {}
}

@misc{d4rl_repo,
title = {D4RL: Datasets for Data-Driven Deep Reinforcement Learning},
author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
note = {Github repository},
year = {2020},
howpublished  = {\url{https://github.com/rail-berkeley/d4rl/wiki/New-Franka-Kitchen-Tasks}}
}

@article{furuichi2004fundamental,
  title={Fundamental properties of Tsallis relative entropy},
  author={Furuichi, Shigeru and Yanagi, Kenjiro and Kuriyama, Ken},
  journal={Journal of Mathematical Physics},
  volume={45},
  number={12},
  pages={4868--4877},
  year={2004},
  publisher={American Institute of Physics}
}

@inproceedings{namkoong2017variance,
  title={Variance-based regularization with convex objectives},
  author={Namkoong, Hongseok and Duchi, John C},
  booktitle={Advances in neural information processing systems},
  pages={2971--2980},
  year={2017}
}

@inproceedings{tamar2014scaling,
  title={Scaling up robust MDPs using function approximation},
  author={Tamar, Aviv and Mannor, Shie and Xu, Huan},
  booktitle={International Conference on Machine Learning},
  pages={181--189},
  year={2014}
}

@article{nair2020accelerating,
  title={Accelerating Online Reinforcement Learning with Offline Datasets},
  author={Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@inproceedings{nilim2004robustness,
  title={Robustness in Markov decision problems with uncertain transition matrices},
  author={Nilim, Arnab and El Ghaoui, Laurent},
  booktitle={Advances in neural information processing systems},
  pages={839--846},
  year={2004}
}

@article{russel2018tight,
  title={Tight bayesian ambiguity sets for robust MDPs},
  author={Russel, Reazul Hasan and Petrik, Marek},
  journal={arXiv preprint arXiv:1811.06512},
  year={2018}
}

@article{iyengar2005robust,
  title={Robust dynamic programming},
  author={Iyengar, Garud N},
  journal={Mathematics of Operations Research},
  volume={30},
  number={2},
  pages={257--280},
  year={2005},
  publisher={INFORMS}
}

@inproceedings{ghavamzadeh2016safe,
  title={Safe policy improvement by minimizing robust baseline regret},
  author={Petrik, Marek and Ghavamzadeh, Mohammad and Chow, Yinlam},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2298--2306},
  year={2016}
}

@inproceedings{strehl2010learning,
  title={Learning from logged implicit exploration data},
  author={Strehl, Alex and Langford, John and Li, Lihong and Kakade, Sham M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2217--2225},
  year={2010}
}

@article{simao2019safe,
  title={Safe Policy Improvement with an Estimated Baseline Policy},
  author={Sim{\~a}o, Thiago D and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1909.05236},
  year={2019}
}

@article{laroche2017safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1712.06924},
  year={2017}
}

@article{nachum2019algaedice,
  title={AlgaeDICE: Policy Gradient from Arbitrary Experience},
  author={Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1912.02074},
  year={2019}
}

@article{brac,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}

@article{kumar2020discor,
  title={DisCor: Corrective Feedback in Reinforcement Learning via Distribution Correction},
  author={Kumar, Aviral and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2003.07305},
  year={2020}
}

@inproceedings{o2018uncertainty,
  title={The Uncertainty Bellman Equation and Exploration},
  author={O’Donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Volodymyr},
  booktitle={International Conference on Machine Learning},
  pages={3836--3845},
  year={2018}
}

@inproceedings{gilotte2018offline,
  title={Offline a/b testing for recommender systems},
  author={Gilotte, Alexandre and Calauz{\`e}nes, Cl{\'e}ment and Nedelec, Thomas and Abraham, Alexandre and Doll{\'e}, Simon},
  booktitle={Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
  pages={198--206},
  year={2018}
}

@article{bottou2013counterfactual,
  title={Counterfactual reasoning and learning systems: The example of computational advertising},
  author={Bottou, L{\'e}on and Peters, Jonas and Qui{\~n}onero-Candela, Joaquin and Charles, Denis X and Chickering, D Max and Portugaly, Elon and Ray, Dipankar and Simard, Patrice and Snelson, Ed},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={3207--3260},
  year={2013},
  publisher={JMLR. org}
}

@inproceedings{theocharous2015personalized,
  title={Personalized ad recommendation systems for life-time value optimization with guarantees},
  author={Theocharous, Georgios and Thomas, Philip S and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}


@article{henderson2008hybrid,
  title={Hybrid reinforcement/supervised learning of dialogue policies from fixed data sets},
  author={Henderson, James and Lemon, Oliver and Georgila, Kallirroi},
  journal={Computational Linguistics},
  volume={34},
  number={4},
  pages={487--511},
  year={2008},
  publisher={MIT Press}
}

@article{jaques2019way,
  title={Way off-policy batch deep reinforcement learning of implicit human preferences in dialog},
  author={Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang and Picard, Rosalind},
  journal={arXiv preprint arXiv:1907.00456},
  year={2019}
}

@inproceedings{tesauro2006hybrid,
  title={A hybrid reinforcement learning approach to autonomic resource allocation},
  author={Tesauro, Gerald and Jong, Nicholas K and Das, Rajarshi and Bennani, Mohamed N},
  booktitle={2006 IEEE International Conference on Autonomic Computing},
  pages={65--73},
  year={2006},
  organization={IEEE}
}

@inproceedings{nazari2018reinforcement,
  title={Reinforcement learning for solving the vehicle routing problem},
  author={Nazari, Mohammadreza and Oroojlooy, Afshin and Snyder, Lawrence and Tak{\'a}c, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9839--9849},
  year={2018}
}

@article{balaji2010urban,
  title={Urban traffic signal control using reinforcement learning agents},
  author={Balaji, PG and German, X and Srinivasan, Dipti},
  journal={IET Intelligent Transport Systems},
  volume={4},
  number={3},
  pages={177--188},
  year={2010},
  publisher={IET}
}

@inproceedings{hein2017industrial,
  title={Batch reinforcement learning on the industrial benchmark: First experiences},
  author={Hein, Daniel and Udluft, Steffen and Tokic, Michel and Hentschel, Alexander and Runkler, Thomas A and Sterzing, Volkmar},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
  pages={4214--4221},
  year={2017},
  organization={IEEE}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}

@article{espeholt2018impala,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  journal={arXiv preprint arXiv:1802.01561},
  year={2018}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={22--31},
  year={2017},
  organization={JMLR. org}
}


@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@article{fu2019diagnosing,
  title={Diagnosing bottlenecks in deep {Q}-learning algorithms},
  author={Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  journal={arXiv preprint arXiv:1902.10250},
  year={2019}
}

@inproceedings{imani2018off,
  title={An off-policy policy gradient theorem using emphatic weightings},
  author={Imani, Ehsan and Graves, Eric and White, Martha},
  booktitle={Advances in Neural Information Processing Systems},
  pages={96--106},
  year={2018}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year={2014}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{gu2017interpolated,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in neural information processing systems},
  pages={3846--3855},
  year={2017}
}

@inproceedings{gelada2019off,
  title={Off-policy deep reinforcement learning by bootstrapping the covariate shift},
  author={Gelada, Carles and Bellemare, Marc G},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={3647--3655},
  year={2019}
}

@article{gabel2008adaptive,
  title={Adaptive reactive job-shop scheduling with reinforcement learning agents},
  author={Gabel, Thomas and Riedmiller, Martin},
  journal={International Journal of Information Technology and Intelligent Computing},
  volume={24},
  number={4},
  pages={14--18},
  year={2008},
  publisher={Citeseer}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@article{peshkin2002learning,
  title={Learning from scarce experience},
  author={Peshkin, Leonid and Shelton, Christian R},
  journal={arXiv preprint cs/0204043},
  year={2002}
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={ICML},
  pages={417--424},
  year={2001}
}

@inproceedings{hallak2017consistent,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1372--1383},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{thomas2016data,
  title={Data-efficient off-policy policy evaluation for reinforcement learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={2139--2148},
  year={2016}
}

@inproceedings{wang2017optimal,
  title={Optimal and adaptive off-policy evaluation in contextual bandits},
  author={Wang, Yu-Xiang and Agarwal, Alekh and Dudik, Miroslav},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3589--3597},
  year={2017},
  organization={JMLR. org}
}

@article{jiang2015doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  journal={arXiv preprint arXiv:1511.03722},
  year={2015}
}

@article{farajtabar2018more,
  title={More robust doubly robust off-policy evaluation},
  author={Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1802.03493},
  year={2018}
}

@inproceedings{thomas2015high,
  title={High confidence policy improvement},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={2380--2388},
  year={2015}
}

@article{chen2019information,
  title={Information-theoretic considerations in batch reinforcement learning},
  author={Chen, Jinglin and Jiang, Nan},
  journal={arXiv preprint arXiv:1905.00360},
  year={2019}
}

@inproceedings{scherrer2014approximate,
  title={Approximate policy iteration schemes: a comparison},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={1314--1322},
  year={2014}
}

@inproceedings{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={568--576},
  year={2010}
}

@article{xie2020q,
  title={Q* Approximation Schemes for Batch Reinforcement Learning: A eoretical Comparison},
  author={Xie, Tengyang and Jiang, Nan},
  year={2020}
}

@inproceedings{hanna2017bootstrapping,
  title={Bootstrapping with models: Confidence intervals for off-policy evaluation},
  author={Hanna, Josiah P and Stone, Peter and Niekum, Scott},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{thomas2015higheval,
  title={High-confidence off-policy evaluation},
  author={Thomas, Philip S and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015}
}


@article{gu2016q,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}

@article{nadjahi2019safe,
  title={Safe Policy Improvement with Soft Baseline Bootstrapping},
  author={Nadjahi, Kimia and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1907.05079},
  year={2019}
}

@article{cheng2019trajectory,
  title={Trajectory-wise control variates for variance reduction in policy gradient methods},
  author={Cheng, Ching-An and Yan, Xinyan and Boots, Byron},
  journal={arXiv preprint arXiv:1908.03263},
  year={2019}
}

@article{pankov2018reward,
  title={Reward-estimation variance elimination in sequential decision processes},
  author={Pankov, Sergey},
  journal={arXiv preprint arXiv:1811.06225},
  year={2018}
}

@article{huang2019importance,
  title={From Importance Sampling to Doubly Robust Policy Gradient},
  author={Huang, Jiawei and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.09066},
  year={2019}
}

@article{sutton2016emphatic,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{yu2015convergence,
  title={On convergence of emphatic temporal-difference learning},
  author={Yu, Huizhen},
  booktitle={Conference on Learning Theory},
  pages={1724--1751},
  year={2015}
}

@inproceedings{hallak2016generalized,
  title={Generalized emphatic temporal difference learning: Bias-variance analysis},
  author={Hallak, Assaf and Tamar, Aviv and Munos, R{\'e}mi and Mannor, Shie},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{zhang2019generalized,
  title={Generalized off-policy actor-critic},
  author={Zhang, Shangtong and Boehmer, Wendelin and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1999--2009},
  year={2019}
}

@article{hallak2015emphatic,
  title={Emphatic TD Bellman Operator is a Contraction},
  author={Hallak, Assaf and Tamar, Aviv and Mannor, Shie},
  journal={arXiv preprint arXiv:1508.03411},
  year={2015}
}

@inproceedings{liu2018breaking,
  title={Breaking the curse of horizon: Infinite-horizon off-policy estimation},
  author={Liu, Qiang and Li, Lihong and Tang, Ziyang and Zhou, Dengyong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5356--5366},
  year={2018}
}

@article{liu2019off,
  title={Off-policy policy gradient with state distribution correction},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={arXiv preprint arXiv:1904.08473},
  year={2019}
}

@article{mousavi2020black,
  title={Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning},
  author={Mousavi, Ali and Li, Lihong and Liu, Qiang and Zhou, Denny},
  journal={arXiv preprint arXiv:2003.11126},
  year={2020}
}

@article{kallus2019efficiently,
  title={Efficiently breaking the curse of horizon: Double reinforcement learning in infinite-horizon processes},
  author={Kallus, Nathan and Uehara, Masatoshi},
  journal={arXiv preprint arXiv:1909.05850},
  year={2019}
}

@inproceedings{kallus2019intrinsically,
  title={Intrinsically efficient, stable, and bounded off-policy evaluation for reinforcement learning},
  author={Kallus, Nathan and Uehara, Masatoshi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3320--3329},
  year={2019}
}

@article{uehara2019minimax,
  title={Minimax Weight and Q-Function Learning for Off-Policy Evaluation},
  author={Uehara, Masatoshi and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.12809},
  year={2019}
}

@article{tang2019doubly,
  title={Doubly robust bias reduction in infinite horizon off-policy estimation},
  author={Tang, Ziyang and Feng, Yihao and Li, Lihong and Zhou, Dengyong and Liu, Qiang},
  journal={arXiv preprint arXiv:1910.07186},
  year={2019}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{dai2017boosting,
  title={Boosting the actor with dual critic},
  author={Dai, Bo and Shaw, Albert and He, Niao and Li, Lihong and Song, Le},
  journal={arXiv preprint arXiv:1712.10282},
  year={2017}
}

@article{dai2017sbeed,
  title={SBEED: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  journal={arXiv preprint arXiv:1712.10285},
  year={2017}
}

@article{chen2016stochastic,
  title={Stochastic primal-dual methods and sample complexity of reinforcement learning},
  author={Chen, Yichen and Wang, Mengdi},
  journal={arXiv preprint arXiv:1612.02516},
  year={2016}
}

@inproceedings{wang2016online,
  title={An online primal-dual method for discounted markov decision processes},
  author={Wang, Mengdi and Chen, Yichen},
  booktitle={2016 IEEE 55th Conference on Decision and Control (CDC)},
  pages={4516--4521},
  year={2016},
  organization={IEEE}
}

@article{lee2018stochastic,
  title={Stochastic primal-dual Q-learning},
  author={Lee, Donghwan and He, Niao},
  journal={arXiv preprint arXiv:1810.08298},
  year={2018}
}

@inproceedings{swaminathan2015counterfactual,
  title={Counterfactual risk minimization: Learning from logged bandit feedback},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={International Conference on Machine Learning},
  pages={814--823},
  year={2015}
}

@STRING{aistats = {AISTATS}}
@STRING{cvpr = {CVPR}}
@STRING{emnlp = {EMNLP}}
@STRING{focs = {FOCS}}
@STRING{iccv = {ICCV}}
@STRING{icdr = {ICDR}}
@STRING{icml = {ICML}}
@STRING{ijcv = {IJCV}}
@STRING{jmlr = {JMLR}}
@STRING{nc = {Neural Comput.}}
@STRING{nips = {NeurIPS}}
@STRING{pami = {IEEE Trans. PAMI}}
@STRING{sigir = {SIGIR}}
@STRING{stoc = {STOC}}
@STRING{socg = {SoCG}}
@STRING{uai = {UAI}}
@STRING{vissapp = {VISSAPP}}
@STRING{eccv = {ECCV}}
@STRING{acl = {ACL}}
@STRING{iclr = {ICLR}}
@STRING{icassp = {ICASSP}}
@STRING{asru = {ASRU}}
@STRING{machlearning = {Mach. Learn. J.}}
@STRING{aaai = {AAAI}}
@STRING{naacl = {NAACL}}
@STRING{iros = {IROS}}
@STRING{tacl = {TACL}}
@STRING{corl = {CoRL}}
@STRING{ijcai = {IJCAI}}
@STRING{aamas = {AAMAS}}

@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={arXiv preprint arXiv:2106.01345},
  year={2021}
}

@article{cao2020heteroskedastic,
  title={Heteroskedastic and imbalanced deep learning with adaptive regularization},
  author={Cao, Kaidi and Chen, Yining and Lu, Junwei and Arechiga, Nikos and Gaidon, Adrien and Ma, Tengyu},
  journal={arXiv preprint arXiv:2006.15766},
  year={2020}
}

@inproceedings{
li2023efficient,
title={Efficient Deep Reinforcement Learning Requires Regulating Overfitting},
author={Qiyang Li and Aviral Kumar and Ilya Kostrikov and Sergey Levine},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=14-kr46GvP-}
}


@article{kostrikov2021offlineb,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@ARTICLE{2022arXiv221005178K,
       author = {{Kumar}, Aviral and {Singh}, Anikait and {Ebert}, Frederik and {Yang}, Yanlai and {Finn}, Chelsea and {Levine}, Sergey},
        title = "{Pre-Training for Robots: Offline RL Enables Learning New Tasks from a Handful of Trials}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Robotics, Computer Science - Machine Learning},
         year = 2022,
        month = oct,
          eid = {arXiv:2210.05178},
        pages = {arXiv:2210.05178},
          doi = {10.48550/arXiv.2210.05178},
archivePrefix = {arXiv},
       eprint = {2210.05178},
 primaryClass = {cs.RO},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2022arXiv221005178K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

@inproceedings{
mandlekar2021what,
title={What Matters in Learning from Offline Human Demonstrations for Robot Manipulation},
author={Ajay Mandlekar and Danfei Xu and Josiah Wong and Soroush Nasiriany and Chen Wang and Rohun Kulkarni and Fei-Fei Li and Silvio Savarese and Yuke Zhu and Roberto Mart{\'\i}n-Mart{\'\i}n},
booktitle={5th Annual Conference on Robot Learning },
year={2021},
url={https://openreview.net/forum?id=JrsfBJtDFdI}
}

@article{rashidinejad2021bridging,
  title={Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
  author={Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
  journal={arXiv preprint arXiv:2103.12021},
  year={2021}
}


@article{ebert2021bridge,
  title={Bridge Data: Boosting Generalization of Robotic Skills with Cross-Domain Datasets},
  author={Ebert, Frederik and Yang, Yanlai and Schmeckpeper, Karl and Bucher, Bernadette and Georgakis, Georgios and Daniilidis, Kostas and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2109.13396},
  year={2021}
}

@inproceedings{ettinger2021large,
  title={Large scale interactive motion forecasting for autonomous driving: The waymo open motion dataset},
  author={Ettinger, Scott and Cheng, Shuyang and Caine, Benjamin and Liu, Chenxi and Zhao, Hang and Pradhan, Sabeek and Chai, Yuning and Sapp, Ben and Qi, Charles R and Zhou, Yin and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9710--9719},
  year={2021}
}

@inproceedings{zheng2022online,
  title={Online decision transformer},
  author={Zheng, Qinqing and Zhang, Amy and Grover, Aditya},
  booktitle={International Conference on Machine Learning},
  pages={27042--27059},
  year={2022},
  organization={PMLR}
}

@article{Rafailov2020LOMPO,
  title={Offline Reinforcement Learning from Images with Latent Space Models},
  author={Rafael Rafailov and Tianhe Yu and A. Rajeswaran and Chelsea Finn},
  journal={Learning for Decision Making and Control (L4DC)},
  year={2021},
}

@article{argenson2020model,
  title={Model-Based Offline Planning},
  author={Argenson, Arthur and Dulac-Arnold, Gabriel},
  journal={arXiv preprint arXiv:2008.05556},
  year={2020}
}

@article{brandfonbrener2021offline,
  title={Offline RL Without Off-Policy Evaluation},
  author={Brandfonbrener, David and Whitney, William F and Ranganath, Rajesh and Bruna, Joan},
  journal={arXiv preprint arXiv:2106.08909},
  year={2021}
}

@article{kidambi2020morel,
  title={MOReL: Model-Based Offline Reinforcement Learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={arXiv preprint arXiv:2005.05951},
  year={2020}
}

@article{matsushima2020deployment,
  title={Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization},
  author={Matsushima, Tatsuya and Furuta, Hiroki and Matsuo, Yutaka and Nachum, Ofir and Gu, Shixiang},
  journal={arXiv preprint arXiv:2006.03647},
  year={2020}
}

@inproceedings{
lee2021representation,
title={Representation Balancing Offline Model-based Reinforcement Learning},
author={Byung-Jun Lee and Jongmin Lee and Kee-Eung Kim},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=QpNz8r_Ri2Y}
}

@article{swazinna2020overcoming,
  title={Overcoming Model Bias for Robust Offline Deep Reinforcement Learning},
  author={Swazinna, Phillip and Udluft, Steffen and Runkler, Thomas},
  journal={arXiv preprint arXiv:2008.05533},
  year={2020}
}

@article{emmons2021rvs,
  title={RvS: What is Essential for Offline RL via Supervised Learning?},
  author={Emmons, Scott and Eysenbach, Benjamin and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.10751},
  year={2021}
}

@article{rezaeifar2021offline,
  title={Offline reinforcement learning as anti-exploration},
  author={Rezaeifar, Shideh and Dadashi, Robert and Vieillard, Nino and Hussenot, L{\'e}onard and Bachem, Olivier and Pietquin, Olivier and Geist, Matthieu},
  journal={arXiv preprint arXiv:2106.06431},
  year={2021}
}

@article{zhou2020plas,
  title={PLAS: Latent Action Space for Offline Reinforcement Learning},
  author={Zhou, Wenxuan and Bajracharya, Sujay and Held, David},
  journal={arXiv preprint arXiv:2011.07213},
  year={2020}
}


@article{chen2022latent,
  title={Latent-Variable Advantage-Weighted Policy Optimization for Offline RL},
  author={Chen, Xi and Ghadirzadeh, Ali and Yu, Tianhe and Gao, Yuan and Wang, Jianhao and Li, Wenzhe and Liang, Bin and Finn, Chelsea and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2203.08949},
  year={2022}
}

@article{fujimoto2021minimalist,
  title={A Minimalist Approach to Offline Reinforcement Learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2106.06860},
  year={2021}
}

@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and {\.Z}o{\l}na, Konrad and Springenberg, Jost Tobias and Reed, Scott and Shahriari, Bobak and Siegel, Noah and Merel, Josh and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={arXiv preprint arXiv:2006.15134},
  year={2020}
}


@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2102.08363},
  year={2021}
}

@inproceedings{
kumar2022should,
title={Should I Run Offline Reinforcement Learning or Behavioral Cloning?},
author={Aviral Kumar and Joey Hong and Anikait Singh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=AP1MKT37rJ}
}


@article{zhang2019all,
  title={Are all layers created equal?},
  author={Zhang, Chiyuan and Bengio, Samy and Singer, Yoram},
  journal={arXiv preprint arXiv:1902.01996},
  year={2019}
}

@article{agarwal2021precipice,
  title={Deep Reinforcement Learning at the Edge of the Statistical Precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel
          and Courville, Aaron and Bellemare, Marc G},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}


@inproceedings{snoek2015scalable,
  title={Scalable bayesian optimization using deep neural networks},
  author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Prabhat, Mr and Adams, Ryan},
  booktitle={International conference on machine learning},
  pages={2171--2180},
  year={2015}
}


@article{schrittwieser2021online,
  title={Online and offline reinforcement learning by planning with a learned model},
  author={Schrittwieser, Julian and Hubert, Thomas and Mandhane, Amol and Barekatain, Mohammadamin and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:2104.06294},
  year={2021}
}

@article{bouthillier2021accounting,
  title={Accounting for variance in machine learning benchmarks},
  author={Bouthillier, Xavier and Delaunay, Pierre and Bronzi, Mirko and Trofimov, Assya and Nichyporuk, Brennan and Szeto, Justin and Mohammadi Sepahvand, Nazanin and Raff, Edward and Madan, Kanika and Voleti, Vikram and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={3},
  year={2021}
}

@inproceedings{li2019towards, 
 title={Towards explaining the regularization effect of initial large learning rate in training neural networks}, 
 author={Li, Yuanzhi and Wei, Colin and Ma, Tengyu}, 
 booktitle={Advances in Neural Information Processing Systems}, 
 pages={11674--11685}, 
 year={2019} 
 }

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{chen2019information,
  title={Information-theoretic considerations in batch reinforcement learning},
  author={Chen, Jinglin and Jiang, Nan},
  journal={ICML},
  year={2019}
}

@book{hastie2015sparsity,
author = {Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
title = {Statistical Learning with Sparsity: The Lasso and Generalizations},
year = {2015},
isbn = {1498712169},
publisher = {Chapman &amp; Hall/CRC},
}

@book{bellman1957dynamic,
  author =       "Bellman, Richard",
  title =        "Dynamic Programming",
  publisher =    "Princeton University Press",
  year =         "1957",
}


@inproceedings{boyan1999least,
  title={Least-squares temporal difference learning},
  author={Boyan, Justin A},
  booktitle={ICML},
  pages={49--56},
  year={1999},
  organization={Citeseer}
}

@article{igl2020impact,
  title={The Impact of Non-stationarity on Generalisation in Deep Reinforcement Learning},
  author={Igl, Maximilian and Farquhar, Gregory and Luketina, Jelena and Boehmer, Wendelin and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2006.05826},
  year={2020}
}

@article{xu2007kernel,
  title={Kernel-based least squares policy iteration for reinforcement learning},
  author={Xu, Xin and Hu, Dewen and Lu, Xicheng},
  journal={IEEE Transactions on Neural Networks},
  volume={18},
  number={4},
  pages={973--992},
  year={2007},
  publisher={IEEE}
}

@article{xu2005kernel,
  title={Kernel least-squares temporal difference learning},
  author={Xu, Xin and Xie, Tao and Hu, Dewen and Lu, Xicheng},
  journal={International Journal of Information Technology},
  volume={11},
  number={9},
  pages={54--63},
  year={2005}
}

@article{dabney2020value,
  title={The Value-Improvement Path: Towards Better Representations for Reinforcement Learning},
  author={Dabney, Will and Barreto, Andr{\'e} and Rowland, Mark and Dadashi, Robert and Quan, John and Bellemare, Marc G and Silver, David},
  journal={arXiv preprint arXiv:2006.02243},
  year={2020}
}

@techreport{townsend2016differentiating,
  title={Differentiating the singular value decomposition},
  author={Townsend, James},
  year={2016},
  institution={Technical Report 2016, https://j-towns. github. io/papers/svd-derivative~…}
}

@Inbook{Hlawka1991dirichlet,
author="Hlawka, Edmund
and Taschner, Rudolf
and Schoi{\ss}engeier, Johannes",
title="The Dirichlet Approximation Theorem",
bookTitle="Geometric and Analytic Number Theory",
year="1991",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--18",
isbn="978-3-642-75306-0",
doi="10.1007/978-3-642-75306-0_1",
url="https://doi.org/10.1007/978-3-642-75306-0_1"
}



@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@book{duffy2015green,
  title={Green's functions with applications},
  author={Duffy, Dean G},
  year={2015},
  publisher={CRC Press}
}

@article{jaderberg2016reinforcement,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}

@article{dabney2017distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1710.10044},
  year={2017}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@article{yang2019harnessing,
  title={Harnessing structures for value-based planning and reinforcement learning},
  author={Yang, Yuzhe and Zhang, Guo and Xu, Zhi and Katabi, Dina},
  journal={arXiv preprint arXiv:1909.12255},
  year={2019}
}

@article{fedus2020catastrophic,
  title={On Catastrophic Interference in Atari 2600 Games},
  author={Fedus, William and Ghosh, Dibya and Martin, John D and Bellemare, Marc G and Bengio, Yoshua and Larochelle, Hugo},
  journal={arXiv preprint arXiv:2002.12499},
  year={2020}
}

@article{paine2020hyperparameter,
  title={Hyperparameter selection for offline reinforcement learning},
  author={Paine, Tom Le and Paduraru, Cosmin and Michi, Andrea and Gulcehre, Caglar and Zolna, Konrad and Novikov, Alexander and Wang, Ziyu and de Freitas, Nando},
  journal={arXiv preprint arXiv:2007.09055},
  year={2020}
}

@article{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang M and Voloshin, Cameron and Yue, Yisong},
  journal={arXiv preprint arXiv:1903.08738},
  year={2019}
}

@inproceedings{gunasekar2018implicit,
  title={Implicit bias of gradient descent on linear convolutional networks},
  author={Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9461--9471},
  year={2018}
}

@inproceedings{luo2020i4r,
  title     = {I4R: Promoting Deep Reinforcement Learning by the Indicator for Expressive Representations},
  author    = {Luo, Xufang and Meng, Qi and He, Di and Chen, Wei and Wang, Yunhong},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  editor    = {Christian Bessiere},	
  pages     = {2669--2675},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/370},
  url       = {https://doi.org/10.24963/ijcai.2020/370},
}


@inproceedings{
Sanyal2020Stable,
title={Stable Rank Normalization for Improved Generalization in Neural Networks and GANs},
author={Amartya Sanyal and Philip H. Torr and Puneet K. Dokania},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=H1enKkrFDB}
}

@book{puterman1994markov,
  title={Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  author={Puterman, Martin L},
  year={1994},
  publisher={John Wiley \& Sons, Inc.}
}

@article{huber1964robust,
  title={Robust estimation of a location parameter},
  author={Huber, PJ},
  journal={Ann. Math. Stat.},
  year={1964}
}


@article{mnih2013playing,
  title={{Playing Atari with deep reinforcement learning}},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv:1312.5602},
  year={2013}
}





@inproceedings{
daskalakis2018training,
title={Training {GAN}s with Optimism},
author={Constantinos Daskalakis and Andrew Ilyas and Vasilis Syrgkanis and Haoyang Zeng},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJJySbbAZ},
}

@inproceedings{sutton1999PG,
  author    = {Richard S. Sutton and
               David A. McAllester and
               Satinder P. Singh and
               Yishay Mansour},
  editor    = {Sara A. Solla and
               Todd K. Leen and
               Klaus{-}Robert M{\"{u}}ller},
  title     = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
  booktitle = {Advances in Neural Information Processing Systems 12, {[NIPS} Conference,
               Denver, Colorado, USA, November 29 - December 4, 1999]},
}

@PhdThesis{Watkins1989,
  author =       "Watkins, Christopher John Cornish Hellaby",
  title =        "Learning from Delayed Rewards",
  school =       "King's College",
  year =         "1989",
  address =   "Cambridge, UK",
  month =     "May",
  url = "http://www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf",
  bib2html_rescat = "Parameter",
}

@inproceedings{hou2017novel,
  title={A novel ddpg method with prioritized experience replay},
  author={Hou, Yuenan and Liu, Lifeng and Wei, Qing and Xu, Xudong and Chen, Chunlin},
  booktitle={2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  pages={316--321},
  year={2017},
  organization={IEEE}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{horgan2018distper,
  author    = {Dan Horgan and
               John Quan and
               David Budden and
               Gabriel Barth{-}Maron and
               Matteo Hessel and
               Hado van Hasselt and
               David Silver},
  title     = {Distributed Prioritized Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1803.00933},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.00933},
  archivePrefix = {arXiv},
  eprint    = {1803.00933},
  timestamp = {Mon, 13 Aug 2018 16:46:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-00933.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{absention,
author = {Thulasidasan, Sunil and Bhattacharya, Tanmoy and Bilmes, Jeff and Chennupati, Gopinath and Mohd-Yusof, Jamal},
year = {2019},
month = {05},
booktitle = {Proceedings of 35th International Conference on Machine Learning},
title = {Combating Label Noise in Deep Learning Using Abstention}
}

@inproceedings{hassalt10doubleq,
 author = {Hasselt, Hado van},
 title = {Double Q-Learning},
 year = {2010},
 booktitle = {Proceedings of the 23rd International Conference on Neural Information Processing Systems - Volume 2}
}

@article{ODonoghue2017TheUB,
  title={The Uncertainty Bellman Equation and Exploration},
  author={Brendan O'Donoghue and Ian Osband and R{\'e}mi Munos and Volodymyr Mnih},
  journal={ICML},
  year={2018},
  volume={abs/1709.05380}
}

@inproceedings{hazan2019maxent,
title	= {Provably Efficient Maximum Entropy Exploration},
author	= {Elad Hazan and Sham Kakade and Karan Singh and Abby Van Soest},
year	= {2019},
journal = {ICML},
URL	= {https://arxiv.org/pdf/1812.02690.pdf}
}


@TECHREPORT{Tsitsiklis97ananalysis,
    author = {John N. Tsitsiklis and Benjamin Van Roy},
    title = {An analysis of temporal-difference learning with function approximation},
    institution = {IEEE Transactions on Automatic Control},
    year = {1997}
}

@inproceedings{rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{zhang2017deeper,
  title={A deeper look at experience replay},
  author={Zhang, Shangtong and Sutton, Richard S},
  journal={arXiv preprint arXiv:1712.01275},
  year={2017}
}

@inproceedings{liu2018effects,
  title={The effects of memory replay in reinforcement learning},
  author={Liu, Ruishan and Zou, James},
  booktitle={2018 56th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  year={2018},
  organization={IEEE}
}

@inproceedings{suggala2018connecting,
  title={Connecting optimization and regularization paths},
  author={Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10608--10619},
  year={2018}
}

@article{ruhe1975closeness,
  title={On the closeness of eigenvalues and singular values for almost normal matrices},
  author={Ruhe, Axel},
  journal={Linear Algebra and its Applications},
  volume={11},
  number={1},
  pages={87--93},
  year={1975},
  publisher={Elsevier}
}

@article{wu2019behavior,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@InProceedings{fujimoto19a,
  title = 	 {Off-Policy Deep Reinforcement Learning without Exploration},
  author = 	 {Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  year = 	 {2019},
}

@incollection{NIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8026--8037},
year = {2019},
}

@inproceedings{tensorflow,
title	= {TensorFlow: A system for large-scale machine learning},
author	= {Martin Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Geoffrey Irving and Michael Isard and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
year	= {2016},
URL	= {https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf},
booktitle	= {12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)},
pages	= {265--283}
}

@inproceedings{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang and Voloshin, Cameron and Yue, Yisong},
  booktitle={International Conference on Machine Learning},
  pages={3703--3712},
  year={2019},
  organization={PMLR}
}

@inproceedings{
fu2021benchmarks,
title={Benchmarks for Deep Off-Policy Evaluation},
author={Justin Fu and Mohammad Norouzi and Ofir Nachum and George Tucker and ziyu wang and Alexander Novikov and Mengjiao Yang and Michael R Zhang and Yutian Chen and Aviral Kumar and Cosmin Paduraru and Sergey Levine and Thomas Paine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=kWSeGEeHvF8}
}


@inproceedings{gulcehre2020rl,
  title={Rl unplugged: Benchmarks for offline reinforcement learning},
  author={Gulcehre, Caglar and Wang, Ziyu and Novikov, Alexander and Paine, Tom Le and Colmenarejo, Sergio G{\'o}mez and Zolna, Konrad and Agarwal, Rishabh and Merel, Josh and Mankowitz, Daniel and Paduraru, Cosmin and others},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@book{rummery1994line,
  title={On-line Q-learning using connectionist systems},
  author={Rummery, Gavin A and Niranjan, Mahesan},
  volume={37},
  year={1994}
}

@inproceedings{perkins2002api,
author = {Perkins, Theodore J. and Precup, Doina},
title = {A Convergent Form of Approximate Policy Iteration},
year = {2002},
series = {NIPS’02}
}

@inproceedings{gunasekar2017implicit,
  title={Implicit regularization in matrix factorization},
  author={Gunasekar, Suriya and Woodworth, Blake E and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6151--6159},
  year={2017}
}

@article{lstd,
  title={Linear least-squares algorithms for temporal difference learning},
  author={Bradtke, Steven J and Barto, Andrew G},
  journal={Machine learning},
  volume={22},
  number={1-3},
  pages={33--57},
  year={1996},
  publisher={Springer}
}

@article{bellemare2013ale,
author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
year = {2013},
issue_date = {May 2013},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {47},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
month = may,
pages = {253–279},
numpages = {27}
}
  
@article{yu2020gradient,
  title={Gradient Surgery for Multi-Task Learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={arXiv preprint arXiv:2001.06782},
  year={2020}
}

  
@incollection{ntk,
title = {Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
booktitle = {Advances in Neural Information Processing Systems 31},
year = {2018},
url = {}
}

@article{lorraine2019optimizing,
  title={Optimizing Millions of Hyperparameters by Implicit Differentiation},
  author={Lorraine, Jonathan and Vicol, Paul and Duvenaud, David},
  journal={arXiv preprint arXiv:1911.02590},
  year={2019}
}


@inproceedings{peters2010reps,
author = {Peters, Jan and M\"{u}lling, Katharina and Alt\"{u}n, Yasemin},
title = {Relative Entropy Policy Search},
year = {2010},
publisher = {AAAI Press},
booktitle = {Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence},
pages = {1607–1612},
numpages = {6},
location = {Atlanta, Georgia},
series = {AAAI’10}
}
  


@article{machado18sticky,
author = {Machado, Marlos C. and Bellemare, Marc G. and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
title = {Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents},
year = {2018},
issue_date = {January 2018},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {61},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
month = jan,
pages = {523–562},
numpages = {40}
}
  


@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={449--458},
  year={2017},
  organization={JMLR. org}
}


@article{castro18dopamine,
  author    = {Pablo Samuel Castro and
               Subhodeep Moitra and
               Carles Gelada and
               Saurabh Kumar and
               Marc G. Bellemare},
  title     = {Dopamine: {A} {R}esearch {F}ramework for {D}eep {R}einforcement {L}earning},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.06110},
  archivePrefix = {arXiv}
}

@article{scherrer15a,
  author  = {Bruno Scherrer and Mohammad Ghavamzadeh and Victor Gabillon and Boris Lesner and Matthieu Geist},
  title   = {Approximate Modified Policy Iteration and its Application to the Game of Tetris},
  journal = {Journal of Machine Learning Research},
  year    = {2015},
  volume  = {16},
  number  = {49},
  pages   = {1629-1676},
  url     = {http://jmlr.org/papers/v16/scherrer15a.html}
}

@article{Lesner2013TightPB,
  title={Tight Performance Bounds for Approximate Modified Policy Iteration with Non-Stationary Policies},
  author={Boris Lesner and Bruno Scherrer},
  journal={ArXiv},
  year={2013},
  volume={abs/1304.5610}
}

@inproceedings{scherrer_comparison,
author = {Scherrer, Bruno},
title = {Approximate Policy Iteration Schemes: A Comparison},
year = {2014},
publisher = {JMLR.org},
booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
pages = {II–1314–II–1322},
numpages = {9},
location = {Beijing, China},
series = {ICML’14}
}
  


@inproceedings{
du2020is,
title={Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?},
author={Simon S. Du and Sham M. Kakade and Ruosong Wang and Lin F. Yang},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=r1genAVKPB}
}

@inproceedings{munos2003api,
author = {Munos, R\'{e}mi},
title = {Error Bounds for Approximate Policy Iteration},
year = {2003},
isbn = {1577351894},
publisher = {AAAI Press},
booktitle = {Proceedings of the Twentieth International Conference on International Conference on Machine Learning},
pages = {560–567},
numpages = {8},
location = {Washington, DC, USA},
series = {ICML’03}
}
  


@inproceedings{yu2019meta,
  title={Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning},
  author={Tianhe Yu and Deirdre Quillen and Zhanpeng He and Ryan Julian and Karol Hausman and Chelsea Finn and Sergey Levine},
  booktitle={Conference on Robot Learning (CoRL)},
  year={2019},
  eprint={1910.10897},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1910.10897},
}

@article{kumar19bear,
  author       = {Aviral Kumar and Justin Fu and George Tucker and Sergey Levine},
  title        = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  conference   = {NeurIPS 2019},
  year = {2019},
  url          = {http://arxiv.org/abs/1906.00949},
}

@article{farias_fixed_points,
author = {Farias, D. and Roy, B.},
year = {2000},
month = {06},
pages = {589-608},
title = {On the Existence of Fixed Points for Approximate Value Iteration and Temporal-Difference Learning},
volume = {105},
journal = {Journal of Optimization Theory and Applications},
doi = {10.1023/A:1004641123405}
}

@inproceedings{Krantz2002TheIF,
  title={The Implicit Function Theorem: History, Theory, and Applications},
  author={Steven G. Krantz and Harold R. Parks},
  year={2002}
}

@InProceedings{ahmed19understanding,
  title = 	 {Understanding the Impact of Entropy on Policy Optimization},
  author = 	 {Ahmed, Zafarali and Le Roux, Nicolas and Norouzi, Mohammad and Schuurmans, Dale},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  publisher = 	 {PMLR},
  year = {2019},
  url = 	 {http://proceedings.mlr.press/v97/ahmed19a.html},
  abstract = 	 {Entropy regularization is commonly used to improve policy optimization in reinforcement learning. It is believed to help with exploration by encouraging the selection of more stochastic policies. In this work, we analyze this claim using new visualizations of the optimization landscape based on randomly perturbing the loss function. We first show that even with access to the exact gradient, policy optimization is difficult due to the geometry of the objective function. We then qualitatively show that in some environments, a policy with higher entropy can make the optimization landscape smoother, thereby connecting local optima and enabling the use of larger learning rates. This paper presents new tools for understanding the optimization landscape, shows that policy entropy serves as a regularizer, and highlights the challenge of designing general-purpose policy optimization algorithms.}
}

@book{rockafellar-1970a,
  added-at = {2008-03-02T02:12:02.000+0100},
  address = {Princeton, N. J.},
  author = {Rockafellar, R. Tyrrell},
  biburl = {https://www.bibsonomy.org/bibtex/223aa07ea525f6dd11585fc2037a0daf1/dmartins},
  callnumber = {UniM Maths 516.08 R59},
  description = {robotica-bib},
  interhash = {30830becb0a2c5ebca5946b895d9740a},
  intrahash = {23aa07ea525f6dd11585fc2037a0daf1},
  keywords = {imported},
  notes = {A SRL reference.},
  publisher = {Princeton University Press},
  series = {Princeton Mathematical Series},
  timestamp = {2008-03-02T02:14:11.000+0100},
  title = {Convex analysis},
  year = 1970
}


@article{Achiam2019TowardsCD,
  title={Towards Characterizing Divergence in Deep Q-Learning},
  author={Joshua Achiam and Ethan Knight and Pieter Abbeel},
  journal={ArXiv},
  year={2019},
  volume={abs/1903.08894}
}

@Article{Tsitsiklis1994,
author="Tsitsiklis, John N.",
title="Asynchronous stochastic approximation and Q-learning",
journal="Machine Learning",
year="1994",
month="Sep",
day="01",
volume="16",
number="3",
pages="185--202",
abstract="We provide some general results on the convergence of a class of stochastic approximation algorithms and their parallel and asynchronous variants. We then use these results to study the Q-learning algorithm, a reinforcement learning method for solving Markov decision problems, and establish its convergence under conditions more general than previously available.",
issn="1573-0565",
doi="10.1007/BF00993306",
url="https://doi.org/10.1007/BF00993306"
}



  @inproceedings{devraj2017zap,
 author = {Devraj, Adithya M. and Meyn, Sean P.},
 title = {Zap Q-Learning},
 year = {2017},
 isbn = {9781510860964},
 publisher = {Curran Associates Inc.},
 address = {Red Hook, NY, USA},
 booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
 pages = {2232–2241},
 numpages = {10},
 location = {Long Beach, California, USA},
 series = {NIPS’17}
}


@inproceedings{maei09nonlineargtd,
 author = {Maei, Hamid R. and Szepesv\'{a}ri, Csaba and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S.},
 title = {Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation},
 year = {2009},
 booktitle = {Proceedings of the 22nd International Conference on Neural Information Processing Systems}
}


@article{Hasselt2018DeepRL,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Hado van Hasselt and Yotam Doron and Florian Strub and Matteo Hessel and Nicolas Sonnerat and Joseph Modayil},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.02648}
}

@inproceedings{Kolter2011TheFP,
  title={The Fixed Points of Off-Policy TD},
  author={J. Zico Kolter},
  booktitle={NIPS},
  year={2011}
}

@inproceedings{du2019distributioncheck,
author = {Du, Simon and Luo, Yuping and Wang, Ruosong and Zhang, Hanrui},
year = {2019},
month = {06},
booktitle={NeurIPS},
title = {Provably Efficient $Q$-learning with Function Approximation via Distribution Shift Error Checking Oracle}
}

@article{sutton16emphatic,
author = {Sutton, Richard S. and Mahmood, A. Rupam and White, Martha},
title = {An Emphatic Approach to the Problem of Off-Policy Temporal-Difference Learning},
year = {2016},
issue_date = {January 2016},
publisher = {JMLR.org},
volume = {17},
number = {1},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {2603–2631},
numpages = {29},
keywords = {function approximation, temporal-difference learning, off-policy learning, convergence, stability}
}

@InProceedings{fu19diagnosing,
  title = 	 {Diagnosing Bottlenecks in Deep Q-learning Algorithms},
  author = 	 {Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  year = {2019},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  publisher = 	 {PMLR},
}


@phdthesis{konda_ac,
author = {Konda, Vijaymohan and Tsitsiklis, John N.},
title = {Actor-Critic Algorithms},
year = {2002},
publisher = {Massachusetts Institute of Technology},
address = {USA},
note = {AAI0804543}
}


@article{schaul2019ray,
  author    = {Tom Schaul and
               Diana Borsa and
               Joseph Modayil and
               Razvan Pascanu},
  title     = {Ray Interference: a Source of Plateaus in Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1904.11455},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.11455},
  archivePrefix = {arXiv},
  eprint    = {1904.11455},
  timestamp = {Thu, 02 May 2019 15:13:44 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1904-11455},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout


@inproceedings{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  year={2010}
}

@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  number={3},
  pages={185--202},
  year={1994},
  publisher={Springer}
}

@inproceedings{
yaz2018the,
title={The Unusual Effectiveness of Averaging in {GAN} Training},
author={Yasin Yaz{\i}c{\i} and Chuan-Sheng Foo and Stefan Winkler and Kim-Hui Yap and Georgios Piliouras and Vijay Chandrasekhar},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SJgw_sRqFQ},
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2018}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@inproceedings{Kakade2002,
author = {Kakade, Sham and Langford, John},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Approximately Optimal Approximate Reinforcement Learning}},
year = {2002}
}

@inproceedings{Maei2010,
author = {Maei, Hamid Reza and Szepesv{\'{a}}ri, Csaba and Bhatnagar, Shalabh and Sutton, Richard S},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Toward off-policy learning control with function approximation}},
year = {2010}
}

@inproceedings{Baird1995,
annote = {Residual gradient = differentiating through target},
author = {Baird, Leemon},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Residual Algorithms : Reinforcement Learning with Function Approximation}},
year = {1995}
}

@article{Mnih2015,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
issn = {0028-0836},
journal = {Nature},
month = {feb},
number = {7540},
pages = {529--533},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
title = {{Human-level control through deep reinforcement learning}},
volume = {518},
year = {2015}
}

@article{Lillicrap2015,
author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
journal = {International Conference on Learning Representations (ICLR)},
title = {{Continuous control with deep reinforcement learning}},
year = {2015}
}


@inproceedings{Precup2001,
author = {Precup, Doina and Sutton, Richard S. and Dasgupta, Sanjoy},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Off-policy temporal-difference learning with function approximation}},
year = {2001}
}

@article{Schulman2017,
  author    = {John Schulman and
               Pieter Abbeel and
               Xi Chen},
  title     = {Equivalence Between Policy Gradients and Soft Q-Learning},
  journal   = {ArXiv Preprint},
  volume    = {abs/1704.06440},
  year      = {2017},
}

@article{Gu2016,
  author    = {Shixiang Gu and
               Ethan Holly and
               Timothy Lillicrap and
               Sergey Levine},
  title     = {Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  journal   = {IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2017},
}

@article{Watkins92,
  author    = {Christopher J.C.H. Watkins and Peter Dayan},
  title     = {Q-learning},
  journal   = {Machine Learning},
  year      = {1992},
  volume    = {8},
  pages     = {279-292},
  issue     = {3},
}

@incollection{Kakade2001,
title = {A Natural Policy Gradient},
author = {Sham M. Kakade},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2001},
}

@incollection{Munos2016,
title = {Safe and Efficient Off-policy Reinforcement Learning},
author = {Remi Munos and Thomas Stepleton and Anna Harutyunyan and Marc G. Bellemare},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2016},
}

@inproceedings{Sutton09a,
title = {A Convergent O(n) Temporal-difference Algorithm for Off-policy Learning with Linear Function Approximation},
author = {Sutton, Richard S. and Hamid Reza Maei and Csaba Szepesv\'{a}ri},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2009},
}

@inproceedings{Sutton09b,
title = {Fast Gradient-Descent Methods for Temporal-Difference Learning
with Linear Function Approximation},
author = {
Richard S. Sutton and Hamid Reza Maei and Doina Precup and Shalabh Bhatnagar and David Silver and Csaba Szepesv\'{a}ri and
Eric Wiewiora},
booktitle = {International Conference on Machine Learning (ICML)},
year = {2009},
}

@article{Bertsekas96,
title = {Neuro-Dynamic Programming},
author = {Bertsekas, Dimitri P., and Tsitsiklis, John N.},
journal = {Athena Scientific},
year = {1996},
}


@inproceedings{Haarnoja2017,
author = {Tuomas Haarnoja and
               Haoran Tang and
               Pieter Abbeel and
               Sergey Levine},
booktitle = {International Conference on Machine Learning (ICML)},
title = {Reinforcement Learning with Deep Energy-Based Policies},
year = {2017}
}

@inproceedings{Hausknecht2016,
author = {Matthew Hausknecht and Peter Stone},
booktitle = {Deep Reinforcement Learning: Frontiers and Challenges Workshop, IJCAI},
title = {On-Policy vs. Off-Policy Updates for Deep Reinforcement Learning},
year = {2016}
}

@inproceedings{Farrell95,
author = {Jay A. Farrell and T. Berger},
booktitle = {American Control Conference},
title = {On the effects of the training sample density in passive learning control},
year = {1995}
}

@inproceedings{Boyan94,
author = {Justin A. Boyan and Andrew W. Moore},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
title = {Generalization in Reinforcement Learning:
Safely Approximating the Value Function},
year = {1994}
}

@article{Haarnoja18,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
}

@inproceedings{kalashnikov18,
  author    = {Dmitry Kalashnikov and
               Alex Irpan and
               Peter Pastor and
               Julian Ibarz and
               Alexander Herzog and
               Eric Jang and
               Deirdre Quillen and
               Ethan Holly and
               Mrinal Kalakrishnan and
               Vincent Vanhoucke and
               Sergey Levine},
  title     = {QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  booktitle = {CoRL},
  year      = {2018}
}

@article{Ernst05,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@book{suttonrlbook,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  edition = {Second}
}

@inproceedings{Dai2018,
  title={Sbeed: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  booktitle={International Conference on Machine Learning},
  pages={1133--1142},
  year={2018}
}

@article{VanHesselt2018,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@inproceedings{Tsitsiklis1997,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1075--1081},
  year={1997}
}

@article{Hallak2017,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  journal={arXiv preprint arXiv:1702.07121},
  year={2017}
}

@article{Sutton2016,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@article{henderson2017deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  journal={arXiv preprint arXiv:1709.06560},
  year={2017}
}

@article{dalal2017finite,
  title={Finite sample analyses for TD (0) with function approximation},
  author={Dalal and Gal , Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Thoppe, Gugan and Mannorand Shie},
  journal={arXiv preprint arXiv:1704.01161},
  year={2017}
}

@inproceedings{bhatnagar2009convergent,
  title={Convergent temporal-difference learning with arbitrary smooth function approximation},
  author={Maei, Hamid R, and Szepesv{\'a}ri, Csaba, and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S },
  booktitle={Advances in Neural Information Processing Systems},
  pages={1204--1212},
  year={2009}
}

@inproceedings{Riedmiller2005,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}

@article{Watkins1992,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{Gu2017,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{fedus2020revisiting,
  title={Revisiting fundamentals of experience replay},
  author={Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
  journal={arXiv preprint arXiv:2007.06700},
  year={2020}
}

@misc{gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@misc{approxstack,
  Author = {Robert Johnson},
  Title = {Approximate Irrational Numbers by Rational Numbers},
  Year = {2016},
  url = {https://math.stackexchange.com/questions/1829743/},
}

@article{Schaul2015,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={International Conference on Learning Representations (ICLR)},
  year={2015}
}

@book{Shalev2014,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@incollection{NIPS2017_6913,
title = {Is the Bellman residual a bad proxy?},
author = {Geist, Matthieu and Piot, Bilal and Pietquin, Olivier},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
pages = {3205--3214},
year = {2017},
}

@inproceedings{Pritzel2017,
  title={Neural Episodic Control},
  author={Pritzel, Alexander and Uria, Benigno and Srinivasan, Sriram and Badia, Adri{\`a} Puigdom{\`e}nech and Vinyals, Oriol and Hassabis, Demis and Wierstra, Daan and Blundell, Charles},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2827--2836},
  year={2017}
}

@InProceedings{pmlr-v80-fujimoto18a,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@inproceedings{Gu2017ipg,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={3846--3855},
  year={2017}
}

@inproceedings{maillard2010finite,
  title={Finite-sample analysis of Bellman residual minimization},
  author={Maillard, Odalric-Ambrym and Munos, R{\'e}mi and Lazaric, Alessandro and Ghavamzadeh, Mohammad},
  booktitle={Asian Conference on Machine Learning (ACML)},
  pages={299--314},
  year={2010}
}

@inproceedings{munos2005error,
  title={Error bounds for approximate value iteration},
  author={Munos, R{\'e}mi},
  booktitle={AAAI Conference on Artificial intelligence (AAAI)},
  pages={1006--1011},
  year={2005},
  organization={AAAI Press}
}

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{zhang2018deeper,
  author    = {Shangtong Zhang and
               Richard S. Sutton},
  title     = {A Deeper Look at Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1712.01275},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.01275},
  archivePrefix = {arXiv},
  eprint    = {1712.01275},
  timestamp = {Mon, 13 Aug 2018 16:46:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1712-01275},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{antos2007fitted,
 author = {Antos, Andr\'{a}s and Munos, R{\'e}mi and Szepesv\'{a}ri, Csaba},
 title = {Fitted Q-iteration in Continuous Action-space MDPs},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 series = {NIPS'07},
 year = {2007},
 location = {Vancouver, British Columbia, Canada},
} 

@phdthesis{de2002alp,
  title={The linear programming approach to approximate dynamic programming: Theory and application},
  author={De Farias, Daniela Pucci},
  year={2002}
}

@article{antos2008concentrability,
  title={Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Machine Learning},
  volume={71},
  number={1},
  pages={89--129},
  year={2008},
  publisher={Springer}
}

@article{metelli2018nips,
  author    = {Alberto Maria Metelli and
               Matteo Papini and
               Francesco Faccio and
               Marcello Restelli},
  title     = {Policy Optimization via Importance Sampling},
  journal   = {CoRR},
  volume    = {abs/1809.06098},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.06098},
  archivePrefix = {arXiv},
  eprint    = {1809.06098},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1809-06098},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{pmlr-v70-arjovsky17a,
  title = 	 {{W}asserstein Generative Adversarial Networks},
  author = 	 {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {214--223},
  year = 	 {2017},
}

@techreport{haarnoja2018sacapps,
  title={Soft Actor-Critic Algorithms and Applications},
  author={Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{hazan2018,
  title={Provably Efficient Maximum Entropy Exploration},
  author={Hazan, Elad and Kakade, Sham M and Singh, Karan and Van Soest, Abby},
  journal={arXiv preprint arXiv:1812.02690},
  year={2018}
}

@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@inproceedings{scherrer2010residual,
  title={Should one compute the temporal difference fix point or minimize the Bellman Residual? The unified oblique projection view},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={959--966},
  year={2010},
}

@inproceedings{tosatto2017boosted,
  title={Boosted fitted q-iteration},
  author={Tosatto, Samuele and Pirotta, Matteo and D'Eramo, Carlo and Restelli, Marcello},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={3434--3443},
  year={2017},
  organization={JMLR. org}
}

@article{lin1992replay,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@article{yarats2022don,
  title={Don't Change the Algorithm, Change the Data: Exploratory Data for Offline Reinforcement Learning},
  author={Yarats, Denis and Brandfonbrener, David and Liu, Hao and Laskin, Michael and Abbeel, Pieter and Lazaric, Alessandro and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2201.13425},
  year={2022}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1054--1062},
  year={2016}
}

@article{sriperum2009ipms,
  author    = {Bharath K. Sriperumbudur and
               Arthur Gretton and
               Kenji Fukumizu and
               Gert R. G. Lanckriet and
               Bernhard Sch{\"{o}}lkopf},
  title     = {A note on integral probability metrics and {\textdollar}{\textbackslash}phi{\textdollar}-divergences},
  journal   = {CoRR},
  volume    = {abs/0901.2698},
  year      = {2009},
  url       = {http://arxiv.org/abs/0901.2698},
  archivePrefix = {arXiv},
  eprint    = {0901.2698},
  timestamp = {Mon, 13 Aug 2018 16:48:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-0901-2698},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kumar2020discor,
  title={Discor: Corrective feedback in reinforcement learning via distribution correction},
  author={Kumar, Aviral and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2003.07305},
  year={2020}
}

@inproceedings{arora2019implicit,
  title={Implicit regularization in deep matrix factorization},
  author={Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7413--7424},
  year={2019}
}

@inproceedings{yang2020theoretical,
  title={A theoretical analysis of deep Q-learning},
  author={Yang, Zhuoran and Xie, Yuchen and Wang, Zhaoran},
  booktitle={Learning for Dynamics and Control},
  pages={486--489},
  year={2020},
  organization={PMLR}
}

@article{cai2019neural,
  title={Neural Temporal-Difference and Q-Learning Provably Converge to Global Optima},
  author={Cai, Qi and Yang, Zhuoran and Lee, Jason D and Wang, Zhaoran},
  journal={arXiv preprint arXiv:1905.10027},
  year={2019}
}

@article{mahadevan2007proto,
  title={Proto-value functions: A Laplacian framework for learning representation and control in Markov decision processes},
  author={Mahadevan, Sridhar and Maggioni, Mauro},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={Oct},
  pages={2169--2231},
  year={2007}
}

@article{wu2018laplacian,
  title={The Laplacian in RL: Learning representations with efficient approximations},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1810.04586},
  year={2018}
}

@article{machado2017eigenoption,
  title={Eigenoption discovery through the deep successor representation},
  author={Machado, Marlos C and Rosenbaum, Clemens and Guo, Xiaoxiao and Liu, Miao and Tesauro, Gerald and Campbell, Murray},
  journal={arXiv preprint arXiv:1710.11089},
  year={2017}
}

@article{van2019use,
  title={When to use parametric models in reinforcement learning?},
  author={van Hasselt, Hado and Hessel, Matteo and Aslanides, John},
  journal={arXiv preprint arXiv:1906.05243},
  year={2019}
}

@article{tian2021understanding,
  title={Understanding self-supervised learning dynamics without contrastive pairs},
  author={Tian, Yuandong and Chen, Xinlei and Ganguli, Surya},
  journal={arXiv preprint arXiv:2102.06810},
  year={2021}
}

@article{tian2020understanding,
  title={Understanding self-supervised learning with dual deep networks},
  author={Tian, Yuandong and Yu, Lantao and Chen, Xinlei and Ganguli, Surya},
  journal={arXiv preprint arXiv:2010.00578},
  year={2020}
}

@article{chen2020exploring,
  title={Exploring Simple Siamese Representation Learning},
  author={Chen, Xinlei and He, Kaiming},
  journal={arXiv preprint arXiv:2011.10566},
  year={2020}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent: A new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre H and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and others},
  journal={arXiv preprint arXiv:2006.07733},
  year={2020}
}

@article{fakoor2021continuous,
  title={Continuous Doubly Constrained Batch Reinforcement Learning},
  author={Fakoor, Rasool and Mueller, Jonas and Chaudhari, Pratik and Smola, Alexander J},
  journal={arXiv preprint arXiv:2102.09225},
  year={2021}
}

@article{kaiser2019model,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@article{woodworth2020kernel,
  title={Kernel and rich regimes in overparametrized models},
  author={Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
  journal={arXiv preprint arXiv:2002.09277},
  year={2020}
}

@inproceedings{lyle2021effect,
  title={On The Effect of Auxiliary Tasks on Representation Dynamics},
  author={Lyle, Clare and Rowland, Mark and Ostrovski, Georg and Dabney, Will},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1--9},
  year={2021},
  organization={PMLR}
}

@article{wei2019regularization,
  title={Regularization matters: Generalization and optimization of neural nets vs their induced kernel},
  author={Wei, Colin and Lee, Jason and Liu, Qiang and Ma, Tengyu},
  year={2019}
}

@article{sedghi2018singular,
  title={The singular values of convolutional layers},
  author={Sedghi, Hanie and Gupta, Vineet and Long, Philip M},
  journal={arXiv preprint arXiv:1805.10408},
  year={2018}
}

@article{zhang2020can,
  title={Can Temporal-Difference and Q-Learning Learn Representation? A Mean-Field Theory},
  author={Zhang, Yufeng and Cai, Qi and Yang, Zhuoran and Chen, Yongxin and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2006.04761},
  year={2020}
}

@article{xu2019finite,
  title={A finite-time analysis of Q-learning with neural network function approximation},
  author={Xu, Pan and Gu, Quanquan},
  journal={arXiv preprint arXiv:1912.04511},
  year={2019}
}

@article{voloshin2019empirical,
  title={Empirical study of off-policy policy evaluation for reinforcement learning},
  author={Voloshin, Cameron and Le, Hoang M and Jiang, Nan and Yue, Yisong},
  journal={arXiv preprint arXiv:1911.06854},
  year={2019}
}

@article{ghosh2020representations,
  title={Representations for Stable Off-Policy Reinforcement Learning},
  author={Ghosh, Dibya and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2007.05520},
  year={2020}
}

@article{mobahi2020self,
  title={Self-distillation amplifies regularization in hilbert space},
  author={Mobahi, Hossein and Farajtabar, Mehrdad and Bartlett, Peter L},
  journal={arXiv preprint arXiv:2002.05715},
  year={2020}
}

@inproceedings{agarwal2019optimistic,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{kumar2020conservative,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@article{arora2018optimization,
  title={On the optimization of deep networks: Implicit acceleration by overparameterization},
  author={Arora, Sanjeev and Cohen, Nadav and Hazan, Elad},
  journal={arXiv preprint arXiv:1802.06509},
  year={2018}
}

@inproceedings{boyan1999least,
  title={Least-squares temporal difference learning},
  author={Boyan, Justin A},
  booktitle={ICML},
  pages={49--56},
  year={1999},
  organization={Citeseer}
}

@inproceedings{melo2008analysis,
  title={An analysis of reinforcement learning with function approximation},
  author={Melo, Francisco S and Meyn, Sean P and Ribeiro, M Isabel},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={664--671},
  year={2008}
}

@inproceedings{devraj2017zap,
  title={Zap Q-learning},
  author={Devraj, Adithya M and Meyn, Sean},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2235--2244},
  year={2017}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{bengio2020interference,
  title={Interference and Generalization in Temporal Difference Learning},
  author={Bengio, Emmanuel and Pineau, Joelle and Precup, Doina},
  journal={arXiv preprint arXiv:2003.06350},
  year={2020}
}

@inproceedings{precup2001offpol,
  title={Off-Policy Temporal Difference Learning with Function Approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={417--424},
  year={2001},
}

@article{dabney2018implicit,
  title={Implicit quantile networks for distributional reinforcement learning},
  author={Dabney, Will and Ostrovski, Georg and Silver, David and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1806.06923},
  year={2018}
}

@inproceedings{hausknecht2016policy,
  title={On-policy vs. off-policy updates for deep reinforcement learning},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={Deep Reinforcement Learning: Frontiers and Challenges, IJCAI},
  year={2016}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{martha2018sparse,
  author    = {Vincent Liu and
               Raksha Kumaraswamy and
               Lei Le and
               Martha White},
  title     = {The Utility of Sparse Representations for Control in Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1811.06626},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.06626},
  archivePrefix = {arXiv},
  eprint    = {1811.06626},
  timestamp = {Sun, 25 Nov 2018 18:57:12 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-06626},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{jaques2019way,
  title={Way off-policy batch deep reinforcement learning of implicit human preferences in dialog},
  author={Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang and Picard, Rosalind},
  journal={arXiv preprint arXiv:1907.00456},
  year={2019}
}

@article{shani2005recommender,
  title={An MDP-based recommender system},
  author={Shani, Guy and Heckerman, David and Brafman, Ronen I},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Sep},
  pages={1265--1295},
  year={2005}
}

@inproceedings{szepesvari1998asymptotic,
  title={The asymptotic convergence-rate of Q-learning},
  author={Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1064--1070},
  year={1998}
}

@inproceedings{ijcai2020-370,
  title     = {I4R: Promoting Deep Reinforcement Learning by the Indicator for Expressive Representations},
  author    = {Luo, Xufang and Meng, Qi and He, Di and Chen, Wei and Wang, Yunhong},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {2669--2675},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/370},
  url       = {https://doi.org/10.24963/ijcai.2020/370},
}

@article{yoshida2017spectral,
  title={Spectral norm regularization for improving the generalizability of deep learning},
  author={Yoshida, Yuichi and Miyato, Takeru},
  journal={arXiv preprint arXiv:1705.10941},
  year={2017}
}

@inproceedings{Parr2008AnAO,
  title={An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning},
  author={Ronald Parr and Lihong Li and Gavin Taylor and Christopher Painter-Wakefield and Michael L. Littman},
  booktitle={ICML '08},
  year={2008}
}


@book{koller_friedman,
 author = {Koller, D. and Friedman, N.},
 title = {Probabilistic Graphical Models: Principles and Techniques},
 year = {2009},
 isbn = {0262013193, 9780262013192},
 publisher = {The MIT Press},
} 

@inproceedings{chebotar2019closing,
  title={Closing the sim-to-real loop: Adapting simulation randomization with real world experience},
  author={Chebotar, Yevgen and Handa, Ankur and Makoviychuk, Viktor and Macklin, Miles and Issac, Jan and Ratliff, Nathan and Fox, Dieter},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8973--8979},
  year={2019},
  organization={IEEE}
}

@article{tan2018sim,
  title={Sim-to-real: Learning agile locomotion for quadruped robots},
  author={Tan, Jie and Zhang, Tingnan and Coumans, Erwin and Iscen, Atil and Bai, Yunfei and Hafner, Danijar and Bohez, Steven and Vanhoucke, Vincent},
  journal={arXiv preprint arXiv:1804.10332},
  year={2018}
}

@inproceedings{sadeghi2016cad2rl,
  title={{CAD2RL}: Real single-image flight without a single real image},
  author={Sadeghi, Fereshteh and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2017}
}

@inproceedings{gae,
title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
author = {J. Schulman and P. Moritz and S. Levine and M. Jordan and P. Abbeel},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2016
}

@misc{kumar_blog,
title = {Data-Driven Deep Reinforcement Learning},
author = {Aviral Kumar},
note = {{BAIR} Blog},
year = {2019},
howpublished  = {\url{https://bair.berkeley.edu/blog/2019/12/05/bear/}}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2013}
}

@article{luo2019learning,
  title={Learning self-correctable policies and value functions from demonstrations with negative sampling},
  author={Luo, Yuping and Xu, Huazhe and Ma, Tengyu},
  journal={arXiv preprint arXiv:1907.05634},
  year={2019}
}

@inproceedings{mulayoff2020unique,
  title={Unique Properties of Flat Minima in Deep Networks},
  author={Mulayoff, Rotem and Michaeli, Tomer},
  booktitle={International Conference on Machine Learning},
  pages={7108--7118},
  year={2020},
  organization={PMLR}
}

@article{van2018deep,
  title={Deep reinforcement learning and the deadly triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@article{damian2021label,
  title={Label Noise SGD Provably Prefers Flat Global Minimizers},
  author={Damian, Alex and Ma, Tengyu and Lee, Jason},
  journal={arXiv preprint arXiv:2106.06530},
  year={2021}
}

@article{mahmood2015emphatic,
  title={Emphatic temporal-difference learning},
  author={Mahmood, A Rupam and Yu, Huizhen and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1507.01569},
  year={2015}
}

@article{chatterji2019intriguing,
  title={The intriguing role of module criticality in the generalization of deep networks},
  author={Chatterji, Niladri S and Neyshabur, Behnam and Sedghi, Hanie},
  journal={arXiv preprint arXiv:1912.00528},
  year={2019}
}

@article{bjorck2021towards,
  title={Towards Deeper Deep Reinforcement Learning},
  author={Bjorck, Johan and Gomes, Carla P and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:2106.01151},
  year={2021}
}

@article{ota2021training,
  title={Training Larger Networks for Deep Reinforcement Learning},
  author={Ota, Kei and Jha, Devesh K and Kanezaki, Asako},
  journal={arXiv preprint arXiv:2102.07920},
  year={2021}
}

@article{yang2020feature,
  title={Feature learning in infinite-width neural networks},
  author={Yang, Greg and Hu, Edward J},
  journal={arXiv preprint arXiv:2011.14522},
  year={2020}
}

@article{sinha2020d2rl,
  title={D2rl: Deep dense architectures in reinforcement learning},
  author={Sinha, Samarth and Bharadhwaj, Homanga and Srinivas, Aravind and Garg, Animesh},
  journal={arXiv preprint arXiv:2010.09163},
  year={2020}
}

@inproceedings{kakade2002natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  booktitle={Advances in neural information processing systems},
  pages={1531--1538},
  year={2002}
}


@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@InProceedings{thomas,
  title = 	 {Bias in Natural Actor-Critic Algorithms},
  author = 	 {Philip Thomas},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2014},
  month = 	 {22--24 Jun},
}

@inproceedings{toussaint06,
 author = {Toussaint, M. and Storkey, A.},
 title = {Probabilistic Inference for Solving Discrete and Continuous State Markov Decision Processes},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2006},
} 

@INPROCEEDINGS{attias,
    author = {H. Attias},
    title = {Planning by Probabilistic Inference},
    booktitle = {Proceedings of the 9th International Workshop on Artificial Intelligence and Statistics},
    year = {2003}
}

@article{hafner2011reinforcement,
  title={Reinforcement learning in feedback control},
  author={Hafner, Roland and Riedmiller, Martin},
  journal={Machine learning},
  volume={84},
  number={1-2},
  pages={137--169},
  year={2011},
  publisher={Springer}
}

@article{tesauro1994td,
  title={{TD-Gammon}, a self-teaching backgammon program, achieves master-level play},
  author={Tesauro, Gerald},
  journal={Neural computation},
  volume={6},
  number={2},
  pages={215--219},
  year={1994},
  publisher={MIT Press}
}

@InProceedings{ebrl,
  title = 	 {Actor-Critic Reinforcement Learning with Energy-Based Policies},
  author = 	 {N. Heess and D. Silver and Y. W. Teh},
  booktitle = 	 {European Workshop on Reinforcement Learning (EWRL)},
  year = 	 {2013},
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={627--635},
  year={2011}
}

@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={661--668},
  year={2010}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={International Conference on Machine Learning (ICML)},
  volume={2},
  year={2002}
}

@inproceedings{ep,
 author = {Minka, T. P.},
 title = {Expectation Propagation for Approximate Bayesian Inference},
 booktitle = {Uncertainty in Artificial Intelligence (UAI)},
 year = {2001},
}

@inproceedings{mpo,
title = {Maximum a Posteriori Policy Optimisation},
author = {A. Abdolmaleki and J. T. Springenberg and Y. Tassa and R. Munos and N. Heess and M. Riedmiller},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2018
}

@article{williams,
 author = {Williams, R. J.},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 journal = {Machine Learning},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 pages = {229--256}
} 

@article{WilliamsPeng91,
  author = {Williams, R. J. and Peng, J.},
  journal = {Connection Science},
  number = 3,
  pages = {241-268},
  title = {Function optimization using connectionist reinforcement learning
	algorithms},
  volume = 3,
  year = 1991
}

@book{sb-irl-98,
 author = {Sutton, R. S. and Barto, A. G.},
 title = {Introduction to Reinforcement Learning},
 year = {1998},
 isbn = {0262193981},
 edition = {1st},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@INPROCEEDINGS{suttonadp,
    author = {R. S. Sutton},
    title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {1990},
}

@inproceedings{pgq,
author = {O'Donoghue, B. and Munos, R. and Kavukcuoglu, K. and Mnih, V.},
year = {2017},
title = {PGQ: Combining policy gradient and Q-learning},
booktitle = {International Conference on Learning Representations (ICLR)}
}

@article{sallans,
 author = {Sallans, B. and Hinton, G. E.},
 title = {Reinforcement Learning with Factored States and Actions},
 journal = {Journal of Machine Learning Research},
 volume = {5},
 month = dec,
 year = {2004}
 },

@article{KLMSurvey,
    author = "L. P. Kaelbling and M. L. Littman and A. P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
url={http://people.csail.mit.edu/lpk/papers/rl-survey.ps}}

@inproceedings{todorov_kalman_duality, 
author={E. Todorov}, 
booktitle={Conference on Decision and Control (CDC)},
title={General duality between optimal control and estimation}, 
year={2008},
}

@inproceedings{covariant,
author = {J. A. Bagnell and J. Schneider},
title = {Covariant Policy Search},
booktitle = {International Joint Conference on Artifical Intelligence (IJCAI)},
year = {2003},
}

@InProceedings{reps,
  author =       "Peters, J. and  M{\"u}lling, K. and Alt{\"u}n, Y.",
  title =        "Relative Entropy Policy Search",
  booktitle =    "AAAI Conference on Artificial Intelligence (AAAI)",
  year =         "2010",
}

@inproceedings{mfgps,
title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
author = {Levine, S. and Abbeel, P.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{lmdp_policy,
  author    = {E. Todorov},
  title     = {Policy gradients in linearly-solvable MDPs},
  booktitle = {Neural Information Processing Systems (NIPS)},
  year      = {2010},
}

@inproceedings{ldmp_irl,
 author = {Dvijotham, K. and Todorov, E.},
 title = {Inverse Optimal Control with Linearly-solvable MDPs},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2010},
} 

@inproceedings{bear,
title = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
author = {Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
booktitle = {Neural Information Processing Systems (NeurIPS)},
year = {2019}
}

@article{lerer2016learning,
  title={Learning physical intuition of block towers by example},
  author={Lerer, Adam and Gross, Sam and Fergus, Rob},
  journal={arXiv preprint arXiv:1603.01312},
  year={2016}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@inproceedings{battaglia2016interaction,
  title={Interaction networks for learning about objects, relations and physics},
  author={Battaglia, Peter and Pascanu, Razvan and Lai, Matthew and Rezende, Danilo Jimenez and others},
  booktitle={Advances in neural information processing systems},
  pages={4502--4510},
  year={2016}
}

@inproceedings{sagawa2019distributionally,
  title={Distributionally Robust Neural Networks},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1907.02893},
  year={2019}
}

@article{sinha2017certifying,
  title={Certifying some distributional robustness with principled adversarial training},
  author={Sinha, Aman and Namkoong, Hongseok and Duchi, John},
  journal={arXiv preprint arXiv:1710.10571},
  year={2017}
}

@inproceedings{kingma2014semi,
  title={Semi-supervised learning with deep generative models},
  author={Kingma, Durk P and Mohamed, Shakir and Rezende, Danilo Jimenez and Welling, Max},
  booktitle={Advances in neural information processing systems},
  pages={3581--3589},
  year={2014}
}

@inproceedings{kendall2017uncertainties,
  title={What uncertainties do we need in bayesian deep learning for computer vision?},
  author={Kendall, Alex and Gal, Yarin},
  booktitle={Advances in neural information processing systems},
  pages={5574--5584},
  year={2017}
}

@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016}
}

@article{scholkopf2019causality,
  title={Causality for Machine Learning},
  author={Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:1911.10500},
  year={2019}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{pi2,
  title = {Learning Policy Improvements with Path Integrals},
  author = {Theodorou, E. A. and Buchli, J. and Schaal, S.},
  booktitle = {International Conference on  Artificial Intelligence and Statistics (AISTATS 2010)},
  year = {2010},
}

@InProceedings{trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {J. Schulman and S. Levine and P. Moritz and M. I. Jordan and P. Abbeel},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2015},
}

@phdthesis{levine_thesis,
author = {Levine, S.},
title = {Motor skill learning with local trajectory methods},
school = {Stanford University},
year = {2014},
}

@phdthesis{ziebart_thesis,
author = {Ziebart, B.},
title = {Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
school = {Carnegie Mellon University},
year = {2010},
}

@article{kappen_oc,
  author    = {H. J. Kappen},
  title     = {Optimal control theory and the linear bellman equation},
  journal   = {Inference and Learning in Dynamic Models},
  year      = {2011},
  pages     = {363-387},
}

@inproceedings{heess2015learning,
  title={Learning continuous control policies by stochastic value gradients},
  author={Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Timothy and Erez, Tom and Tassa, Yuval},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2944--2952},
  year={2015}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1352--1361},
  year={2017},
  organization={JMLR. org}
}

@article{kappen_pgm,
  author    = {H. J. Kappen and
               V. G{\'o}mez and
               M. Opper},
  title     = {Optimal control as a graphical model inference problem},
  journal   = {Machine Learning},
  volume    = {87},
  number    = {2},
  year      = {2012},
  pages     = {159-182},
}

@inproceedings{rawlik_soc,
  author    = {K. Rawlik and
               M. Toussaint and
               S. Vijayakumar},
  title     = {On Stochastic Optimal Control and Reinforcement Learning
               by Approximate Inference},
  year = {2013},
  booktitle = {Robotics: Science and Systems (RSS)},
}

@inproceedings{toussaint_soc,
  author    = {M. Toussaint},
  title     = {Robot trajectory optimization using approximate inference},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2009},
}

@inproceedings{toussaint_pgm,
  title={Hierarchical POMDP Controller Optimization by Likelihood Maximization},
  author={Toussaint, M. and Charlin, L. and Poupart, P.},
  booktitle={Uncertainty in Artificial Intelligence (UAI)},
  volume={24},
  pages={562--570},
  year={2008}
}

@article{kalman_filter,
  author={R. Kalman},
  title={A new approach to linear filtering and prediction problems},
  journal={ASME Transactions journal of basic engineering},
  volume={82},
  number={1},
  pages={35-45},
  year={1960}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}

@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{todorov_lmdp,
  author    = {E. Todorov},
  title     = {Linearly-solvable Markov decision problems},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2006},
}

@inproceedings{rwr,
 author = {Peters, J. and Schaal, S.},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2007},
} 


@inproceedings{neumann,
  author    = {G. Neumann},
  title     = {Variational Inference for Policy Search in changing situations},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2011},
}

@inproceedings{levine_vgps,
  author    = {S. Levine and V. Koltun},
  title     = {Variational policy search via trajectory optimization},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2013},
}

@inproceedings{em_policy_search,
  title = {Efficient Sample Reuse in EM-Based Policy Search},
  author = {Hachiya, H. and Peters, J. and Sugiyama, M.},
  booktitle = {European Conference on Machine Learning (ECML)},
  year = {2009},
}

@article{vmp,
    title={Variational message passing},
    author={Winn, J. and Bishop, C.},
    journal={Journal of Machine Learning Research},
    volume={6},
    year={2005},
    pages={661-694}
}

@inproceedings{haarnoja,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, T. and Tang, H. and Abbeel, P. and Levine, S.},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{sac,
title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
author  = {T. Haarnoja and A. Zhou and P. Abbeel and S. Levine},
year  = {2018},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1801.01290.pdf}
}

@inproceedings{d4rl,
title = {D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
author  = {J. Fu and A. Kumar and O. Nachum and G. Tucker and S. Levine},
year  = {2020},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/2004.07219}
}

@inproceedings{pcl,
title = {Bridging the Gap Between Value and Policy Based Reinforcement Learning},
author  = {O. Nachum and M. Norouzi and K. Xu and D. Schuurmans},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1702.08892.pdf}
}

@inproceedings{gps,
 author = {Levine, S. and Koltun, V.},
 title = {Guided Policy Search},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2013},
} 

@inproceedings{maxentirl,
 author = {Ziebart, B. D. and Maas, A. and Bagnell, J. A. and Dey, A. K.},
 title = {Maximum Entropy Inverse Reinforcement Learning},
 booktitle = {International Conference on Artificial Intelligence (AAAI)},
 year = {2008},
} 

@inproceedings{haarnoja_composable,
author = {Haarnjoa, T. and Pong, V. and Zhou, A. and Dalal, M. and Abbeel, P. and Levine, S.},
title = {Composable Deep Reinforcement Learning for Robotic Manipulation},
booktitle = {International Conference on Robotics and Automation (ICRA)},
year = {2018},
}

@article{trust_pcl,
  author    = {O. Nachum and
               M. Norouzi and
               K. Xu and
               D. Schuurmans},
  title     = {Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1707.01891},
  year      = {2017},
}

@inproceedings{gpirl,
 author = {Levine, S. and Popovi\'{c}, Z. and Koltun, V.},
 title = {Nonlinear Inverse Reinforcement Learning with Gaussian Processes},
 booktitle = {Neural Information Processing Systems (NIPS)},
 year = {2011},
}

@inproceedings{localioc,
    author = {S. Levine and V. Koltun},
    title = {Continuous Inverse Optimal Control with Locally Optimal Examples},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2012},
}

@inproceedings{legibility,
  author    = {A. D. Dragan and
               K. C. T. Lee and
               S. S. Srinivasa},
  title     = {Legibility and predictability of robot motion},
  booktitle = {International Conference on Human-Robot Interaction (HRI)},
  year      = {2013},
}

@inproceedings{maxentdeepirl,
author = {M. Wulfmeier and
P. Ondruska and
I. Posner},
title = {Maximum Entropy Deep Inverse Reinforcement Learning},
Booktitle = {Neural Information Processing Systems Conference, Deep Reinforcement Learning Workshop},
year = {2015},
}

@inproceedings{maxcausalent,
  author    = {B. D. Ziebart and
               J. A. Bagnell and
               A. K. Dey},
  title     = {Modeling Interaction via the Principle of Maximum Causal Entropy},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2010},
}

@inproceedings{kitani1,
  author    = {D. Huang and
               K. M. Kitani},
  title     = {Action-Reaction: Forecasting the Dynamics of Human Interaction},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2014},
}

@inproceedings{kitani2,
  author    = {D. Huang and
               A. Farahmand and
               K. M. Kitani and
               J. A. Bagnell},
  title     = {Approximate {MaxEnt} Inverse Optimal Control and Its Application for
               Mental Simulation of Human Interactions},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2015},
}

@article{realnvp,
title={Latent Space Policies for Hierarchical Reinforcement Learning},
author={T. Haarnoja and K. Hartikainen and P. Abbeel and S. Levine},
journal   = {CoRR},
volume    = {abs/1804.02808},
year      = {2018},
}

@inproceedings{Javdani, 
    AUTHOR    = {S. Javdani and S. Srinivasa and J. A. Bagnell}, 
    TITLE     = {Shared Autonomy via Hindsight Optimization}, 
    BOOKTITLE = {Robotics: Science and Systems (RSS)}, 
    YEAR      = {2015}, 
}

@inproceedings{airl,
title={Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
author={Fu, J. and Luo, K. and Levine, S.},
}

@inproceedings{hausman,
title={Learning an Embedding Space for Transferable Robot Skills},
author={K. Hausman and J. T. Springenberg and Z. Wang and N. Heess and M. Riedmiller},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
}

@article{learning_to_explore,
  author    = {A. Gupta and
               R. Mendonca and
               Y. Liu and
               P. Abbeel and
               S. Levine},
  title     = {Meta-Reinforcement Learning of Structured Exploration Strategies},
  journal   = {CoRR},
  volume    = {abs/1802.07245},
  year      = {2018},
}

@article{endtoend,
 author = {Levine, S. and Finn, C. and Darrell, T. and Abbeel, P.},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {Journal of Machine Learning Research},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
} 

@inproceedings{cgps,
    author = {Sergey Levine and Vladlen Koltun},
    title = {Learning Complex Neural Network Policies with Trajectory Optimization},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2014},
}
@inproceedings{schulman,
title = {Equivalence Between Policy Gradients and Soft Q-Learning},
author  = {J. Schulman and X. Chen and P. Abbeel},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1704.06440}
}

@inproceedings{nvil,
  author    = {A. Mnih and
               K. Gregor},
  title     = {Neural Variational Inference and Learning in Belief Networks},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2014}
}

@inproceedings{gcl,
  author    = {Chelsea Finn and
               Sergey Levine and
               Pieter Abbeel},
  title     = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
    booktitle   = {International Conference on Machine Learning (ICML)},
  year      = {2016},
}

@inproceedings{gan,
title = {Generative Adversarial Nets},
author = {Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{gail,
title = {Generative Adversarial Imitation Learning},
author = {Ho, J. and Ermon, S.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2016},
}

@article{finn_adversarial,
  author    = {Chelsea Finn and
               Paul Christiano and
               Pieter Abbeel and
               Sergey Levine},
  title     = {A Connection between Generative Adversarial Networks, Inverse Reinforcement
               Learning, and Energy-Based Models},
  journal   = {CoRR},
  volume    = {abs/1611.03852},
  year      = {2016},
}

@inproceedings{bornschein2016bidirectional,
  title={Bidirectional helmholtz machines},
  author={Bornschein, Jorg and Shabanian, Samira and Fischer, Asja and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={2511--2519},
  year={2016}
}

@article{marino2018iterative,
  title={Iterative amortized inference},
  author={Marino, Joseph and Yue, Yisong and Mandt, Stephan},
  journal={arXiv preprint arXiv:1807.09356},
  year={2018}
}

@inproceedings{rasmus2015semi,
  title={Semi-supervised learning with ladder networks},
  author={Rasmus, Antti and Berglund, Mathias and Honkala, Mikko and Valpola, Harri and Raiko, Tapani},
  booktitle={Advances in neural information processing systems},
  pages={3546--3554},
  year={2015}
}

@inproceedings{sonderby2016ladder,
  title={Ladder variational autoencoders},
  author={S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
  booktitle={Advances in neural information processing systems},
  pages={3738--3746},
  year={2016}
}

@inproceedings{zhao2017learning,
  title={Learning hierarchical features from deep generative models},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={4091--4099},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{hsu2017unsupervised,
  title={Unsupervised learning of disentangled and interpretable representations from sequential data},
  author={Hsu, Wei-Ning and Zhang, Yu and Glass, James},
  booktitle={Advances in neural information processing systems},
  pages={1878--1889},
  year={2017}
}


@inproceedings{kalashnikov2018qtopt,
  title={Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  pages={651--673},
  year={2018}
}

@article{cabi2019framework,
  title={A Framework for Data-Driven Robotics},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and {\.Z}o{\l}na, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

 @article{Mo18AdobeIndoorNav,
        Author = {Kaichun Mo and Haoxiang Li and Zhe Lin and Joon-Young Lee},
        Title = {The AdobeIndoorNav Dataset: Towards Deep Reinforcement Learning based Real-world Indoor Robot Visual Navigation},
        Year = {2018},
        Eprint = {arXiv:1802.08824},
    }
    
@article{kandasamy2017batch,
  title={Batch policy gradient methods for improving neural conversation models},
  author={Kandasamy, Kirthevasan and Bachrach, Yoram and Tomioka, Ryota and Tarlow, Daniel and Carter, David},
  journal={arXiv preprint arXiv:1702.03334},
  year={2017}
}

@inproceedings{sun2018fast,
  title={A fast integrated planning and control framework for autonomous driving via imitation learning},
  author={Sun, Liting and Peng, Cheng and Zhan, Wei and Tomizuka, Masayoshi},
  booktitle={Dynamic Systems and Control Conference},
  volume={51913},
  pages={V003T37A012},
  year={2018},
  organization={American Society of Mechanical Engineers}
}

@article{zhou2017end,
  title={End-to-end offline goal-oriented dialog policy learning via policy gradient},
  author={Zhou, Li and Small, Kevin and Rokhlenko, Oleg and Elkan, Charles},
  journal={arXiv preprint arXiv:1712.02838},
  year={2017}
}

@article{pan2017agile,
  title={Agile autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{nie2019learning,
  title={Learning when-to-treat policies},
  author={Nie, Xinkun and Brunskill, Emma and Wager, Stefan},
  journal={arXiv preprint arXiv:1905.09751},
  year={2019}
}

@article{bojarski2016end,
  title={End to end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}

@article{yu2018bdd100k,
  title={Bdd100k: A diverse driving video database with scalable annotation tooling},
  author={Yu, Fisher and Xian, Wenqi and Chen, Yingying and Liu, Fangchen and Liao, Mike and Madhavan, Vashisht and Darrell, Trevor},
  journal={arXiv preprint arXiv:1805.04687},
  year={2018}
}

@article{sallab2017deep,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}

@article{yurtsever2020survey,
  title={A survey of autonomous driving: Common practices and emerging technologies},
  author={Yurtsever, Ekim and Lambert, Jacob and Carballo, Alexander and Takeda, Kazuya},
  journal={IEEE Access},
  year={2020},
  publisher={IEEE}
}

@inproceedings{kendall2019learning,
  title={Learning to drive in a day},
  author={Kendall, Alex and Hawke, Jeffrey and Janz, David and Mazur, Przemyslaw and Reda, Daniele and Allen, John-Mark and Lam, Vinh-Dieu and Bewley, Alex and Shah, Amar},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8248--8254},
  year={2019},
  organization={IEEE}
}

@article{maddern2017robotcar,
  title={1 year, 1000 km: The Oxford RobotCar dataset},
  author={Maddern, Will and Pascoe, Geoffrey and Linegar, Chris and Newman, Paul},
  journal={The International Journal of Robotics Research},
  volume={36},
  number={1},
  pages={3--15},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{codevilla2018end,
  title={End-to-end driving via conditional imitation learning},
  author={Codevilla, Felipe and Miiller, Matthias and L{\'o}pez, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1--9},
  year={2018},
  organization={IEEE}
}

@inproceedings{tassa2012synthesis,
  title={Synthesis and stabilization of complex behaviors through online trajectory optimization},
  author={Tassa, Yuval and Erez, Tom and Todorov, Emanuel},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={4906--4913},
  year={2012},
  organization={IEEE}
}

@inproceedings{pets,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4754--4765},
  year={2018}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{pietquin2011sample,
  title={Sample-efficient batch reinforcement learning for dialogue management optimization},
  author={Pietquin, Olivier and Geist, Matthieu and Chandramohan, Senthilkumar and Frezza-Buet, Herv{\'e}},
  journal={ACM Transactions on Speech and Language Processing (TSLP)},
  volume={7},
  number={3},
  pages={1--21},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@article{gottesman2019guidelines,
  title={Guidelines for reinforcement learning in healthcare},
  author={Gottesman, Omer and Johansson, Fredrik and Komorowski, Matthieu and Faisal, Aldo and Sontag, David and Doshi-Velez, Finale and Celi, Leo Anthony},
  journal={Nat Med},
  volume={25},
  number={1},
  pages={16--18},
  year={2019}
}

@inproceedings{swaminathan2015self,
  title={The self-normalized estimator for counterfactual learning},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={advances in neural information processing systems},
  pages={3231--3239},
  year={2015}
}

@book{rockafellar1970convex,
  title={Convex analysis},
  author={Rockafellar, R Tyrrell},
  number={28},
  year={1970},
  publisher={Princeton university press}
}

@article{nachum2020reinforcement,
  title={Reinforcement Learning via Fenchel-Rockafellar Duality},
  author={Nachum, Ofir and Dai, Bo},
  journal={arXiv preprint arXiv:2001.01866},
  year={2020}
}

@inproceedings{nachum2019dualdice,
  title={Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections},
  author={Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2315--2325},
  year={2019}
}

@article{eysenbach2017leave,
  title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
  author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.06782},
  year={2017}
}

@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@inproceedings{osband2018randomized,
  title={Randomized prior functions for deep reinforcement learning},
  author={Osband, Ian and Aslanides, John and Cassirer, Albin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8617--8629},
  year={2018}
}


@inproceedings{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Advances in neural information processing systems},
  pages={6402--6413},
  year={2017}
}

@article{achiam2019towards,
  title={Towards characterizing divergence in deep q-learning},
  author={Achiam, Joshua and Knight, Ethan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1903.08894},
  year={2019}
}

@article{gupta2019relay,
  title={Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:1910.11956},
  year={2019}
}

@inproceedings{osband2016deep,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={4026--4034},
  year={2016}
}

@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={Journal of machine learning research},
  volume={4},
  number={Dec},
  pages={1107--1149},
  year={2003}
}

@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM Sigart Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011}
}

@article{johnson2016mimic,
  title={MIMIC-III, a freely accessible critical care database},
  author={Johnson, Alistair EW and Pollard, Tom J and Shen, Lu and Li-wei, H Lehman and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Celi, Leo Anthony and Mark, Roger G},
  journal={Scientific data},
  volume={3},
  pages={160035},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{guez2008adaptive,
  title={Adaptive Treatment of Epilepsy via Batch-mode Reinforcement Learning.},
  author={Guez, Arthur and Vincent, Robert D and Avoli, Massimo and Pineau, Joelle},
  booktitle={AAAI},
  pages={1671--1678},
  year={2008}
}

@article{pipps,
  title={PIPPS: Flexible model-based policy search robust to the curse of chaos},
  author={Parmas, Paavo and Rasmussen, Carl Edward and Peters, Jan and Doya, Kenji},
  journal={arXiv preprint arXiv:1902.01240},
  year={2019}
}

@article{simpl,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@inproceedings{mbpo,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12498--12509},
  year={2019}
}

@article{raghu2017deep,
  title={Deep reinforcement learning for sepsis treatment},
  author={Raghu, Aniruddh and Komorowski, Matthieu and Ahmed, Imran and Celi, Leo and Szolovits, Peter and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:1711.09602},
  year={2017}
}

@article{prasad2017reinforcement,
  title={A reinforcement learning approach to weaning of mechanical ventilation in intensive care units},
  author={Prasad, Niranjani and Cheng, Li-Fang and Chivers, Corey and Draugelis, Michael and Engelhardt, Barbara E},
  journal={arXiv preprint arXiv:1704.06300},
  year={2017}
}

@inproceedings{swaminathan2017off,
  title={Off-policy evaluation for slate recommendation},
  author={Swaminathan, Adith and Krishnamurthy, Akshay and Agarwal, Alekh and Dudik, Miro and Langford, John and Jose, Damien and Zitouni, Imed},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3632--3642},
  year={2017}
}

@inproceedings{osband2017posterior,
  title={Why is posterior sampling better than optimism for reinforcement learning?},
  author={Osband, Ian and Van Roy, Benjamin},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2701--2710},
  year={2017},
  organization={JMLR. org}
}

@article{peng2019awr,
  title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{sriperumbudur2009integral,
  title={On integral probability metrics,$\backslash$phi-divergences and binary classification},
  author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG},
  journal={arXiv preprint arXiv:0901.2698},
  year={2009}
}

@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}

@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11761--11771},
  year={2019}
}

@article{siegel2020keep,
  title={Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning},
  author={Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Riedmiller, Martin},
  journal={arXiv preprint arXiv:2002.08396},
  year={2020}
}

@inproceedings{nowozin2016f,
  title={f-gan: Training generative neural samplers using variational divergence minimization},
  author={Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
  booktitle={Advances in neural information processing systems},
  pages={271--279},
  year={2016}
}

@article{wu2019domain,
  title={Domain adaptation with asymmetrically-relaxed distribution alignment},
  author={Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  journal={arXiv preprint arXiv:1903.01689},
  year={2019}
}

@inproceedings{sutton2009fastgtd,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={993--1000},
  year={2009}
}


@article{alphastar,
  title={Mastering the Real-Time Strategy Game StarCraft II},
  author={AlphaStar, DeepMind},
  journal={URL: https://deepmind. com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii}
}

@article{lu2018general,
  title={A General Family of Robust Stochastic Operators for Reinforcement Learning},
  author={Lu, Yingdong and Squillante, Mark S and Wu, Chai Wah},
  journal={arXiv preprint arXiv:1805.08122},
  year={2018}
}

@inproceedings{
Zhang2020GenDICE:,
title={GenDICE: Generalized Offline Estimation of Stationary Values},
author={Ruiyi Zhang and Bo Dai and Lihong Li and Dale Schuurmans},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HkxlcnVFwB}
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{bellemare2016increasing,
  title={Increasing the action gap: New operators for reinforcement learning},
  author={Bellemare, Marc G and Ostrovski, Georg and Guez, Arthur and Thomas, Philip S and Munos, R{\'e}mi},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{rajeswaran2018dapg,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2018}
}

@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@misc{
sachdeva2020offpolicy,
title={Off-policy Bandits with Deficient Support},
author={Noveen Sachdeva and Yi Su and Thorsten Joachims},
year={2020},
url={https://openreview.net/forum?id=SklcyJBtvB}
}

@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 19th international conference on World wide web},
  pages={661--670},
  year={2010}
}

@article{o2018variational,
  title={Variational Bayesian reinforcement learning with regret bounds},
  author={O'Donoghue, Brendan},
  journal={arXiv preprint arXiv:1807.09647},
  year={2018}
}

@inproceedings{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado V},
  booktitle={Advances in neural information processing systems},
  pages={2613--2621},
  year={2010}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@InProceedings{fujimoto2018addressing,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@misc{d4rl_repo,
title = {D4RL: Datasets for Data-Driven Deep Reinforcement Learning},
author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
note = {Github repository},
year = {2020},
howpublished  = {\url{https://github.com/rail-berkeley/d4rl/wiki/New-Franka-Kitchen-Tasks}}
}

@inproceedings{blanc2020implicit,
  title={Implicit regularization for deep neural networks driven by an ornstein-uhlenbeck like process},
  author={Blanc, Guy and Gupta, Neha and Valiant, Gregory and Valiant, Paul},
  booktitle={Conference on learning theory},
  pages={483--513},
  year={2020},
  organization={PMLR}
}

@article{furuichi2004fundamental,
  title={Fundamental properties of Tsallis relative entropy},
  author={Furuichi, Shigeru and Yanagi, Kenjiro and Kuriyama, Ken},
  journal={Journal of Mathematical Physics},
  volume={45},
  number={12},
  pages={4868--4877},
  year={2004},
  publisher={American Institute of Physics}
}

@inproceedings{namkoong2017variance,
  title={Variance-based regularization with convex objectives},
  author={Namkoong, Hongseok and Duchi, John C},
  booktitle={Advances in neural information processing systems},
  pages={2971--2980},
  year={2017}
}

@inproceedings{tamar2014scaling,
  title={Scaling up robust MDPs using function approximation},
  author={Tamar, Aviv and Mannor, Shie and Xu, Huan},
  booktitle={International Conference on Machine Learning},
  pages={181--189},
  year={2014}
}

@article{nair2020accelerating,
  title={Accelerating Online Reinforcement Learning with Offline Datasets},
  author={Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@inproceedings{nilim2004robustness,
  title={Robustness in Markov decision problems with uncertain transition matrices},
  author={Nilim, Arnab and El Ghaoui, Laurent},
  booktitle={Advances in neural information processing systems},
  pages={839--846},
  year={2004}
}

@article{russel2018tight,
  title={Tight bayesian ambiguity sets for robust MDPs},
  author={Russel, Reazul Hasan and Petrik, Marek},
  journal={arXiv preprint arXiv:1811.06512},
  year={2018}
}

@article{iyengar2005robust,
  title={Robust dynamic programming},
  author={Iyengar, Garud N},
  journal={Mathematics of Operations Research},
  volume={30},
  number={2},
  pages={257--280},
  year={2005},
  publisher={INFORMS}
}

@inproceedings{ghavamzadeh2016safe,
  title={Safe policy improvement by minimizing robust baseline regret},
  author={Petrik, Marek and Ghavamzadeh, Mohammad and Chow, Yinlam},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2298--2306},
  year={2016}
}

@inproceedings{strehl2010learning,
  title={Learning from logged implicit exploration data},
  author={Strehl, Alex and Langford, John and Li, Lihong and Kakade, Sham M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2217--2225},
  year={2010}
}

@article{simao2019safe,
  title={Safe Policy Improvement with an Estimated Baseline Policy},
  author={Sim{\~a}o, Thiago D and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1909.05236},
  year={2019}
}

@article{laroche2017safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1712.06924},
  year={2017}
}

@article{nachum2019algaedice,
  title={AlgaeDICE: Policy Gradient from Arbitrary Experience},
  author={Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1912.02074},
  year={2019}
}

@article{brac,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}

@inproceedings{o2018uncertainty,
  title={The Uncertainty Bellman Equation and Exploration},
  author={O’Donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Volodymyr},
  booktitle={International Conference on Machine Learning},
  pages={3836--3845},
  year={2018}
}

@inproceedings{gilotte2018offline,
  title={Offline a/b testing for recommender systems},
  author={Gilotte, Alexandre and Calauz{\`e}nes, Cl{\'e}ment and Nedelec, Thomas and Abraham, Alexandre and Doll{\'e}, Simon},
  booktitle={Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
  pages={198--206},
  year={2018}
}

@article{bottou2013counterfactual,
  title={Counterfactual reasoning and learning systems: The example of computational advertising},
  author={Bottou, L{\'e}on and Peters, Jonas and Qui{\~n}onero-Candela, Joaquin and Charles, Denis X and Chickering, D Max and Portugaly, Elon and Ray, Dipankar and Simard, Patrice and Snelson, Ed},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={3207--3260},
  year={2013},
  publisher={JMLR. org}
}

@inproceedings{theocharous2015personalized,
  title={Personalized ad recommendation systems for life-time value optimization with guarantees},
  author={Theocharous, Georgios and Thomas, Philip S and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}


@article{henderson2008hybrid,
  title={Hybrid reinforcement/supervised learning of dialogue policies from fixed data sets},
  author={Henderson, James and Lemon, Oliver and Georgila, Kallirroi},
  journal={Computational Linguistics},
  volume={34},
  number={4},
  pages={487--511},
  year={2008},
  publisher={MIT Press}
}


@inproceedings{tesauro2006hybrid,
  title={A hybrid reinforcement learning approach to autonomic resource allocation},
  author={Tesauro, Gerald and Jong, Nicholas K and Das, Rajarshi and Bennani, Mohamed N},
  booktitle={2006 IEEE International Conference on Autonomic Computing},
  pages={65--73},
  year={2006},
  organization={IEEE}
}

@inproceedings{nazari2018reinforcement,
  title={Reinforcement learning for solving the vehicle routing problem},
  author={Nazari, Mohammadreza and Oroojlooy, Afshin and Snyder, Lawrence and Tak{\'a}c, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9839--9849},
  year={2018}
}

@article{balaji2010urban,
  title={Urban traffic signal control using reinforcement learning agents},
  author={Balaji, PG and German, X and Srinivasan, Dipti},
  journal={IET Intelligent Transport Systems},
  volume={4},
  number={3},
  pages={177--188},
  year={2010},
  publisher={IET}
}

@inproceedings{hein2017industrial,
  title={Batch reinforcement learning on the industrial benchmark: First experiences},
  author={Hein, Daniel and Udluft, Steffen and Tokic, Michel and Hentschel, Alexander and Runkler, Thomas A and Sterzing, Volkmar},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
  pages={4214--4221},
  year={2017},
  organization={IEEE}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}

@article{espeholt2018impala,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Volodymir and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  journal={arXiv preprint arXiv:1802.01561},
  year={2018}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={22--31},
  year={2017},
  organization={JMLR. org}
}


@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@article{fu2019diagnosing,
  title={Diagnosing bottlenecks in deep {Q}-learning algorithms},
  author={Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  journal={arXiv preprint arXiv:1902.10250},
  year={2019}
}

@inproceedings{imani2018off,
  title={An off-policy policy gradient theorem using emphatic weightings},
  author={Imani, Ehsan and Graves, Eric and White, Martha},
  booktitle={Advances in Neural Information Processing Systems},
  pages={96--106},
  year={2018}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year={2014}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{gu2017interpolated,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in neural information processing systems},
  pages={3846--3855},
  year={2017}
}

@inproceedings{gelada2019off,
  title={Off-policy deep reinforcement learning by bootstrapping the covariate shift},
  author={Gelada, Carles and Bellemare, Marc G},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={3647--3655},
  year={2019}
}

@article{gabel2008adaptive,
  title={Adaptive reactive job-shop scheduling with reinforcement learning agents},
  author={Gabel, Thomas and Riedmiller, Martin},
  journal={International Journal of Information Technology and Intelligent Computing},
  volume={24},
  number={4},
  pages={14--18},
  year={2008},
  publisher={Citeseer}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@article{peshkin2002learning,
  title={Learning from scarce experience},
  author={Peshkin, Leonid and Shelton, Christian R},
  journal={arXiv preprint cs/0204043},
  year={2002}
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={ICML},
  pages={417--424},
  year={2001}
}

@inproceedings{hallak2017consistent,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1372--1383},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{thomas2016data,
  title={Data-efficient off-policy policy evaluation for reinforcement learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={2139--2148},
  year={2016}
}

@inproceedings{wang2017optimal,
  title={Optimal and adaptive off-policy evaluation in contextual bandits},
  author={Wang, Yu-Xiang and Agarwal, Alekh and Dudik, Miroslav},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3589--3597},
  year={2017},
  organization={JMLR. org}
}

@article{jiang2015doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  journal={arXiv preprint arXiv:1511.03722},
  year={2015}
}

@article{farajtabar2018more,
  title={More robust doubly robust off-policy evaluation},
  author={Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1802.03493},
  year={2018}
}

@inproceedings{thomas2015high,
  title={High confidence policy improvement},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={2380--2388},
  year={2015}
}


@inproceedings{scherrer2014approximate,
  title={Approximate policy iteration schemes: a comparison},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={1314--1322},
  year={2014}
}

@article{kumar2022pre,
  title={Pre-Training for Robots: Offline RL Enables Learning New Tasks from a Handful of Trials},
  author={Kumar, Aviral and Singh, Anikait and Ebert, Frederik and Yang, Yanlai and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2210.05178},
  year={2022}
}

@article{ajay2020opal,
  title={Opal: Offline primitive discovery for accelerating offline reinforcement learning},
  author={Ajay, Anurag and Kumar, Aviral and Agrawal, Pulkit and Levine, Sergey and Nachum, Ofir},
  journal={arXiv preprint arXiv:2010.13611},
  year={2020}
}

@inproceedings{hanna2017bootstrapping,
  title={Bootstrapping with models: Confidence intervals for off-policy evaluation},
  author={Hanna, Josiah P and Stone, Peter and Niekum, Scott},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{thomas2015higheval,
  title={High-confidence off-policy evaluation},
  author={Thomas, Philip S and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015}
}


@article{gu2016q,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}

@article{nadjahi2019safe,
  title={Safe Policy Improvement with Soft Baseline Bootstrapping},
  author={Nadjahi, Kimia and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1907.05079},
  year={2019}
}

@article{cheng2019trajectory,
  title={Trajectory-wise control variates for variance reduction in policy gradient methods},
  author={Cheng, Ching-An and Yan, Xinyan and Boots, Byron},
  journal={arXiv preprint arXiv:1908.03263},
  year={2019}
}

@article{pankov2018reward,
  title={Reward-estimation variance elimination in sequential decision processes},
  author={Pankov, Sergey},
  journal={arXiv preprint arXiv:1811.06225},
  year={2018}
}

@article{huang2019importance,
  title={From Importance Sampling to Doubly Robust Policy Gradient},
  author={Huang, Jiawei and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.09066},
  year={2019}
}

@article{sutton2016emphatic,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{yu2015convergence,
  title={On convergence of emphatic temporal-difference learning},
  author={Yu, Huizhen},
  booktitle={Conference on Learning Theory},
  pages={1724--1751},
  year={2015}
}

@inproceedings{hallak2016generalized,
  title={Generalized emphatic temporal difference learning: Bias-variance analysis},
  author={Hallak, Assaf and Tamar, Aviv and Munos, R{\'e}mi and Mannor, Shie},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{zhang2019generalized,
  title={Generalized off-policy actor-critic},
  author={Zhang, Shangtong and Boehmer, Wendelin and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1999--2009},
  year={2019}
}

@article{agarwal2021deep,
  title={Deep reinforcement learning at the edge of the statistical precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{ghasemipour2021emaq,
  title={Emaq: Expected-max q-learning operator for simple yet effective offline and online rl},
  author={Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  booktitle={International Conference on Machine Learning},
  pages={3682--3691},
  year={2021},
  organization={PMLR}
}

@article{hallak2015emphatic,
  title={Emphatic TD Bellman Operator is a Contraction},
  author={Hallak, Assaf and Tamar, Aviv and Mannor, Shie},
  journal={arXiv preprint arXiv:1508.03411},
  year={2015}
}

@inproceedings{liu2018breaking,
  title={Breaking the curse of horizon: Infinite-horizon off-policy estimation},
  author={Liu, Qiang and Li, Lihong and Tang, Ziyang and Zhou, Dengyong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5356--5366},
  year={2018}
}

@article{liu2019off,
  title={Off-policy policy gradient with state distribution correction},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={arXiv preprint arXiv:1904.08473},
  year={2019}
}

@article{mousavi2020black,
  title={Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning},
  author={Mousavi, Ali and Li, Lihong and Liu, Qiang and Zhou, Denny},
  journal={arXiv preprint arXiv:2003.11126},
  year={2020}
}

@article{kallus2019efficiently,
  title={Efficiently breaking the curse of horizon: Double reinforcement learning in infinite-horizon processes},
  author={Kallus, Nathan and Uehara, Masatoshi},
  journal={arXiv preprint arXiv:1909.05850},
  year={2019}
}

@inproceedings{kallus2019intrinsically,
  title={Intrinsically efficient, stable, and bounded off-policy evaluation for reinforcement learning},
  author={Kallus, Nathan and Uehara, Masatoshi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3320--3329},
  year={2019}
}

@article{uehara2019minimax,
  title={Minimax Weight and Q-Function Learning for Off-Policy Evaluation},
  author={Uehara, Masatoshi and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.12809},
  year={2019}
}

@article{tang2019doubly,
  title={Doubly robust bias reduction in infinite horizon off-policy estimation},
  author={Tang, Ziyang and Feng, Yihao and Li, Lihong and Zhou, Dengyong and Liu, Qiang},
  journal={arXiv preprint arXiv:1910.07186},
  year={2019}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{dai2017boosting,
  title={Boosting the actor with dual critic},
  author={Dai, Bo and Shaw, Albert and He, Niao and Li, Lihong and Song, Le},
  journal={arXiv preprint arXiv:1712.10282},
  year={2017}
}

@article{wang2021instabilities,
  title={Instabilities of Offline RL with Pre-Trained Neural Representation},
  author={Wang, Ruosong and Wu, Yifan and Salakhutdinov, Ruslan and Kakade, Sham M},
  journal={arXiv preprint arXiv:2103.04947},
  year={2021}
}

@article{kostrikov2021offline,
  title={Offline Reinforcement Learning with Fisher Divergence Critic Regularization},
  author={Kostrikov, Ilya and Tompson, Jonathan and Fergus, Rob and Nachum, Ofir},
  journal={arXiv preprint arXiv:2103.08050},
  year={2021}
}

@inproceedings{jin2021pessimism,
  title={Is pessimism provably efficient for offline rl?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={5084--5096},
  year={2021},
  organization={PMLR}
}

@article{dai2017sbeed,
  title={SBEED: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  journal={arXiv preprint arXiv:1712.10285},
  year={2017}
}

@article{chen2016stochastic,
  title={Stochastic primal-dual methods and sample complexity of reinforcement learning},
  author={Chen, Yichen and Wang, Mengdi},
  journal={arXiv preprint arXiv:1612.02516},
  year={2016}
}

@inproceedings{wang2016online,
  title={An online primal-dual method for discounted markov decision processes},
  author={Wang, Mengdi and Chen, Yichen},
  booktitle={2016 IEEE 55th Conference on Decision and Control (CDC)},
  pages={4516--4521},
  year={2016},
  organization={IEEE}
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=O9bnihsFfXU}
}

@article{hastie2019surprises,
  title={Surprises in high-dimensional ridgeless least squares interpolation},
  author={Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:1903.08560},
  year={2019}
}

@article{durugkar2018td,
  title={TD learning with constrained gradients},
  author={Durugkar, Ishan and Stone, Peter},
  year={2018}
}

@article{singh2020cog,
  title={COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning},
  author={Singh, Avi and Yu, Albert and Yang, Jonathan and Zhang, Jesse and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2010.14500},
  year={2020}
}

@inproceedings{dong2020expressivity,
  title={On the expressivity of neural networks for deep reinforcement learning},
  author={Dong, Kefan and Luo, Yuping and Yu, Tianhe and Finn, Chelsea and Ma, Tengyu},
  booktitle={International Conference on Machine Learning},
  pages={2627--2637},
  year={2020},
  organization={PMLR}
}

@inproceedings{savarese2019infinite,
  title={How do infinite width bounded norm networks look in function space?},
  author={Savarese, Pedro and Evron, Itay and Soudry, Daniel and Srebro, Nathan},
  booktitle={Conference on Learning Theory},
  pages={2667--2690},
  year={2019},
  organization={PMLR}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{
kumar2021workflow,
title={A Workflow for Offline Model-Free Robotic Reinforcement Learning},
author={Aviral Kumar and Anikait Singh and Stephen Tian and Chelsea Finn and Sergey Levine},
booktitle={5th Annual Conference on Robot Learning },
year={2021},
url={https://openreview.net/forum?id=fy4ZBWxYbIo}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@inproceedings{ghiassian2020gradient,
  title={Gradient temporal-difference learning with regularized corrections},
  author={Ghiassian, Sina and Patterson, Andrew and Garg, Shivam and Gupta, Dhawal and White, Adam and White, Martha},
  booktitle={International Conference on Machine Learning},
  pages={3524--3534},
  year={2020},
  organization={PMLR}
}

@inproceedings{gogianu2021spectral,
  title={Spectral normalisation for deep reinforcement learning: an optimisation perspective},
  author={Gogianu, Florin and Berariu, Tudor and Rosca, Mihaela C and Clopath, Claudia and Busoniu, Lucian and Pascanu, Razvan},
  booktitle={International Conference on Machine Learning},
  pages={3734--3744},
  year={2021},
  organization={PMLR}
}

@article{lee2021versions,
  title={Versions of Gradient Temporal Difference Learning},
  author={Lee, Donghwan and Lim, Han-Dong and Park, Jihoon and Choi, Okyong},
  journal={arXiv preprint arXiv:2109.04033},
  year={2021}
}

@article{cheng2022adversarially,
  title={Adversarially Trained Actor Critic for Offline Reinforcement Learning},
  author={Cheng, Ching-An and Xie, Tengyang and Jiang, Nan and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2202.02446},
  year={2022}
}

@article{xie2021bellman,
  title={Bellman-consistent pessimism for offline reinforcement learning},
  author={Xie, Tengyang and Cheng, Ching-An and Jiang, Nan and Mineiro, Paul and Agarwal, Alekh},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@inproceedings{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={322--332},
  year={2019},
  organization={PMLR}
}

@article{du2018gradient,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={arXiv preprint arXiv:1810.02054},
  year={2018}
}

@article{kostrikov2020image,
  title={Image augmentation is all you need: Regularizing deep reinforcement learning from pixels},
  author={Kostrikov, Ilya and Yarats, Denis and Fergus, Rob},
  journal={arXiv preprint arXiv:2004.13649},
  year={2020}
}

@article{kumar2021dr3,
  title={{DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization}},
  author={Kumar, Aviral and Agarwal, Rishabh and Ma, Tengyu and Courville, Aaron and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.04716},
  year={2021}
}

@article{pohlen2018observe,
  title={Observe and look further: Achieving consistent performance on atari},
  author={Pohlen, Tobias and Piot, Bilal and Hester, Todd and Azar, Mohammad Gheshlaghi and Horgan, Dan and Budden, David and Barth-Maron, Gabriel and Van Hasselt, Hado and Quan, John and Ve{\v{c}}er{\'\i}k, Mel and others},
  journal={arXiv preprint arXiv:1805.11593},
  year={2018}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{zanette2020exponential,
  title={Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can be Exponentially Harder than Online RL},
  author={Zanette, Andrea},
  journal={arXiv preprint arXiv:2012.08005},
  year={2020}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}

@inproceedings{
wang2021what,
title={What are the Statistical Limits of Offline {\{}RL{\}} with Linear Function Approximation?},
author={Ruosong Wang and Dean Foster and Sham M. Kakade},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=30EvkP2aQLD}
}

@article{liu2020provably,
  title={Provably Good Batch Off-Policy Reinforcement Learning Without Great Exploration},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{lee2018stochastic,
  title={Stochastic primal-dual Q-learning},
  author={Lee, Donghwan and He, Niao},
  journal={arXiv preprint arXiv:1810.08298},
  year={2018}
}

@inproceedings{swaminathan2015counterfactual,
  title={Counterfactual risk minimization: Learning from logged bandit feedback},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={International Conference on Machine Learning},
  pages={814--823},
  year={2015}
}

@article{hayes2005large,
  title={A large-deviation inequality for vector-valued martingales},
  author={Hayes, Thomas P},
  journal={Combinatorics, Probability and Computing},
  year={2005}
}


@ARTICLE{2019arXiv190600949K,
       author = {{Kumar}, Aviral and {Fu}, Justin and {Tucker}, George and {Levine}, Sergey},
        title = "{Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2019,
        month = jun,
          eid = {arXiv:1906.00949},
        pages = {arXiv:1906.00949},
archivePrefix = {arXiv},
       eprint = {1906.00949},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190600949K},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@ARTICLE{2021arXiv211001548A,
       author = {{An}, Gaon and {Moon}, Seungyong and {Kim}, Jang-Hyun and {Song}, Hyun Oh},
        title = "{Uncertainty-Based Offline Reinforcement Learning with Diversified Q-Ensemble}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
         year = 2021,
        month = oct,
          eid = {arXiv:2110.01548},
        pages = {arXiv:2110.01548},
archivePrefix = {arXiv},
       eprint = {2110.01548},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv211001548A},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{AWAC,
  author    = {Ashvin Nair and
               Murtaza Dalal and
               Abhishek Gupta and
               Sergey Levine},
  title     = {Accelerating Online Reinforcement Learning with Offline Datasets},
  journal   = {CoRR},
  volume    = {abs/2006.09359},
  year      = {2020},
  url       = {https://arxiv.org/abs/2006.09359},
  eprinttype = {arXiv},
  eprint    = {2006.09359},
  timestamp = {Wed, 17 Jun 2020 14:28:54 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2006-09359.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{one_step_RL,
  author    = {David Brandfonbrener and
               William F. Whitney and
               Rajesh Ranganath and
               Joan Bruna},
  title     = {Offline {RL} Without Off-Policy Evaluation},
  journal   = {CoRR},
  volume    = {abs/2106.08909},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.08909},
  eprinttype = {arXiv},
  eprint    = {2106.08909},
  timestamp = {Tue, 29 Jun 2021 16:55:04 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-08909.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@article{td3bc,
  author    = {Scott Fujimoto and
               Shixiang Shane Gu},
  title     = {A Minimalist Approach to Offline Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/2106.06860},
  year      = {2021},
  url       = {https://arxiv.org/abs/2106.06860},
  eprinttype = {arXiv},
  eprint    = {2106.06860},
  timestamp = {Tue, 15 Jun 2021 16:35:15 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2106-06860.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{
xiao2023the,
title={The In-Sample Softmax for Offline Reinforcement Learning},
author={Chenjun Xiao and Han Wang and Yangchen Pan and Adam White and Martha White},
booktitle={International Conference on Learning Representations},
year={2023},
url={https://openreview.net/forum?id=u-RuvyDYqCM}
}


%%%%%%%%%%%%%%%%%%%%
%%% Below are bib for the ROLLIN paper
%%%%%%%%%%%%%%%%%%%%
@inproceedings{sidford2018variance,
  title={Variance reduced value iteration and faster algorithms for solving markov decision processes},
  author={Sidford, Aaron and Wang, Mengdi and Wu, Xian and Ye, Yinyu},
  booktitle={Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms},
  pages={770--787},
  year={2018},
  organization={SIAM}
}

@article{sidford2018near,
  title={Near-optimal time and sample complexities for solving discounted Markov decision process with a generative model},
  author={Sidford, Aaron and Wang, Mengdi and Wu, Xian and Yang, Lin F and Ye, Yinyu},
  journal={arXiv preprint arXiv:1806.01492},
  year={2018}
}
@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{
goyal2018transfer,
title={Transfer and Exploration via the Information Bottleneck},
author={Anirudh Goyal and Riashat Islam and DJ Strouse and Zafarali Ahmed and Hugo Larochelle and Matthew Botvinick and Sergey Levine and Yoshua Bengio},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=rJg8yhAqKm},
}

@inproceedings{
Goyal2020The,
title={The Variational Bandwidth Bottleneck: Stochastic Evaluation on an Information Budget},
author={Anirudh Goyal and Yoshua Bengio and Matthew Botvinick and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Hye1kTVFDS}
}

@inproceedings{alemi2016deep,
title	= {Deep Variational Information Bottleneck},
author	= {Alex Alemi and Ian Fischer and Josh Dillon and Kevin Murphy},
year	= {2017},
URL	= {https://arxiv.org/abs/1612.00410},
booktitle	= {ICLR}
}



@inproceedings{agarwal2020model,
  title={Model-based reinforcement learning with a generative model is minimax optimal},
  author={Agarwal, Alekh and Kakade, Sham and Yang, Lin F},
  booktitle={Conference on Learning Theory},
  pages={67--83},
  year={2020}
}

@article{yang2019sample,
  title={Sample-optimal parametric q-learning using linearly additive features},
  author={Yang, Lin F and Wang, Mengdi},
  journal={arXiv preprint arXiv:1902.04779},
  year={2019}
}

@article{li2020breaking,
  title={Breaking the sample size barrier in model-based reinforcement learning with a generative model},
  author={Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
  journal={arXiv preprint arXiv:2005.12900},
  year={2020}
}

@article{wang2020randomized,
  title={Randomized linear programming solves the Markov decision problem in nearly linear (sometimes sublinear) time},
  author={Wang, Mengdi},
  journal={Mathematics of Operations Research},
  volume={45},
  number={2},
  pages={517--546},
  year={2020},
  publisher={INFORMS}
}

@article{azar2013minimax,
  title={Minimax PAC bounds on the sample complexity of reinforcement learning with a generative model},
  author={Azar, Mohammad Gheshlaghi and Munos, R{\'e}mi and Kappen, Hilbert J},
  journal={Machine learning},
  volume={91},
  number={3},
  pages={325--349},
  year={2013},
  publisher={Springer}
}

@inproceedings{kearns1999finite,
  title={Finite-sample convergence rates for Q-learning and indirect algorithms},
  author={Kearns, Michael J and Singh, Satinder P},
  booktitle={Advances in neural information processing systems},
  pages={996--1002},
  year={1999}
}

@inproceedings{yang2020harnessing,
  title={Harnessing Structures for Value-Based Planning and Reinforcement Learning},
  author={Yuzhe Yang and Guo Zhang and Zhi Xu and Dina Katabi},
  booktitle={International Conference on Learning Representations},
  year={2020},
  url={https://openreview.net/forum?id=rklHqRVKvH}
}

@inproceedings{dubeyICLRW18human,
    Author = {Dubey, Rachit and Agrawal, Pulkit
    and Pathak, Deepak and Griffiths, Thomas L.
    and Efros, Alexei A.},
    Title = {Investigating Human Priors for
    Playing Video Games},
    Booktitle = {ICML},
    Year = {2018},
}


@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{pananjady2020instance,
  title={Instance-dependent ℓ∞-bounds for policy evaluation in tabular reinforcement learning},
  author={Pananjady, Ashwin and Wainwright, Martin J},
  journal={IEEE Transactions on Information Theory},
  year={2020},
  publisher={IEEE}
}

@article{wainwright2019variance,
  title={Variance-reduced $ Q $-learning is minimax optimal},
  author={Wainwright, Martin J},
  journal={arXiv preprint arXiv:1906.04697},
  year={2019}
}


@inproceedings{
Wang2020Exploring,
title={Exploring Model-based Planning with Policy Networks},
author={Tingwu Wang and Jimmy Ba},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=H1exf64KwH}
}

@article{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@inproceedings{pathak2017curiosity,
  title={Curiosity-driven exploration by self-supervised prediction},
  author={Pathak, Deepak and Agrawal, Pulkit and Efros, Alexei A and Darrell, Trevor},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops},
  pages={16--17},
  year={2017}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@inproceedings{ng1999policy,
  title={Policy invariance under reward transformations: Theory and application to reward shaping},
  author={Ng, Andrew Y and Harada, Daishi and Russell, Stuart},
  booktitle={ICML},
  volume={99},
  pages={278--287},
  year={1999}
}

@article{even2003learning,
  title={Learning rates for Q-learning},
  author={Even-Dar, Eyal and Mansour, Yishay},
  journal={Journal of machine learning Research},
  volume={5},
  number={Dec},
  pages={1--25},
  year={2003}
}

@inproceedings{jiang2018open,
  title={Open problem: The dependence of sample complexity lower bounds on planning horizon},
  author={Jiang, Nan and Agarwal, Alekh},
  booktitle={Conference On Learning Theory},
  pages={3395--3398},
  year={2018}
}

@inproceedings{forejt2011automated,
  title={Automated verification techniques for probabilistic systems},
  author={Forejt, Vojt{\v{e}}ch and Kwiatkowska, Marta and Norman, Gethin and Parker, David},
  booktitle={International School on Formal Methods for the Design of Computer, Communication and Software Systems},
  pages={53--113},
  year={2011},
  organization={Springer}
}

@inproceedings{
liu2018competitive,
title={Competitive experience replay},
author={Hao Liu and Alexander Trott and Richard Socher and Caiming Xiong},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Sklsm20ctX},
}

@incollection{ng2006autonomous,
  title={Autonomous inverted helicopter flight via reinforcement learning},
  author={Ng, Andrew Y and Coates, Adam and Diel, Mark and Ganapathi, Varun and Schulte, Jamie and Tse, Ben and Berger, Eric and Liang, Eric},
  booktitle={Experimental robotics IX},
  pages={363--372},
  year={2006},
  publisher={Springer}
}

@article{levine2018learning,
  title={Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection},
  author={Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Ibarz, Julian and Quillen, Deirdre},
  journal={The International Journal of Robotics Research},
  volume={37},
  number={4-5},
  pages={421--436},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{tian2019elf,
  title={Elf opengo: An analysis and open reimplementation of alphazero},
  author={Tian, Yuandong and Ma, Jerry and Gong, Qucheng and Sengupta, Shubho and Chen, Zhuoyuan and Pinkerton, James and Zitnick, C Lawrence},
  journal={arXiv preprint arXiv:1902.04522},
  year={2019}
}

@article{li2018deep,
  title={Deep reinforcement learning},
  author={Li, Yuxi},
  journal={arXiv preprint arXiv:1810.06339},
  year={2018}
}

@article{guestrin2003efficient,
  title={Efficient solution algorithms for factored MDPs},
  author={Guestrin, Carlos and Koller, Daphne and Parr, Ronald and Venkataraman, Shobha},
  journal={Journal of Artificial Intelligence Research},
  volume={19},
  pages={399--468},
  year={2003}
}

@article{boutilier2000stochastic,
  title={Stochastic dynamic programming with factored representations},
  author={Boutilier, Craig and Dearden, Richard and Goldszmidt, Mois{\'e}s},
  journal={Artificial intelligence},
  volume={121},
  number={1-2},
  pages={49--107},
  year={2000},
  publisher={Elsevier}
}

%%% Q learning convergence paper

@inproceedings{bertsekas1995neuro,
  title={Neuro-dynamic programming: an overview},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  booktitle={Proceedings of 1995 34th IEEE conference on decision and control},
  volume={1},
  pages={560--564},
  year={1995},
  organization={IEEE}
}

@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  number={3},
  pages={185--202},
  year={1994},
  publisher={Springer}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{littman1996generalized,
  title={A generalized reinforcement-learning model: Convergence and applications},
  author={Littman, Michael L and Szepesv{\'a}ri, Csaba},
  booktitle={ICML},
  volume={96},
  pages={310--318},
  year={1996},
  organization={Citeseer}
}

@article{jaakkola1994convergence,
  title={On the convergence of stochastic iterative dynamic programming algorithms},
  author={Jaakkola, Tommi and Jordan, Michael I and Singh, Satinder P},
  journal={Neural computation},
  volume={6},
  number={6},
  pages={1185--1201},
  year={1994},
  publisher={MIT Press}
}

@article{borkar2000ode,
  title={The ODE method for convergence of stochastic approximation and reinforcement learning},
  author={Borkar, Vivek S and Meyn, Sean P},
  journal={SIAM Journal on Control and Optimization},
  volume={38},
  number={2},
  pages={447--469},
  year={2000},
  publisher={SIAM}
}

%%% Q learning convergence paper

@article{schrittwieser2020mastering,
  title={Mastering atari, go, chess and shogi by planning with a learned model},
  author={Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and others},
  journal={Nature},
  volume={588},
  number={7839},
  pages={604--609},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{liu2020learning,
  title={Learning Abstract Models for Strategic Exploration and Fast Reward Transfer},
  author={Liu, Evan Zheran and Keramati, Ramtin and Seshadri, Sudarshan and Guu, Kelvin and Pasupat, Panupong and Brunskill, Emma and Liang, Percy},
  journal={arXiv preprint arXiv:2007.05896},
  year={2020}
}

@misc{gym_minigrid,
  author = {Chevalier-Boisvert, Maxime and Willems, Lucas and Pal, Suman},
  title = {Minimalistic Gridworld Environment for OpenAI Gym},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/maximecb/gym-minigrid}},
}

@misc{Brockman2016OpenAI,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@inproceedings{
gleave2021quantifying,
title={Quantifying Differences in Reward Functions},
author={Adam Gleave and Michael D Dennis and Shane Legg and Stuart Russell and Jan Leike},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=LwEQnp6CYev}
}

@article{kearns2002sparse,
  title={A sparse sampling algorithm for near-optimal planning in large Markov decision processes},
  author={Kearns, Michael and Mansour, Yishay and Ng, Andrew Y},
  journal={Machine learning},
  volume={49},
  number={2},
  pages={193--208},
  year={2002},
  publisher={Springer}
}

@article{boutilier1999decision,
  title={Decision-theoretic planning: Structural assumptions and computational leverage},
  author={Boutilier, Craig and Dean, Thomas and Hanks, Steve},
  journal={Journal of Artificial Intelligence Research},
  volume={11},
  pages={1--94},
  year={1999}
}


@book{powell2007approximate,
  title={Approximate Dynamic Programming: Solving the curses of dimensionality},
  author={Powell, Warren B},
  volume={703},
  year={2007},
  publisher={John Wiley \& Sons}
}

@article{rintanen2001overview,
  title={An overview of recent algorithms for AI planning},
  author={Rintanen, Jussi and Hoffmann, J{\"o}rg},
  journal={KI},
  volume={15},
  number={2},
  pages={5--11},
  year={2001}
}


%%%%%
% Books for MDP
%%%%%

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@book{bertsekas1996neuro,
  title={Neuro-dynamic programming},
  author={Bertsekas, Dimitri P and Tsitsiklis, John N},
  year={1996},
  publisher={Athena Scientific}
}

@book{bertsekas2019reinforcement,
  title={Reinforcement Learning and Optimal Control},
  author={Bertsekas, Dimitri P},
  year = {2019},
  publisher = {Athena Scientific}
}

@book{bertsekas1995dynamic,
  title={Dynamic Programming and Optimal Control},
  author={Bertsekas, Dimitri P},
  year={1995},
  publisher={Athena Scientific}
}

@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{szepesvari2010algorithms,
  title={Algorithms for reinforcement learning},
  author={Szepesv{\'a}ri, Csaba},
  journal={Synthesis lectures on artificial intelligence and machine learning},
  volume={4},
  number={1},
  pages={1--103},
  year={2010},
  publisher={Morgan \& Claypool Publishers}
}

%%%%%
% Hierarchical Robotics Planning
%%%%%

@inproceedings{kaelbling2011hierarchical,
  title={Hierarchical task and motion planning in the now},
  author={Kaelbling, Leslie Pack and Lozano-P{\'e}rez, Tom{\'a}s},
  booktitle={2011 IEEE International Conference on Robotics and Automation},
  pages={1470--1477},
  year={2011},
  organization={IEEE}
}

@article{silver2021learning,
  title={Learning Symbolic Operators for Task and Motion Planning},
  author={Silver, Tom and Chitnis, Rohan and Tenenbaum, Joshua and Kaelbling, Leslie Pack and Lozano-Perez, Tomas},
  journal={arXiv preprint arXiv:2103.00589},
  year={2021}
}

@inproceedings{singh2009rewards,
  title={Where do rewards come from},
  author={Singh, Satinder and Lewis, Richard L and Barto, Andrew G},
  booktitle={Proceedings of the annual conference of the cognitive science society},
  pages={2601--2606},
  year={2009},
  organization={Cognitive Science Society}
}

@article{singh2010intrinsically,
  title={Intrinsically motivated reinforcement learning: An evolutionary perspective},
  author={Singh, Satinder and Lewis, Richard L and Barto, Andrew G and Sorg, Jonathan},
  journal={IEEE Transactions on Autonomous Mental Development},
  volume={2},
  number={2},
  pages={70--82},
  year={2010},
  publisher={IEEE}
}


%%%%%%
% Methods that study the hierarchical structures with subgoals
%%%%%%

@article{wen2020efficiency,
  title={On Efficiency in Hierarchical Reinforcement Learning},
  author={Wen, Zheng and Precup, Doina and Ibrahimi, Morteza and Barreto, Andre and Van Roy, Benjamin and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{kaelbling1993hierarchical,
  title={Hierarchical learning in stochastic domains: Preliminary results},
  author={Kaelbling, Leslie Pack},
  booktitle={Proceedings of the tenth international conference on machine learning},
  volume={951},
  pages={167--173},
  year={1993}
}

@inproceedings{dayan1992feudal,
 author = {Dayan, Peter and Hinton, Geoffrey E},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Hanson and J. Cowan and C. Giles},
 pages = {},
 publisher = {Morgan-Kaufmann},
 title = {Feudal Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/1992/file/d14220ee66aeec73c49038385428ec4c-Paper.pdf},
 volume = {5},
 year = {1993}
}

@inproceedings{sutton1998intra,
  title={Intra-Option Learning about Temporally Abstract Actions.},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder P},
  booktitle={ICML},
  volume={98},
  pages={556--564},
  year={1998}
}

@inproceedings{diuk2008object,
  title={An object-oriented representation for efficient reinforcement learning},
  author={Diuk, Carlos and Cohen, Andre and Littman, Michael L},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={240--247},
  year={2008}
}

@inproceedings{vezhnevets2017feudal,
  title={Feudal networks for hierarchical reinforcement learning},
  author={Vezhnevets, Alexander Sasha and Osindero, Simon and Schaul, Tom and Heess, Nicolas and Jaderberg, Max and Silver, David and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={3540--3549},
  year={2017},
  organization={PMLR}
}

@article{dietterich2000hierarchical,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={Journal of artificial intelligence research},
  volume={13},
  pages={227--303},
  year={2000}
}

@article{kulkarni2016hierarchical,
  title={Hierarchical deep reinforcement learning: Integrating temporal abstraction and intrinsic motivation},
  author={Kulkarni, Tejas D and Narasimhan, Karthik R and Saeedi, Ardavan and Tenenbaum, Joshua B},
  journal={arXiv preprint arXiv:1604.06057},
  year={2016}
}

@inproceedings{le2018hierarchical,
  title={Hierarchical imitation and reinforcement learning},
  author={Le, Hoang and Jiang, Nan and Agarwal, Alekh and Dud{\'\i}k, Miroslav and Yue, Yisong and Daum{\'e}, Hal},
  booktitle={International Conference on Machine Learning},
  pages={2917--2926},
  year={2018},
  organization={PMLR}
}

@article{sutton1999between,
  title={Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning},
  author={Sutton, Richard S and Precup, Doina and Singh, Satinder},
  journal={Artificial intelligence},
  volume={112},
  number={1-2},
  pages={181--211},
  year={1999},
  publisher={Elsevier}
}

@article{barto2003recent,
  title={Recent advances in hierarchical reinforcement learning},
  author={Barto, Andrew G and Mahadevan, Sridhar},
  journal={Discrete event dynamic systems},
  volume={13},
  number={1},
  pages={41--77},
  year={2003},
  publisher={Springer}
}

@article{parr1998reinforcement,
  title={Reinforcement learning with hierarchies of machines},
  author={Parr, Ronald and Russell, Stuart},
  journal={Advances in neural information processing systems},
  pages={1043--1049},
  year={1998},
  publisher={MORGAN KAUFMANN PUBLISHERS}
}

@book{parr1998hierarchical,
  title={Hierarchical control and learning for Markov decision processes},
  author={Parr, Ronald Edward},
  year={1998},
  publisher={University of California, Berkeley Berkeley, CA}
}

%% Subgoals
@inproceedings{dean1995decomposition,
  title={Decomposition techniques for planning in stochastic domains},
  author={Dean, Thomas and Lin, Shieu-Hong},
  booktitle={IJCAI},
  volume={2},
  pages={3},
  year={1995},
  organization={Citeseer}
}

@article{singh1998dynamically,
  title={How to dynamically merge Markov decision processes},
  author={Singh, Satinder and Cohn, David and others},
  journal={Advances in neural information processing systems},
  number={10},
  pages={1057--1063},
  year={1998},
  publisher={Citeseer}
}

@inproceedings{meuleau1998solving,
  title={Solving very large weakly coupled Markov decision processes},
  author={Meuleau, Nicolas and Hauskrecht, Milos and Kim, Kee-Eung and Peshkin, Leonid and Kaelbling, Leslie Pack and Dean, Thomas L and Boutilier, Craig},
  booktitle={AAAI/IAAI},
  pages={165--172},
  year={1998}
}

@article{mann2015approximate,
  title={Approximate value iteration with temporally extended actions},
  author={Mann, Timothy A and Mannor, Shie and Precup, Doina},
  journal={Journal of Artificial Intelligence Research},
  volume={53},
  pages={375--438},
  year={2015}
}

@inproceedings{stolle2002learning,
  title={Learning options in reinforcement learning},
  author={Stolle, Martin and Precup, Doina},
  booktitle={International Symposium on abstraction, reformulation, and approximation},
  pages={212--223},
  year={2002},
  organization={Springer}
}

@inproceedings{simsek2008skill,
  title={Skill characterization based on betweenness},
  author={Simsek, Ozgur and Barreto, Andre S},
  booktitle={Advances in neural information processing systems},
  pages={1497--1504},
  year={2008}
}

@article{solway2014optimal,
  title={Optimal behavioral hierarchy},
  author={Solway, Alec and Diuk, Carlos and C{\'o}rdova, Natalia and Yee, Debbie and Barto, Andrew G and Niv, Yael and Botvinick, Matthew M},
  journal={PLOS Comput Biol},
  volume={10},
  number={8},
  pages={e1003779},
  year={2014},
  publisher={Public Library of Science}
}

@inproceedings{jiang2016structural,
  title={On Structural Properties of MDPs that Bound Loss Due to Shallow Planning.},
  author={Jiang, Nan and Singh, Satinder P and Tewari, Ambuj},
  booktitle={IJCAI},
  pages={1640--1647},
  year={2016}
}

@inproceedings{bakker2004hierarchical,
  title={Hierarchical reinforcement learning based on subgoal discovery and subpolicy specialization},
  author={Bakker, Bram and Schmidhuber, J{\"u}rgen and others},
  booktitle={Proc. of the 8-th Conf. on Intelligent Autonomous Systems},
  pages={438--445},
  year={2004},
  organization={Citeseer}
}

@article{mcgovern2001automatic,
  title={Automatic discovery of subgoals in reinforcement learning using diverse density},
  author={McGovern, Amy and Barto, Andrew G},
  year={2001}
}

@inproceedings{goel2003subgoal,
  title={Subgoal discovery for hierarchical reinforcement learning using learned policies},
  author={Goel, Sandeep and Huber, Manfred},
  booktitle={FLAIRS conference},
  pages={346--350},
  year={2003}
}

%% Robotics planning

@inproceedings{gopalan2017planning,
  title={Planning with abstract Markov decision processes},
  author={Gopalan, Nakul and Littman, Michael and MacGlashan, James and Squire, Shawn and Tellex, Stefanie and Winder, John and Wong, Lawson and others},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  volume={27},
  number={1},
  year={2017}
}

@inproceedings{goel2003subgoal,
  title={Subgoal discovery for hierarchical reinforcement learning using learned policies},
  author={Goel, Sandeep and Huber, Manfred},
  booktitle={FLAIRS conference},
  pages={346--350},
  year={2003}
}

@book{lavalle2006planning,
  title={Planning algorithms},
  author={LaValle, Steven M},
  year={2006},
  publisher={Cambridge university press}
}

@book{siciliano2010robotics,
  title={Robotics: modelling, planning and control},
  author={Siciliano, Bruno and Sciavicco, Lorenzo and Villani, Luigi and Oriolo, Giuseppe},
  year={2010},
  publisher={Springer Science \& Business Media}
}

@book{russell2016artificial,
  title={Artificial Intelligence: a modern approach},
  author={Russell, Stuart J. and Norvig, Peter},
  edition={3},
  year={2009},
  publisher={Pearson}
}

%% Planning & Subgoals & MDP

@article{xu2020hierarchial,
  title={Hierarchial Reinforcement Learning in StarCraft II with Human Expertise in Subgoals Selection},
  author={Xu, Xinyi and Huang, Tiancheng and Wei, Pengfei and Narayan, Akshay and Leong, Tze-Yun},
  journal={arXiv preprint arXiv:2008.03444},
  year={2020}
}

@inproceedings{goel2003subgoal,
  title={Subgoal discovery for hierarchical reinforcement learning using learned policies},
  author={Goel, Sandeep and Huber, Manfred},
  booktitle={FLAIRS conference},
  pages={346--350},
  year={2003}
}

@inproceedings{mcgovern1998hierarchical,
  title={Hierarchical optimal control of MDPs},
  author={McGovern, Amy and Precup, Doina and Ravindran, Balaraman and Singh, Satinder and Sutton, Richard S},
  booktitle={Proceedings of the Tenth Yale Workshop on Adaptive and Learning Systems},
  pages={186--191},
  year={1998}
}

@article{hauskrecht2013hierarchical,
  title={Hierarchical solution of Markov decision processes using macro-actions},
  author={Hauskrecht, Milos and Meuleau, Nicolas and Kaelbling, Leslie Pack and Dean, Thomas L and Boutilier, Craig},
  journal={arXiv preprint arXiv:1301.7381},
  year={2013}
}

@article{precup1998multi,
  title={Multi-time models for temporally abstract planning},
  author={Precup, Doina and Sutton, Richard S and Singh, S},
  journal={Advances in neural information processing systems},
  pages={1050--1056},
  year={1998},
  publisher={MORGAN KAUFMANN PUBLISHERS}
}
%%%%%
%% Carefully designed reward function papers:
%%%%%

@article{oh2015action,
  title={Action-conditional video prediction using deep networks in atari games},
  author={Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard and Singh, Satinder},
  journal={arXiv preprint arXiv:1507.08750},
  year={2015}
}

@article{sorg2010reward,
  title={Reward design via online gradient ascent},
  author={Sorg, Jonathan and Lewis, Richard L and Singh, Satinder},
  journal={Advances in Neural Information Processing Systems},
  volume={23},
  pages={2190--2198},
  year={2010},
  publisher={Citeseer}
}

@article{guo2014deep,
  title={Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning},
  author={Guo, Xiaoxiao and Singh, Satinder and Lee, Honglak and Lewis, Richard L and Wang, Xiaoshi},
  journal={Advances in neural information processing systems},
  volume={27},
  pages={3338--3346},
  year={2014}
}

@phdthesis{guo2017deep,
  title={Deep learning and reward design for reinforcement learning},
  author={Guo, Xiaoxiao},
  year={2017}
}

@article{rudner2021outcome,
  title={Outcome-Driven Reinforcement Learning via Variational Inference},
  author={Rudner, Tim GJ and Pong, Vitchyr H and McAllister, Rowan and Gal, Yarin and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.10190},
  year={2021}
}

%(The pacman)
@inproceedings{
Raileanu2020RIDE:,
title={RIDE: Rewarding Impact-Driven Exploration for Procedurally-Generated Environments},
author={Roberta Raileanu and Tim Rocktäschel},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkg-TJBFPB}
}

@article{berner2019dota,
  title={Dota 2 with large scale deep reinforcement learning},
  author={Berner, Christopher and Brockman, Greg and Chan, Brooke and Cheung, Vicki and D{\k{e}}biak, Przemys{\l}aw and Dennison, Christy and Farhi, David and Fischer, Quirin and Hashme, Shariq and Hesse, Chris and others},
  journal={arXiv preprint arXiv:1912.06680},
  year={2019}
}

@misc{OpenAI_dota,
      author = {OpenAI},
      title = {OpenAI Five},
      howpublished = {\url{https://blog.openai.com/openai-five/}},
      year = {2018}
}

@article{fuchs2021super,
  title={Super-human performance in gran turismo sport using deep reinforcement learning},
  author={Fuchs, Florian and Song, Yunlong and Kaufmann, Elia and Scaramuzza, Davide and D{\"u}rr, Peter},
  journal={IEEE Robotics and Automation Letters},
  volume={6},
  number={3},
  pages={4257--4264},
  year={2021},
  publisher={IEEE}
}

@inproceedings{ye2020towards,
 author = {Ye, Deheng and Chen, Guibin and Zhang, Wen and Chen, Sheng and Yuan, Bo and Liu, Bo and Chen, Jia and Liu, Zhao and Qiu, Fuhao and Yu, Hongsheng and Yin, Yinyuting and Shi, Bei and Wang, Liang and Shi, Tengfei and Fu, Qiang and Yang, Wei and Huang, Lanxiao and Liu, Wei},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Larochelle and M. Ranzato and R. Hadsell and M. F. Balcan and H. Lin},
 pages = {621--632},
 publisher = {Curran Associates, Inc.},
 title = {Towards Playing Full MOBA Games with Deep Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/2020/file/06d5ae105ea1bea4d800bc96491876e9-Paper.pdf},
 volume = {33},
 year = {2020}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{vinyals2017starcraft,
  title={Starcraft ii: A new challenge for reinforcement learning},
  author={Vinyals, Oriol and Ewalds, Timo and Bartunov, Sergey and Georgiev, Petko and Vezhnevets, Alexander Sasha and Yeo, Michelle and Makhzani, Alireza and K{\"u}ttler, Heinrich and Agapiou, John and Schrittwieser, Julian and others},
  journal={arXiv preprint arXiv:1708.04782},
  year={2017}
}

@inproceedings{racaniere2017imagination,
  title={Imagination-augmented agents for deep reinforcement learning},
  author={Racani{\`e}re, S{\'e}bastien and Weber, Th{\'e}ophane and Reichert, David P and Buesing, Lars and Guez, Arthur and Rezende, Danilo and Badia, Adria Puigdomenech and Vinyals, Oriol and Heess, Nicolas and Li, Yujia and others},
  booktitle={Proceedings of the 31st International Conference on Neural Information Processing Systems},
  pages={5694--5705},
  year={2017}
}

@article{popov2017data,
  title={Data-efficient deep reinforcement learning for dexterous manipulation},
  author={Popov, Ivaylo and Heess, Nicolas and Lillicrap, Timothy and Hafner, Roland and Barth-Maron, Gabriel and Vecerik, Matej and Lampe, Thomas and Tassa, Yuval and Erez, Tom and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1704.03073},
  year={2017}
}

%%%
% Negative result of ``bad'' reward design
%%%

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@inproceedings{VanSeijen2017Hybrid,
 author = {Van Seijen, Harm and Fatemi, Mehdi and Romoff, Joshua and Laroche, Romain and Barnes, Tavian and Tsang, Jeffrey},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Hybrid Reward Architecture for Reinforcement Learning},
 url = {https://proceedings.neurips.cc/paper/2017/file/1264a061d82a2edae1574b07249800d6-Paper.pdf},
 volume = {30},
 year = {2017}
}



%%%
% Deep Learning
%%%

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
  volume={1},
  number={2},
  year={2016},
  publisher={MIT press Cambridge}
}

@article{Krakovsky2016Reinforcement,
author = {Krakovsky, Marina},
title = {Reinforcement Renaissance},
year = {2016},
issue_date = {August 2016},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {59},
number = {8},
issn = {0001-0782},
url = {https://doi.org/10.1145/2949662},
doi = {10.1145/2949662},
abstract = {The power of deep neural networks has sparked renewed interest in reinforcement learning, with applications to games, robotics, and beyond.},
journal = {Commun. ACM},
month = jul,
pages = {12–14},
numpages = {3}
}

%% Mujoco

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@inproceedings{duan2016benchmarking,
  title={Benchmarking deep reinforcement learning for continuous control},
  author={Duan, Yan and Chen, Xi and Houthooft, Rein and Schulman, John and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1329--1338},
  year={2016},
  organization={PMLR}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{kingma2017adam,
      title={Adam: A Method for Stochastic Optimization}, 
      author={Diederik P. Kingma and Jimmy Ba},
      year={2015},
      booktitle={International Conference on Learning Representations},
}

@misc{tieleman2012rmsprop,
  title={Lecture 6.5---RmsProp: Divide the gradient by a running average of its recent magnitude},
  author={Tieleman, T. and Hinton, G.},
  howpublished={COURSERA: Neural Networks for Machine Learning},
  year={2012}
}

%% Citing for JAIR
@article{kolter2011fixed,
  title={The fixed points of off-policy TD},
  author={Kolter, J},
  journal={Advances in Neural Information Processing Systems},
  volume={24},
  pages={2169--2177},
  year={2011}
}

@article{doroudi2019s,
  title={Where’s the reward?},
  author={Doroudi, Shayan and Aleven, Vincent and Brunskill, Emma},
  journal={International Journal of Artificial Intelligence in Education},
  volume={29},
  number={4},
  pages={568--620},
  year={2019},
  publisher={Springer}
}

%%% Reward Design HCI and Robotics
@article{he2021assisted,
  title={Assisted Robust Reward Design},
  author={He, Jerry Zhi-Yang and Dragan, Anca D},
  journal={arXiv preprint arXiv:2111.09884},
  year={2021}
}

%%% Goal Conditioned and Reward Design

@article{nasiriany2019planning,
  title={Planning with goal-conditioned policies},
  author={Nasiriany, Soroush and Pong, Vitchyr H and Lin, Steven and Levine, Sergey},
  journal={arXiv preprint arXiv:1911.08453},
  year={2019}
}

@inproceedings{schmidhuber1991curious,
  title={Curious model-building control systems},
  author={Schmidhuber, J{\"u}rgen},
  booktitle={Proc. international joint conference on neural networks},
  pages={1458--1463},
  year={1991}
}

@inproceedings{portelas2020teacher,
  title={Teacher algorithms for curriculum learning of deep rl in continuously parameterized environments},
  author={Portelas, R{\'e}my and Colas, C{\'e}dric and Hofmann, Katja and Oudeyer, Pierre-Yves},
  booktitle={Conference on Robot Learning},
  pages={835--853},
  year={2020},
  organization={PMLR}
}

@article{nair2018visual,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, Ashvin V and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{eysenbach2020rewriting,
  title={Rewriting history with inverse rl: Hindsight inference for policy improvement},
  author={Eysenbach, Ben and Geng, Xinyang and Levine, Sergey and Salakhutdinov, Russ R},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={14783--14795},
  year={2020}
}

@article{mendonca2021discovering,
  title={Discovering and achieving goals via world models},
  author={Mendonca, Russell and Rybkin, Oleh and Daniilidis, Kostas and Hafner, Danijar and Pathak, Deepak},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{tishby2000information,
  title={The information bottleneck method},
  author={Tishby, Naftali and Pereira, Fernando C and Bialek, William},
  journal={arXiv preprint physics/0004057},
  year={2000}
}

@inproceedings{hafner2019learning,
  title={Learning latent dynamics for planning from pixels},
  author={Hafner, Danijar and Lillicrap, Timothy and Fischer, Ian and Villegas, Ruben and Ha, David and Lee, Honglak and Davidson, James},
  booktitle={International conference on machine learning},
  pages={2555--2565},
  year={2019},
  organization={PMLR}
}

@article{hafner2020mastering,
  title={Mastering atari with discrete world models},
  author={Hafner, Danijar and Lillicrap, Timothy and Norouzi, Mohammad and Ba, Jimmy},
  journal={arXiv preprint arXiv:2010.02193},
  year={2020}
}

@article{peng2018variational,
  title={Variational discriminator bottleneck: Improving imitation learning, inverse rl, and gans by constraining information flow},
  author={Peng, Xue Bin and Kanazawa, Angjoo and Toyer, Sam and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1810.00821},
  year={2018}
}

@article{hafner2019dream,
  title={Dream to control: Learning behaviors by latent imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}

@inproceedings{tang2021hindsight,
  title={Hindsight expectation maximization for goal-conditioned reinforcement learning},
  author={Tang, Yunhao and Kucukelbir, Alp},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2863--2871},
  year={2021},
  organization={PMLR}
}

@article{borsa2018universal,
  title={Universal successor features approximators},
  author={Borsa, Diana and Barreto, Andr{\'e} and Quan, John and Mankowitz, Daniel and Munos, R{\'e}mi and Van Hasselt, Hado and Silver, David and Schaul, Tom},
  journal={arXiv preprint arXiv:1812.07626},
  year={2018}
}

@article{ghosh2019learning,
  title={Learning to reach goals via iterated supervised learning},
  author={Ghosh, Dibya and Gupta, Abhishek and Reddy, Ashwin and Fu, Justin and Devin, Coline and Eysenbach, Benjamin and Levine, Sergey},
  journal={arXiv preprint arXiv:1912.06088},
  year={2019}
}

@article{eysenbach2020c,
  title={C-learning: Learning to achieve goals via recursive classification},
  author={Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.08909},
  year={2020}
}

@article{rudner2021outcome,
  title={Outcome-Driven Reinforcement Learning via Variational Inference},
  author={Rudner, Tim GJ and Pong, Vitchyr H and McAllister, Rowan and Gal, Yarin and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.10190},
  year={2021}
}

@article{fu2018variational,
  title={Variational inverse control with events: A general framework for data-driven reward definition},
  author={Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey},
  journal={arXiv preprint arXiv:1805.11686},
  year={2018}
}

@article{pong2019skew,
  title={Skew-fit: State-covering self-supervised reinforcement learning},
  author={Pong, Vitchyr H and Dalal, Murtaza and Lin, Steven and Nair, Ashvin and Bahl, Shikhar and Levine, Sergey},
  journal={arXiv preprint arXiv:1903.03698},
  year={2019}
}

@inproceedings{andreas2017modular,
  title={Modular multitask reinforcement learning with policy sketches},
  author={Andreas, Jacob and Klein, Dan and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={166--175},
  year={2017},
  organization={PMLR}
}

@article{eysenbach2021replacing,
  title={Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification},
  author={Eysenbach, Benjamin and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2103.12656},
  year={2021}
}

@article{chebotar2021actionable,
  title={Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills},
  author={Chebotar, Yevgen and Hausman, Karol and Lu, Yao and Xiao, Ted and Kalashnikov, Dmitry and Varley, Jake and Irpan, Alex and Eysenbach, Benjamin and Julian, Ryan and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2104.07749},
  year={2021}
}

@article{khazatsky2021can,
  title={What Can I Do Here? Learning New Skills by Imagining Visual Affordances},
  author={Khazatsky, Alexander and Nair, Ashvin and Jing, Daniel and Levine, Sergey},
  journal={arXiv preprint arXiv:2106.00671},
  year={2021}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  pages={1094--1099},
  year={1993},
  organization={Citeseer}
}

@inproceedings{sutton2011horde,
  title={Horde: A scalable real-time architecture for learning knowledge from unsupervised sensorimotor interaction},
  author={Sutton, Richard S and Modayil, Joseph and Delp, Michael and Degris, Thomas and Pilarski, Patrick M and White, Adam and Precup, Doina},
  booktitle={The 10th International Conference on Autonomous Agents and Multiagent Systems-Volume 2},
  pages={761--768},
  year={2011}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1707.01495},
  year={2017}
}

@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}


@article{kadian2020sim2real,
  title={Sim2Real predictivity: Does evaluation in simulation predict real-world performance?},
  author={Kadian, Abhishek and Truong, Joanne and Gokaslan, Aaron and Clegg, Alexander and Wijmans, Erik and Lee, Stefan and Savva, Manolis and Chernova, Sonia and Batra, Dhruv},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={4},
  pages={6670--6677},
  year={2020},
  publisher={IEEE}
}

@inproceedings{fujita2020distributed,
  title={Distributed Reinforcement Learning of Targeted Grasping with Active Vision for Mobile Manipulators},
  author={Fujita, Yasuhiro and Uenishi, Kota and Ummadisingu, Avinash and Nagarajan, Prabhat and Masuda, Shimpei and Castro, Mario Ynocente},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={9712--9719},
  year={2020},
  organization={IEEE}
}

@article{ratner2018simplifying,
  title={Simplifying reward design through divide-and-conquer},
  author={Ratner, Ellis and Hadfield-Menell, Dylan and Dragan, Anca D},
  journal={arXiv preprint arXiv:1806.02501},
  year={2018}
}

@inproceedings{graves2017automated,
  title={Automated curriculum learning for neural networks},
  author={Graves, Alex and Bellemare, Marc G and Menick, Jacob and Munos, Remi and Kavukcuoglu, Koray},
  booktitle={international conference on machine learning},
  pages={1311--1320},
  year={2017},
  organization={PMLR}
}

@article{parker2022evolving,
  title={Evolving Curricula with Regret-Based Environment Design},
  author={Parker-Holder, Jack and Jiang, Minqi and Dennis, Michael and Samvelyan, Mikayel and Foerster, Jakob and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  journal={arXiv preprint arXiv:2203.01302},
  year={2022}
}

@article{fang2020adaptive,
  title={Adaptive procedural task generation for hard-exploration problems},
  author={Fang, Kuan and Zhu, Yuke and Savarese, Silvio and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2007.00350},
  year={2020}
}


@article{zhang2021c,
  title={C-Planning: An Automatic Curriculum for Learning Goal-Reaching Tasks},
  author={Zhang, Tianjun and Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey and Gonzalez, Joseph E},
  journal={arXiv preprint arXiv:2110.12080},
  year={2021}
}

@inproceedings{pitis2020maximum,
  title={Maximum entropy gain exploration for long horizon multi-goal reinforcement learning},
  author={Pitis, Silviu and Chan, Harris and Zhao, Stephen and Stadie, Bradly and Ba, Jimmy},
  booktitle={International Conference on Machine Learning},
  pages={7750--7761},
  year={2020},
  organization={PMLR}
}

@article{dennis2020emergent,
  title={Emergent complexity and zero-shot transfer via unsupervised environment design},
  author={Dennis, Michael and Jaques, Natasha and Vinitsky, Eugene and Bayen, Alexandre and Russell, Stuart and Critch, Andrew and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13049--13061},
  year={2020}
}

@article{matiisen2019teacher,
  title={Teacher--student curriculum learning},
  author={Matiisen, Tambet and Oliver, Avital and Cohen, Taco and Schulman, John},
  journal={IEEE transactions on neural networks and learning systems},
  volume={31},
  number={9},
  pages={3732--3740},
  year={2019},
  publisher={IEEE}
}


@article{warde2018unsupervised,
  title={Unsupervised control through non-parametric discriminative rewards},
  author={Warde-Farley, David and Van de Wiele, Tom and Kulkarni, Tejas and Ionescu, Catalin and Hansen, Steven and Mnih, Volodymyr},
  journal={arXiv preprint arXiv:1811.11359},
  year={2018}
}

@inproceedings{florensa2017reverse,
  title={Reverse curriculum generation for reinforcement learning},
  author={Florensa, Carlos and Held, David and Wulfmeier, Markus and Zhang, Michael and Abbeel, Pieter},
  booktitle={Conference on robot learning},
  pages={482--495},
  year={2017},
  organization={PMLR}
}

@inproceedings{
fan2018learning,
title={Learning to Teach},
author={Yang Fan and Fei Tian and Tao Qin and Xiang-Yang Li and Tie-Yan Liu},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=HJewuJWCZ},
}

@article{wu2018learning,
  title={Learning to teach with dynamic loss functions},
  author={Wu, Lijun and Tian, Fei and Xia, Yingce and Fan, Yang and Qin, Tao and Jian-Huang, Lai and Liu, Tie-Yan},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  year={2018}
}

@inproceedings{weinshall2018curriculum,
  title={Curriculum learning by transfer learning: Theory and experiments with deep networks},
  author={Weinshall, Daphna and Cohen, Gad and Amir, Dan},
  booktitle={International Conference on Machine Learning},
  pages={5238--5246},
  year={2018},
  organization={PMLR}
}

@inproceedings{such2020generative,
  title={Generative teaching networks: Accelerating neural architecture search by learning to generate synthetic training data},
  author={Such, Felipe Petroski and Rawal, Aditya and Lehman, Joel and Stanley, Kenneth and Clune, Jeffrey},
  booktitle={International Conference on Machine Learning},
  pages={9206--9216},
  year={2020},
  organization={PMLR}
}

@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}

@inproceedings{ivanovic2019barc,
  title={Barc: Backward reachability curriculum for robotic reinforcement learning},
  author={Ivanovic, Boris and Harrison, James and Sharma, Apoorva and Chen, Mo and Pavone, Marco},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={15--21},
  year={2019},
  organization={IEEE}
}

@article{kim2018screenernet,
  title={Screenernet: Learning self-paced curriculum for deep neural networks},
  author={Kim, Tae-Hoon and Choi, Jonghyun},
  journal={arXiv preprint arXiv:1801.00904},
  year={2018}
}

@inproceedings{omidshafiei2019learning,
  title={Learning to teach in cooperative multiagent reinforcement learning},
  author={Omidshafiei, Shayegan and Kim, Dong-Ki and Liu, Miao and Tesauro, Gerald and Riemer, Matthew and Amato, Christopher and Campbell, Murray and How, Jonathan P},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={33},
  number={01},
  pages={6128--6136},
  year={2019}
}

@inproceedings{jiang2018mentornet,
  title={Mentornet: Learning data-driven curriculum for very deep neural networks on corrupted labels},
  author={Jiang, Lu and Zhou, Zhengyuan and Leung, Thomas and Li, Li-Jia and Fei-Fei, Li},
  booktitle={International Conference on Machine Learning},
  pages={2304--2313},
  year={2018},
  organization={PMLR}
}

@article{ghosh2018learning,
  title={Learning actionable representations with goal-conditioned policies},
  author={Ghosh, Dibya and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:1811.07819},
  year={2018}
}

@article{sukhbaatar2018learning,
  title={Learning goal embeddings via self-play for hierarchical reinforcement learning},
  author={Sukhbaatar, Sainbayar and Denton, Emily and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1811.09083},
  year={2018}
}

@inproceedings{
ghosh2021learning,
title={Learning to Reach Goals via Iterated Supervised Learning},
author={Dibya Ghosh and Abhishek Gupta and Ashwin Reddy and Justin Fu and Coline Manon Devin and Benjamin Eysenbach and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=rALA0Xo6yNJ}
}

@article{sukhbaatar2017intrinsic,
  title={Intrinsic motivation and automatic curricula via asymmetric self-play},
  author={Sukhbaatar, Sainbayar and Lin, Zeming and Kostrikov, Ilya and Synnaeve, Gabriel and Szlam, Arthur and Fergus, Rob},
  journal={arXiv preprint arXiv:1703.05407},
  year={2017}
}

@inproceedings{florensa2018automatic,
  title={Automatic goal generation for reinforcement learning agents},
  author={Florensa, Carlos and Held, David and Geng, Xinyang and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={1515--1528},
  year={2018},
  organization={PMLR}
}

@article{openai2021asymmetric,
  title={Asymmetric self-play for automatic goal discovery in robotic manipulation},
  author={OpenAI, OpenAI and Plappert, Matthias and Sampedro, Raul and Xu, Tao and Akkaya, Ilge and Kosaraju, Vineet and Welinder, Peter and D'Sa, Ruben and Petron, Arthur and Pinto, Henrique P d O and others},
  journal={arXiv preprint arXiv:2101.04882},
  year={2021}
}

@article{ecoffet2019go,
  title={Go-explore: a new approach for hard-exploration problems},
  author={Ecoffet, Adrien and Huizinga, Joost and Lehman, Joel and Stanley, Kenneth O and Clune, Jeff},
  journal={arXiv preprint arXiv:1901.10995},
  year={2019}
}

@article{hartikainen2019dynamical,
  title={Dynamical distance learning for semi-supervised and unsupervised skill discovery},
  author={Hartikainen, Kristian and Geng, Xinyang and Haarnoja, Tuomas and Levine, Sergey},
  journal={arXiv preprint arXiv:1907.08225},
  year={2019}
}

@article{ren2019exploration,
  title={Exploration via hindsight goal generation},
  author={Ren, Zhizhou and Dong, Kefan and Zhou, Yuan and Liu, Qiang and Peng, Jian},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019}
}

@article{klink2020self,
  title={Self-paced deep reinforcement learning},
  author={Klink, Pascal and D'Eramo, Carlo and Peters, Jan R and Pajarinen, Joni},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={9216--9227},
  year={2020}
}

@inproceedings{nair2022learning,
  title={Learning language-conditioned robot behavior from offline data and crowd-sourced annotation},
  author={Nair, Suraj and Mitchell, Eric and Chen, Kevin and Savarese, Silvio and Finn, Chelsea and others},
  booktitle={Conference on Robot Learning},
  pages={1303--1315},
  year={2022},
  organization={PMLR}
}

@article{zhang2020automatic,
  title={Automatic curriculum learning through value disagreement},
  author={Zhang, Yunzhi and Abbeel, Pieter and Pinto, Lerrel},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={7648--7659},
  year={2020}
}

@InProceedings{pmlr-v37-schaul15,
  title = 	 {Universal Value Function Approximators},
  author = 	 {Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {1312--1320},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/schaul15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/schaul15.html},
  abstract = 	 {Value functions are a core component of reinforcement learning. The main idea is to to construct a single function approximator V(s; theta) that estimates the long-term reward from any state s, using parameters θ. In this paper we introduce universal value function approximators (UVFAs) V(s,g;theta) that generalise not just over states s but also over goals g. We develop an efficient technique for supervised learning of UVFAs, by factoring observed values into separate embedding vectors for state and goal, and then learning a mapping from s and g to these factored embedding vectors. We show how this technique may be incorporated into a reinforcement learning algorithm that updates the UVFA solely from observed rewards. Finally, we demonstrate that a UVFA can successfully generalise to previously unseen goals.}
}


@article{kalashnikov2021mt,
  title={Mt-opt: Continuous multi-task robotic reinforcement learning at scale},
  author={Kalashnikov, Dmitry and Varley, Jacob and Chebotar, Yevgen and Swanson, Benjamin and Jonschkowski, Rico and Finn, Chelsea and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:2104.08212},
  year={2021}
}

@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@inproceedings{nair2020contextual,
  title={Contextual imagined goals for self-supervised robotic learning},
  author={Nair, Ashvin and Bahl, Shikhar and Khazatsky, Alexander and Pong, Vitchyr and Berseth, Glen and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={530--539},
  year={2020},
  organization={PMLR}
}

@book{allgower2012numerical,
  title={Numerical continuation methods: an introduction},
  author={Allgower, Eugene L and Georg, Kurt},
  volume={13},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@article{akkaya2019solving,
  title={Solving rubik's cube with a robot hand},
  author={Akkaya, Ilge and Andrychowicz, Marcin and Chociej, Maciek and Litwin, Mateusz and McGrew, Bob and Petron, Arthur and Paino, Alex and Plappert, Matthias and Powell, Glenn and Ribas, Raphael and others},
  journal={arXiv preprint arXiv:1910.07113},
  year={2019}
}

@inproceedings{li2021mural,
  title={MURAL: Meta-Learning Uncertainty-Aware Rewards for Outcome-Driven Reinforcement Learning},
  author={Li, Kevin and Gupta, Abhishek and Reddy, Ashwin and Pong, Vitchyr H and Zhou, Aurick and Yu, Justin and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={6346--6356},
  year={2021},
  organization={PMLR}
}

@inproceedings{azar2017minimax,
  title={Minimax regret bounds for reinforcement learning},
  author={Azar, Mohammad Gheshlaghi and Osband, Ian and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={263--272},
  year={2017},
  organization={PMLR}
}

@article{zhai2022computational,
  title={Computational Benefits of Intermediate Rewards for Goal-Reaching Policy Learning},
  author={Zhai, Yuexiang and Baek, Christina and Zhou, Zhengyuan and Jiao, Jiantao and Ma, Yi},
  journal={Journal of Artificial Intelligence Research},
  volume={73},
  pages={847--896},
  year={2022}
}

@article{janner2021offline,
  title={Offline Reinforcement Learning as One Big Sequence Modeling Problem},
  author={Janner, Michael and Li, Qiyang and Levine, Sergey},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@inproceedings{sodhani2021multi,
  title={Multi-task reinforcement learning with context-based representations},
  author={Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
  booktitle={International Conference on Machine Learning},
  pages={9767--9779},
  year={2021},
  organization={PMLR}
}

@inproceedings{mei2020global,
  title={On the global convergence rates of softmax policy gradient methods},
  author={Mei, Jincheng and Xiao, Chenjun and Szepesvari, Csaba and Schuurmans, Dale},
  booktitle={International Conference on Machine Learning},
  pages={6820--6829},
  year={2020},
  organization={PMLR}
}


@article{nachum2017bridging,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{rechtoptimization,
  title={Optimization for Modern Data Analysis. 2019},
  author={Recht, Benjamin and Wright, Stephen J},
  journal={Preprint available at http://eecs. berkeley. edu/brecht/opt4mlbook}
}


@inproceedings{agarwal2020model,
  title={Model-based reinforcement learning with a generative model is minimax optimal},
  author={Agarwal, Alekh and Kakade, Sham and Yang, Lin F},
  booktitle={Conference on Learning Theory},
  pages={67--83},
  year={2020},
  organization={PMLR}
}

@book{haarnoja2018acquiring,
  title={Acquiring diverse robot skills via maximum entropy deep reinforcement learning},
  author={Haarnoja, Tuomas},
  year={2018},
  publisher={University of California, Berkeley}
}

@article{ding2021beyond,
  title={Beyond Exact Gradients: Convergence of Stochastic Soft-Max Policy Gradient Methods with Entropy Regularization},
  author={Ding, Yuhao and Zhang, Junzi and Lavaei, Javad},
  journal={arXiv preprint arXiv:2110.10117},
  year={2021}
}

@article{agarwal2019reinforcement,
  title={Reinforcement learning: Theory and algorithms},
  author={Agarwal, Alekh and Jiang, Nan and Kakade, Sham M and Sun, Wen},
  journal={CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep},
  year={2019}
}

@article{agarwal2021theory,
  title={On the theory of policy gradient methods: Optimality, approximation, and distribution shift},
  author={Agarwal, Alekh and Kakade, Sham M and Lee, Jason D and Mahajan, Gaurav},
  journal={Journal of Machine Learning Research},
  volume={22},
  number={98},
  pages={1--76},
  year={2021}
}

@inproceedings{bengio2009curriculum,
  title={Curriculum learning},
  author={Bengio, Yoshua and Louradour, J{\'e}r{\^o}me and Collobert, Ronan and Weston, Jason},
  booktitle={Proceedings of the 26th annual international conference on machine learning},
  pages={41--48},
  year={2009}
}

@article{kumar2010self,
  title={Self-paced learning for latent variable models},
  author={Kumar, M and Packer, Benjamin and Koller, Daphne},
  journal={Advances in neural information processing systems},
  volume={23},
  year={2010}
}

@inproceedings{murali2018cassl,
  title={Cassl: Curriculum accelerated self-supervised learning},
  author={Murali, Adithyavairavan and Pinto, Lerrel and Gandhi, Dhiraj and Gupta, Abhinav},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={6453--6460},
  year={2018},
  organization={IEEE}
}

@article{borsa2016learning,
  title={Learning shared representations in multi-task reinforcement learning},
  author={Borsa, Diana and Graepel, Thore and Shawe-Taylor, John},
  journal={arXiv preprint arXiv:1603.02041},
  year={2016}
}

@article{calandriello2014sparse,
  title={Sparse multi-task reinforcement learning},
  author={Calandriello, Daniele and Lazaric, Alessandro and Restelli, Marcello},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{maurer2016benefit,
  title={The benefit of multitask representation learning},
  author={Maurer, Andreas and Pontil, Massimiliano and Romera-Paredes, Bernardino},
  journal={Journal of Machine Learning Research},
  volume={17},
  number={81},
  pages={1--32},
  year={2016}
}

@article{wu2019comprehensive,
  title={A comprehensive survey on graph neural networks},
  author={Wu, Zonghan and Pan, Shirui and Chen, Fengwen and Long, Guodong and Zhang, Chengqi and Yu, Philip S},
  journal={arXiv preprint arXiv:1901.00596},
  year={2019}
}

@article{selsam2018learning,
  title={Learning a SAT solver from single-bit supervision},
  author={Selsam, Daniel and Lamm, Matthew and B{\"u}nz, Benedikt and Liang, Percy and de Moura, Leonardo and Dill, David L},
  journal={arXiv preprint arXiv:1802.03685},
  year={2018}
}

@article{davis1962machine,
  title={A machine program for theorem-proving},
  author={Davis, Martin and Logemann, George and Loveland, Donald},
  journal={Communications of the ACM},
  volume={5},
  number={7},
  pages={394--397},
  year={1962},
  publisher={ACM New York, NY, USA}
}

@article{bansal2019holist,
  title={HOList: An environment for machine learning of higher-order theorem proving (extended version)},
  author={Bansal, Kshitij and Loos, Sarah M and Rabe, Markus N and Szegedy, Christian and Wilcox, Stewart},
  journal={arXiv preprint arXiv:1904.03241},
  year={2019}
}


@article{wu2018understanding,
  title={Understanding short-horizon bias in stochastic meta-optimization},
  author={Wu, Yuhuai and Ren, Mengye and Liao, Renjie and Grosse, Roger},
  journal={arXiv preprint arXiv:1803.02021},
  year={2018}
}

@article{huang2018gamepad,
  title={Gamepad: A learning environment for theorem proving},
  author={Huang, Daniel and Dhariwal, Prafulla and Song, Dawn and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1806.00608},
  year={2018}
}

@article{paliwal2019graph,
  title={Graph Representations for Higher-Order Logic and Theorem Proving},
  author={Paliwal, Aditya and Loos, Sarah and Rabe, Markus and Bansal, Kshitij and Szegedy, Christian},
  journal={arXiv preprint arXiv:1905.10006},
  year={2019}
}

@inproceedings{wang2017premise,
  title={Premise selection for theorem proving by deep graph embedding},
  author={Wang, Mingzhe and Tang, Yihe and Wang, Jian and Deng, Jia},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2786--2796},
  year={2017}
}

@inproceedings{schulz2013system,
  title={System description: E 1.8},
  author={Schulz, Stephan},
  booktitle={International Conference on Logic for Programming Artificial Intelligence and Reasoning},
  pages={735--743},
  year={2013},
  organization={Springer}
}

@inproceedings{selman1992new,
  title={A New Method for Solving Hard Satisfiability Problems.},
  author={Selman, Bart and Levesque, Hector J and Mitchell, David G and others},
  organization={Citeseer}
}

@inproceedings{nudelman2004understanding,
  title={Understanding random SAT: Beyond the clauses-to-variables ratio},
  author={Nudelman, Eugene and Leyton-Brown, Kevin and Hoos, Holger H and Devkar, Alex and Shoham, Yoav},
  booktitle={International Conference on Principles and Practice of Constraint Programming},
  pages={438--452},
  year={2004},
  organization={Springer}
}


@article{elman1993learning,
  title={Learning and development in neural networks: The importance of starting small},
  author={Elman, Jeffrey L},
  journal={Cognition},
  volume={48},
  number={1},
  pages={71--99},
  year={1993},
  publisher={Elsevier}
}

@inproceedings{ellis2018learning,
  title={Learning libraries of subroutines for neurally--guided bayesian program induction},
  author={Ellis, Kevin and Morales, Lucas and Sabl{\'e}-Meyer, Mathias and Solar-Lezama, Armando and Tenenbaum, Josh},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7805--7815},
  year={2018}
}


@article{silver2019few,
  title={Few-Shot Bayesian Imitation Learning with Logic over Programs},
  author={Silver, Tom and Allen, Kelsey R and Lew, Alex K and Kaelbling, Leslie Pack and Tenenbaum, Josh},
  journal={arXiv preprint arXiv:1904.06317},
  year={2019}
}

@article{cropper2019playgol,
  title={Playgol: learning programs through play},
  author={Cropper, Andrew},
  journal={arXiv preprint arXiv:1904.08993},
  year={2019}
}

@inproceedings{ritchie2016neurally,
  title={Neurally-guided procedural models: Amortized inference for procedural graphics programs using neural networks},
  author={Ritchie, Daniel and Thomas, Anna and Hanrahan, Pat and Goodman, Noah},
  booktitle={Advances in neural information processing systems},
  pages={622--630},
  year={2016}
}

@article{shin2019program,
  title={Program Synthesis and Semantic Parsing with Learned Code Idioms},
  author={Shin, Richard and Allamanis, Miltiadis and Brockschmidt, Marc and Polozov, Oleksandr},
  journal={arXiv preprint arXiv:1906.10816},
  year={2019}
}


@article{yang2019learning,
  title={Learning to Prove Theorems via Interacting with Proof Assistants},
  author={Yang, Kaiyu and Deng, Jia},
  journal={arXiv preprint arXiv:1905.09381},
  year={2019}
}

@inproceedings{
anonymous2020towards,
title={Towards Finding Longer Proofs},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=Hkeh21BKPH},
note={under review}
}

@article{nachum2018near,
  title={Near-optimal representation learning for hierarchical reinforcement learning},
  author={Nachum, Ofir and Gu, Shixiang and Lee, Honglak and Levine, Sergey},
  journal={arXiv preprint arXiv:1810.01257},
  year={2018}
}

@inproceedings{
anonymous2020learning,
title={Learning to Prove Theorems by Learning to Generate Theorems},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=BJxiqxSYPB},
note={under review}
}

@inproceedings{
anonymous2020adaptive,
title={{\{}ADAPTIVE{\}} {\{}GENERATION{\}} {\{}OF{\}} {\{}PROGRAMMING{\}} {\{}PUZZLES{\}}},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HJeRveHKDH},
note={under review}
}

@inproceedings{
anonymous2020what,
title={What Can Neural Networks Reason About?},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rJxbJeHFPS},
note={under review}
}

@inproceedings{
anonymous2020synthesizing,
title={Synthesizing Programmatic Policies that Inductively Generalize},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1l8oANFDH},
note={under review}
}

@inproceedings{
anonymous2020neuralguided,
title={Neural-Guided Symbolic Regression with Asymptotic Constraints},
author={Anonymous},
booktitle={Submitted to International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=S1gTAp4FDB},
note={under review}
}

@article{chang2018automatically,
  title={Automatically composing representation transformations as a means for generalization},
  author={Chang, Michael B and Gupta, Abhishek and Levine, Sergey and Griffiths, Thomas L},
  journal={arXiv preprint arXiv:1807.04640},
  year={2018}
}


@incollection{NIPS2019_9241,
title = {G2SAT: Learning to Generate SAT Formulas},
author = {You, Jiaxuan and Wu, Haoze and Barrett, Clark and Ramanujan, Raghuram and Leskovec, Jure},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. dAlch\'{e}-Buc and E. Fox and R. Garnett},
pages = {10552--10563},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9241-g2sat-learning-to-generate-sat-formulas.pdf}
}

@inproceedings{burnett2019building,
  title={Building a winning self-driving car in six months},
  author={Burnett, Keenan and Schimpe, Andreas and Samavi, Sepehr and Gridseth, Mona and Liu, Chengzhi Winston and Li, Qiyang and Kroeze, Zachary and Schoellig, Angela P},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={9583--9589},
  year={2019},
  organization={IEEE}
}

@article{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={229--256},
  year={1992},
  publisher={Springer}
}

@inproceedings{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Advances in neural information processing systems},
  pages={6402--6413},
  year={2017}
}

@article{mohamed2019monte,
  title={Monte carlo gradient estimation in machine learning},
  author={Mohamed, Shakir and Rosca, Mihaela and Figurnov, Michael and Mnih, Andriy},
  journal={arXiv preprint arXiv:1906.10652},
  year={2019}
}

@inproceedings{een2003extensible,
    title={An extensible SAT-solver},
    author={E{\'e}n, Niklas and S{\"o}rensson, Niklas},
    booktitle={International conference on theory and applications of satisfiability testing},
    pages={502--518},
    year={2003},
    organization={Springer}
}
@article{selman1996generating,
  title={Generating hard satisfiability problems},
  author={Selman, Bart and Mitchell, David G and Levesque, Hector J},
  journal={Artificial intelligence},
  volume={81},
  number={1-2},
  pages={17--29},
  year={1996},
  publisher={Elsevier}
}

@article{cheeseman1991really,
  title={Where really hard problems are},
  author={Cheeseman, Peter and Kanefsky, Bob and Taylor, William M.},
  journal={Proc. 12th IJCAI, 1991},
  year={1991}
}
@article{lee2019wide,
  title={Wide neural networks of any depth evolve as linear models under gradient descent},
  author={Lee, Jaehoon and Xiao, Lechao and Schoenholz, Samuel S and Bahri, Yasaman and Sohl-Dickstein, Jascha and Pennington, Jeffrey},
  journal={arXiv preprint arXiv:1902.06720},
  year={2019}
}


@inproceedings{kingma2015variational,
  title={Variational dropout and the local reparameterization trick},
  author={Kingma, Durk P and Salimans, Tim and Welling, Max},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2575--2583},
  year={2015}
}

@article{wen2018flipout,
  title={Flipout: Efficient pseudo-independent weight perturbations on mini-batches},
  author={Wen, Yeming and Vicol, Paul and Ba, Jimmy and Tran, Dustin and Grosse, Roger},
  journal={arXiv preprint arXiv:1803.04386},
  year={2018}
}

@article{zaremba2014learning,
  title={Learning to execute},
  author={Zaremba, Wojciech and Sutskever, Ilya},
  journal={arXiv preprint arXiv:1410.4615},
  year={2014}
}

@inproceedings{bellemare2016unifying,
  title={Unifying count-based exploration and intrinsic motivation},
  author={Bellemare, Marc and Srinivasan, Sriram and Ostrovski, Georg and Schaul, Tom and Saxton, David and Munos, Remi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1471--1479},
  year={2016}
}

@inproceedings{cohn1995active,
  title={Active learning with statistical models},
  author={Cohn, David A and Ghahramani, Zoubin and Jordan, Michael I},
  booktitle={Advances in neural information processing systems},
  pages={705--712},
  year={1995}
}

@article{mackay1992information,
  title={Information-based objective functions for active data selection},
  author={MacKay, David JC},
  journal={Neural computation},
  volume={4},
  number={4},
  pages={590--604},
  year={1992},
  publisher={MIT Press}
}


@article{pierrot2019learning,
  title={Learning Compositional Neural Programs with Recursive Tree Search and Planning},
  author={Pierrot, Thomas and Ligner, Guillaume and Reed, Scott and Sigaud, Olivier and Perrin, Nicolas and Laterre, Alexandre and Kas, David and Beguir, Karim and de Freitas, Nando},
  journal={arXiv preprint arXiv:1905.12941},
  year={2019}
}

@incollection{NIPS2019_8724,
title = {Adaptive Auxiliary Task Weighting for Reinforcement Learning},
author = {Lin, Xingyu and Baweja, Harjatin and Kantor, George and Held, David},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. dAlch\'{e}-Buc and E. Fox and R. Garnett},
pages = {4773--4784},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/8724-adaptive-auxiliary-task-weighting-for-reinforcement-learning.pdf}
}


@inproceedings{graves2011practical,
  title={Practical variational inference for neural networks},
  author={Graves, Alex},
  booktitle={Advances in neural information processing systems},
  pages={2348--2356},
  year={2011}
}

@inproceedings{hinton1993keeping,
  title={Keeping the neural networks simple by minimizing the description length of the weights},
  author={Hinton, Geoffrey E and Van Camp, Drew},
  booktitle={Proceedings of the sixth annual conference on Computational learning theory},
  pages={5--13},
  year={1993}
}

@article{rissanen1978modeling,
  title={Modeling by shortest data description},
  author={Rissanen, Jorma},
  journal={Automatica},
  volume={14},
  number={5},
  pages={465--471},
  year={1978},
  publisher={Pergamon}
}

@inproceedings{you2019g2sat,
  title={G2SAT: Learning to Generate SAT Formulas},
  author={You, Jiaxuan and Wu, Haoze and Barrett, Clark and Ramanujan, Raghuram and Leskovec, Jure},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10552--10563},
  year={2019}
}


@inproceedings{spitkovsky2010baby,
  title={From baby steps to leapfrog: How less is more in unsupervised dependency parsing},
  author={Spitkovsky, Valentin I and Alshawi, Hiyan and Jurafsky, Daniel},
  booktitle={Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  pages={751--759},
  year={2010},
  organization={Association for Computational Linguistics}
}

@article{cai2017making,
  title={Making neural programming architectures generalize via recursion},
  author={Cai, Jonathon and Shin, Richard and Song, Dawn},
  journal={arXiv preprint arXiv:1704.06611},
  year={2017}
}

@article{reed2015neural,
  title={Neural programmer-interpreters},
  author={Reed, Scott and De Freitas, Nando},
  journal={arXiv preprint arXiv:1511.06279},
  year={2015}
}

@misc{jaxrl,
  author = {Kostrikov, Ilya},
  doi = {10.5281/zenodo.5535154},
  month = {10},
  title = {{JAXRL: Implementations of Reinforcement Learning algorithms in JAX}},
  url = {https://github.com/ikostrikov/jaxrl},
  year = {2021}
}


@inproceedings{houthooft2016vime,
  title={Vime: Variational information maximizing exploration},
  author={Houthooft, Rein and Chen, Xi and Duan, Yan and Schulman, John and De Turck, Filip and Abbeel, Pieter},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1109--1117},
  year={2016}
}

@inproceedings{li2018visualizing,
  title={Visualizing the loss landscape of neural nets},
  author={Li, Hao and Xu, Zheng and Taylor, Gavin and Studer, Christoph and Goldstein, Tom},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6389--6399},
  year={2018}
}

@article{wu2020curricula,
  title={When do curricula work?},
  author={Wu, Xiaoxia and Dyer, Ethan and Neyshabur, Behnam},
  journal={arXiv preprint arXiv:2012.03107},
  year={2020}
}

@article{cobbe2019procgen,
  title={Leveraging Procedural Generation to Benchmark Reinforcement Learning},
  author={Cobbe, Karl and Hesse, Christopher and Hilton, Jacob and Schulman, John},
  journal={arXiv preprint arXiv:1912.01588},
  year={2019}
}

@article{narvekar2020curriculum,
  title={Curriculum learning for reinforcement learning domains: A framework and survey},
  author={Narvekar, Sanmit and Peng, Bei and Leonetti, Matteo and Sinapov, Jivko and Taylor, Matthew E and Stone, Peter},
  journal={arXiv preprint arXiv:2003.04960},
  year={2020}
}


@inproceedings{tanaka2003multitask,
  title={Multitask reinforcement learning on the distribution of MDPs},
  author={Tanaka, Fumihide and Yamamura, Masayuki},
  booktitle={Proceedings 2003 IEEE International Symposium on Computational Intelligence in Robotics and Automation. Computational Intelligence in Robotics and Automation for the New Millennium (Cat. No. 03EX694)},
  volume={3},
  pages={1108--1113},
  year={2003},
  organization={IEEE}
}

@article{rusu2015policy,
  title={Policy distillation},
  author={Rusu, Andrei A and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
  journal={arXiv preprint arXiv:1511.06295},
  year={2015}
}

@article{rajeswaran2016epopt,
  title={Epopt: Learning robust neural network policies using model ensembles},
  author={Rajeswaran, Aravind and Ghotra, Sarvjeet and Ravindran, Balaraman and Levine, Sergey},
  journal={arXiv preprint arXiv:1610.01283},
  year={2016}
}

@inproceedings{
D'Eramo2020Sharing,
title={Sharing Knowledge in Multi-Task Deep Reinforcement Learning},
author={Carlo D'Eramo and Davide Tateo and Andrea Bonarini and Marcello Restelli and Jan Peters},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=rkgpv2VFvr}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={5824--5836},
  year={2020}
}

@article{bhandari2019global,
  title={Global optimality guarantees for policy gradient methods},
  author={Bhandari, Jalaj and Russo, Daniel},
  journal={arXiv preprint arXiv:1906.01786},
  year={2019}
}

@article{cen2021fast,
  title={Fast global convergence of natural policy gradient methods with entropy regularization},
  author={Cen, Shicong and Cheng, Chen and Chen, Yuxin and Wei, Yuting and Chi, Yuejie},
  journal={Operations Research},
  year={2021},
  publisher={INFORMS}
}

@inproceedings{fazel2018global,
  title={Global convergence of policy gradient methods for the linear quadratic regulator},
  author={Fazel, Maryam and Ge, Rong and Kakade, Sham and Mesbahi, Mehran},
  booktitle={International Conference on Machine Learning},
  pages={1467--1476},
  year={2018},
  organization={PMLR}
}

@inproceedings{li2021softmax,
  title={Softmax policy gradient methods can take exponential time to converge},
  author={Li, Gen and Wei, Yuting and Chi, Yuejie and Gu, Yuantao and Chen, Yuxin},
  booktitle={Conference on Learning Theory},
  pages={3107--3110},
  year={2021},
  organization={PMLR}
}

@article{zhang2020global,
  title={Global convergence of policy gradient methods to (almost) locally optimal policies},
  author={Zhang, Kaiqing and Koppel, Alec and Zhu, Hao and Basar, Tamer},
  journal={SIAM Journal on Control and Optimization},
  volume={58},
  number={6},
  pages={3586--3612},
  year={2020},
  publisher={SIAM}
}

@article{zhang2020sample,
  title={Sample efficient reinforcement learning with REINFORCE},
  author={Zhang, Junzi and Kim, Jongho and O’Donoghue, Brendan and Boyd, Stephen},
  journal={arXiv preprint arXiv:2010.11364},
  pages={97},
  year={2020}
}

@article{andrychowicz2020learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, OpenAI: Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={1},
  pages={3--20},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{tang2017exploration,
  title={\# Exploration: A study of count-based exploration for deep reinforcement learning},
  author={Tang, Haoran and Houthooft, Rein and Foote, Davis and Stooke, Adam and Chen, OpenAI Xi and Duan, Yan and Schulman, John and DeTurck, Filip and Abbeel, Pieter},
  booktitle={Advances in neural information processing systems},
  pages={2753--2762},
  year={2017}
}

@article{stadie2015incentivizing,
  title={Incentivizing exploration in reinforcement learning with deep predictive models},
  author={Stadie, Bradly C and Levine, Sergey and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1507.00814},
  year={2015}
}

%% Contextual MDPs

@article{belogolovsky2021inverse,
  title={Inverse reinforcement learning in contextual MDPs},
  author={Belogolovsky, Stav and Korsunsky, Philip and Mannor, Shie and Tessler, Chen and Zahavy, Tom},
  journal={Machine Learning},
  volume={110},
  number={9},
  pages={2295--2334},
  year={2021},
  publisher={Springer}
}

@article{hallak2015contextual,
  title={Contextual markov decision processes},
  author={Hallak, Assaf and Di Castro, Dotan and Mannor, Shie},
  journal={arXiv preprint arXiv:1502.02259},
  year={2015}
}

@inproceedings{dann2019policy,
  title={Policy certificates: Towards accountable reinforcement learning},
  author={Dann, Christoph and Li, Lihong and Wei, Wei and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={1507--1516},
  year={2019},
  organization={PMLR}
}

@inproceedings{jiang2017contextual,
  title={Contextual decision processes with low bellman rank are pac-learnable},
  author={Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John and Schapire, Robert E},
  booktitle={International Conference on Machine Learning},
  pages={1704--1713},
  year={2017},
  organization={PMLR}
}

@inproceedings{modi2018markov,
  title={Markov decision processes with continuous side information},
  author={Modi, Aditya and Jiang, Nan and Singh, Satinder and Tewari, Ambuj},
  booktitle={Algorithmic Learning Theory},
  pages={597--618},
  year={2018},
  organization={PMLR}
}

@article{abbasi2014online,
  title={Online learning in MDPs with side information},
  author={Abbasi-Yadkori, Yasin and Neu, Gergely},
  journal={arXiv preprint arXiv:1406.6812},
  year={2014}
}

@inproceedings{modi2020sample,
  title={Sample complexity of reinforcement learning using linearly combined model ensembles},
  author={Modi, Aditya and Jiang, Nan and Tewari, Ambuj and Singh, Satinder},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={2010--2020},
  year={2020},
  organization={PMLR}
}

@inproceedings{misra2020kinematic,
  title={Kinematic state abstraction and provably efficient rich-observation reinforcement learning},
  author={Misra, Dipendra and Henaff, Mikael and Krishnamurthy, Akshay and Langford, John},
  booktitle={International conference on machine learning},
  pages={6961--6971},
  year={2020},
  organization={PMLR}
}

@inproceedings{sun2019model,
  title={Model-based rl in contextual decision processes: Pac bounds and exponential improvements over model-free approaches},
  author={Sun, Wen and Jiang, Nan and Krishnamurthy, Akshay and Agarwal, Alekh and Langford, John},
  booktitle={Conference on learning theory},
  pages={2898--2933},
  year={2019},
  organization={PMLR}
}


@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@article{peters2008natural,
  title={Natural actor-critic},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neurocomputing},
  volume={71},
  number={7-9},
  pages={1180--1190},
  year={2008},
  publisher={Elsevier}
}

@article{konda1999actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay and Tsitsiklis, John},
  journal={Advances in neural information processing systems},
  volume={12},
  year={1999}
}

@book{lattimore2020bandit,
  title={Bandit algorithms},
  author={Lattimore, Tor and Szepesv{\'a}ri, Csaba},
  year={2020},
  publisher={Cambridge University Press}
}

@article{kulkarni2016deep,
  title={Deep successor reinforcement learning},
  author={Kulkarni, Tejas D and Saeedi, Ardavan and Gautam, Simanta and Gershman, Samuel J},
  journal={arXiv preprint arXiv:1606.02396},
  year={2016}
}

@article{siriwardhana2019vusfa,
  title={Vusfa: Variational universal successor features approximator to improve transfer drl for target driven visual navigation},
  author={Siriwardhana, Shamane and Weerasakera, Rivindu and Matthies, Denys JC and Nanayakkara, Suranga},
  journal={arXiv preprint arXiv:1908.06376},
  year={2019}
}


@inproceedings{yuan2022general,
  title={A general sample complexity analysis of vanilla policy gradient},
  author={Yuan, Rui and Gower, Robert M and Lazaric, Alessandro},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={3332--3380},
  year={2022},
  organization={PMLR}
}

@article{jin2018q,
  title={Is Q-learning provably efficient?},
  author={Jin, Chi and Allen-Zhu, Zeyuan and Bubeck, Sebastien and Jordan, Michael I},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{zhang2020almost,
  title={Almost optimal model-free reinforcement learningvia reference-advantage decomposition},
  author={Zhang, Zihan and Zhou, Yuan and Ji, Xiangyang},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={15198--15207},
  year={2020}
}

@article{li2021breaking,
  title={Breaking the sample complexity barrier to regret-optimal model-free reinforcement learning},
  author={Li, Gen and Shi, Laixi and Chen, Yuxin and Gu, Yuantao and Chi, Yuejie},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}


@article{agarwal2020pc,
  title={Pc-pg: Policy cover directed exploration for provable policy gradient learning},
  author={Agarwal, Alekh and Henaff, Mikael and Kakade, Sham and Sun, Wen},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={13399--13412},
  year={2020}
}

@book{aastrom2013adaptive,
  title={Adaptive control},
  author={{\AA}str{\"o}m, Karl J and Wittenmark, Bj{\"o}rn},
  year={2013},
  publisher={Courier Corporation}
}

@book{landau2011adaptive,
  title={Adaptive control: algorithms, analysis and applications},
  author={Landau, Ioan Dor{\'e} and Lozano, Rogelio and M'Saad, Mohammed and Karimi, Alireza},
  year={2011},
  publisher={Springer Science \& Business Media}
}

@book{tao2003adaptive,
  title={Adaptive control design and analysis},
  author={Tao, Gang},
  volume={37},
  year={2003},
  publisher={John Wiley \& Sons}
}

@book{goodwin2014adaptive,
  title={Adaptive filtering prediction and control},
  author={Goodwin, Graham C and Sin, Kwai Sang},
  year={2014},
  publisher={Courier Corporation}
}

@misc{sastry1990adaptive,
  title={Adaptive control: stability, convergence, and robustness},
  author={Sastry, Shankar and Bodson, Marc and Bartram, James F},
  year={1990},
  publisher={Acoustical Society of America}
}

@inproceedings{moskovitz2022towards,
  title={Towards an Understanding of Default Policies in Multitask Policy Optimization},
  author={Moskovitz, Ted and Arbel, Michael and Parker-Holder, Jack and Pacchiano, Aldo},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={10661--10686},
  year={2022},
  organization={PMLR}
}

@book{nesterov2018lectures,
  title={Lectures on convex optimization},
  author={Nesterov, Yurii and others},
  volume={137},
  year={2018},
  publisher={Springer}
}

@inproceedings{du2019provably,
  title={Provably efficient RL with rich observations via latent state decoding},
  author={Du, Simon and Krishnamurthy, Akshay and Jiang, Nan and Agarwal, Alekh and Dudik, Miroslav and Langford, John},
  booktitle={International Conference on Machine Learning},
  pages={1665--1674},
  year={2019},
  organization={PMLR}
}

@article{kakade2001natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  journal={Advances in neural information processing systems},
  volume={14},
  year={2001}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ international conference on intelligent robots and systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{gupta2022unpacking,
  title={Unpacking Reward Shaping: Understanding the Benefits of Reward Engineering on Sample Complexity},
  author={Gupta, Abhishek and Pacchiano, Aldo and Zhai, Yuexiang and Kakade, Sham M and Levine, Sergey},
  journal={arXiv preprint arXiv:2210.09579},
  year={2022}
}

@article{liu2022revolver,
  title={REvolveR: Continuous Evolutionary Models for Robot-to-robot Policy Transfer},
  author={Liu, Xingyu and Pathak, Deepak and Kitani, Kris M},
  journal={arXiv preprint arXiv:2202.05244},
  year={2022}
}

@article{bassich2020curriculum,
  title={Curriculum learning with a progression function},
  author={Bassich, Andrea and Foglino, Francesco and Leonetti, Matteo and Kudenko, Daniel},
  journal={arXiv preprint arXiv:2008.00511},
  year={2020}
}

@inproceedings{clavera2018model,
  title={Model-based reinforcement learning via meta-policy optimization},
  author={Clavera, Ignasi and Rothfuss, Jonas and Schulman, John and Fujita, Yasuhiro and Asfour, Tamim and Abbeel, Pieter},
  booktitle={Conference on Robot Learning},
  pages={617--629},
  year={2018},
  organization={PMLR}
}

@article{agarwal2022provable,
  title={Provable Benefits of Representational Transfer in Reinforcement Learning},
  author={Agarwal, Alekh and Song, Yuda and Sun, Wen and Wang, Kaiwen and Wang, Mengdi and Zhang, Xuezhou},
  journal={arXiv preprint arXiv:2205.14571},
  year={2022}
}

@inproceedings{tian2019elf,
  title={Elf opengo: An analysis and open reimplementation of alphazero},
  author={Tian, Yuandong and Ma, Jerry and Gong, Qucheng and Sengupta, Shubho and Chen, Zhuoyuan and Pinkerton, James and Zitnick, Larry},
  booktitle={International Conference on Machine Learning},
  pages={6244--6253},
  year={2019},
  organization={PMLR}
}

@article{li2022understanding,
  title={Understanding the Complexity Gains of Single-Task RL with a Curriculum},
  author={Li, Qiyang and Zhai, Yuexiang and Ma, Yi and Levine, Sergey},
  journal={arXiv preprint arXiv:2212.12809},
  year={2022}
}

@inproceedings{ostrovski2017count,
  title={Count-based exploration with neural density models},
  author={Ostrovski, Georg and Bellemare, Marc G and Oord, A{\"a}ron and Munos, R{\'e}mi},
  booktitle={International conference on machine learning},
  pages={2721--2730},
  year={2017},
  organization={PMLR}
}

@inproceedings{guo2020batch,
  title={Batch reinforcement learning through continuation method},
  author={Guo, Yijie and Feng, Shengyu and Le Roux, Nicolas and Chi, Ed and Lee, Honglak and Chen, Minmin},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{buckman2020importance,
  title={The importance of pessimism in fixed-dataset policy optimization},
  author={Buckman, Jacob and Gelada, Carles and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2009.06799},
  year={2020}
}

@article{lyu2022mildly,
  title={Mildly conservative Q-learning for offline reinforcement learning},
  author={Lyu, Jiafei and Ma, Xiaoteng and Li, Xiu and Lu, Zongqing},
  journal={arXiv preprint arXiv:2206.04745},
  year={2022}
}

@article{beeson2022improving,
  title={Improving TD3-BC: Relaxed Policy Constraint for Offline Learning and Stable Online Fine-Tuning},
  author={Beeson, Alex and Montana, Giovanni},
  journal={arXiv preprint arXiv:2211.11802},
  year={2022}
}

@inproceedings{mark2022fine,
  title={Fine-tuning Offline Policies with Optimistic Action Selection},
  author={Mark, Max Sobol and Ghadirzadeh, Ali and Chen, Xi and Finn, Chelsea},
  booktitle={Deep Reinforcement Learning Workshop NeurIPS 2022},
  year={2022}
}

@inproceedings{lee2022offline,
  title={Offline-to-online reinforcement learning via balanced replay and pessimistic q-ensemble},
  author={Lee, Seunghyun and Seo, Younggyo and Lee, Kimin and Abbeel, Pieter and Shin, Jinwoo},
  booktitle={Conference on Robot Learning},
  pages={1702--1712},
  year={2022},
  organization={PMLR}
}

@article{wu2022supported,
  title={Supported Policy Optimization for Offline Reinforcement Learning},
  author={Wu, Jialong and Wu, Haixu and Qiu, Zihan and Wang, Jianmin and Long, Mingsheng},
  journal={arXiv preprint arXiv:2202.06239},
  year={2022}
}

@article{xie2021policy,
  title={Policy finetuning: Bridging sample-efficient offline and online reinforcement learning},
  author={Xie, Tengyang and Jiang, Nan and Wang, Huan and Xiong, Caiming and Bai, Yu},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={27395--27407},
  year={2021}
}

@article{wagenmaker2022leveraging,
  title={Leveraging Offline Data in Online Reinforcement Learning},
  author={Wagenmaker, Andrew and Pacchiano, Aldo},
  journal={arXiv preprint arXiv:2211.04974},
  year={2022}
}

@inproceedings{
song2023hybrid,
title={Hybrid {RL}: Using both offline and online data can make {RL} efficient},
author={Yuda Song and Yifei Zhou and Ayush Sekhari and Drew Bagnell and Akshay Krishnamurthy and Wen Sun},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=yyBis80iUuU}
}

@inproceedings{du2021bilinear,
  title={Bilinear classes: A structural framework for provable generalization in rl},
  author={Du, Simon and Kakade, Sham and Lee, Jason and Lovett, Shachar and Mahajan, Gaurav and Sun, Wen and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={2826--2836},
  year={2021},
  organization={PMLR}
}

@inproceedings{xie2020q,
  title={Q* approximation schemes for batch reinforcement learning: A theoretical comparison},
  author={Xie, Tengyang and Jiang, Nan},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  pages={550--559},
  year={2020},
  organization={PMLR}
}

@article{zhao2022adaptive,
  title={Adaptive behavior cloning regularization for stable offline-to-online reinforcement learning},
  author={Zhao, Yi and Boney, Rinu and Ilin, Alexander and Kannala, Juho and Pajarinen, Joni},
  journal={arXiv preprint arXiv:2210.13846},
  year={2022}
}

@article{zanette2021provable,
  title={Provable benefits of actor-critic methods for offline reinforcement learning},
  author={Zanette, Andrea and Wainwright, Martin J and Brunskill, Emma},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13626--13640},
  year={2021}
}

@article{geng2022jaxcql,
  title={JaxCQL: a simple implementation of SAC and CQL in JAX},
  author={Xinyang Geng},
  year={2022},
  url={https://github.com/young-geng/JaxCQL}
}


@article{jin2021bellman,
  title={Bellman eluder dimension: New rich classes of rl problems, and sample-efficient algorithms},
  author={Jin, Chi and Liu, Qinghua and Miryoosefi, Sobhan},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={13406--13418},
  year={2021}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@inproceedings{zhu2019dexterous,
  title={Dexterous manipulation with deep reinforcement learning: Efficient, general, and low-cost},
  author={Zhu, Henry and Gupta, Abhishek and Rajeswaran, Aravind and Levine, Sergey and Kumar, Vikash},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={3651--3657},
  year={2019},
  organization={IEEE}
}

@article{zhu2018reinforcement,
  title={Reinforcement and imitation learning for diverse visuomotor skills},
  author={Zhu, Yuke and Wang, Ziyu and Merel, Josh and Rusu, Andrei and Erez, Tom and Cabi, Serkan and Tunyasuvunakool, Saran and Kram{\'a}r, J{\'a}nos and Hadsell, Raia and de Freitas, Nando and others},
  journal={arXiv preprint arXiv:1802.09564},
  year={2018}
}

@article{peters2008reinforcement,
  title={Reinforcement learning of motor skills with policy gradients},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neural networks},
  volume={21},
  number={4},
  pages={682--697},
  year={2008},
  publisher={Elsevier}
}

@article{schaal1996learning,
  title={Learning from demonstration},
  author={Schaal, Stefan},
  journal={Advances in neural information processing systems},
  volume={9},
  year={1996}
}

@inproceedings{kang2018policy,
  title={Policy optimization with demonstrations},
  author={Kang, Bingyi and Jie, Zequn and Feng, Jiashi},
  booktitle={International conference on machine learning},
  pages={2469--2478},
  year={2018},
  organization={PMLR}
}

@inproceedings{he2022masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, Kaiming and Chen, Xinlei and Xie, Saining and Li, Yanghao and Doll{\'a}r, Piotr and Girshick, Ross},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16000--16009},
  year={2022}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{
redq,
title={Randomized Ensembled Double Q-Learning: Learning Fast Without a Model},
author={Xinyue Chen and Che Wang and Zijian Zhou and Keith W. Ross},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=AY8zfZm0tDd}
}

@inproceedings{
replaybarrier,
title={Sample-Efficient Reinforcement Learning by Breaking the Replay Ratio Barrier},
author={Pierluca D'Oro and Max Schwarzer and Evgenii Nikishin and Pierre-Luc Bacon and Marc G Bellemare and Aaron Courville},
booktitle={The Eleventh International Conference on Learning Representations },
year={2023},
url={https://openreview.net/forum?id=OpC-9aBBVJe}
}

@inproceedings{
droq,
title={Dropout Q-Functions for Doubly Efficient Reinforcement Learning},
author={Takuya Hiraoka and Takahisa Imagawa and Taisei Hashimoto and Takashi Onishi and Yoshimasa Tsuruoka},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=xCVJMsPv3RT}
}

@article{rlpd,
  title={Efficient Online Reinforcement Learning with Offline Data},
  author={Ball, Philip J and Smith, Laura and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2302.02948},
  year={2023}
}

@book{boyd2004convex,
  title={Convex optimization},
  author={Boyd, Stephen and Boyd, Stephen P and Vandenberghe, Lieven},
  year={2004},
  publisher={Cambridge university press}
}

@article{luo2023finetuning,
  title={Finetuning from Offline Reinforcement Learning: Challenges, Trade-offs and Practical Solutions},
  author={Luo, Yicheng and Kay, Jackie and Grefenstette, Edward and Deisenroth, Marc Peter},
  journal={arXiv preprint arXiv:2303.17396},
  year={2023}
}


@incollection{Bengio+chapter2007,
author = {Bengio, Yoshua and LeCun, Yann},
booktitle = {Large Scale Kernel Machines},
publisher = {MIT Press},
title = {Scaling Learning Algorithms Towards {AI}},
year = {2007}
}

@article{anonymous2021ptr,
  title={Pre-Training for Robots: Offline RL Enables Learning New Tasks from a Handful of Trials},
  author={Kumar, Aviral and Singh, Anikait and Ebert, Frederik and Yang, Yanlai and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2210.05178},
  year={2022}
}


@inproceedings{kumar2021should,
  title={Should I Run Offline Reinforcement Learning or Behavioral Cloning?},
  author={Kumar, Aviral and Hong, Joey and Singh, Anikait and Levine, Sergey},
  booktitle={International Conference on Learning Representations},
  year={2021}
}

@article{agarwal2022beyond,
  title={Reincarnating Reinforcement Learning: Reusing Prior Computation to Accelerate Progress},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron and Bellemare, Marc G},
  journal={NeurIPS},
  year={2022}
}

@article{agarwal2021deep,
  title={Deep reinforcement learning at the edge of the statistical precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={29304--29320},
  year={2021}
}

@article{reed2022generalist,
  title={A generalist agent},
  author={Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and others},
  journal={arXiv preprint arXiv:2205.06175},
  year={2022}
}


@inproceedings{ijcai2020-370,
  title     = {I4R: Promoting Deep Reinforcement Learning by the Indicator for Expressive Representations},
  author    = {Luo, Xufang and Meng, Qi and He, Di and Chen, Wei and Wang, Yunhong},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {2669--2675},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/370},
  url       = {https://doi.org/10.24963/ijcai.2020/370},
}

@article{yoshida2017spectral,
  title={Spectral norm regularization for improving the generalizability of deep learning},
  author={Yoshida, Yuichi and Miyato, Takeru},
  journal={arXiv preprint arXiv:1705.10941},
  year={2017}
}

@inproceedings{Parr2008AnAO,
  title={An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning},
  author={Ronald Parr and Lihong Li and Gavin Taylor and Christopher Painter-Wakefield and Michael L. Littman},
  booktitle={ICML '08},
  year={2008}
}


@book{koller_friedman,
 author = {Koller, D. and Friedman, N.},
 title = {Probabilistic Graphical Models: Principles and Techniques},
 year = {2009},
 isbn = {0262013193, 9780262013192},
 publisher = {The MIT Press},
} 

@inproceedings{chebotar2019closing,
  title={Closing the sim-to-real loop: Adapting simulation randomization with real world experience},
  author={Chebotar, Yevgen and Handa, Ankur and Makoviychuk, Viktor and Macklin, Miles and Issac, Jan and Ratliff, Nathan and Fox, Dieter},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8973--8979},
  year={2019},
  organization={IEEE}
}

@article{tan2018sim,
  title={Sim-to-real: Learning agile locomotion for quadruped robots},
  author={Tan, Jie and Zhang, Tingnan and Coumans, Erwin and Iscen, Atil and Bai, Yunfei and Hafner, Danijar and Bohez, Steven and Vanhoucke, Vincent},
  journal={arXiv preprint arXiv:1804.10332},
  year={2018}
}

@inproceedings{sadeghi2016cad2rl,
  title={{CAD2RL}: Real single-image flight without a single real image},
  author={Sadeghi, Fereshteh and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2017}
}

@inproceedings{gae,
title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
author = {J. Schulman and P. Moritz and S. Levine and M. Jordan and P. Abbeel},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2016
}

@misc{kumar_blog,
title = {Data-Driven Deep Reinforcement Learning},
author = {Aviral Kumar},
note = {{BAIR} Blog},
year = {2019},
howpublished  = {\url{https://bair.berkeley.edu/blog/2019/12/05/bear/}}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2013}
}

@article{luo2019learning,
  title={Learning self-correctable policies and value functions from demonstrations with negative sampling},
  author={Luo, Yuping and Xu, Huazhe and Ma, Tengyu},
  journal={arXiv preprint arXiv:1907.05634},
  year={2019}
}

@inproceedings{mulayoff2020unique,
  title={Unique Properties of Flat Minima in Deep Networks},
  author={Mulayoff, Rotem and Michaeli, Tomer},
  booktitle={International Conference on Machine Learning},
  pages={7108--7118},
  year={2020},
  organization={PMLR}
}

@article{van2018deep,
  title={Deep reinforcement learning and the deadly triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@article{damian2021label,
  title={Label Noise SGD Provably Prefers Flat Global Minimizers},
  author={Damian, Alex and Ma, Tengyu and Lee, Jason},
  journal={arXiv preprint arXiv:2106.06530},
  year={2021}
}

@article{mahmood2015emphatic,
  title={Emphatic temporal-difference learning},
  author={Mahmood, A Rupam and Yu, Huizhen and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1507.01569},
  year={2015}
}

@article{chatterji2019intriguing,
  title={The intriguing role of module criticality in the generalization of deep networks},
  author={Chatterji, Niladri S and Neyshabur, Behnam and Sedghi, Hanie},
  journal={arXiv preprint arXiv:1912.00528},
  year={2019}
}


@article{farebrother2018generalization,
  title={Generalization and regularization in DQN},
  author={Farebrother, Jesse and Machado, Marlos C and Bowling, Michael},
  journal={arXiv preprint arXiv:1810.00123},
  year={2018}
}

@article{vinyals2019grandmaster,
  title={Grandmaster level in StarCraft II using multi-agent reinforcement learning},
  author={Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M and Mathieu, Micha{\"e}l and Dudzik, Andrew and Chung, Junyoung and Choi, David H and Powell, Richard and Ewalds, Timo and Georgiev, Petko and others},
  journal={Nature},
  volume={575},
  number={7782},
  pages={350--354},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{schrittwieser2021online,
  title={Online and offline reinforcement learning by planning with a learned model},
  author={Schrittwieser, Julian and Hubert, Thomas and Mandhane, Amol and Barekatain, Mohammadamin and Antonoglou, Ioannis and Silver, David},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={27580--27591},
  year={2021}
}

@article{bjorck2021towards,
  title={Towards Deeper Deep Reinforcement Learning},
  author={Bjorck, Johan and Gomes, Carla P and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:2106.01151},
  year={2021}
}

@article{ota2021training,
  title={Training Larger Networks for Deep Reinforcement Learning},
  author={Ota, Kei and Jha, Devesh K and Kanezaki, Asako},
  journal={arXiv preprint arXiv:2102.07920},
  year={2021}
}

@article{yang2020feature,
  title={Feature learning in infinite-width neural networks},
  author={Yang, Greg and Hu, Edward J},
  journal={arXiv preprint arXiv:2011.14522},
  year={2020}
}

@article{sinha2020d2rl,
  title={D2rl: Deep dense architectures in reinforcement learning},
  author={Sinha, Samarth and Bharadhwaj, Homanga and Srinivas, Aravind and Garg, Animesh},
  journal={arXiv preprint arXiv:2010.09163},
  year={2020}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@inproceedings{kakade2002natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  booktitle={Advances in neural information processing systems},
  pages={1531--1538},
  year={2002}
}


@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@InProceedings{dehghani2021scenic,
    author    = {Dehghani, Mostafa and Gritsenko, Alexey and Arnab, Anurag and Minderer, Matthias and Tay, Yi},
    title     = {Scenic: A JAX Library for Computer Vision Research and Beyond},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2022},
    pages     = {21393-21398}
}


@inproceedings{dean2022don,
  title={Don't Freeze Your Embedding: Lessons from Policy Finetuning in Environment Transfer},
  author={Dean, Victoria and Toyama, Daniel Kenji and Precup, Doina},
  booktitle={ICLR Workshop on Agent Learning in Open-Endedness},
  year={2022}
}

@article{machado18sticky,
  title={Revisiting the arcade learning environment: Evaluation protocols and open problems for general agents},
  author={Machado, Marlos C and Bellemare, Marc G and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={61},
  pages={523--562},
  year={2018}
}

@InProceedings{thomas,
  title = 	 {Bias in Natural Actor-Critic Algorithms},
  author = 	 {Philip Thomas},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2014},
  month = 	 {22--24 Jun},
}

@inproceedings{toussaint06,
 author = {Toussaint, M. and Storkey, A.},
 title = {Probabilistic Inference for Solving Discrete and Continuous State Markov Decision Processes},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2006},
} 

@INPROCEEDINGS{attias,
    author = {H. Attias},
    title = {Planning by Probabilistic Inference},
    booktitle = {Proceedings of the 9th International Workshop on Artificial Intelligence and Statistics},
    year = {2003}
}

@article{hafner2011reinforcement,
  title={Reinforcement learning in feedback control},
  author={Hafner, Roland and Riedmiller, Martin},
  journal={Machine learning},
  volume={84},
  number={1-2},
  pages={137--169},
  year={2011},
  publisher={Springer}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{peters2008reinforcement,
  title={Reinforcement learning of motor skills with policy gradients},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neural networks},
  volume={21},
  number={4},
  pages={682--697},
  year={2008},
  publisher={Elsevier}
}

@article{tesauro1994td,
  title={{TD-Gammon}, a self-teaching backgammon program, achieves master-level play},
  author={Tesauro, Gerald},
  journal={Neural computation},
  volume={6},
  number={2},
  pages={215--219},
  year={1994},
  publisher={MIT Press}
}

@InProceedings{ebrl,
  title = 	 {Actor-Critic Reinforcement Learning with Energy-Based Policies},
  author = 	 {N. Heess and D. Silver and Y. W. Teh},
  booktitle = 	 {European Workshop on Reinforcement Learning (EWRL)},
  year = 	 {2013},
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={627--635},
  year={2011}
}

@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={661--668},
  year={2010}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={International Conference on Machine Learning (ICML)},
  volume={2},
  year={2002}
}

@inproceedings{ep,
 author = {Minka, T. P.},
 title = {Expectation Propagation for Approximate Bayesian Inference},
 booktitle = {Uncertainty in Artificial Intelligence (UAI)},
 year = {2001},
}

@inproceedings{mpo,
title = {Maximum a Posteriori Policy Optimisation},
author = {A. Abdolmaleki and J. T. Springenberg and Y. Tassa and R. Munos and N. Heess and M. Riedmiller},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2018
}

@article{williams,
 author = {Williams, R. J.},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 journal = {Machine Learning},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 pages = {229--256}
} 

@article{WilliamsPeng91,
  author = {Williams, R. J. and Peng, J.},
  journal = {Connection Science},
  number = 3,
  pages = {241-268},
  title = {Function optimization using connectionist reinforcement learning
	algorithms},
  volume = 3,
  year = 1991
}

@book{sb-irl-98,
 author = {Sutton, R. S. and Barto, A. G.},
 title = {Introduction to Reinforcement Learning},
 year = {1998},
 isbn = {0262193981},
 edition = {1st},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@INPROCEEDINGS{suttonadp,
    author = {R. S. Sutton},
    title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {1990},
}

@inproceedings{pgq,
author = {O'Donoghue, B. and Munos, R. and Kavukcuoglu, K. and Mnih, V.},
year = {2017},
title = {PGQ: Combining policy gradient and Q-learning},
booktitle = {International Conference on Learning Representations (ICLR)}
}

@article{sallans,
 author = {Sallans, B. and Hinton, G. E.},
 title = {Reinforcement Learning with Factored States and Actions},
 journal = {Journal of Machine Learning Research},
 volume = {5},
 month = dec,
 year = {2004}
 },

@article{KLMSurvey,
    author = "L. P. Kaelbling and M. L. Littman and A. P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
url={http://people.csail.mit.edu/lpk/papers/rl-survey.ps}}

@inproceedings{todorov_kalman_duality, 
author={E. Todorov}, 
booktitle={Conference on Decision and Control (CDC)},
title={General duality between optimal control and estimation}, 
year={2008},
}

@inproceedings{covariant,
author = {J. A. Bagnell and J. Schneider},
title = {Covariant Policy Search},
booktitle = {International Joint Conference on Artifical Intelligence (IJCAI)},
year = {2003},
}

@InProceedings{reps,
  author =       "Peters, J. and  M{\"u}lling, K. and Alt{\"u}n, Y.",
  title =        "Relative Entropy Policy Search",
  booktitle =    "AAAI Conference on Artificial Intelligence (AAAI)",
  year =         "2010",
}

@inproceedings{mfgps,
title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
author = {Levine, S. and Abbeel, P.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{lmdp_policy,
  author    = {E. Todorov},
  title     = {Policy gradients in linearly-solvable MDPs},
  booktitle = {Neural Information Processing Systems (NIPS)},
  year      = {2010},
}

@inproceedings{ldmp_irl,
 author = {Dvijotham, K. and Todorov, E.},
 title = {Inverse Optimal Control with Linearly-solvable MDPs},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2010},
} 

@inproceedings{bear,
title = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
author = {Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
booktitle = {Neural Information Processing Systems (NeurIPS)},
year = {2019}
}

@article{lerer2016learning,
  title={Learning physical intuition of block towers by example},
  author={Lerer, Adam and Gross, Sam and Fergus, Rob},
  journal={arXiv preprint arXiv:1603.01312},
  year={2016}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@inproceedings{battaglia2016interaction,
  title={Interaction networks for learning about objects, relations and physics},
  author={Battaglia, Peter and Pascanu, Razvan and Lai, Matthew and Rezende, Danilo Jimenez and others},
  booktitle={Advances in neural information processing systems},
  pages={4502--4510},
  year={2016}
}

@inproceedings{sagawa2019distributionally,
  title={Distributionally Robust Neural Networks},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1907.02893},
  year={2019}
}

@article{sinha2017certifying,
  title={Certifying some distributional robustness with principled adversarial training},
  author={Sinha, Aman and Namkoong, Hongseok and Duchi, John},
  journal={arXiv preprint arXiv:1710.10571},
  year={2017}
}

@inproceedings{kingma2014semi,
  title={Semi-supervised learning with deep generative models},
  author={Kingma, Durk P and Mohamed, Shakir and Rezende, Danilo Jimenez and Welling, Max},
  booktitle={Advances in neural information processing systems},
  pages={3581--3589},
  year={2014}
}

@inproceedings{kendall2017uncertainties,
  title={What uncertainties do we need in bayesian deep learning for computer vision?},
  author={Kendall, Alex and Gal, Yarin},
  booktitle={Advances in neural information processing systems},
  pages={5574--5584},
  year={2017}
}

@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016}
}

@article{scholkopf2019causality,
  title={Causality for Machine Learning},
  author={Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:1911.10500},
  year={2019}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{pi2,
  title = {Learning Policy Improvements with Path Integrals},
  author = {Theodorou, E. A. and Buchli, J. and Schaal, S.},
  booktitle = {International Conference on  Artificial Intelligence and Statistics (AISTATS 2010)},
  year = {2010},
}

@InProceedings{trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {J. Schulman and S. Levine and P. Moritz and M. I. Jordan and P. Abbeel},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2015},
}

@phdthesis{levine_thesis,
author = {Levine, S.},
title = {Motor skill learning with local trajectory methods},
school = {Stanford University},
year = {2014},
}

@phdthesis{ziebart_thesis,
author = {Ziebart, B.},
title = {Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
school = {Carnegie Mellon University},
year = {2010},
}

@article{kappen_oc,
  author    = {H. J. Kappen},
  title     = {Optimal control theory and the linear bellman equation},
  journal   = {Inference and Learning in Dynamic Models},
  year      = {2011},
  pages     = {363-387},
}

@inproceedings{heess2015learning,
  title={Learning continuous control policies by stochastic value gradients},
  author={Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Timothy and Erez, Tom and Tassa, Yuval},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2944--2952},
  year={2015}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1352--1361},
  year={2017},
  organization={JMLR. org}
}

@article{kappen_pgm,
  author    = {H. J. Kappen and
               V. G{\'o}mez and
               M. Opper},
  title     = {Optimal control as a graphical model inference problem},
  journal   = {Machine Learning},
  volume    = {87},
  number    = {2},
  year      = {2012},
  pages     = {159-182},
}

@inproceedings{rawlik_soc,
  author    = {K. Rawlik and
               M. Toussaint and
               S. Vijayakumar},
  title     = {On Stochastic Optimal Control and Reinforcement Learning
               by Approximate Inference},
  year = {2013},
  booktitle = {Robotics: Science and Systems (RSS)},
}

@inproceedings{toussaint_soc,
  author    = {M. Toussaint},
  title     = {Robot trajectory optimization using approximate inference},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2009},
}

@inproceedings{toussaint_pgm,
  title={Hierarchical POMDP Controller Optimization by Likelihood Maximization},
  author={Toussaint, M. and Charlin, L. and Poupart, P.},
  booktitle={Uncertainty in Artificial Intelligence (UAI)},
  volume={24},
  pages={562--570},
  year={2008}
}

@article{kalman_filter,
  author={R. Kalman},
  title={A new approach to linear filtering and prediction problems},
  journal={ASME Transactions journal of basic engineering},
  volume={82},
  number={1},
  pages={35-45},
  year={1960}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}

@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{todorov_lmdp,
  author    = {E. Todorov},
  title     = {Linearly-solvable Markov decision problems},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2006},
}

@inproceedings{rwr,
 author = {Peters, J. and Schaal, S.},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2007},
} 


@inproceedings{neumann,
  author    = {G. Neumann},
  title     = {Variational Inference for Policy Search in changing situations},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2011},
}

@inproceedings{levine_vgps,
  author    = {S. Levine and V. Koltun},
  title     = {Variational policy search via trajectory optimization},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2013},
}

@inproceedings{em_policy_search,
  title = {Efficient Sample Reuse in EM-Based Policy Search},
  author = {Hachiya, H. and Peters, J. and Sugiyama, M.},
  booktitle = {European Conference on Machine Learning (ECML)},
  year = {2009},
}

@article{vmp,
    title={Variational message passing},
    author={Winn, J. and Bishop, C.},
    journal={Journal of Machine Learning Research},
    volume={6},
    year={2005},
    pages={661-694}
}

@inproceedings{haarnoja,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, T. and Tang, H. and Abbeel, P. and Levine, S.},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{sac,
title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
author  = {T. Haarnoja and A. Zhou and P. Abbeel and S. Levine},
year  = {2018},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1801.01290.pdf}
}

@inproceedings{d4rl,
title = {D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
author  = {J. Fu and A. Kumar and O. Nachum and G. Tucker and S. Levine},
year  = {2020},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/2004.07219}
}

@inproceedings{pcl,
title = {Bridging the Gap Between Value and Policy Based Reinforcement Learning},
author  = {O. Nachum and M. Norouzi and K. Xu and D. Schuurmans},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1702.08892.pdf}
}

@inproceedings{gps,
 author = {Levine, S. and Koltun, V.},
 title = {Guided Policy Search},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2013},
} 

@inproceedings{maxentirl,
 author = {Ziebart, B. D. and Maas, A. and Bagnell, J. A. and Dey, A. K.},
 title = {Maximum Entropy Inverse Reinforcement Learning},
 booktitle = {International Conference on Artificial Intelligence (AAAI)},
 year = {2008},
} 

@inproceedings{haarnoja_composable,
author = {Haarnjoa, T. and Pong, V. and Zhou, A. and Dalal, M. and Abbeel, P. and Levine, S.},
title = {Composable Deep Reinforcement Learning for Robotic Manipulation},
booktitle = {International Conference on Robotics and Automation (ICRA)},
year = {2018},
}

@article{trust_pcl,
  author    = {O. Nachum and
               M. Norouzi and
               K. Xu and
               D. Schuurmans},
  title     = {Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1707.01891},
  year      = {2017},
}

@inproceedings{gpirl,
 author = {Levine, S. and Popovi\'{c}, Z. and Koltun, V.},
 title = {Nonlinear Inverse Reinforcement Learning with Gaussian Processes},
 booktitle = {Neural Information Processing Systems (NIPS)},
 year = {2011},
}

@inproceedings{localioc,
    author = {S. Levine and V. Koltun},
    title = {Continuous Inverse Optimal Control with Locally Optimal Examples},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2012},
}

@inproceedings{legibility,
  author    = {A. D. Dragan and
               K. C. T. Lee and
               S. S. Srinivasa},
  title     = {Legibility and predictability of robot motion},
  booktitle = {International Conference on Human-Robot Interaction (HRI)},
  year      = {2013},
}

@inproceedings{maxentdeepirl,
author = {M. Wulfmeier and
P. Ondruska and
I. Posner},
title = {Maximum Entropy Deep Inverse Reinforcement Learning},
Booktitle = {Neural Information Processing Systems Conference, Deep Reinforcement Learning Workshop},
year = {2015},
}

@inproceedings{maxcausalent,
  author    = {B. D. Ziebart and
               J. A. Bagnell and
               A. K. Dey},
  title     = {Modeling Interaction via the Principle of Maximum Causal Entropy},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2010},
}

@inproceedings{kitani1,
  author    = {D. Huang and
               K. M. Kitani},
  title     = {Action-Reaction: Forecasting the Dynamics of Human Interaction},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2014},
}

@inproceedings{kitani2,
  author    = {D. Huang and
               A. Farahmand and
               K. M. Kitani and
               J. A. Bagnell},
  title     = {Approximate {MaxEnt} Inverse Optimal Control and Its Application for
               Mental Simulation of Human Interactions},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2015},
}

@article{realnvp,
title={Latent Space Policies for Hierarchical Reinforcement Learning},
author={T. Haarnoja and K. Hartikainen and P. Abbeel and S. Levine},
journal   = {CoRR},
volume    = {abs/1804.02808},
year      = {2018},
}

@inproceedings{Javdani, 
    AUTHOR    = {S. Javdani and S. Srinivasa and J. A. Bagnell}, 
    TITLE     = {Shared Autonomy via Hindsight Optimization}, 
    BOOKTITLE = {Robotics: Science and Systems (RSS)}, 
    YEAR      = {2015}, 
}

@inproceedings{airl,
title={Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
author={Fu, J. and Luo, K. and Levine, S.},
}

@inproceedings{hausman,
title={Learning an Embedding Space for Transferable Robot Skills},
author={K. Hausman and J. T. Springenberg and Z. Wang and N. Heess and M. Riedmiller},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
}

@article{learning_to_explore,
  author    = {A. Gupta and
               R. Mendonca and
               Y. Liu and
               P. Abbeel and
               S. Levine},
  title     = {Meta-Reinforcement Learning of Structured Exploration Strategies},
  journal   = {CoRR},
  volume    = {abs/1802.07245},
  year      = {2018},
}

@article{endtoend,
 author = {Levine, S. and Finn, C. and Darrell, T. and Abbeel, P.},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {Journal of Machine Learning Research},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
} 

@inproceedings{cgps,
    author = {Sergey Levine and Vladlen Koltun},
    title = {Learning Complex Neural Network Policies with Trajectory Optimization},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2014},
}
@inproceedings{schulman,
title = {Equivalence Between Policy Gradients and Soft Q-Learning},
author  = {J. Schulman and X. Chen and P. Abbeel},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1704.06440}
}

@inproceedings{nvil,
  author    = {A. Mnih and
               K. Gregor},
  title     = {Neural Variational Inference and Learning in Belief Networks},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2014}
}

@inproceedings{gcl,
  author    = {Chelsea Finn and
               Sergey Levine and
               Pieter Abbeel},
  title     = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
    booktitle   = {International Conference on Machine Learning (ICML)},
  year      = {2016},
}

@inproceedings{gan,
title = {Generative Adversarial Nets},
author = {Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{gail,
title = {Generative Adversarial Imitation Learning},
author = {Ho, J. and Ermon, S.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2016},
}

@article{finn_adversarial,
  author    = {Chelsea Finn and
               Paul Christiano and
               Pieter Abbeel and
               Sergey Levine},
  title     = {A Connection between Generative Adversarial Networks, Inverse Reinforcement
               Learning, and Energy-Based Models},
  journal   = {CoRR},
  volume    = {abs/1611.03852},
  year      = {2016},
}

@inproceedings{bornschein2016bidirectional,
  title={Bidirectional helmholtz machines},
  author={Bornschein, Jorg and Shabanian, Samira and Fischer, Asja and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={2511--2519},
  year={2016}
}

@article{marino2018iterative,
  title={Iterative amortized inference},
  author={Marino, Joseph and Yue, Yisong and Mandt, Stephan},
  journal={arXiv preprint arXiv:1807.09356},
  year={2018}
}

@inproceedings{rasmus2015semi,
  title={Semi-supervised learning with ladder networks},
  author={Rasmus, Antti and Berglund, Mathias and Honkala, Mikko and Valpola, Harri and Raiko, Tapani},
  booktitle={Advances in neural information processing systems},
  pages={3546--3554},
  year={2015}
}

@inproceedings{sonderby2016ladder,
  title={Ladder variational autoencoders},
  author={S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
  booktitle={Advances in neural information processing systems},
  pages={3738--3746},
  year={2016}
}

@inproceedings{zhao2017learning,
  title={Learning hierarchical features from deep generative models},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={4091--4099},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{hsu2017unsupervised,
  title={Unsupervised learning of disentangled and interpretable representations from sequential data},
  author={Hsu, Wei-Ning and Zhang, Yu and Glass, James},
  booktitle={Advances in neural information processing systems},
  pages={1878--1889},
  year={2017}
}


@inproceedings{kalashnikov2018qtopt,
  title={Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  pages={651--673},
  year={2018}
}

@article{cabi2019framework,
  title={A Framework for Data-Driven Robotics},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and {\.Z}o{\l}na, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

 @article{Mo18AdobeIndoorNav,
        Author = {Kaichun Mo and Haoxiang Li and Zhe Lin and Joon-Young Lee},
        Title = {The AdobeIndoorNav Dataset: Towards Deep Reinforcement Learning based Real-world Indoor Robot Visual Navigation},
        Year = {2018},
        Eprint = {arXiv:1802.08824},
    }
    
@article{kandasamy2017batch,
  title={Batch policy gradient methods for improving neural conversation models},
  author={Kandasamy, Kirthevasan and Bachrach, Yoram and Tomioka, Ryota and Tarlow, Daniel and Carter, David},
  journal={arXiv preprint arXiv:1702.03334},
  year={2017}
}

@inproceedings{zhang2018deep,
  title={Deep imitation learning for complex manipulation tasks from virtual reality teleoperation},
  author={Zhang, Tianhao and McCarthy, Zoe and Jow, Owen and Lee, Dennis and Chen, Xi and Goldberg, Ken and Abbeel, Pieter},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5628--5635},
  year={2018},
  organization={IEEE}
}

@inproceedings{sun2018fast,
  title={A fast integrated planning and control framework for autonomous driving via imitation learning},
  author={Sun, Liting and Peng, Cheng and Zhan, Wei and Tomizuka, Masayoshi},
  booktitle={Dynamic Systems and Control Conference},
  volume={51913},
  pages={V003T37A012},
  year={2018},
  organization={American Society of Mechanical Engineers}
}

@article{zhou2017end,
  title={End-to-end offline goal-oriented dialog policy learning via policy gradient},
  author={Zhou, Li and Small, Kevin and Rokhlenko, Oleg and Elkan, Charles},
  journal={arXiv preprint arXiv:1712.02838},
  year={2017}
}

@article{pan2017agile,
  title={Agile autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{nie2019learning,
  title={Learning when-to-treat policies},
  author={Nie, Xinkun and Brunskill, Emma and Wager, Stefan},
  journal={arXiv preprint arXiv:1905.09751},
  year={2019}
}

@article{bojarski2016end,
  title={End to end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}

@article{yu2018bdd100k,
  title={Bdd100k: A diverse driving video database with scalable annotation tooling},
  author={Yu, Fisher and Xian, Wenqi and Chen, Yingying and Liu, Fangchen and Liao, Mike and Madhavan, Vashisht and Darrell, Trevor},
  journal={arXiv preprint arXiv:1805.04687},
  year={2018}
}

@article{sallab2017deep,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}

@article{yurtsever2020survey,
  title={A survey of autonomous driving: Common practices and emerging technologies},
  author={Yurtsever, Ekim and Lambert, Jacob and Carballo, Alexander and Takeda, Kazuya},
  journal={IEEE Access},
  year={2020},
  publisher={IEEE}
}

@inproceedings{kendall2019learning,
  title={Learning to drive in a day},
  author={Kendall, Alex and Hawke, Jeffrey and Janz, David and Mazur, Przemyslaw and Reda, Daniele and Allen, John-Mark and Lam, Vinh-Dieu and Bewley, Alex and Shah, Amar},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8248--8254},
  year={2019},
  organization={IEEE}
}

@article{maddern2017robotcar,
  title={1 year, 1000 km: The Oxford RobotCar dataset},
  author={Maddern, Will and Pascoe, Geoffrey and Linegar, Chris and Newman, Paul},
  journal={The International Journal of Robotics Research},
  volume={36},
  number={1},
  pages={3--15},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{codevilla2018end,
  title={End-to-end driving via conditional imitation learning},
  author={Codevilla, Felipe and Miiller, Matthias and L{\'o}pez, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1--9},
  year={2018},
  organization={IEEE}
}

@inproceedings{tassa2012synthesis,
  title={Synthesis and stabilization of complex behaviors through online trajectory optimization},
  author={Tassa, Yuval and Erez, Tom and Todorov, Emanuel},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={4906--4913},
  year={2012},
  organization={IEEE}
}

@inproceedings{pets,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4754--4765},
  year={2018}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{pietquin2011sample,
  title={Sample-efficient batch reinforcement learning for dialogue management optimization},
  author={Pietquin, Olivier and Geist, Matthieu and Chandramohan, Senthilkumar and Frezza-Buet, Herv{\'e}},
  journal={ACM Transactions on Speech and Language Processing (TSLP)},
  volume={7},
  number={3},
  pages={1--21},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@article{gottesman2019guidelines,
  title={Guidelines for reinforcement learning in healthcare},
  author={Gottesman, Omer and Johansson, Fredrik and Komorowski, Matthieu and Faisal, Aldo and Sontag, David and Doshi-Velez, Finale and Celi, Leo Anthony},
  journal={Nat Med},
  volume={25},
  number={1},
  pages={16--18},
  year={2019}
}

@inproceedings{swaminathan2015self,
  title={The self-normalized estimator for counterfactual learning},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={advances in neural information processing systems},
  pages={3231--3239},
  year={2015}
}

@book{rockafellar1970convex,
  title={Convex analysis},
  author={Rockafellar, R Tyrrell},
  number={28},
  year={1970},
  publisher={Princeton university press}
}

@article{nachum2020reinforcement,
  title={Reinforcement Learning via Fenchel-Rockafellar Duality},
  author={Nachum, Ofir and Dai, Bo},
  journal={arXiv preprint arXiv:2001.01866},
  year={2020}
}

@inproceedings{nachum2019dualdice,
  title={Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections},
  author={Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2315--2325},
  year={2019}
}

@article{eysenbach2017leave,
  title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
  author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.06782},
  year={2017}
}

@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@inproceedings{osband2018randomized,
  title={Randomized prior functions for deep reinforcement learning},
  author={Osband, Ian and Aslanides, John and Cassirer, Albin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8617--8629},
  year={2018}
}


@inproceedings{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Advances in neural information processing systems},
  pages={6402--6413},
  year={2017}
}

@article{achiam2019towards,
  title={Towards characterizing divergence in deep q-learning},
  author={Achiam, Joshua and Knight, Ethan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1903.08894},
  year={2019}
}

@article{gupta2019relay,
  title={Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:1910.11956},
  year={2019}
}

@inproceedings{osband2016deep,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={4026--4034},
  year={2016}
}

@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={Journal of machine learning research},
  volume={4},
  number={Dec},
  pages={1107--1149},
  year={2003}
}

@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM Sigart Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011}
}

@article{johnson2016mimic,
  title={MIMIC-III, a freely accessible critical care database},
  author={Johnson, Alistair EW and Pollard, Tom J and Shen, Lu and Li-wei, H Lehman and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Celi, Leo Anthony and Mark, Roger G},
  journal={Scientific data},
  volume={3},
  pages={160035},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{guez2008adaptive,
  title={Adaptive Treatment of Epilepsy via Batch-mode Reinforcement Learning.},
  author={Guez, Arthur and Vincent, Robert D and Avoli, Massimo and Pineau, Joelle},
  booktitle={AAAI},
  pages={1671--1678},
  year={2008}
}

@article{pipps,
  title={PIPPS: Flexible model-based policy search robust to the curse of chaos},
  author={Parmas, Paavo and Rasmussen, Carl Edward and Peters, Jan and Doya, Kenji},
  journal={arXiv preprint arXiv:1902.01240},
  year={2019}
}

@article{simpl,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@inproceedings{mbpo,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12498--12509},
  year={2019}
}

@article{raghu2017deep,
  title={Deep reinforcement learning for sepsis treatment},
  author={Raghu, Aniruddh and Komorowski, Matthieu and Ahmed, Imran and Celi, Leo and Szolovits, Peter and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:1711.09602},
  year={2017}
}

@article{prasad2017reinforcement,
  title={A reinforcement learning approach to weaning of mechanical ventilation in intensive care units},
  author={Prasad, Niranjani and Cheng, Li-Fang and Chivers, Corey and Draugelis, Michael and Engelhardt, Barbara E},
  journal={arXiv preprint arXiv:1704.06300},
  year={2017}
}

@inproceedings{swaminathan2017off,
  title={Off-policy evaluation for slate recommendation},
  author={Swaminathan, Adith and Krishnamurthy, Akshay and Agarwal, Alekh and Dudik, Miro and Langford, John and Jose, Damien and Zitouni, Imed},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3632--3642},
  year={2017}
}

@inproceedings{osband2017posterior,
  title={Why is posterior sampling better than optimism for reinforcement learning?},
  author={Osband, Ian and Van Roy, Benjamin},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2701--2710},
  year={2017},
  organization={JMLR. org}
}

@article{peng2019awr,
  title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{sriperumbudur2009integral,
  title={On integral probability metrics,$\backslash$phi-divergences and binary classification},
  author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG},
  journal={arXiv preprint arXiv:0901.2698},
  year={2009}
}

@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}

@article{siegel2020keep,
  title={Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning},
  author={Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Riedmiller, Martin},
  journal={arXiv preprint arXiv:2002.08396},
  year={2020}
}

@inproceedings{nowozin2016f,
  title={f-gan: Training generative neural samplers using variational divergence minimization},
  author={Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
  booktitle={Advances in neural information processing systems},
  pages={271--279},
  year={2016}
}

@article{wu2019domain,
  title={Domain adaptation with asymmetrically-relaxed distribution alignment},
  author={Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  journal={arXiv preprint arXiv:1903.01689},
  year={2019}
}

@inproceedings{sutton2009fastgtd,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={993--1000},
  year={2009}
}


@article{alphastar,
  title={Mastering the Real-Time Strategy Game StarCraft II},
  author={AlphaStar, DeepMind},
  journal={URL: https://deepmind. com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii}
}

@article{lu2018general,
  title={A General Family of Robust Stochastic Operators for Reinforcement Learning},
  author={Lu, Yingdong and Squillante, Mark S and Wu, Chai Wah},
  journal={arXiv preprint arXiv:1805.08122},
  year={2018}
}

@inproceedings{
Zhang2020GenDICE:,
title={GenDICE: Generalized Offline Estimation of Stationary Values},
author={Ruiyi Zhang and Bo Dai and Lihong Li and Dale Schuurmans},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HkxlcnVFwB}
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{bellemare2016increasing,
  title={Increasing the action gap: New operators for reinforcement learning},
  author={Bellemare, Marc G and Ostrovski, Georg and Guez, Arthur and Thomas, Philip S and Munos, R{\'e}mi},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{rajeswaran2018dapg,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2018}
}

@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@misc{
sachdeva2020offpolicy,
title={Off-policy Bandits with Deficient Support},
author={Noveen Sachdeva and Yi Su and Thorsten Joachims},
year={2020},
url={https://openreview.net/forum?id=SklcyJBtvB}
}

@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 19th international conference on World wide web},
  pages={661--670},
  year={2010}
}

@article{o2018variational,
  title={Variational Bayesian reinforcement learning with regret bounds},
  author={O'Donoghue, Brendan},
  journal={arXiv preprint arXiv:1807.09647},
  year={2018}
}

@inproceedings{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado V},
  booktitle={Advances in neural information processing systems},
  pages={2613--2621},
  year={2010}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@InProceedings{fujimoto2018addressing,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@misc{d4rl_repo,
title = {D4RL: Datasets for Data-Driven Deep Reinforcement Learning},
author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
note = {Github repository},
year = {2020},
howpublished  = {\url{https://github.com/rail-berkeley/d4rl/wiki/New-Franka-Kitchen-Tasks}}
}



@inproceedings{blanc2020implicit,
  title={Implicit regularization for deep neural networks driven by an ornstein-uhlenbeck like process},
  author={Blanc, Guy and Gupta, Neha and Valiant, Gregory and Valiant, Paul},
  booktitle={Conference on learning theory},
  pages={483--513},
  year={2020},
  organization={PMLR}
}

@article{furuichi2004fundamental,
  title={Fundamental properties of Tsallis relative entropy},
  author={Furuichi, Shigeru and Yanagi, Kenjiro and Kuriyama, Ken},
  journal={Journal of Mathematical Physics},
  volume={45},
  number={12},
  pages={4868--4877},
  year={2004},
  publisher={American Institute of Physics}
}

@inproceedings{namkoong2017variance,
  title={Variance-based regularization with convex objectives},
  author={Namkoong, Hongseok and Duchi, John C},
  booktitle={Advances in neural information processing systems},
  pages={2971--2980},
  year={2017}
}

@inproceedings{tamar2014scaling,
  title={Scaling up robust MDPs using function approximation},
  author={Tamar, Aviv and Mannor, Shie and Xu, Huan},
  booktitle={International Conference on Machine Learning},
  pages={181--189},
  year={2014}
}

@article{nair2020accelerating,
  title={Accelerating Online Reinforcement Learning with Offline Datasets},
  author={Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@inproceedings{nilim2004robustness,
  title={Robustness in Markov decision problems with uncertain transition matrices},
  author={Nilim, Arnab and El Ghaoui, Laurent},
  booktitle={Advances in neural information processing systems},
  pages={839--846},
  year={2004}
}

@article{russel2018tight,
  title={Tight bayesian ambiguity sets for robust MDPs},
  author={Russel, Reazul Hasan and Petrik, Marek},
  journal={arXiv preprint arXiv:1811.06512},
  year={2018}
}

@article{iyengar2005robust,
  title={Robust dynamic programming},
  author={Iyengar, Garud N},
  journal={Mathematics of Operations Research},
  volume={30},
  number={2},
  pages={257--280},
  year={2005},
  publisher={INFORMS}
}

@inproceedings{ghavamzadeh2016safe,
  title={Safe policy improvement by minimizing robust baseline regret},
  author={Petrik, Marek and Ghavamzadeh, Mohammad and Chow, Yinlam},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2298--2306},
  year={2016}
}

@inproceedings{strehl2010learning,
  title={Learning from logged implicit exploration data},
  author={Strehl, Alex and Langford, John and Li, Lihong and Kakade, Sham M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2217--2225},
  year={2010}
}

@article{simao2019safe,
  title={Safe Policy Improvement with an Estimated Baseline Policy},
  author={Sim{\~a}o, Thiago D and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1909.05236},
  year={2019}
}

@article{laroche2017safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1712.06924},
  year={2017}
}

@article{nachum2019algaedice,
  title={AlgaeDICE: Policy Gradient from Arbitrary Experience},
  author={Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1912.02074},
  year={2019}
}

@article{brac,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}

@inproceedings{o2018uncertainty,
  title={The Uncertainty Bellman Equation and Exploration},
  author={O’Donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Volodymyr},
  booktitle={International Conference on Machine Learning},
  pages={3836--3845},
  year={2018}
}

@inproceedings{gilotte2018offline,
  title={Offline a/b testing for recommender systems},
  author={Gilotte, Alexandre and Calauz{\`e}nes, Cl{\'e}ment and Nedelec, Thomas and Abraham, Alexandre and Doll{\'e}, Simon},
  booktitle={Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
  pages={198--206},
  year={2018}
}

@article{bottou2013counterfactual,
  title={Counterfactual reasoning and learning systems: The example of computational advertising},
  author={Bottou, L{\'e}on and Peters, Jonas and Qui{\~n}onero-Candela, Joaquin and Charles, Denis X and Chickering, D Max and Portugaly, Elon and Ray, Dipankar and Simard, Patrice and Snelson, Ed},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={3207--3260},
  year={2013},
  publisher={JMLR. org}
}

@inproceedings{theocharous2015personalized,
  title={Personalized ad recommendation systems for life-time value optimization with guarantees},
  author={Theocharous, Georgios and Thomas, Philip S and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}


@article{henderson2008hybrid,
  title={Hybrid reinforcement/supervised learning of dialogue policies from fixed data sets},
  author={Henderson, James and Lemon, Oliver and Georgila, Kallirroi},
  journal={Computational Linguistics},
  volume={34},
  number={4},
  pages={487--511},
  year={2008},
  publisher={MIT Press}
}


@inproceedings{tesauro2006hybrid,
  title={A hybrid reinforcement learning approach to autonomic resource allocation},
  author={Tesauro, Gerald and Jong, Nicholas K and Das, Rajarshi and Bennani, Mohamed N},
  booktitle={2006 IEEE International Conference on Autonomic Computing},
  pages={65--73},
  year={2006},
  organization={IEEE}
}

@inproceedings{nazari2018reinforcement,
  title={Reinforcement learning for solving the vehicle routing problem},
  author={Nazari, Mohammadreza and Oroojlooy, Afshin and Snyder, Lawrence and Tak{\'a}c, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9839--9849},
  year={2018}
}

@article{balaji2010urban,
  title={Urban traffic signal control using reinforcement learning agents},
  author={Balaji, PG and German, X and Srinivasan, Dipti},
  journal={IET Intelligent Transport Systems},
  volume={4},
  number={3},
  pages={177--188},
  year={2010},
  publisher={IET}
}

@inproceedings{hein2017industrial,
  title={Batch reinforcement learning on the industrial benchmark: First experiences},
  author={Hein, Daniel and Udluft, Steffen and Tokic, Michel and Hentschel, Alexander and Runkler, Thomas A and Sterzing, Volkmar},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
  pages={4214--4221},
  year={2017},
  organization={IEEE}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={22--31},
  year={2017},
  organization={JMLR. org}
}


@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@article{fu2019diagnosing,
  title={Diagnosing bottlenecks in deep {Q}-learning algorithms},
  author={Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  journal={arXiv preprint arXiv:1902.10250},
  year={2019}
}

@inproceedings{imani2018off,
  title={An off-policy policy gradient theorem using emphatic weightings},
  author={Imani, Ehsan and Graves, Eric and White, Martha},
  booktitle={Advances in Neural Information Processing Systems},
  pages={96--106},
  year={2018}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year={2014}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{gu2017interpolated,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in neural information processing systems},
  pages={3846--3855},
  year={2017}
}

@inproceedings{gelada2019off,
  title={Off-policy deep reinforcement learning by bootstrapping the covariate shift},
  author={Gelada, Carles and Bellemare, Marc G},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={3647--3655},
  year={2019}
}

@article{gabel2008adaptive,
  title={Adaptive reactive job-shop scheduling with reinforcement learning agents},
  author={Gabel, Thomas and Riedmiller, Martin},
  journal={International Journal of Information Technology and Intelligent Computing},
  volume={24},
  number={4},
  pages={14--18},
  year={2008},
  publisher={Citeseer}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@article{peshkin2002learning,
  title={Learning from scarce experience},
  author={Peshkin, Leonid and Shelton, Christian R},
  journal={arXiv preprint cs/0204043},
  year={2002}
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={ICML},
  pages={417--424},
  year={2001}
}

@inproceedings{hallak2017consistent,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1372--1383},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{thomas2016data,
  title={Data-efficient off-policy policy evaluation for reinforcement learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={2139--2148},
  year={2016}
}

@inproceedings{wang2017optimal,
  title={Optimal and adaptive off-policy evaluation in contextual bandits},
  author={Wang, Yu-Xiang and Agarwal, Alekh and Dudik, Miroslav},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3589--3597},
  year={2017},
  organization={JMLR. org}
}

@article{jiang2015doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  journal={arXiv preprint arXiv:1511.03722},
  year={2015}
}

@article{farajtabar2018more,
  title={More robust doubly robust off-policy evaluation},
  author={Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1802.03493},
  year={2018}
}

@inproceedings{thomas2015high,
  title={High confidence policy improvement},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={2380--2388},
  year={2015}
}


@inproceedings{scherrer2014approximate,
  title={Approximate policy iteration schemes: a comparison},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={1314--1322},
  year={2014}
}


@article{xie2020q,
  title={Q* Approximation Schemes for Batch Reinforcement Learning: A eoretical Comparison},
  author={Xie, Tengyang and Jiang, Nan},
  year={2020}
}

@inproceedings{hanna2017bootstrapping,
  title={Bootstrapping with models: Confidence intervals for off-policy evaluation},
  author={Hanna, Josiah P and Stone, Peter and Niekum, Scott},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{thomas2015higheval,
  title={High-confidence off-policy evaluation},
  author={Thomas, Philip S and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015}
}


@article{gu2016q,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}

@article{nadjahi2019safe,
  title={Safe Policy Improvement with Soft Baseline Bootstrapping},
  author={Nadjahi, Kimia and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1907.05079},
  year={2019}
}

@article{cheng2019trajectory,
  title={Trajectory-wise control variates for variance reduction in policy gradient methods},
  author={Cheng, Ching-An and Yan, Xinyan and Boots, Byron},
  journal={arXiv preprint arXiv:1908.03263},
  year={2019}
}

@article{pankov2018reward,
  title={Reward-estimation variance elimination in sequential decision processes},
  author={Pankov, Sergey},
  journal={arXiv preprint arXiv:1811.06225},
  year={2018}
}

@article{huang2019importance,
  title={From Importance Sampling to Doubly Robust Policy Gradient},
  author={Huang, Jiawei and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.09066},
  year={2019}
}

@article{sutton2016emphatic,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{yu2015convergence,
  title={On convergence of emphatic temporal-difference learning},
  author={Yu, Huizhen},
  booktitle={Conference on Learning Theory},
  pages={1724--1751},
  year={2015}
}

@inproceedings{hallak2016generalized,
  title={Generalized emphatic temporal difference learning: Bias-variance analysis},
  author={Hallak, Assaf and Tamar, Aviv and Munos, R{\'e}mi and Mannor, Shie},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{zhang2019generalized,
  title={Generalized off-policy actor-critic},
  author={Zhang, Shangtong and Boehmer, Wendelin and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1999--2009},
  year={2019}
}


@article{fu2021benchmarks,
  title={Benchmarks for deep off-policy evaluation},
  author={Fu, Justin and Norouzi, Mohammad and Nachum, Ofir and Tucker, George and Wang, Ziyu and Novikov, Alexander and Yang, Mengjiao and Zhang, Michael R and Chen, Yutian and Kumar, Aviral and others},
  journal={arXiv preprint arXiv:2103.16596},
  year={2021}
}

@inproceedings{ghasemipour2021emaq,
  title={Emaq: Expected-max q-learning operator for simple yet effective offline and online rl},
  author={Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  booktitle={International Conference on Machine Learning},
  pages={3682--3691},
  year={2021},
  organization={PMLR}
}

@article{hallak2015emphatic,
  title={Emphatic TD Bellman Operator is a Contraction},
  author={Hallak, Assaf and Tamar, Aviv and Mannor, Shie},
  journal={arXiv preprint arXiv:1508.03411},
  year={2015}
}

@inproceedings{liu2018breaking,
  title={Breaking the curse of horizon: Infinite-horizon off-policy estimation},
  author={Liu, Qiang and Li, Lihong and Tang, Ziyang and Zhou, Dengyong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5356--5366},
  year={2018}
}

@article{liu2019off,
  title={Off-policy policy gradient with state distribution correction},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={arXiv preprint arXiv:1904.08473},
  year={2019}
}

@article{mousavi2020black,
  title={Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning},
  author={Mousavi, Ali and Li, Lihong and Liu, Qiang and Zhou, Denny},
  journal={arXiv preprint arXiv:2003.11126},
  year={2020}
}

@article{kallus2019efficiently,
  title={Efficiently breaking the curse of horizon: Double reinforcement learning in infinite-horizon processes},
  author={Kallus, Nathan and Uehara, Masatoshi},
  journal={arXiv preprint arXiv:1909.05850},
  year={2019}
}

@inproceedings{kallus2019intrinsically,
  title={Intrinsically efficient, stable, and bounded off-policy evaluation for reinforcement learning},
  author={Kallus, Nathan and Uehara, Masatoshi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3320--3329},
  year={2019}
}

@article{uehara2019minimax,
  title={Minimax Weight and Q-Function Learning for Off-Policy Evaluation},
  author={Uehara, Masatoshi and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.12809},
  year={2019}
}

@article{tang2019doubly,
  title={Doubly robust bias reduction in infinite horizon off-policy estimation},
  author={Tang, Ziyang and Feng, Yihao and Li, Lihong and Zhou, Dengyong and Liu, Qiang},
  journal={arXiv preprint arXiv:1910.07186},
  year={2019}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{dai2017boosting,
  title={Boosting the actor with dual critic},
  author={Dai, Bo and Shaw, Albert and He, Niao and Li, Lihong and Song, Le},
  journal={arXiv preprint arXiv:1712.10282},
  year={2017}
}

@article{wang2021instabilities,
  title={Instabilities of Offline RL with Pre-Trained Neural Representation},
  author={Wang, Ruosong and Wu, Yifan and Salakhutdinov, Ruslan and Kakade, Sham M},
  journal={arXiv preprint arXiv:2103.04947},
  year={2021}
}

@article{jin2020pessimism,
  title={Is Pessimism Provably Efficient for Offline RL?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2012.15085},
  year={2020}
}

@article{dai2017sbeed,
  title={SBEED: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  journal={arXiv preprint arXiv:1712.10285},
  year={2017}
}

@article{chen2016stochastic,
  title={Stochastic primal-dual methods and sample complexity of reinforcement learning},
  author={Chen, Yichen and Wang, Mengdi},
  journal={arXiv preprint arXiv:1612.02516},
  year={2016}
}

@inproceedings{wang2016online,
  title={An online primal-dual method for discounted markov decision processes},
  author={Wang, Mengdi and Chen, Yichen},
  booktitle={2016 IEEE 55th Conference on Decision and Control (CDC)},
  pages={4516--4521},
  year={2016},
  organization={IEEE}
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=O9bnihsFfXU}
}

@article{hastie2019surprises,
  title={Surprises in high-dimensional ridgeless least squares interpolation},
  author={Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:1903.08560},
  year={2019}
}

@article{durugkar2018td,
  title={TD learning with constrained gradients},
  author={Durugkar, Ishan and Stone, Peter},
  year={2018}
}

@article{singh2020cog,
  title={COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning},
  author={Singh, Avi and Yu, Albert and Yang, Jonathan and Zhang, Jesse and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2010.14500},
  year={2020}
}

@inproceedings{dong2020expressivity,
  title={On the expressivity of neural networks for deep reinforcement learning},
  author={Dong, Kefan and Luo, Yuping and Yu, Tianhe and Finn, Chelsea and Ma, Tengyu},
  booktitle={International Conference on Machine Learning},
  pages={2627--2637},
  year={2020},
  organization={PMLR}
}

@inproceedings{savarese2019infinite,
  title={How do infinite width bounded norm networks look in function space?},
  author={Savarese, Pedro and Evron, Itay and Soudry, Daniel and Srebro, Nathan},
  booktitle={Conference on Learning Theory},
  pages={2667--2690},
  year={2019},
  organization={PMLR}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{
kumar2021workflow,
title={A Workflow for Offline Model-Free Robotic Reinforcement Learning},
author={Aviral Kumar and Anikait Singh and Stephen Tian and Chelsea Finn and Sergey Levine},
booktitle={5th Annual Conference on Robot Learning },
year={2021},
url={https://openreview.net/forum?id=fy4ZBWxYbIo}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@inproceedings{ghiassian2020gradient,
  title={Gradient temporal-difference learning with regularized corrections},
  author={Ghiassian, Sina and Patterson, Andrew and Garg, Shivam and Gupta, Dhawal and White, Adam and White, Martha},
  booktitle={International Conference on Machine Learning},
  pages={3524--3534},
  year={2020},
  organization={PMLR}
}

@inproceedings{gogianu2021spectral,
  title={Spectral normalisation for deep reinforcement learning: an optimisation perspective},
  author={Gogianu, Florin and Berariu, Tudor and Rosca, Mihaela C and Clopath, Claudia and Busoniu, Lucian and Pascanu, Razvan},
  booktitle={International Conference on Machine Learning},
  pages={3734--3744},
  year={2021},
  organization={PMLR}
}

@article{lee2021versions,
  title={Versions of Gradient Temporal Difference Learning},
  author={Lee, Donghwan and Lim, Han-Dong and Park, Jihoon and Choi, Okyong},
  journal={arXiv preprint arXiv:2109.04033},
  year={2021}
}

@article{cheng2022adversarially,
  title={Adversarially Trained Actor Critic for Offline Reinforcement Learning},
  author={Cheng, Ching-An and Xie, Tengyang and Jiang, Nan and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2202.02446},
  year={2022}
}

@article{xie2021bellman,
  title={Bellman-consistent pessimism for offline reinforcement learning},
  author={Xie, Tengyang and Cheng, Ching-An and Jiang, Nan and Mineiro, Paul and Agarwal, Alekh},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@inproceedings{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={322--332},
  year={2019},
  organization={PMLR}
}

@article{du2018gradient,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={arXiv preprint arXiv:1810.02054},
  year={2018}
}

@article{kostrikov2020image,
  title={Image augmentation is all you need: Regularizing deep reinforcement learning from pixels},
  author={Kostrikov, Ilya and Yarats, Denis and Fergus, Rob},
  journal={arXiv preprint arXiv:2004.13649},
  year={2020}
}

@article{kumar2021dr3,
  title={{DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization}},
  author={Kumar, Aviral and Agarwal, Rishabh and Ma, Tengyu and Courville, Aaron and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.04716},
  year={2021}
}

@article{pohlen2018observe,
  title={Observe and look further: Achieving consistent performance on atari},
  author={Pohlen, Tobias and Piot, Bilal and Hester, Todd and Azar, Mohammad Gheshlaghi and Horgan, Dan and Budden, David and Barth-Maron, Gabriel and Van Hasselt, Hado and Quan, John and Ve{\v{c}}er{\'\i}k, Mel and others},
  journal={arXiv preprint arXiv:1805.11593},
  year={2018}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}


@article{zanette2020exponential,
  title={Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can be Exponentially Harder than Online RL},
  author={Zanette, Andrea},
  journal={arXiv preprint arXiv:2012.08005},
  year={2020}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv:2005.13239},
  year={2020}
}

@inproceedings{
wang2021what,
title={What are the Statistical Limits of Offline {\{}RL{\}} with Linear Function Approximation?},
author={Ruosong Wang and Dean Foster and Sham M. Kakade},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=30EvkP2aQLD}
}


@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{lee2018stochastic,
  title={Stochastic primal-dual Q-learning},
  author={Lee, Donghwan and He, Niao},
  journal={arXiv preprint arXiv:1810.08298},
  year={2018}
}

@inproceedings{swaminathan2015counterfactual,
  title={Counterfactual risk minimization: Learning from logged bandit feedback},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={International Conference on Machine Learning},
  pages={814--823},
  year={2015}
}

@article{hayes2005large,
  title={A large-deviation inequality for vector-valued martingales},
  author={Hayes, Thomas P},
  journal={Combinatorics, Probability and Computing},
  year={2005}
}

@article{McGeer01041990,
  author = {McGeer, Tad}, 
  title = {\href{http://ijr.sagepub.com/content/9/2/62.abstract}{Passive Dynamic Walking}}, 
  volume = {9}, 
  number = {2}, 
  pages = {62-82}, 
  year = {1990}, 
  doi = {10.1177/027836499000900206}, 
  URL = {http://ijr.sagepub.com/content/9/2/62.abstract}, 
  eprint = {http://ijr.sagepub.com/content/9/2/62.full.pdf+html}, 
  journal = {The International Journal of Robotics Research}
}

@article{kalman1960new,
  title={A new approach to linear filtering and prediction problems},
  author={Kalman, R.E.},
  journal={Journal of Basic Engineering},
  volume={82},
  number={1},
  pages={35--45},
  year={1960},
  publisher={Citeseer}
}

@article{ghosh2021generalization,
  title={Why generalization in rl is difficult: Epistemic pomdps and implicit partial observability},
  author={Ghosh, Dibya and Rahme, Jad and Kumar, Aviral and Zhang, Amy and Adams, Ryan P and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{cobbe2020leveraging,
  title={Leveraging procedural generation to benchmark reinforcement learning},
  author={Cobbe, Karl and Hesse, Chris and Hilton, Jacob and Schulman, John},
  booktitle={International conference on machine learning},
  pages={2048--2056},
  year={2020},
  organization={PMLR}
}

@article{sharma2021autonomoussubgoal,
  title={Autonomous Reinforcement Learning via Subgoal Curricula},
  author={Sharma, Archit and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{gupta2021reset,
  title={Reset-Free Reinforcement Learning via Multi-Task Learning: Learning Dexterous Manipulation Behaviors without Human Intervention},
  author={Gupta, Abhishek and Yu, Justin and Zhao, Tony Z and Kumar, Vikash and Rovinsky, Aaron and Xu, Kelvin and Devlin, Thomas and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.11203},
  year={2021}
}

@article{ha2020learning,
  title={Learning to walk in the real world with minimal human effort},
  author={Ha, Sehoon and Xu, Peng and Tan, Zhenyu and Levine, Sergey and Tan, Jie},
  journal={arXiv preprint arXiv:2002.08550},
  year={2020}
}

@article{zhu2020ingredients,
  title={The ingredients of real-world robotic reinforcement learning},
  author={Zhu, Henry and Yu, Justin and Gupta, Abhishek and Shah, Dhruv and Hartikainen, Kristian and Singh, Avi and Kumar, Vikash and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.12570},
  year={2020}
}

@article{xu2020continual,
  title={Continual Learning of Control Primitives: Skill Discovery via Reset-Games},
  author={Xu, Kelvin and Verma, Siddharth and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.05286},
  year={2020}
}

@article{eysenbach2017leave,
  title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
  author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.06782},
  year={2017}
}

@inproceedings{han2015learning,
  title={Learning compound multi-step controllers under unknown dynamics},
  author={Han, Weiqiao and Levine, Sergey and Abbeel, Pieter},
  booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={6435--6442},
  year={2015},
  organization={IEEE}
}

@article{sharma2021autonomous,
  title={Autonomous Reinforcement Learning: Formalism and Benchmarking},
  author={Sharma, Archit and Xu, Kelvin and Sardana, Nikhil and Gupta, Abhishek and Hausman, Karol and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2112.09605},
  year={2021}
}

@article{wang2016learning,
  title={Learning to reinforcement learn},
  author={Wang, Jane X and Kurth-Nelson, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z and Munos, Remi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},
  journal={arXiv preprint arXiv:1611.05763},
  year={2016}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{duan2016rl,
  title={R$\mathrm{L}^{2}$: Fast reinforcement learning via slow reinforcement learning},
  author={Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1611.02779},
  year={2016}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@inproceedings{rakelly2019efficient,
  title={Efficient off-policy meta-reinforcement learning via probabilistic context variables},
  author={Rakelly, Kate and Zhou, Aurick and Finn, Chelsea and Levine, Sergey and Quillen, Deirdre},
  booktitle={International conference on machine learning},
  pages={5331--5340},
  year={2019},
  organization={PMLR}
}

@article{kalashnikov2021mt,
  title={MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale},
  author={Kalashnikov, Dmitry and Varley, Jacob and Chebotar, Yevgen and Swanson, Benjamin and Jonschkowski, Rico and Finn, Chelsea and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:2104.08212},
  year={2021}
}

@article{yu2021conservative,
  title={Conservative data sharing for multi-task offline reinforcement learning},
  author={Yu, Tianhe and Kumar, Aviral and Chebotar, Yevgen and Hausman, Karol and Levine, Sergey and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{li2019multi,
  title={Multi-task batch reinforcement learning with metric learning},
  author={Li, Jiachen and Vuong, Quan and Liu, Shuang and Liu, Minghua and Ciosek, Kamil and Ross, Keith and Christensen, Henrik Iskov and Su, Hao},
  journal={arXiv preprint arXiv:1909.11373},
  year={2019}
}

@article{yang2021representation,
  title={Representation matters: Offline pretraining for sequential decision making},
  author={Yang, Mengjiao and Nachum, Ofir},
  journal={arXiv preprint arXiv:2102.05815},
  year={2021}
}

@inproceedings{mitchell2021offline,
  title={Offline meta-reinforcement learning with advantage weighting},
  author={Mitchell, Eric and Rafailov, Rafael and Peng, Xue Bin and Levine, Sergey and Finn, Chelsea},
  booktitle={International Conference on Machine Learning},
  pages={7780--7791},
  year={2021},
  organization={PMLR}
}

@article{pong2021offline,
  title={Offline Meta-Reinforcement Learning with Online Self-Supervision},
  author={Pong, Vitchyr H and Nair, Ashvin and Smith, Laura and Huang, Catherine and Levine, Sergey},
  journal={arXiv preprint arXiv:2107.03974},
  year={2021}
}

@article{dorfman2020offline,
  title={Offline meta reinforcement learning},
  author={Dorfman, Ron and Tamar, Aviv},
  journal={arXiv e-prints},
  pages={arXiv--2008},
  year={2020}
}

@article{singh2020parrot,
  title={Parrot: Data-driven behavioral priors for reinforcement learning},
  author={Singh, Avi and Liu, Huihan and Zhou, Gaoyue and Yu, Albert and Rhinehart, Nicholas and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.10024},
  year={2020}
}

@article{ajay2020opal,
  title={Opal: Offline primitive discovery for accelerating offline reinforcement learning},
  author={Ajay, Anurag and Kumar, Aviral and Agrawal, Pulkit and Levine, Sergey and Nachum, Ofir},
  journal={arXiv preprint arXiv:2010.13611},
  year={2020}
}

@inproceedings{nair19ccrig,
    author    = {A. Nair and S. Bahl and A. Khazatsky and V. Pong and G. Berseth and S. Levine},
    title     = {Contextual Imagined Goals for Self-Supervised Robotic Learning},
    booktitle = {Conference on Robot Learning (CoRL)},
    year      = {2019}
}

@article{khazatsky2021can,
  title={What Can I Do Here? Learning New Skills by Imagining Visual Affordances},
  author={Khazatsky, Alexander and Nair, Ashvin and Jing, Daniel and Levine, Sergey},
  journal={arXiv preprint arXiv:2106.00671},
  year={2021}
}

@article{huh2016makes,
  title={What makes ImageNet good for transfer learning?},
  author={Huh, Minyoung and Agrawal, Pulkit and Efros, Alexei A},
  journal={arXiv preprint arXiv:1608.08614},
  year={2016}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{radford2021clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  journal={arXiv preprint arXiv:2103.00020},
  year={2021}
}

@inproceedings{pinto2016supersizing,
  title={Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours},
  author={Pinto, Lerrel and Gupta, Abhinav},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={3406--3413},
  year={2016},
  organization={IEEE}
}

@inproceedings{mandlekar2020iris,
  title={Iris: Implicit reinforcement without interaction at scale for learning control from offline robot manipulation data},
  author={Mandlekar, Ajay and Ramos, Fabio and Boots, Byron and Savarese, Silvio and Fei-Fei, Li and Garg, Animesh and Fox, Dieter},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4414--4420},
  year={2020},
  organization={IEEE}
}

@article{julian2020efficient,
  title={Efficient adaptation for end-to-end vision-based robotic manipulation},
  author={Julian, Ryan and Swanson, Benjamin and Sukhatme, Gaurav S and Levine, Sergey and Finn, Chelsea and Hausman, Karol},
  year={2020}
}

@article{kurin2022defense,
  title={In defense of the unitary scalarization for deep multi-task learning},
  author={Kurin, Vitaly and De Palma, Alessandro and Kostrikov, Ilya and Whiteson, Shimon and Kumar, M Pawan},
  journal={arXiv preprint arXiv:2201.04122},
  year={2022}
}

@article{brandfonbrener2021offline,
  title={Offline RL Without Off-Policy Evaluation},
  author={Brandfonbrener, David and Whitney, William F and Ranganath, Rajesh and Bruna, Joan},
  journal={arXiv preprint arXiv:2106.08909},
  year={2021}
}

@article{cabi2019scaling,
  title={Scaling data-driven robotics with reward sketching and batch reinforcement learning},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and Zolna, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

@inproceedings{hausman2018learning,
  title={Learning an embedding space for transferable robot skills},
  author={Hausman, Karol and Springenberg, Jost Tobias and Wang, Ziyu and Heess, Nicolas and Riedmiller, Martin},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{zintgraf2019varibad,
  title={Varibad: A very good method for bayes-adaptive deep rl via meta-learning},
  author={Zintgraf, Luisa and Shiarlis, Kyriacos and Igl, Maximilian and Schulze, Sebastian and Gal, Yarin and Hofmann, Katja and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1910.08348},
  year={2019}
}

@article{kirk2021survey,
  title={A Survey of Generalisation in Deep Reinforcement Learning},
  author={Kirk, Robert and Zhang, Amy and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  journal={arXiv preprint arXiv:2111.09794},
  year={2021}
}


@article{schaal1997learning,
  title={Learning from demonstration},
  author={Schaal, Stefan and others},
  journal={Advances in neural information processing systems},
  pages={1040--1046},
  year={1997},
  publisher={Citeseer}
}

@article{hester2017learning,
  title={Learning from demonstrations for real world reinforcement learning},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Sendonaris, Andrew and Dulac-Arnold, Gabriel and Osband, Ian and Agapiou, John and others},
  year={2017}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@article{peng2018deepmimic,
  title={Deepmimic: Example-guided deep reinforcement learning of physics-based character skills},
  author={Peng, Xue Bin and Abbeel, Pieter and Levine, Sergey and van de Panne, Michiel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={37},
  number={4},
  pages={1--14},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@inproceedings{kormushev2010robot,
  title={Robot motor skill coordination with EM-based reinforcement learning},
  author={Kormushev, Petar and Calinon, Sylvain and Caldwell, Darwin G},
  booktitle={2010 IEEE/RSJ international conference on intelligent robots and systems},
  pages={3232--3237},
  year={2010},
  organization={IEEE}
}

@article{nair2017overcoming,
  title={Overcoming Exploration in Reinforcement Learning with Demonstrations. CoRR abs/1709.10089 (2017)},
  author={Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1709.10089},
  year={2017}
}

@article{kalashnikov2018qt,
  title={Qt-opt: Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  journal={arXiv preprint arXiv:1806.10293},
  year={2018}
}

@article{lu2020reset,
  title={Reset-free lifelong learning with skill-space planning},
  author={Lu, Kevin and Grover, Aditya and Abbeel, Pieter and Mordatch, Igor},
  journal={arXiv preprint arXiv:2012.03548},
  year={2020}
}

@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@inproceedings{peters2007reinforcement,
  title={Reinforcement learning by reward-weighted regression for operational space control},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={745--750},
  year={2007}
}

@article{peng2019advantage,
  title={Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{fujimoto2021minimalist,
  title={A Minimalist Approach to Offline Reinforcement Learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2106.06860},
  year={2021}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@inproceedings{kostrikov2021offline,
  title={Offline reinforcement learning with fisher divergence critic regularization},
  author={Kostrikov, Ilya and Fergus, Rob and Tompson, Jonathan and Nachum, Ofir},
  booktitle={International Conference on Machine Learning},
  pages={5774--5783},
  year={2021},
  organization={PMLR}
}

@inproceedings{kostrikov2021iql,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@inproceedings{wilson2007multi,
  title={Multi-task reinforcement learning: a hierarchical bayesian approach},
  author={Wilson, Aaron and Fern, Alan and Ray, Soumya and Tadepalli, Prasad},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={1015--1022},
  year={2007}
}

@article{parisotto2015actor,
  title={Actor-mimic: Deep multitask and transfer reinforcement learning},
  author={Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1511.06342},
  year={2015}
}



@inproceedings{hessel2019multi,
  title={Multi-task deep reinforcement learning with popart},
  author={Hessel, Matteo and Soyer, Hubert and Espeholt, Lasse and Czarnecki, Wojciech and Schmitt, Simon and van Hasselt, Hado},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={3796--3803},
  year={2019}
}

@article{xu2020knowledge,
  title={Knowledge transfer in multi-task deep reinforcement learning for continuous control},
  author={Xu, Zhiyuan and Wu, Kun and Che, Zhengping and Tang, Jian and Ye, Jieping},
  journal={arXiv preprint arXiv:2010.07494},
  year={2020}
}

@article{yang2020multi,
  title={Multi-task reinforcement learning with soft modularization},
  author={Yang, Ruihan and Xu, Huazhe and Wu, Yi and Wang, Xiaolong},
  journal={arXiv preprint arXiv:2003.13661},
  year={2020}
}

@article{sodhani2021multi,
  title={Multi-Task Reinforcement Learning with Context-based Representations},
  author={Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
  journal={arXiv preprint arXiv:2102.06177},
  year={2021}
}

@article{lin2021,
  author    = {Yen{-}Chen Lin and
               Andy Zeng and
               Shuran Song and
               Phillip Isola and
               Tsung{-}Yi Lin},
  title     = {Learning to See before Learning to Act: Visual Pre-training for Manipulation},
  journal   = {CoRR},
  volume    = {abs/2107.00646},
  year      = {2021},
  eprint    = {2107.00646},
}

@article{yang2021trail,
  title={TRAIL: Near-Optimal Imitation Learning with Suboptimal Data},
  author={Yang, Mengjiao and Levine, Sergey and Nachum, Ofir},
  journal={arXiv preprint arXiv:2110.14770},
  year={2021}
}

@article{yu2022leverage,
  title={How to Leverage Unlabeled Data in Offline Reinforcement Learning},
  author={Yu, Tianhe and Kumar, Aviral and Chebotar, Yevgen and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2202.01741},
  year={2022}
}

@article{lee2022spend,
  title={How to Spend Your Robot Time: Bridging Kickstarting and Offline Reinforcement Learning for Vision-based Robotic Manipulation},
  author={Lee, Alex X and Devin, Coline and Springenberg, Jost Tobias and Zhou, Yuxiang and Lampe, Thomas and Abdolmaleki, Abbas and Bousmalis, Konstantinos},
  journal={arXiv preprint arXiv:2205.03353},
  year={2022}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{julian2020never,
  title={Never stop learning: The effectiveness of fine-tuning in robotic reinforcement learning},
  author={Julian, Ryan and Swanson, Benjamin and Sukhatme, Gaurav S and Levine, Sergey and Finn, Chelsea and Hausman, Karol},
  journal={arXiv preprint arXiv:2004.10190},
  year={2020}
}

@misc{young2020visual,
    title={Visual Imitation Made Easy},
    author={Sarah Young and Dhiraj Gandhi and Shubham Tulsiani and Abhinav Gupta and Pieter Abbeel and Lerrel Pinto},
    year={2020},
    eprint={2008.04899},
    archivePrefix={arXiv},
    primaryClass={cs.RO}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{ahn2022can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@inproceedings{lee2022offline,
  title={Offline-to-Online Reinforcement Learning via Balanced Replay and Pessimistic Q-Ensemble},
  author={Lee, Seunghyun and Seo, Younggyo and Lee, Kimin and Abbeel, Pieter and Shin, Jinwoo},
  booktitle={Conference on Robot Learning},
  pages={1702--1712},
  year={2022},
  organization={PMLR}
}


@article{shapenet,
  author    = {Angel X. Chang and
               Thomas A. Funkhouser and
               Leonidas J. Guibas and
               Pat Hanrahan and
               Qi{-}Xing Huang and
               Zimo Li and
               Silvio Savarese and
               Manolis Savva and
               Shuran Song and
               Hao Su and
               Jianxiong Xiao and
               Li Yi and
               Fisher Yu},
  title     = {ShapeNet: An Information-Rich 3D Model Repository},
  journal   = {CoRR},
  volume    = {abs/1512.03012},
  year      = {2015},
}

@article{coumans2016pybullet,
  title={Pybullet, a python module for physics simulation for games, robotics and machine learning},
  author={Coumans, E and Bai, Y},
  journal={GitHub repository},
  year={2016}
}

@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}




@inproceedings{cobbe2020leveraging,
  title={Leveraging procedural generation to benchmark reinforcement learning},
  author={Cobbe, Karl and Hesse, Chris and Hilton, Jacob and Schulman, John},
  booktitle={International conference on machine learning},
  pages={2048--2056},
  year={2020},
  organization={PMLR}
}



@article{lee2022multi,
  title={Multi-Game Decision Transformers},
  author={Lee, Kuang-Huei and Nachum, Ofir and Yang, Mengjiao and Lee, Lisa and Freeman, Daniel and Xu, Winnie and Guadarrama, Sergio and Fischer, Ian and Jang, Eric and Michalewski, Henryk and others},
  journal={arXiv preprint arXiv:2205.15241},
  year={2022}
}


@article{bjorck2021towards,
  title={Towards Deeper Deep Reinforcement Learning with Spectral Normalization},
  author={Bjorck, Nils and Gomes, Carla P and Weinberger, Kilian Q},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={8242--8255},
  year={2021}
}


@article{oord2018representation,
  title={Representation learning with contrastive predictive coding},
  author={Oord, Aaron van den and Li, Yazhe and Vinyals, Oriol},
  journal={arXiv preprint arXiv:1807.03748},
  year={2018}
}

@article{soarespulserl,
  title={PulseRL: Enabling Offline Reinforcement Learning for Digital Marketing Systems via Conservative Q-Learning},
  author={Soares, Douglas W and Certo, Acordo and Lima, Telma and Brazil, Deep Learning},
  year={2021}
}

@article{he2111masked,
  title={Masked autoencoders are scalable vision learners},
  author={He, K and Chen, X and Xie, S and Li, Y and Doll{'a}r, P and Girshick, RB},
  journal={arXiv preprint arXiv.2111.06377},
  year={2021}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@inproceedings{badia2020agent57,
  title={Agent57: Outperforming the human Atari benchmark},
  author={Badia, A and Piot, B and Kapturowski, S and Sprechmann, P and Vitvitskyi, A and Guo, D and Blundell, C},
  booktitle={Proceedings of the 37th International Conference on Machine Learning, Online, PMLR},
  volume={119},
  pages={2020},
  year={2020}
}


@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Misha and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={Advances in neural information processing systems},
  volume={34},
  pages={15084--15097},
  year={2021}
}

@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={International Conference on Machine Learning},
  pages={449--458},
  year={2017},
  organization={PMLR}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={22--31},
  year={2017},
  organization={JMLR. org}
}

@article{konyushkova2020semi,
  title={Semi-supervised reward learning for offline reinforcement learning},
  author={Konyushkova, Ksenia and Zolna, Konrad and Aytar, Yusuf and Novikov, Alexander and Reed, Scott and Cabi, Serkan and de Freitas, Nando},
  journal={arXiv preprint arXiv:2012.06899},
  year={2020}
}

@inproceedings{chebotar2017path,
  title={Path integral guided policy search},
  author={Chebotar, Yevgen and Kalakrishnan, Mrinal and Yahya, Ali and Li, Adrian and Schaal, Stefan and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3381--3388},
  year={2017},
  organization={IEEE}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@article{singh2020cog,
  title={Cog: Connecting new skills to past experience with offline reinforcement learning},
  author={Singh, Avi and Yu, Albert and Yang, Jonathan and Zhang, Jesse and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2010.14500},
  year={2020}
}

@article{yu2021conservative,
  title={Conservative Data Sharing for Multi-Task Offline Reinforcement Learning},
  author={Yu, Tianhe and Kumar, Aviral and Chebotar, Yevgen and Hausman, Karol and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2109.08128},
  year={2021}
}

@article{eysenbach2021replacing,
  title={Replacing Rewards with Examples: Example-Based Policy Search via Recursive Classification},
  author={Eysenbach, Benjamin and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2103.12656},
  year={2021}
}

@article{fu2018variational,
  title={Variational inverse control with events: A general framework for data-driven reward definition},
  author={Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey},
  journal={arXiv preprint arXiv:1805.11686},
  year={2018}
}

@article{kumar2020conservative,
  title={Conservative q-learning for offline reinforcement learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}


@inproceedings{yu2020meta,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@article{kalashnikov2021mt,
  title={MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale},
  author={Kalashnikov, Dmitry and Varley, Jacob and Chebotar, Yevgen and Swanson, Benjamin and Jonschkowski, Rico and Finn, Chelsea and Levine, Sergey and Hausman, Karol},
  journal={Conference on Robot Learning (CoRL)},
  year={2021}
}

@inproceedings{lee2019SLAC,
  title={Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model
},
  author={Alex X. Lee and Anusha Nagabandi and Pieter Abbeel and Sergey Levine},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}


@inproceedings{Hafner2019PlanNet,
  title={International Conference on Machine
Learning},
  author={Danijar Hafner and Timothy Lillicrap and Ian Fischer and Ruben Villegas and David Ha and Honglak Lee and James Davidson},
  booktitle={ International Conference on Machine
Learning},
  year={2019}
}

@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@article{liu2020provably,
  title={Provably good batch reinforcement learning without great exploration},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={arXiv preprint arXiv:2007.08202},
  year={2020}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul and Leike, Jan and Brown, Tom B and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={arXiv preprint arXiv:1706.03741},
  year={2017}
}

@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11761--11771},
  year={2019}
}

@article{wu2019behavior,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{jaques2019way,
  title={Way off-policy batch deep reinforcement learning of implicit human preferences in dialog},
  author={Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang and Picard, Rosalind},
  journal={arXiv preprint arXiv:1907.00456},
  year={2019}
}



@inproceedings{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12498--12509},
  year={2019}
}

@inproceedings{mittel2019visual,
  title={Visual transfer between atari games using competitive reinforcement learning},
  author={Mittel, Akshita and Sowmya Munukutla, Purna},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},
  pages={0--0},
  year={2019}
}

@article{song2019v,
  title={V-mpo: On-policy maximum a posteriori policy optimization for discrete and continuous control},
  author={Song, H Francis and Abdolmaleki, Abbas and Springenberg, Jost Tobias and Clark, Aidan and Soyer, Hubert and Rae, Jack W and Noury, Seb and Ahuja, Arun and Liu, Siqi and Tirumala, Dhruva and others},
  journal={arXiv preprint arXiv:1909.12238},
  year={2019}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@article{luo2018algorithmic,
  title={Algorithmic framework for model-based deep reinforcement learning with theoretical guarantees},
  author={Luo, Yuping and Xu, Huazhe and Li, Yuanzhi and Tian, Yuandong and Darrell, Trevor and Ma, Tengyu},
  journal={arXiv preprint arXiv:1807.03858},
  year={2018}
}

@inproceedings{agarwal2019optimistic,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={104--114},
  year={2020},
  organization={PMLR}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{balaji2017ensemble,
author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
title = {Simple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {6405–6416},
numpages = {12},
location = {Long Beach, California, USA},
series = {NIPS’17}
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={ICML},
  pages={417--424},
  year={2001}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1054--1062},
  year={2016}
}

@article{ajksbook,
  title={Reinforcement learning: Theory and algorithms},
  author={Agarwal, Alekh and Jiang, Nan and Kakade, Sham M},
  journal={CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep},
  year={2019}
}

@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{fujimoto2019benchmarking,
  title={Benchmarking Batch Deep Reinforcement Learning Algorithms},
  author={Fujimoto, Scott and Conti, Edoardo and Ghavamzadeh, Mohammad and Pineau, Joelle},
  journal={arXiv preprint arXiv:1910.01708},
  year={2019}
}

@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM Sigart Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@InCollection{LangeGR12,
	title =	"Batch Reinforcement Learning",
	author =	"Sascha Lange and Thomas Gabel and Martin A.
	Riedmiller",
	booktitle =	"Reinforcement Learning",
	publisher =	"Springer",
	year = 	"2012",
	volume =	"12",
}

@Article{LiuSAB19,
  title =	"Off-Policy Policy Gradient with State Distribution
		 Correction",
  author =	"Yao Liu and Adith Swaminathan and Alekh Agarwal
		 and Emma Brunskill",
  journal =	"CoRR",
  year = 	"2019",
  volume =	"abs/1904.08473",
}

@Article{SwaminathanJ15,
	title =	"Batch learning from logged bandit feedback through
	counterfactual risk minimization",
	author =	"Adith Swaminathan and Thorsten Joachims",
	journal =	"J. Mach. Learn. Res",
	year = 	"2015",
	volume =	"16",
	pages =	"1731--1755",
}

@article{Liu2020ProvablyGB,
  title={Provably Good Batch Reinforcement Learning Without Great Exploration},
  author={Yao Liu and A. Swaminathan and A. Agarwal and Emma Brunskill},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.08202}
}

@article{argenson2020model,
  title={Model-Based Offline Planning},
  author={Argenson, Arthur and Dulac-Arnold, Gabriel},
  journal={arXiv preprint arXiv:2008.05556},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{kidambi2020morel,
  title={MOReL: Model-Based Offline Reinforcement Learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={arXiv preprint arXiv:2005.05951},
  year={2020}
}

@article{matsushima2020deployment,
  title={Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization},
  author={Matsushima, Tatsuya and Furuta, Hiroki and Matsuo, Yutaka and Nachum, Ofir and Gu, Shixiang},
  journal={arXiv preprint arXiv:2006.03647},
  year={2020}
}

@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and {\.Z}o{\l}na, Konrad and Springenberg, Jost Tobias and Reed, Scott and Shahriari, Bobak and Siegel, Noah and Merel, Josh and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={arXiv preprint arXiv:2006.15134},
  year={2020}
}


@article{zhanggendice,
  title={GenDICE: Generalized offline estimation of stationary values, 2020},
  author={Zhang, Ruiyi and Dai, Bo and Lihong, Li and Schuurmans, Dale},
  journal={Preprint}
}

@inproceedings{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4754--4765},
  year={2018}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@phdthesis{thomas2015safe,
  title={Safe reinforcement learning},
  author={Thomas, Philip S},
  year={2015},
  school={University of Massachusetts Libraries}
}


@article{Wang2018SupervisedRL,
  title={Supervised Reinforcement Learning with Recurrent Neural Network for Dynamic Treatment Recommendation},
  author={L. Wang and Wei Zhang and Xiaofeng He and H. Zha},
  journal={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  year={2018}
}

@article{Rafailov2020LOMPO,
  title={Offline Reinforcement Learning from Images with Latent Space Models},
  author={Rafael Rafailov and Tianhe Yu and A. Rajeswaran and Chelsea Finn},
  journal={Learning for Decision Making and Control (L4DC)},
  year={2021},
}

@article{Buckman2020TheIO,
  title={The Importance of Pessimism in Fixed-Dataset Policy Optimization},
  author={J. Buckman and Carles Gelada and Marc G. Bellemare},
  journal={ArXiv},
  year={2020},
  volume={abs/2009.06799}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  pages={503--556},
  year={2005},
  publisher={Microtome Publishing}
}

@inproceedings{riedmiller2005neural,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}

@article{rafailov2020offline,
  title={Offline Reinforcement Learning from Images with Latent Space Models},
  author={Rafailov, Rafael and Yu, Tianhe and Rajeswaran, Aravind and Finn, Chelsea},
  journal={arXiv preprint arXiv:2012.11547},
  year={2020}
}

@article{singh2020parrot,
  title={Parrot: Data-Driven Behavioral Priors for Reinforcement Learning},
  author={Singh, Avi and Liu, Huihan and Zhou, Gaoyue and Yu, Albert and Rhinehart, Nicholas and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.10024},
  year={2020}
}

@article{xie2019improvisation,
  title={Improvisation through physical understanding: Using novel objects as tools with visual foresight},
  author={Xie, Annie and Ebert, Frederik and Levine, Sergey and Finn, Chelsea},
  journal={Robotics: Science and Systems (RSS)},
  year={2019}
}

@article{jaques2020human,
  title={Human-centric dialog training via offline reinforcement learning},
  author={Jaques, Natasha and Shen, Judy Hanwen and Ghandeharioun, Asma and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang Shane and Picard, Rosalind},
  journal={arXiv preprint arXiv:2010.05848},
  year={2020}
}

@article{kumar2020discor,
  title={DisCor: Corrective Feedback in Reinforcement Learning via Distribution Correction},
  author={Kumar, Aviral and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2003.07305},
  year={2020}
}

@article{dorfman2020offline,
  title={Offline meta reinforcement learning},
  author={Dorfman, Ron and Tamar, Aviv},
  journal={arXiv preprint arXiv:2008.02598},
  year={2020}
}

@article{sutton2016emphatic,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@article{raghu2017deep,
  title={Deep reinforcement learning for sepsis treatment},
  author={Raghu, Aniruddh and Komorowski, Matthieu and Ahmed, Imran and Celi, Leo and Szolovits, Peter and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:1711.09602},
  year={2017}
}

@article{shortreed2011informing,
  title={Informing sequential clinical decision-making through reinforcement learning: an empirical study},
  author={Shortreed, Susan M and Laber, Eric and Lizotte, Daniel J and Stroup, T Scott and Pineau, Joelle and Murphy, Susan A},
  journal={Machine learning},
  volume={84},
  number={1-2},
  pages={109--136},
  year={2011},
  publisher={Springer}
}

@inproceedings{pinto2016supersizing,
  title={Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours},
  author={Pinto, Lerrel and Gupta, Abhinav},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={3406--3413},
  year={2016},
  organization={IEEE}
}

@inproceedings{kalashnikov2018scalable,
  title={Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  pages={651--673},
  year={2018},
  organization={PMLR}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@article{oh2015action,
  title={Action-conditional video prediction using deep networks in atari games},
  author={Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard and Singh, Satinder},
  journal={arXiv preprint arXiv:1507.08750},
  year={2015}
}

@article{kaiser2019model,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@InProceedings{RossB12,
  title =	"Agnostic System Identification for Model-Based Reinforcement Learning",
  author =	"Stephane Ross and Drew Bagnell",
  year = 	"2012",
  booktitle =	"ICML",
}

@INPROCEEDINGS{Rajeswaran-Game-MBRL,
    AUTHOR    = {Aravind Rajeswaran AND Igor Mordatch AND Vikash Kumar},
    TITLE     = "{A Game Theoretic Framework for
Model-Based Reinforcement Learning}",
    BOOKTITLE = {ICML},
    YEAR      = {2020},
}

@article{Abdolmaleki2018MaximumAP,
  title={Maximum a Posteriori Policy Optimisation},
  author={Abbas Abdolmaleki and Jost Tobias Springenberg and Y. Tassa and R. Munos and N. Heess and Martin A. Riedmiller},
  journal={ArXiv},
  year={2018},
  volume={abs/1806.06920}
}

@INPROCEEDINGS{POLO,
    AUTHOR  = {Kendall Lowrey AND Aravind Rajeswaran AND Sham Kakade AND 
             Emanuel Todorov AND Igor Mordatch},
    TITLE   = "{Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control}",
    BOOKTITLE = "{International Conference on Learning Representations (ICLR)}",
    YEAR      = {2019},
}

@inproceedings{Todorov2005,
  title={A generalized iterative LQG method for locally-optimal feedback control of constrained nonlinear stochastic systems},
  author={Emanuel Todorov and Weiwei Li},
  booktitle={ACC},
  year={2005},
}

@article{WilliamsMPPI,
  title={Information theoretic MPC for model-based reinforcement learning},
  author={Grady Williams and Nolan Wagener and Brian Goldfain and Paul Drews and James M. Rehg and Byron Boots and Evangelos Theodorou},
  journal={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2017},
  pages={1714-1721}
}

@Misc{RRT,
  title =	"Rapidly-Exploring Random Trees: A New Tool for Path Planning",
  author =	"Steven M. Lavalle",
  year = 	"1998",
}

@article{Nagabandi2019DeepDM,
  title={Deep Dynamics Models for Learning Dexterous Manipulation},
  author={Anusha Nagabandi and K. Konolige and S. Levine and V. Kumar},
  journal={ArXiv},
  year={2019},
  volume={abs/1909.11652}
}

@Article{OsbandAC18,
  title =	"Randomized Prior Functions for Deep Reinforcement Learning",
  author =	"Ian Osband and John Aslanides and Albin Cassirer",
  journal =	"CoRR",
  year = 	"2018",
  volume =	"abs/1806.03335",
}

@InProceedings{Azizzadenesheli18,
  title =	"Efficient Exploration Through Bayesian Deep
		 Q-Networks",
  author =	"Kamyar Azizzadenesheli and Emma Brunskill and
		 Animashree Anandkumar",
  publisher =	"IEEE",
  year = 	"2018",
  booktitle =	"ITA",
  pages =	"1--9",
}

@InProceedings{BurdaESK19,
  title =	"Exploration by random network distillation",
  author =	"Yuri Burda and Harrison Edwards and Amos J. Storkey and Oleg Klimov",
  publisher =	"OpenReview.net",
  year = 	"2019",
  booktitle =	"ICLR",
}

@article{Chen2019InformationTheoreticCI,
  title={Information-Theoretic Considerations in Batch Reinforcement Learning},
  author={J. Chen and Nan Jiang},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.00360}
}

@Book{BertsekasBook,
  author =	"Dimitri P. Bertsekas and John N. Tsitsiklis",
  title =	"Neuro-Dynamic Programming",
  publisher =	"Athena Scientific",
  year = 	"1996",
  address =	"Belmont, MA",
}

@Book{SuttonBook,
  author =	"R. S. Sutton and A. G. Barto",
  title =	"Reinforcement Learning: An Introduction",
  year = 	"1998",
  publisher =	"MIT Press",
  address =	"Cambridge, MA",
}

@article{Munos2008FiniteTimeBF,
  title={Finite-Time Bounds for Fitted Value Iteration},
  author={R{\'e}mi Munos and Csaba Szepesvari},
  journal={J. Mach. Learn. Res.},
  year={2008},
  volume={9},
  pages={815-857}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{mandlekar2020iris,
  title={Iris: Implicit reinforcement without interaction at scale for learning control from offline robot manipulation data},
  author={Mandlekar, Ajay and Ramos, Fabio and Boots, Byron and Savarese, Silvio and Fei-Fei, Li and Garg, Animesh and Fox, Dieter},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4414--4420},
  year={2020},
  organization={IEEE}
}

@article{zhou2020plas,
  title={PLAS: Latent Action Space for Offline Reinforcement Learning},
  author={Zhou, Wenxuan and Bajracharya, Sujay and Held, David},
  journal={arXiv preprint arXiv:2011.07213},
  year={2020}
}

@inproceedings{kahn2018composable,
  title={Composable action-conditioned predictors: Flexible off-policy learning for robot navigation},
  author={Kahn, Gregory and Villaflor, Adam and Abbeel, Pieter and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={806--816},
  year={2018},
  organization={PMLR}
}

@article{Yu2020BDD100KAD,
  title={BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning},
  author={F. Yu and H. Chen and X. Wang and Wenqi Xian and Yingying Chen and Fangchen Liu and V. Madhavan and Trevor Darrell},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
  pages={2633-2642}
}

@inproceedings{
lee2021representation,
title={Representation Balancing Offline Model-based Reinforcement Learning},
author={Byung-Jun Lee and Jongmin Lee and Kee-Eung Kim},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=QpNz8r_Ri2Y}
}

@article{swazinna2020overcoming,
  title={Overcoming Model Bias for Robust Offline Deep Reinforcement Learning},
  author={Swazinna, Phillip and Udluft, Steffen and Runkler, Thomas},
  journal={arXiv preprint arXiv:2008.05533},
  year={2020}
}

@article{tassa2018deepmind,
  title={Deepmind control suite},
  author={Tassa, Yuval and Doron, Yotam and Muldal, Alistair and Erez, Tom and Li, Yazhe and Casas, Diego de Las and Budden, David and Abdolmaleki, Abbas and Merel, Josh and Lefrancq, Andrew and others},
  journal={arXiv preprint arXiv:1801.00690},
  year={2018}
}

@article{ovadia2019can,
  title={Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift},
  author={Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, David and Nowozin, Sebastian and Dillon, Joshua V and Lakshminarayanan, Balaji and Snoek, Jasper},
  journal={arXiv preprint arXiv:1906.02530},
  year={2019}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@inproceedings{laroche2019safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Des Combes, Remi Tachet},
  booktitle={International Conference on Machine Learning},
  pages={3652--3661},
  year={2019},
  organization={PMLR}
}

@article{petrik2016safe,
  title={Safe policy improvement by minimizing robust baseline regret},
  author={Petrik, Marek and Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1607.03842},
  year={2016}
}

@inproceedings{osband2017posterior,
  title={Why is posterior sampling better than optimism for reinforcement learning?},
  author={Osband, Ian and Van Roy, Benjamin},
  booktitle={International Conference on Machine Learning},
  pages={2701--2710},
  year={2017},
  organization={PMLR}
}

@article{jaksch2010near,
  title={Near-optimal Regret Bounds for Reinforcement Learning.},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={4},
  year={2010}
}

@misc{dasari2020robonet,
      title={RoboNet: Large-Scale Multi-Robot Learning}, 
      author={Sudeep Dasari and Frederik Ebert and Stephen Tian and Suraj Nair and Bernadette Bucher and Karl Schmeckpeper and Siddharth Singh and Sergey Levine and Chelsea Finn},
      year={2020},
      eprint={1910.11215},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=O9bnihsFfXU}
}

@article{eysenbach2020rewriting,
  title={Rewriting history with inverse rl: Hindsight inference for policy improvement},
  author={Eysenbach, Benjamin and Geng, Xinyang and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2002.11089},
  year={2020}
}

@article{li2020generalized,
  title={Generalized hindsight for reinforcement learning},
  author={Li, Alexander C and Pinto, Lerrel and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2002.11708},
  year={2020}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1707.01495},
  year={2017}
}

@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  number={1},
  pages={41--75},
  year={1997},
  publisher={Springer}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015},
  organization={PMLR}
}

@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  pages={1094--1099},
  year={1993},
  organization={Citeseer}
}

@inproceedings{espeholt2018impala,
  author    = {Lasse Espeholt and
               Hubert Soyer and
               R{\'{e}}mi Munos and
               Karen Simonyan and
               Volodymyr Mnih and
               Tom Ward and
               Yotam Doron and
               Vlad Firoiu and
               Tim Harley and
               Iain Dunning and
               Shane Legg and
               Koray Kavukcuoglu},
  title     = {{IMPALA:} Scalable Distributed Deep-RL with Importance Weighted Actor-Learner
               Architectures},
  booktitle = { International Conference on Machine Learning},
  year      = {2018},
}

@inproceedings{hessel2019popart,
  title={Multi-task deep reinforcement learning with popart},
  author={Hessel, Matteo and Soyer, Hubert and Espeholt, Lasse and Czarnecki, Wojciech and Schmitt, Simon and van Hasselt, Hado},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  year={2019}
}

@inproceedings{riedmiller2018learning,
  title={Learning by playing solving sparse reward tasks from scratch},
  author={Riedmiller, Martin and Hafner, Roland and Lampe, Thomas and Neunert, Michael and Degrave, Jonas and Wiele, Tom and Mnih, Vlad and Heess, Nicolas and Springenberg, Jost Tobias},
  booktitle={International Conference on Machine Learning},
  pages={4344--4353},
  year={2018},
  organization={PMLR}
}

@article{teh2017distral,
  title={Distral: Robust multitask reinforcement learning},
  author={Teh, Yee Whye and Bapst, Victor and Czarnecki, Wojciech Marian and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  journal={arXiv preprint arXiv:1707.04175},
  year={2017}
}

@inproceedings{wilson2007multi,
  title={Multi-task reinforcement learning: a hierarchical bayesian approach},
  author={Wilson, Aaron and Fern, Alan and Ray, Soumya and Tadepalli, Prasad},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={1015--1022},
  year={2007}
}

@article{rusu2015policy,
  title={Policy distillation},
  author={Rusu, Andrei A and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
  journal={arXiv preprint arXiv:1511.06295},
  year={2015}
}

@article{ghosh2017divide,
  title={Divide-and-conquer reinforcement learning},
  author={Ghosh, Dibya and Singh, Avi and Rajeswaran, Aravind and Kumar, Vikash and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.09874},
  year={2017}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={arXiv preprint arXiv:2001.06782},
  year={2020}
}

@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={arXiv:2102.08363},
  year={2021}
}

@article{strehl2010learning,
  title={Learning from logged implicit exploration data},
  author={Strehl, Alex and Langford, John and Kakade, Sham and Li, Lihong},
  journal={arXiv preprint arXiv:1003.0120},
  year={2010}
}

@inproceedings{garcin2014offline,
  title={Offline and online evaluation of news recommender systems at swissinfo. ch},
  author={Garcin, Florent and Faltings, Boi and Donatsch, Olivier and Alazzawi, Ayar and Bruttin, Christophe and Huber, Amr},
  booktitle={Proceedings of the 8th ACM Conference on Recommender systems},
  pages={169--176},
  year={2014}
}

@article{charles2013counterfactual,
  title={Counterfactual reasoning and learning systems: The example of computational advertising},
  author={Charles, Denis and Chickering, Max and Simard, Patrice},
  journal={Journal of Machine Learning Research},
  volume={14},
  year={2013}
}

@inproceedings{theocharous2015ad,
  title={Ad recommendation systems for life-time value optimization},
  author={Theocharous, Georgios and Thomas, Philip S and Ghavamzadeh, Mohammad},
  booktitle={Proceedings of the 24th International Conference on World Wide Web},
  pages={1305--1310},
  year={2015}
}

@inproceedings{thomas2017predictive,
  title={Predictive Off-Policy Policy Evaluation for Nonstationary Decision Problems, with Applications to Digital Marketing.},
  author={Thomas, Philip S and Theocharous, Georgios and Ghavamzadeh, Mohammad and Durugkar, Ishan and Brunskill, Emma},
  booktitle={AAAI},
  pages={4740--4745},
  year={2017}
}

@article{schaul2019ray,
  title={Ray interference: a source of plateaus in deep reinforcement learning},
  author={Schaul, Tom and Borsa, Diana and Modayil, Joseph and Pascanu, Razvan},
  journal={arXiv preprint arXiv:1904.11455},
  year={2019}
}

@inproceedings{yu2020metaworld,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@article{sodhani2021multi,
  title={Multi-Task Reinforcement Learning with Context-based Representations},
  author={Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
  journal={arXiv preprint arXiv:2102.06177},
  year={2021}
}

@article{xu2020knowledge,
  title={Knowledge Transfer in Multi-Task Deep Reinforcement Learning for Continuous Control},
  author={Xu, Zhiyuan and Wu, Kun and Che, Zhengping and Tang, Jian and Ye, Jieping},
  year={2020}
}

@inproceedings{guez2008adaptive,
  title={Adaptive Treatment of Epilepsy via Batch-mode Reinforcement Learning.},
  author={Guez, Arthur and Vincent, Robert D and Avoli, Massimo and Pineau, Joelle},
  booktitle={AAAI},
  pages={1671--1678},
  year={2008}
}

@inproceedings{d2019sharing,
  title={Sharing knowledge in multi-task deep reinforcement learning},
  author={D'Eramo, Carlo and Tateo, Davide and Bonarini, Andrea and Restelli, Marcello and Peters, Jan},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{gulcehre2020rl,
  title={Rl unplugged: Benchmarks for offline reinforcement learning},
  author={Gulcehre, Caglar and Wang, Ziyu and Novikov, Alexander and Paine, Tom Le and Colmenarejo, Sergio G{\'o}mez and Zolna, Konrad and Agarwal, Rishabh and Merel, Josh and Mankowitz, Daniel and Paduraru, Cosmin and others},
  journal={arXiv preprint arXiv:2006.13888},
  year={2020}
}

@article{yang2020multi,
  title={Multi-task reinforcement learning with soft modularization},
  author={Yang, Ruihan and Xu, Huazhe and Wu, Yi and Wang, Xiaolong},
  journal={arXiv preprint arXiv:2003.13661},
  year={2020}
}

@article{tao2020repaint,
  title={REPAINT: Knowledge Transfer in Deep Reinforcement Learning},
  author={Tao, Yunzhe and Genc, Sahika and Chung, Jonathan and Sun, Tao and Mallya, Sunil},
  journal={arXiv preprint arXiv:2011.11827},
  year={2020}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@article{tian2020model,
  title={Model-Based Visual Planning with Self-Supervised Functional Distances},
  author={Tian, Stephen and Nair, Suraj and Ebert, Frederik and Dasari, Sudeep and Eysenbach, Benjamin and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2012.15373},
  year={2020}
}

@article{chebotar2021actionable,
  title={Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills},
  author={Chebotar, Yevgen and Hausman, Karol and Lu, Yao and Xiao, Ted and Kalashnikov, Dmitry and Varley, Jake and Irpan, Alex and Eysenbach, Benjamin and Julian, Ryan and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.07749},
  year={2021}
}

@article{sun2019policy,
  title={Policy continuation with hindsight inverse dynamics},
  author={Sun, Hao and Li, Zhizhong and Liu, Xiaotong and Lin, Dahua and Zhou, Bolei},
  journal={arXiv preprint arXiv:1910.14055},
  year={2019}
}

@article{pitis2020counterfactual,
  title={Counterfactual Data Augmentation using Locally Factored Dynamics},
  author={Pitis, Silviu and Creager, Elliot and Garg, Animesh},
  journal={arXiv preprint arXiv:2007.02863},
  year={2020}
}

@article{liu2019competitive,
  title={Competitive experience replay},
  author={Liu, Hao and Trott, Alexander and Socher, Richard and Xiong, Caiming},
  journal={arXiv preprint arXiv:1902.00528},
  year={2019}
}

@article{yang2021bias,
  title={Bias-reduced multi-step hindsight experience replay},
  author={Yang, Rui and Lyu, Jiafei and Yang, Yu and Ya, Jiangpeng and Luo, Feng and Luo, Dijun and Li, Lanqing and Li, Xiu},
  journal={arXiv preprint arXiv:2102.12962},
  year={2021}
}

@article{lynch2020grounding,
  title={Grounding language in play},
  author={Lynch, Corey and Sermanet, Pierre},
  journal={arXiv preprint arXiv:2005.07648},
  year={2020}
}

@article{lin2019reinforcement,
  title={Reinforcement learning without ground-truth state},
  author={Lin, Xingyu and Baweja, Harjatin Singh and Held, David},
  journal={arXiv preprint arXiv:1905.07866},
  year={2019}
}

@article{huang2019mapping,
  title={Mapping state space using landmarks for universal goal reaching},
  author={Huang, Zhiao and Liu, Fangchen and Su, Hao},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={1942--1952},
  year={2019}
}

@article{nair2018visual,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, Ashvin and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  journal={arXiv preprint arXiv:1807.04742},
  year={2018}
}

@inproceedings{xie2018few,
  title={Few-shot goal inference for visuomotor learning and planning},
  author={Xie, Annie and Singh, Avi and Levine, Sergey and Finn, Chelsea},
  booktitle={Conference on Robot Learning},
  pages={40--52},
  year={2018},
  organization={PMLR}
}

@article{chen2021learning,
  title={Learning Generalizable Robotic Reward Functions from" In-The-Wild" Human Videos},
  author={Chen, Annie S and Nair, Suraj and Finn, Chelsea},
  journal={arXiv preprint arXiv:2103.16817},
  year={2021}
}

@article{yang2021representation,
  title={Representation matters: Offline pretraining for sequential decision making},
  author={Yang, Mengjiao and Nachum, Ofir},
  journal={arXiv preprint arXiv:2102.05815},
  year={2021}
}

@article{li2019multi,
  title={Multi-task batch reinforcement learning with metric learning},
  author={Li, Jiachen and Vuong, Quan and Liu, Shuang and Liu, Minghua and Ciosek, Kamil and Ross, Keith and Christensen, Henrik Iskov and Su, Hao},
  journal={arXiv preprint arXiv:1909.11373},
  year={2019}
}

@article{killian2020empirical,
  title={An Empirical Study of Representation Learning for Reinforcement Learning in Healthcare},
  author={Killian, Taylor W and Zhang, Haoran and Subramanian, Jayakumar and Fatemi, Mehdi and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:2011.11235},
  year={2020}
}

@inproceedings{sharma2018multiple,
  title={Multiple interactions made easy (mime): Large scale demonstrations data for imitation},
  author={Sharma, Pratyusha and Mohan, Lekha and Pinto, Lerrel and Gupta, Abhinav},
  booktitle={Conference on robot learning},
  pages={906--915},
  year={2018},
  organization={PMLR}
}

@article{zhang2021method,
  title={A Method of Offline Reinforcement Learning Virtual Reality Satellite Attitude Control Based on Generative Adversarial Network},
  author={Zhang, Jian and Wu, Fengge},
  journal={Wireless Communications and Mobile Computing},
  volume={2021},
  year={2021},
  publisher={Hindawi}
}

@inproceedings{xiao2021general,
  title={A general offline reinforcement learning framework for interactive recommendation},
  author={Xiao, Teng and Wang, Donglin},
  booktitle={The Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021},
  year={2021}
}

@article{kiyohara2021accelerating,
  title={Accelerating Offline Reinforcement Learning Application in Real-Time Bidding and Recommendation: Potential Use of Simulation},
  author={Kiyohara, Haruka and Kawakami, Kosuke and Saito, Yuta},
  journal={arXiv preprint arXiv:2109.08331},
  year={2021}
}

@inproceedings{kreutzer2021offline,
  title={Offline Reinforcement Learning from Human Feedback in Real-World Sequence-to-Sequence Tasks},
  author={Kreutzer, Julia and Riezler, Stefan and Lawrence, Carolin},
  booktitle={Proceedings of the 5th Workshop on Structured Prediction for NLP (SPNLP 2021)},
  pages={37--43},
  year={2021}
}

@article{tang2021model,
  title={Model Selection for Offline Reinforcement Learning: Practical Considerations for Healthcare Settings},
  author={Tang, Shengpu and Wiens, Jenna},
  journal={arXiv preprint arXiv:2107.11003},
  year={2021}
}

@article{liu2021offline,
  title={Offline reinforcement learning with uncertainty for treatment strategies in sepsis},
  author={Liu, Ran and Greenstein, Joseph L and Fackler, James C and Bergmann, Jules and Bembea, Melania M and Winslow, Raimond L},
  journal={arXiv preprint arXiv:2107.04491},
  year={2021}
}

@article{apostolopoulos2021personalization,
  title={Personalization for Web-based Services using Offline Reinforcement Learning},
  author={Apostolopoulos, Pavlos Athanasios and Wang, Zehui and Wang, Hanson and Zhou, Chad and Virochsiri, Kittipat and Zhou, Norm and Markov, Igor L},
  journal={arXiv preprint arXiv:2102.05612},
  year={2021}
}

@article{de2021discovering,
  title={Discovering an Aid Policy to Minimize Student Evasion Using Offline Reinforcement Learning},
  author={de Lima, Leandro M and Krohling, Renato A},
  journal={arXiv preprint arXiv:2104.10258},
  year={2021}
}

@article{zhan2021deepthermal,
  title={DeepThermal: Combustion Optimization for Thermal Power Generating Units Using Offline Reinforcement Learning},
  author={Zhan, Xianyuan and Xu, Haoran and Zhang, Yue and Huo, Yusen and Zhu, Xiangyu and Yin, Honglei and Zheng, Yu},
  journal={arXiv preprint arXiv:2102.11492},
  year={2021}
}

@article{sinha2021s4rl,
  title={S4RL: Surprisingly Simple Self-Supervision for Offline Reinforcement Learning},
  author={Sinha, Samarth and Garg, Animesh},
  journal={arXiv preprint arXiv:2103.06326},
  year={2021}
}

@inproceedings{ghasemipour2021emaq,
  title={Emaq: Expected-max q-learning operator for simple yet effective offline and online rl},
  author={Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  booktitle={International Conference on Machine Learning},
  pages={3682--3691},
  year={2021},
  organization={PMLR}
}

@inproceedings{stooke2021decoupling,
  title={Decoupling representation learning from reinforcement learning},
  author={Stooke, Adam and Lee, Kimin and Abbeel, Pieter and Laskin, Michael},
  booktitle={International Conference on Machine Learning},
  pages={9870--9879},
  year={2021},
  organization={PMLR}
}

@article{sener2018multi,
  title={Multi-task learning as multi-objective optimization},
  author={Sener, Ozan and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1810.04650},
  year={2018}
}

@inproceedings{Ziebart2008MaximumEI,
  title={Maximum Entropy Inverse Reinforcement Learning},
  author={Brian D. Ziebart and Andrew L. Maas and J. Bagnell and A. Dey},
  booktitle={AAAI},
  year={2008}
}

@article{gangwani2019learning,
      title={Learning Belief Representations for Imitation Learning in POMDPs}, 
      author={Tanmay Gangwani and Joel Lehman and Qiang Liu and Jian Peng},
      year={2020},
      journal = {Conference on Uncertainty in Artificial Intelligence}
}

@article{baram2016modelbased,
      title={Model-based Adversarial Imitation Learning}, 
      author={Nir Baram and Oron Anschel and Shie Mannor},
      year={2016},
      journal = {Conference on Neural Information Processing Systems}

}

@article{sun2021attention,
      title={Adversarial Inverse Reinforcement Learning with
Self-attention Dynamics Model}, 
      author={Jiankai Sun and Lantao Yu and Pinqian Dong and Bo Lu and Bolei Zhou},
      year={2021},
      journal = {IEEE Robotics and Automation Letters}

}


@article{gelada2019deepmdp,
      title={DeepMDP: Learning Continuous Latent Space Models for Representation Learning}, 
      author={Carles Gelada and Saurabh Kumar and Jacob Buckman and Ofir Nachum and Marc G. Bellemare},
      year={2019},
      journal = { International Conference on Machine Learning}

}

@article{hafner2020dream,
      title={Dream to Control: Learning Behaviors by Latent Imagination}, 
      author={Danijar Hafner and Timothy Lillicrap and Jimmy Ba and Mohammad Norouzi},
      year={2020},
      journal = {International Conference on Learning Representations},

}

@inproceedings{finn2016deep,
  title={Deep spatial autoencoders for visuomotor learning},
  author={Finn, Chelsea and Tan, Xin Yu and Duan, Yan and Darrell, Trevor and Levine, Sergey and Abbeel, Pieter},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={512--519},
  year={2016},
  organization={IEEE}
}

@article{hafner2019learning,
      title={Learning Latent Dynamics for Planning from Pixels}, 
      author={Danijar Hafner and Timothy Lillicrap and Ian Fischer and Ruben Villegas and David Ha and Honglak Lee and James Davidson},
      year={2019},
      journal = { International Conference on Machine Learning}
}

@article{lee2020stochastic,
      title={Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model}, 
      author={Alex X. Lee and Anusha Nagabandi and Pieter Abbeel and Sergey Levine},
      year={2020},
      journal = {Conference on Neural Information Processing Systems}
      }

@article{karl2017deep,
      title={Deep Variational Bayes Filters: Unsupervised Learning of State Space Models from Raw Data}, 
      author={Maximilian Karl and Maximilian Soelch and Justin Bayer and Patrick van der Smagt},
      year={2017},
      journal = { International Conference on Machine Learning}
}

@article{zhang2019solar,
      title={SOLAR: Deep Structured Representations for Model-Based Reinforcement Learning}, 
      author={Marvin Zhang and Sharad Vikram and Laura Smith and Pieter Abbeel and Matthew J. Johnson and Sergey Levine},
      year={2019},
      journal = { International Conference on Machine Learning}
}

@miarticlesc{watter2015embed,
      title={Embed to Control: A Locally Linear Latent Dynamics Model for Control from Raw Images}, 
      author={Manuel Watter and Jost Tobias Springenberg and Joschka Boedecker and Martin Riedmiller},
      year={2015},
      journal = {Conference on Neural Information Processing Systems}
}

@article{zolna2020taskrelevant,
      title={Task-Relevant Adversarial Imitation Learning}, 
      author={Konrad Zolna and Scott Reed and Alexander Novikov and Sergio Gomez Colmenarejo and David Budden and Serkan Cabi and Misha Denil and Nando de Freitas and Ziyu Wang},
      year={2020},
      journal = {Conference on Robot Learning},
}


@article{visual2018reed,
author = {Scott Reed and Yusuf Aytar and Ziyu Wang and Tom Paine and Aaron van den Oord and Tobias Pfaff and Sergio Gomez and Alexander Novikov and David Budden and Oriol Vinyals},
journal = {DeepMind Technical Report},
title = {Visual Imitation with a Minimal Adversary},
year = {2018}
}



@article{Hinton06,
author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee Whye},
journal = {Neural Computation},
pages = {1527--1554},
title = {A Fast Learning Algorithm for Deep Belief Nets},
volume = {18},
year = {2006}
}

@inproceedings{pomerleau1988alvinn,
  title={ALVINN: an autonomous land vehicle in a neural network},
  author={Pomerleau, Dean A},
  booktitle={Proceedings of the 1st International Conference on Neural Information Processing Systems},
  pages={305--313},
  year={1988}
}

@inproceedings{finn2016guided,
  title={Guided cost learning: Deep inverse optimal control via policy optimization},
  author={Finn, Chelsea and Levine, Sergey and Abbeel, Pieter},
  booktitle={International conference on machine learning},
  pages={49--58},
  year={2016},
  organization={PMLR}
}

@article{MGAIL2016Baram,
author = {Nir Baram and Oron Anschel and Shie Mannor},
journal = {Conference on Neural Information Processing Systems },
title = {Model-based Adversarial Imitation Learning},
year = {2016}
}

@article{CI2018Levine,
author = {Sergey Levine},
journal = {ArXiv Preprint},
title = {Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review},
year = {2018}
}


@article{SLAC20202Lee,
author = {Alex X. Lee and Anusha Nagabandi and Pieter Abbeel and Sergey Levine},
journal = {Conference on Neural Information Processing Systems},
title = {Stochastic Latent Actor-Critic: Deep Reinforcement
Learning with a Latent Variable Model},
year = {2020}
}

@article{PlanNet2019Hafner,
author = {Danijar Hafner and Timothy Lillicrap and Ian Fischer and Ruben Villegas and David Ha and Honglak Lee and James Davidson},
journal = {International Conference on Machine
Learning},
title = {Learning Latent Dynamics for Planning from Pixels},
year = {2019}
}


@article{Dreamer2020Hafner,
author = {Danijar Hafner and Timothy Lillicrap and Jimmy Ba and Mohammad Norouzi},
journal = {International Conference on Learning Representations},
title = {Dream to Control: Learning Behaviors by Latent Imagination},
year = {2020}
}



@article{VICEFu2018,
author = {Justin Fu and Avi Singh and Dibya Ghosh and Larry Yang and Sergey Levine},
journal = {Conference on Neural Information Processing Systems},
title = {Variational Inverse Control with Events: A General
Framework for Data-Driven Reward Definition},
year = {2018}
}

@article{AIRLFu2018,
author = {Justin Fu and Katie Luo and Sergey Levine},
journal = {International Conference on Learning Representations},
title = {Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
year = {2018}
}

@article{LS2019Muller,
author = {Rafael Müller and Simon Kornblith and Geoffrey Hinton},
journal = {Conference on Neural Information Processing Systems},
title = {When Does Label Smoothing Help?},
year = {2019}
}

@article{rafailov2020offline,
  title={Offline Reinforcement Learning from Images with Latent Space Models},
  author={Rafailov, Rafael and Yu, Tianhe and Rajeswaran, Aravind and Finn, Chelsea},
  journal={arXiv preprint arXiv:2012.11547},
  year={2020}
}

@article{ValueDICE2019Kostrikov,
author = {Ilya Kostrikov and Ofir Nachum and Jonathan Tompson},
journal = {International Conference on Learning Representations},
title = {Imitation Learning via Off-Policy Distribution Matching},
year = {2020}
}

@article{SQIL2020Reddy,
author = {Siddharth Reddy and Anca D. Dragan and Sergey Levine},
journal = {International Conference on Learning Representations},
title = {SQIL: Imitation Learning via Reinforcement Learning with Sparse Rewards},
year = {2020}
}


@article{SAM2019Blonde,
author = {Lionel Blondé and Alexandros Kalousis},
journal = {AISTATS},
title = {Sample-Efficient Imitation Learning via Generative Adversarial Nets
},
year = {2019}
}



@article{DAC2019Kostrikov,
author = {Ilya Kostrikov and Kumar Krishna Agrawal and Debidatta Dwibedi and Sergey Levine and Jonathan Tompson},
journal = {International Conference on Learning Representations},
title = {Discriminator-Actor-Critic: Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning},
year = {2019}
}

@article{Feedback2021Spencer,
author = {Jonathan Spencer and Sanjiban Choudhury and Arun Venkatraman and Brian Ziebart and J. Andrew Bagnell},
journal = {ArXiv Preprint},
title = {Feedback in Imitation Learning: The Three Regimes of Covariate Shift},
year = {2021}
}



@article{Dagger2011Ross,
author = {Stephane Ross and Geoffrey J. Gordon and J. Andrew Bagnell},
journal = {AISTATS},
title = {A Reduction of Imitation Learning and Structured Prediction to No-Regret Online Learning},
year = {2011}
}




@article{GAIL2016Ho,
author = {Jonathan Ho and Stefano Ermon},
journal = {Conference on Neural Information Processing Systems},
title = {Generative Adversarial Imitation Learning},
year = {2016}
}


@article{GAIL201Finn,
author = {Chelsea Finn and Paul Christiano and Pieter Abbeel and Sergey Levine},
journal = {ArXiv Preprint},
title = {A connection between generative adversarial
networks, inverse reinforcement learning, and energy-based models},
year = {2016}
}







@article{DIV2019Sayed,
author = {Seyed Kamyar Seyed Ghasemipour and Richard Zemel and Shixiang Gu},
journal = {Conference on Robot Learning},
title = {A Divergence Minimization Perspective on Imitation Learning Methods},
year = {2019}
}


@article{Ke2019ImitationLA,
  title={Imitation Learning as f-Divergence Minimization},
  author={Liyiming Ke and Matt Barnes and W. Sun and Gilwoo Lee and Sanjiban Choudhury and S. Srinivasa},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.12888}
}






@misc{mnih2013playing,
      title={Playing Atari with Deep Reinforcement Learning}, 
      author={Volodymyr Mnih and Koray Kavukcuoglu and David Silver and Alex Graves and Ioannis Antonoglou and Daan Wierstra and Martin Riedmiller},
      year={2013},
      eprint={1312.5602},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{tassa2018deepmind,
      title={DeepMind Control Suite}, 
      author={Yuval Tassa and Yotam Doron and Alistair Muldal and Tom Erez and Yazhe Li and Diego de Las Casas and David Budden and Abbas Abdolmaleki and Josh Merel and Andrew Lefrancq and Timothy Lillicrap and Martin Riedmiller},
      year={2018},
      eprint={1801.00690},
      archivePrefix={arXiv},
      primaryClass={cs.AI}
}



@INPROCEEDINGS{Rajeswaran-RSS-18,
    AUTHOR    = {Aravind Rajeswaran AND Vikash Kumar AND Abhishek Gupta AND
                 Giulia Vezzani AND John Schulman AND Emanuel Todorov AND Sergey Levine},
    TITLE     = "{Learning Complex Dexterous Manipulation with Deep Reinforcement Learning and Demonstrations}",
    BOOKTITLE = {Proceedings of Robotics: Science and Systems (RSS)},
    YEAR      = {2018},
}


@inproceedings{RajeswaranGameMBRL,
	title        = {{A Game Theoretic Framework for Model-Based Reinforcement Learning}},
	author       = {Aravind Rajeswaran AND Igor Mordatch AND Vikash Kumar},
	year         = 2020,
	booktitle    = {{ICML}},
}


@article{pddm2019Nagabandi,
author = {Anusha Nagabandi and Kurt Konolige and Sergey Levine and Vikash Kumar},
journal = {Conference on Robot Learning},
title = {Deep Dynamics Models
for Learning Dexterous Manipulation},
year = {2019}
}


@misc{blonde2020lipschitzness,
      title={Lipschitzness Is All You Need To Tame Off-policy Generative Adversarial Imitation Learning}, 
      author={Lionel Blondé and Pablo Strasser and Alexandros Kalousis},
      year={2020},
      eprint={2006.16785},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@book{goodfellow2016deep,
title={Deep learning},
author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron and Bengio, Yoshua},
volume={1},
year={2016},
publisher={MIT Press}
}

@misc{gelada2019deepmdp,
      title={DeepMDP: Learning Continuous Latent Space Models for Representation Learning}, 
      author={Carles Gelada and Saurabh Kumar and Jacob Buckman and Ofir Nachum and Marc G. Bellemare},
journal = {International conference on machine learning},
title = {DeepMDP: Learning Continuous Latent Space Models for Representation Learning},
year = {2019}
}

@article{Amodei2016ConcretePI,
  title={Concrete Problems in AI Safety},
  author={Dario Amodei and Chris Olah and J. Steinhardt and Paul F. Christiano and John Schulman and Dan Man{\'e}},
  journal={ArXiv},
  year={2016},
  volume={abs/1606.06565},
}

@article{Everitt2019RewardTP,
  title={Reward Tampering Problems and Solutions in Reinforcement Learning: A Causal Influence Diagram Perspective},
  author={Tom Everitt and Marcus Hutter},
  journal={ArXiv},
  year={2019},
  volume={abs/1908.04734}
}

@inproceedings{Goodfellow2014GenerativeAN,
  title={Generative Adversarial Nets},
  author={Ian J. Goodfellow and Jean Pouget-Abadie and M. Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron C. Courville and Yoshua Bengio},
  booktitle={NIPS},
  year={2014}
}

@inproceedings{Ziebart2008MaximumEI,
  title={Maximum Entropy Inverse Reinforcement Learning},
  author={Brian D. Ziebart and Andrew L. Maas and J. Bagnell and A. Dey},
  booktitle={AAAI},
  year={2008}
}

@article{Portelas2020AutomaticCL,
  title={Automatic Curriculum Learning For Deep RL: A Short Survey},
  author={R{\'e}my Portelas and C{\'e}dric Colas and Lilian Weng and Katja Hofmann and Pierre-Yves Oudeyer},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.04664}
}

@article{Khetarpal2020TowardsCR,
  title={Towards Continual Reinforcement Learning: A Review and Perspectives},
  author={Khimya Khetarpal and Matthew Riemer and I. Rish and Doina Precup},
  journal={ArXiv},
  year={2020},
  volume={abs/2012.13490}
}

@inproceedings{Lowe2017MultiAgentAF,
  title={Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments},
  author={Ryan Lowe and Yi Wu and Aviv Tamar and Jean Harb and P. Abbeel and Igor Mordatch},
  booktitle={NIPS},
  year={2017}
}

@article{Blei2016VariationalIA,
  title={Variational Inference: A Review for Statisticians},
  author={David M. Blei and A. Kucukelbir and Jon D. McAuliffe},
  journal={Journal of the American Statistical Association},
  year={2016},
  volume={112},
  pages={859 - 877}
}

@article{eysenbach2020c,
  title={C-Learning: Learning to Achieve Goals via Recursive Classification},
  author={Eysenbach, Benjamin and Salakhutdinov, Ruslan and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.08909},
  year={2020}
}

@inproceedings{zeng2018learning,
  title={Learning synergies between pushing and grasping with self-supervised deep reinforcement learning},
  author={Zeng, Andy and Song, Shuran and Welker, Stefan and Lee, Johnny and Rodriguez, Alberto and Funkhouser, Thomas},
  booktitle={2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={4238--4245},
  year={2018},
  organization={IEEE}
}

@article{andrychowicz2020learning,
  title={Learning dexterous in-hand manipulation},
  author={Andrychowicz, OpenAI: Marcin and Baker, Bowen and Chociej, Maciek and Jozefowicz, Rafal and McGrew, Bob and Pachocki, Jakub and Petron, Arthur and Plappert, Matthias and Powell, Glenn and Ray, Alex and others},
  journal={The International Journal of Robotics Research},
  volume={39},
  number={1},
  pages={3--20},
  year={2020},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{van2015learning,
  title={Learning robot in-hand manipulation with tactile features},
  author={Van Hoof, Herke and Hermans, Tucker and Neumann, Gerhard and Peters, Jan},
  booktitle={2015 IEEE-RAS 15th International Conference on Humanoid Robots (Humanoids)},
  pages={121--127},
  year={2015},
  organization={IEEE}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@article{kumar2016learning,
  title={Learning dexterous manipulation policies from experience and imitation},
  author={Kumar, Vikash and Gupta, Abhishek and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.05095},
  year={2016}
}

@inproceedings{schenck2017visual,
  title={Visual closed-loop control for pouring liquids},
  author={Schenck, Connor and Fox, Dieter},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2629--2636},
  year={2017},
  organization={IEEE}
}

@inproceedings{yahya2017collective,
  title={Collective robot reinforcement learning with distributed asynchronous guided policy search},
  author={Yahya, Ali and Li, Adrian and Kalakrishnan, Mrinal and Chebotar, Yevgen and Levine, Sergey},
  booktitle={2017 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={79--86},
  year={2017},
  organization={IEEE}
}

@inproceedings{matas2018sim,
  title={Sim-to-real reinforcement learning for deformable object manipulation},
  author={Matas, Jan and James, Stephen and Davison, Andrew J},
  booktitle={Conference on Robot Learning},
  pages={734--743},
  year={2018},
  organization={PMLR}
}

@article{singh2019end,
  title={End-to-end robotic reinforcement learning without reward engineering},
  author={Singh, Avi and Yang, Larry and Hartikainen, Kristian and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:1904.07854},
  year={2019}
}

@article{julian2020efficient,
  title={Efficient Adaptation for End-to-End Vision-Based Robotic Manipulation},
  author={Julian, Ryan and Swanson, Benjamin and Sukhatme, Gaurav S and Levine, Sergey and Finn, Chelsea and Hausman, Karol},
  journal={arXiv preprint arXiv:2004.10190},
  year={2020}
}

@article{cabi2019framework,
  title={A framework for data-driven robotics},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and Zo{\l}na, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

@inproceedings{kappler2015leveraging,
  title={Leveraging big data for grasp planning},
  author={Kappler, Daniel and Bohg, Jeannette and Schaal, Stefan},
  booktitle={2015 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4304--4311},
  year={2015},
  organization={IEEE}
}

@inproceedings{pinto2016supersizing,
  title={Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours},
  author={Pinto, Lerrel and Gupta, Abhinav},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={3406--3413},
  year={2016},
  organization={IEEE}
}

@article{levine2018learning,
  title={Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection},
  author={Levine, Sergey and Pastor, Peter and Krizhevsky, Alex and Ibarz, Julian and Quillen, Deirdre},
  journal={The International Journal of Robotics Research},
  volume={37},
  number={4-5},
  pages={421--436},
  year={2018},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{gupta2018robot,
  title={Robot learning in homes: Improving generalization and reducing dataset bias},
  author={Gupta, Abhinav and Murali, Adithyavairavan and Gandhi, Dhiraj and Pinto, Lerrel},
  journal={arXiv preprint arXiv:1807.07049},
  year={2018}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}


@article{mandlekar2020learning,
  title={Learning to generalize across long-horizon tasks from human demonstrations},
  author={Mandlekar, Ajay and Xu, Danfei and Mart{\'\i}n-Mart{\'\i}n, Roberto and Savarese, Silvio and Fei-Fei, Li},
  journal={arXiv preprint arXiv:2003.06085},
  year={2020}
}

@article{torabi2018generative,
  title={Generative adversarial imitation from observation},
  author={Torabi, Faraz and Warnell, Garrett and Stone, Peter},
  journal={arXiv preprint arXiv:1807.06158},
  year={2018}
}

@article{cabi2019scaling,
  title={Scaling data-driven robotics with reward sketching and batch reinforcement learning},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and Zolna, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

@article{zolna2020offline,
  title={Offline Learning from Demonstrations and Unlabeled Experience},
  author={Zolna, Konrad and Novikov, Alexander and Konyushkova, Ksenia and Gulcehre, Caglar and Wang, Ziyu and Aytar, Yusuf and Denil, Misha and de Freitas, Nando and Reed, Scott},
  journal={arXiv preprint arXiv:2011.13885},
  year={2020}
}

@article{zhu2020ingredients,
  title={The ingredients of real-world robotic reinforcement learning},
  author={Zhu, Henry and Yu, Justin and Gupta, Abhishek and Shah, Dhruv and Hartikainen, Kristian and Singh, Avi and Kumar, Vikash and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.12570},
  year={2020}
}

@inproceedings{ng2000irl,
 author={Ng, Andrew Y. and Russell, Stuart J.},
 title={Algorithms for Inverse Reinforcement Learning},
 booktitle={Proceedings of the Seventeenth International Conference on Machine Learning},
 series={ICML '00},
 year={2000}
} 

@inproceedings{ratliff2006,
 author = {Ratliff, Nathan D. and Bagnell, J. Andrew and Zinkevich, Martin A.},
 title = {Maximum Margin Planning},
 booktitle = {Proceedings of the 23rd International Conference on Machine Learning},
 series = {ICML '06},
 year = {2006}
} 

@inproceedings{ramachandran2007bayesianirl,
 author = {Ramachandran, Deepak and Amir, Eyal},
 title = {Bayesian Inverse Reinforcement Learning},
 booktitle = {Proceedings of the 20th International Joint Conference on Artifical Intelligence},
 series = {IJCAI'07},
 year = {2007}
} 

@inproceedings{ziebart2008maximum,
  title={Maximum entropy inverse reinforcement learning.},
  author={Ziebart, Brian D and Maas, Andrew L and Bagnell, J Andrew and Dey, Anind K},
  booktitle={Aaai},
  volume={8},
  pages={1433--1438},
  year={2008},
  organization={Chicago, IL, USA}
}

@INPROCEEDINGS{abbeel2004apprenticeship,
    author = "Abbeel, Pieter and Ng, Andrew Y",
    title = "Apprenticeship learning via inverse reinforcement learning",
    booktitle = "Proceedings of the twenty-first international conference on Machine learning",
    pages = "1",
    institution = "ACM",
    year = "2004"
}

@inproceedings{jin2021pessimism,
  title={Is Pessimism Provably Efficient for Offline RL?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  booktitle={International Conference on Machine Learning},
  pages={5084--5096},
  year={2021},
  organization={PMLR}
}

@article{rashidinejad2021bridging,
  title={Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
  author={Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
  journal={arXiv preprint arXiv:2103.12021},
  year={2021}
}

@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{yang2021trail,
  title={TRAIL: Near-Optimal Imitation Learning with Suboptimal Data},
  author={Yang, Mengjiao and Levine, Sergey and Nachum, Ofir},
  journal={arXiv preprint arXiv:2110.14770},
  year={2021}
}


@inproceedings{mitchell2021offline,
  title={Offline meta-reinforcement learning with advantage weighting},
  author={Mitchell, Eric and Rafailov, Rafael and Peng, Xue Bin and Levine, Sergey and Finn, Chelsea},
  booktitle={International Conference on Machine Learning},
  pages={7780--7791},
  year={2021},
  organization={PMLR}
}

@article{dorfman2021offline,
  title={Offline Meta Reinforcement Learning--Identifiability Challenges and Effective Data Collection Strategies},
  author={Dorfman, Ron and Shenfeld, Idan and Tamar, Aviv},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{laskin2020reinforcement,
  title={Reinforcement Learning with Augmented Data},
  author={Laskin, Michael and Lee, Kimin and Stooke, Adam and Pinto, Lerrel and Abbeel, Pieter and Srinivas, Aravind},
  journal={arXiv preprint arXiv:2004.14990},
  year={2020}
}

@article{srinivas2020curl,
  title={Curl: Contrastive unsupervised representations for reinforcement learning},
  author={Srinivas, Aravind and Laskin, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2004.04136},
  year={2020}
}

@article{yarats2019improving,
  title={Improving sample efficiency in model-free reinforcement learning from images},
  author={Yarats, Denis and Zhang, Amy and Kostrikov, Ilya and Amos, Brandon and Pineau, Joelle and Fergus, Rob},
  journal={arXiv preprint arXiv:1910.01741},
  year={2019}
}

@article{Blei2016VariationalIA,
  title={Variational Inference: A Review for Statisticians},
  author={D. Blei and A. Kucukelbir and J. McAuliffe},
  journal={Journal of the American Statistical Association},
  year={2016},
  volume={112},
  pages={859 - 877}
}

@article{nair2022r3m,
  title={R3m: A universal visual representation for robot manipulation},
  author={Nair, Suraj and Rajeswaran, Aravind and Kumar, Vikash and Finn, Chelsea and Gupta, Abhinav},
  journal={arXiv preprint arXiv:2203.12601},
  year={2022}
}

@article{parisi2022unsurprising,
  title={The unsurprising effectiveness of pre-trained vision models for control},
  author={Parisi, Simone and Rajeswaran, Aravind and Purushwalkam, Senthil and Gupta, Abhinav},
  journal={arXiv preprint arXiv:2203.03580},
  year={2022}
}

@article{xiao2022masked,
  title={Masked visual pre-training for motor control},
  author={Xiao, Tete and Radosavovic, Ilija and Darrell, Trevor and Malik, Jitendra},
  journal={arXiv preprint arXiv:2203.06173},
}

@inproceedings{tan2019efficientnet,
  title={Efficientnet: Rethinking model scaling for convolutional neural networks},
  author={Tan, Mingxing and Le, Quoc},
  booktitle={International conference on machine learning},
  pages={6105--6114},
  year={2019},
  organization={PMLR}
}

@article{castro2018dopamine,
  title={Dopamine: A research framework for deep reinforcement learning},
  author={Castro, Pablo Samuel and Moitra, Subhodeep and Gelada, Carles and Kumar, Saurabh and Bellemare, Marc G},
  journal={arXiv preprint arXiv:1812.06110},
  year={2018}
}


% This file was created with JabRef 2.10.
% Encoding: UTF-8


@Article{Gauss1857,
  Title                    = {Theory of the motion of the heavenly bodies moving about the sun in conic sections},
  Author                   = {Carl Friedrich Gauss and Charles Henry Davis},
  Journal                  = {Gauss's Theoria Motus},
  Year                     = {1857},
  Number                   = {1},
  Pages                    = {5--23},
  Volume                   = {76}
}

@ARTICLE{2021arXiv210105982C,
       author = {{Chen}, Xinyue and {Wang}, Che and {Zhou}, Zijian and {Ross}, Keith},
        title = "{Randomized Ensembled Double Q-Learning: Learning Fast Without a Model}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
         year = 2021,
        month = jan,
          eid = {arXiv:2101.05982},
        pages = {arXiv:2101.05982},
          doi = {10.48550/arXiv.2101.05982},
archivePrefix = {arXiv},
       eprint = {2101.05982},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2021arXiv210105982C},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}



@inproceedings{xu2022prompting,
  title={Prompting decision transformer for few-shot policy generalization},
  author={Xu, Mengdi and Shen, Yikang and Zhang, Shun and Lu, Yuchen and Zhao, Ding and Tenenbaum, Joshua and Gan, Chuang},
  booktitle={International Conference on Machine Learning},
  pages={24631--24645},
  year={2022},
  organization={PMLR}
}

@ARTICLE{2020arXiv200806043M,
       author = {{Mitchell}, Eric and {Rafailov}, Rafael and {Peng}, Xue Bin and {Levine}, Sergey and {Finn}, Chelsea},
        title = "{Offline Meta-Reinforcement Learning with Advantage Weighting}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Statistics - Machine Learning},
         year = 2020,
        month = aug,
          eid = {arXiv:2008.06043},
        pages = {arXiv:2008.06043},
archivePrefix = {arXiv},
       eprint = {2008.06043},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2020arXiv200806043M},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{shafiullah2022behavior,
  title={Behavior Transformers: Cloning $ k $ modes with one stone},
  author={Shafiullah, Nur Muhammad Mahi and Cui, Zichen Jeff and Altanzaya, Ariuntuya and Pinto, Lerrel},
  journal={arXiv preprint arXiv:2206.11251},
  year={2022}
}

@article{eysenbach2021replacing,
  title={Replacing rewards with examples: Example-based policy search via recursive classification},
  author={Eysenbach, Ben and Levine, Sergey and Salakhutdinov, Russ R},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  pages={11541--11552},
  year={2021}
}

@article{he2111masked,
  title={Masked autoencoders are scalable vision learners. arXiv. 2021 doi: 10.48550},
  author={He, K and Chen, X and Xie, S and Li, Y and Doll{\'a}r, P and Girshick, RB},
  journal={arXiv preprint arXiv.2111.06377},
  year={2021},
}


@article{ebert2021bridge,
  title={Bridge Data: Boosting Generalization of Robotic Skills with Cross-Domain Datasets},
  author={Ebert, Frederik and Yang, Yanlai and Schmeckpeper, Karl and Bucher, Bernadette and Georgakis, Georgios and Daniilidis, Kostas and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2109.13396},
  year={2021}
}

@article{nair2022r3m,
  title={R3M: A Universal Visual Representation for Robot Manipulation},
  author={Nair, Suraj and Rajeswaran, Aravind and Kumar, Vikash and Finn, Chelsea and Gupta, Abhinav},
  journal={arXiv preprint arXiv:2203.12601},
  year={2022}
}


@inproceedings{shridhar2022cliport,
  title={Cliport: What and where pathways for robotic manipulation},
  author={Shridhar, Mohit and Manuelli, Lucas and Fox, Dieter},
  booktitle={Conference on Robot Learning},
  pages={894--906},
  year={2022},
  organization={PMLR}
}

@inproceedings{kober2009learning,
  title={Learning motor primitives for robotics},
  author={Kober, Jens and Peters, Jan},
  booktitle={2009 IEEE International Conference on Robotics and Automation},
  pages={2112--2118},
  year={2009},
  organization={IEEE}
}

@inproceedings{chebotar2017combining,
  title={Combining model-based and model-free updates for trajectory-centric reinforcement learning},
  author={Chebotar, Yevgen and Hausman, Karol and Zhang, Marvin and Sukhatme, Gaurav and Schaal, Stefan and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={703--711},
  year={2017},
  organization={PMLR}
}

@article{hafner2019dream,
  title={Dream to control: Learning behaviors by latent imagination},
  author={Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1912.01603},
  year={2019}
}

@article{wang2019exploring,
  title={Exploring model-based planning with policy networks},
  author={Wang, Tingwu and Ba, Jimmy},
  journal={arXiv preprint arXiv:1906.08649},
  year={2019}
}

@inproceedings{ramesh2021zero,
  title={Zero-shot text-to-image generation},
  author={Ramesh, Aditya and Pavlov, Mikhail and Goh, Gabriel and Gray, Scott and Voss, Chelsea and Radford, Alec and Chen, Mark and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={8821--8831},
  year={2021},
  organization={PMLR}
}

@STRING{aistats = {AISTATS}}
@STRING{cvpr = {CVPR}}
@STRING{emnlp = {EMNLP}}
@STRING{focs = {FOCS}}
@STRING{iccv = {ICCV}}
@STRING{icdr = {ICDR}}
@STRING{icml = {ICML}}
@STRING{ijcv = {IJCV}}
@STRING{jmlr = {JMLR}}
@STRING{nc = {Neural Comput.}}
@STRING{nips = {NeurIPS}}
@STRING{pami = {IEEE Trans. PAMI}}
@STRING{sigir = {SIGIR}}
@STRING{stoc = {STOC}}
@STRING{socg = {SoCG}}
@STRING{uai = {UAI}}
@STRING{vissapp = {VISSAPP}}
@STRING{eccv = {ECCV}}
@STRING{acl = {ACL}}
@STRING{iclr = {ICLR}}
@STRING{icassp = {ICASSP}}
@STRING{asru = {ASRU}}
@STRING{machlearning = {Mach. Learn. J.}}
@STRING{aaai = {AAAI}}
@STRING{naacl = {NAACL}}
@STRING{iros = {IROS}}
@STRING{tacl = {TACL}}
@STRING{corl = {CoRL}}
@STRING{ijcai = {IJCAI}}
@STRING{aamas = {AAMAS}}

@article{chen2021decision,
  title={Decision transformer: Reinforcement learning via sequence modeling},
  author={Chen, Lili and Lu, Kevin and Rajeswaran, Aravind and Lee, Kimin and Grover, Aditya and Laskin, Michael and Abbeel, Pieter and Srinivas, Aravind and Mordatch, Igor},
  journal={arXiv preprint arXiv:2106.01345},
  year={2021}
}

@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}

@inproceedings{arjovsky2017wasserstein,
  title={Wasserstein generative adversarial networks},
  author={Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'e}on},
  booktitle={International conference on machine learning},
  pages={214--223},
  year={2017},
  organization={PMLR}
}

@article{gupta2018robot,
  title={Robot learning in homes: Improving generalization and reducing dataset bias},
  author={Gupta, Abhinav and Murali, Adithyavairavan and Gandhi, Dhiraj Prakashchand and Pinto, Lerrel},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@article{reed2022generalist,
  title={A generalist agent},
  author={Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and others},
  journal={arXiv preprint arXiv:2205.06175},
  year={2022}
}

@inproceedings{dasari2020robonet,
  title={RoboNet: Large-Scale Multi-Robot Learning},
  author={Dasari, Sudeep and Ebert, Frederik and Tian, Stephen and Nair, Suraj and Bucher, Bernadette and Schmeckpeper, Karl and Singh, Siddharth and Levine, Sergey and Finn, Chelsea},
  booktitle={Conference on Robot Learning},
  pages={885--897},
  year={2020},
  organization={PMLR}
}

@inproceedings{wu2021greedy,
  title={Greedy hierarchical variational autoencoders for large-scale video prediction},
  author={Wu, Bohan and Nair, Suraj and Martin-Martin, Roberto and Fei-Fei, Li and Finn, Chelsea},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2318--2328},
  year={2021}
}

@article{xie2021lifelong,
  title={Lifelong robotic reinforcement learning by retaining experiences},
  author={Xie, Annie and Finn, Chelsea},
  journal={arXiv preprint arXiv:2109.09180},
  year={2021}
}

@inproceedings{
mandlekar2021what,
title={What Matters in Learning from Offline Human Demonstrations for Robot Manipulation},
author={Ajay Mandlekar and Danfei Xu and Josiah Wong and Soroush Nasiriany and Chen Wang and Rohun Kulkarni and Fei-Fei Li and Silvio Savarese and Yuke Zhu and Roberto Mart{\'\i}n-Mart{\'\i}n},
booktitle={5th Annual Conference on Robot Learning },
year={2021},
url={https://openreview.net/forum?id=JrsfBJtDFdI}
}

@article{lin2022model,
  title={Model-Based Offline Meta-Reinforcement Learning with Regularization},
  author={Lin, Sen and Wan, Jialin and Xu, Tengyu and Liang, Yingbin and Zhang, Junshan},
  journal={arXiv preprint arXiv:2202.02929},
  year={2022}
}

@article{rashidinejad2021bridging,
  title={Bridging offline reinforcement learning and imitation learning: A tale of pessimism},
  author={Rashidinejad, Paria and Zhu, Banghua and Ma, Cong and Jiao, Jiantao and Russell, Stuart},
  journal={arXiv preprint arXiv:2103.12021},
  year={2021}
}

@inproceedings{ettinger2021large,
  title={Large scale interactive motion forecasting for autonomous driving: The waymo open motion dataset},
  author={Ettinger, Scott and Cheng, Shuyang and Caine, Benjamin and Liu, Chenxi and Zhao, Hang and Pradhan, Sabeek and Chai, Yuning and Sapp, Ben and Qi, Charles R and Zhou, Yin and others},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={9710--9719},
  year={2021}
}

@article{Rafailov2020LOMPO,
  title={Offline Reinforcement Learning from Images with Latent Space Models},
  author={Rafael Rafailov and Tianhe Yu and A. Rajeswaran and Chelsea Finn},
  journal={Learning for Decision Making and Control (L4DC)},
  year={2021},
}

@article{argenson2020model,
  title={Model-Based Offline Planning},
  author={Argenson, Arthur and Dulac-Arnold, Gabriel},
  journal={arXiv preprint arXiv:2008.05556},
  year={2020}
}

@article{brandfonbrener2021offline,
  title={Offline RL Without Off-Policy Evaluation},
  author={Brandfonbrener, David and Whitney, William F and Ranganath, Rajesh and Bruna, Joan},
  journal={arXiv preprint arXiv:2106.08909},
  year={2021}
}

@article{ho2021retinagan,
  title={Retinagan: An object-aware approach to sim-to-real transfer},
  author={Ho, Daniel and Rao, Kanishka and Xu, Zhuo and Jang, Eric and Khansari, Mohi and Bai, Yunfei},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={10920--10926},
  year={2021},
  organization={IEEE}
}


@article{Rao_2020_CVPR,
author = {Rao, Kanishka and Harris, Chris and Irpan, Alex and Levine, Sergey and Ibarz, Julian and Khansari, Mohi},
title = {RL-CycleGAN: Reinforcement Learning Aware Simulation-to-Real},
booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}




@article{kidambi2020morel,
  title={MOReL: Model-Based Offline Reinforcement Learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={arXiv preprint arXiv:2005.05951},
  year={2020}
}

@article{2019arXiv190205605B,
       author = {{Bhatt}, Aditya and {Argus}, Max and {Amiranashvili}, Artemij and {Brox}, Thomas},
        title = "{CrossNorm: Normalization for Off-Policy TD Reinforcement Learning}",
      journal = {arXiv e-prints},
     keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
         year = 2019,
        month = feb,
          eid = {arXiv:1902.05605},
        pages = {arXiv:1902.05605},
archivePrefix = {arXiv},
       eprint = {1902.05605},
 primaryClass = {cs.LG},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2019arXiv190205605B},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}


@article{matsushima2020deployment,
  title={Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization},
  author={Matsushima, Tatsuya and Furuta, Hiroki and Matsuo, Yutaka and Nachum, Ofir and Gu, Shixiang},
  journal={arXiv preprint arXiv:2006.03647},
  year={2020}
}

@inproceedings{
lee2021representation,
title={Representation Balancing Offline Model-based Reinforcement Learning},
author={Byung-Jun Lee and Jongmin Lee and Kee-Eung Kim},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=QpNz8r_Ri2Y}
}

@article{swazinna2020overcoming,
  title={Overcoming Model Bias for Robust Offline Deep Reinforcement Learning},
  author={Swazinna, Phillip and Udluft, Steffen and Runkler, Thomas},
  journal={arXiv preprint arXiv:2008.05533},
  year={2020}
}

@article{emmons2021rvs,
  title={RvS: What is Essential for Offline RL via Supervised Learning?},
  author={Emmons, Scott and Eysenbach, Benjamin and Kostrikov, Ilya and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.10751},
  year={2021}
}

@article{rezaeifar2021offline,
  title={Offline reinforcement learning as anti-exploration},
  author={Rezaeifar, Shideh and Dadashi, Robert and Vieillard, Nino and Hussenot, L{\'e}onard and Bachem, Olivier and Pietquin, Olivier and Geist, Matthieu},
  journal={arXiv preprint arXiv:2106.06431},
  year={2021}
}

@article{zhou2020plas,
  title={PLAS: Latent Action Space for Offline Reinforcement Learning},
  author={Zhou, Wenxuan and Bajracharya, Sujay and Held, David},
  journal={arXiv preprint arXiv:2011.07213},
  year={2020}
}


@article{chen2022latent,
  title={Latent-Variable Advantage-Weighted Policy Optimization for Offline RL},
  author={Chen, Xi and Ghadirzadeh, Ali and Yu, Tianhe and Gao, Yuan and Wang, Jianhao and Li, Wenzhe and Liang, Bin and Finn, Chelsea and Zhang, Chongjie},
  journal={arXiv preprint arXiv:2203.08949},
  year={2022}
}

@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and {\.Z}o{\l}na, Konrad and Springenberg, Jost Tobias and Reed, Scott and Shahriari, Bobak and Siegel, Noah and Merel, Josh and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={arXiv preprint arXiv:2006.15134},
  year={2020}
}


@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2102.08363},
  year={2021}
}

@inproceedings{
kumar2022should,
title={Should I Run Offline Reinforcement Learning or Behavioral Cloning?},
author={Aviral Kumar and Joey Hong and Anikait Singh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2022},
url={https://openreview.net/forum?id=AP1MKT37rJ}
}


@article{zhang2019all,
  title={Are all layers created equal?},
  author={Zhang, Chiyuan and Bengio, Samy and Singer, Yoram},
  journal={arXiv preprint arXiv:1902.01996},
  year={2019}
}

@article{agarwal2021precipice,
  title={Deep Reinforcement Learning at the Edge of the Statistical Precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel
          and Courville, Aaron and Bellemare, Marc G},
  journal={Advances in Neural Information Processing Systems},
  year={2021}
}


@inproceedings{snoek2015scalable,
  title={Scalable bayesian optimization using deep neural networks},
  author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Prabhat, Mr and Adams, Ryan},
  booktitle={International conference on machine learning},
  pages={2171--2180},
  year={2015}
}


@article{schrittwieser2021online,
  title={Online and offline reinforcement learning by planning with a learned model},
  author={Schrittwieser, Julian and Hubert, Thomas and Mandhane, Amol and Barekatain, Mohammadamin and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:2104.06294},
  year={2021}
}

@article{bouthillier2021accounting,
  title={Accounting for variance in machine learning benchmarks},
  author={Bouthillier, Xavier and Delaunay, Pierre and Bronzi, Mirko and Trofimov, Assya and Nichyporuk, Brennan and Szeto, Justin and Mohammadi Sepahvand, Nazanin and Raff, Edward and Madan, Kanika and Voleti, Vikram and others},
  journal={Proceedings of Machine Learning and Systems},
  volume={3},
  year={2021}
}

@inproceedings{li2019towards, 
 title={Towards explaining the regularization effect of initial large learning rate in training neural networks}, 
 author={Li, Yuanzhi and Wei, Colin and Ma, Tengyu}, 
 booktitle={Advances in Neural Information Processing Systems}, 
 pages={11674--11685}, 
 year={2019} 
 }

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{chen2019information,
  title={Information-theoretic considerations in batch reinforcement learning},
  author={Chen, Jinglin and Jiang, Nan},
  journal={ICML},
  year={2019}
}

@book{hastie2015sparsity,
author = {Hastie, Trevor and Tibshirani, Robert and Wainwright, Martin},
title = {Statistical Learning with Sparsity: The Lasso and Generalizations},
year = {2015},
isbn = {1498712169},
publisher = {Chapman &amp; Hall/CRC},
}

@book{bellman1957dynamic,
  author =       "Bellman, Richard",
  title =        "Dynamic Programming",
  publisher =    "Princeton University Press",
  year =         "1957",
}


@inproceedings{boyan1999least,
  title={Least-squares temporal difference learning},
  author={Boyan, Justin A},
  booktitle={ICML},
  pages={49--56},
  year={1999},
  organization={Citeseer}
}

@article{igl2020impact,
  title={The Impact of Non-stationarity on Generalisation in Deep Reinforcement Learning},
  author={Igl, Maximilian and Farquhar, Gregory and Luketina, Jelena and Boehmer, Wendelin and Whiteson, Shimon},
  journal={arXiv preprint arXiv:2006.05826},
  year={2020}
}

@article{xu2007kernel,
  title={Kernel-based least squares policy iteration for reinforcement learning},
  author={Xu, Xin and Hu, Dewen and Lu, Xicheng},
  journal={IEEE Transactions on Neural Networks},
  volume={18},
  number={4},
  pages={973--992},
  year={2007},
  publisher={IEEE}
}

@article{xu2005kernel,
  title={Kernel least-squares temporal difference learning},
  author={Xu, Xin and Xie, Tao and Hu, Dewen and Lu, Xicheng},
  journal={International Journal of Information Technology},
  volume={11},
  number={9},
  pages={54--63},
  year={2005}
}

@article{dabney2020value,
  title={The Value-Improvement Path: Towards Better Representations for Reinforcement Learning},
  author={Dabney, Will and Barreto, Andr{\'e} and Rowland, Mark and Dadashi, Robert and Quan, John and Bellemare, Marc G and Silver, David},
  journal={arXiv preprint arXiv:2006.02243},
  year={2020}
}

@techreport{townsend2016differentiating,
  title={Differentiating the singular value decomposition},
  author={Townsend, James},
  year={2016},
  institution={Technical Report 2016, https://j-towns. github. io/papers/svd-derivative~…}
}

@Inbook{Hlawka1991dirichlet,
author="Hlawka, Edmund
and Taschner, Rudolf
and Schoi{\ss}engeier, Johannes",
title="The Dirichlet Approximation Theorem",
bookTitle="Geometric and Analytic Number Theory",
year="1991",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="1--18",
isbn="978-3-642-75306-0",
doi="10.1007/978-3-642-75306-0_1",
url="https://doi.org/10.1007/978-3-642-75306-0_1"
}



@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@book{duffy2015green,
  title={Green's functions with applications},
  author={Duffy, Dean G},
  year={2015},
  publisher={CRC Press}
}

@article{jaderberg2016reinforcement,
  title={Reinforcement learning with unsupervised auxiliary tasks},
  author={Jaderberg, Max and Mnih, Volodymyr and Czarnecki, Wojciech Marian and Schaul, Tom and Leibo, Joel Z and Silver, David and Kavukcuoglu, Koray},
  journal={arXiv preprint arXiv:1611.05397},
  year={2016}
}

@article{dabney2017distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1710.10044},
  year={2017}
}

@article{fu2020d4rl,
  title={D4rl: Datasets for deep data-driven reinforcement learning},
  author={Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.07219},
  year={2020}
}

@article{yang2019harnessing,
  title={Harnessing structures for value-based planning and reinforcement learning},
  author={Yang, Yuzhe and Zhang, Guo and Xu, Zhi and Katabi, Dina},
  journal={arXiv preprint arXiv:1909.12255},
  year={2019}
}

@article{fedus2020catastrophic,
  title={On Catastrophic Interference in Atari 2600 Games},
  author={Fedus, William and Ghosh, Dibya and Martin, John D and Bellemare, Marc G and Bengio, Yoshua and Larochelle, Hugo},
  journal={arXiv preprint arXiv:2002.12499},
  year={2020}
}

@article{paine2020hyperparameter,
  title={Hyperparameter selection for offline reinforcement learning},
  author={Paine, Tom Le and Paduraru, Cosmin and Michi, Andrea and Gulcehre, Caglar and Zolna, Konrad and Novikov, Alexander and Wang, Ziyu and de Freitas, Nando},
  journal={arXiv preprint arXiv:2007.09055},
  year={2020}
}

@article{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang M and Voloshin, Cameron and Yue, Yisong},
  journal={arXiv preprint arXiv:1903.08738},
  year={2019}
}

@inproceedings{gunasekar2018implicit,
  title={Implicit bias of gradient descent on linear convolutional networks},
  author={Gunasekar, Suriya and Lee, Jason D and Soudry, Daniel and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9461--9471},
  year={2018}
}

@inproceedings{luo2020i4r,
  title     = {I4R: Promoting Deep Reinforcement Learning by the Indicator for Expressive Representations},
  author    = {Luo, Xufang and Meng, Qi and He, Di and Chen, Wei and Wang, Yunhong},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  editor    = {Christian Bessiere},	
  pages     = {2669--2675},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/370},
  url       = {https://doi.org/10.24963/ijcai.2020/370},
}


@inproceedings{
Sanyal2020Stable,
title={Stable Rank Normalization for Improved Generalization in Neural Networks and GANs},
author={Amartya Sanyal and Philip H. Torr and Puneet K. Dokania},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=H1enKkrFDB}
}

@book{puterman1994markov,
  title={Markov Decision Processes: Discrete Stochastic Dynamic Programming},
  author={Puterman, Martin L},
  year={1994},
  publisher={John Wiley \& Sons, Inc.}
}

@article{huber1964robust,
  title={Robust estimation of a location parameter},
  author={Huber, PJ},
  journal={Ann. Math. Stat.},
  year={1964}
}


@article{mnih2013playing,
  title={{Playing Atari with deep reinforcement learning}},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv:1312.5602},
  year={2013}
}





@inproceedings{
daskalakis2018training,
title={Training {GAN}s with Optimism},
author={Constantinos Daskalakis and Andrew Ilyas and Vasilis Syrgkanis and Haoyang Zeng},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJJySbbAZ},
}

@inproceedings{sutton1999PG,
  author    = {Richard S. Sutton and
               David A. McAllester and
               Satinder P. Singh and
               Yishay Mansour},
  editor    = {Sara A. Solla and
               Todd K. Leen and
               Klaus{-}Robert M{\"{u}}ller},
  title     = {Policy Gradient Methods for Reinforcement Learning with Function Approximation},
  booktitle = {Advances in Neural Information Processing Systems 12, {[NIPS} Conference,
               Denver, Colorado, USA, November 29 - December 4, 1999]},
}

@PhdThesis{Watkins1989,
  author =       "Watkins, Christopher John Cornish Hellaby",
  title =        "Learning from Delayed Rewards",
  school =       "King's College",
  year =         "1989",
  address =   "Cambridge, UK",
  month =     "May",
  url = "http://www.cs.rhul.ac.uk/~chrisw/new_thesis.pdf",
  bib2html_rescat = "Parameter",
}

@inproceedings{hou2017novel,
  title={A novel ddpg method with prioritized experience replay},
  author={Hou, Yuenan and Liu, Lifeng and Wei, Qing and Xu, Xudong and Chen, Chunlin},
  booktitle={2017 IEEE International Conference on Systems, Man, and Cybernetics (SMC)},
  pages={316--321},
  year={2017},
  organization={IEEE}
}

@inproceedings{hessel2018rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{horgan2018distper,
  author    = {Dan Horgan and
               John Quan and
               David Budden and
               Gabriel Barth{-}Maron and
               Matteo Hessel and
               Hado van Hasselt and
               David Silver},
  title     = {Distributed Prioritized Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1803.00933},
  year      = {2018},
  url       = {http://arxiv.org/abs/1803.00933},
  archivePrefix = {arXiv},
  eprint    = {1803.00933},
  timestamp = {Mon, 13 Aug 2018 16:46:02 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1803-00933.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@inproceedings{absention,
author = {Thulasidasan, Sunil and Bhattacharya, Tanmoy and Bilmes, Jeff and Chennupati, Gopinath and Mohd-Yusof, Jamal},
year = {2019},
month = {05},
booktitle = {Proceedings of 35th International Conference on Machine Learning},
title = {Combating Label Noise in Deep Learning Using Abstention}
}

@inproceedings{hassalt10doubleq,
 author = {Hasselt, Hado van},
 title = {Double Q-Learning},
 year = {2010},
 booktitle = {Proceedings of the 23rd International Conference on Neural Information Processing Systems - Volume 2}
}

@article{ODonoghue2017TheUB,
  title={The Uncertainty Bellman Equation and Exploration},
  author={Brendan O'Donoghue and Ian Osband and R{\'e}mi Munos and Volodymyr Mnih},
  journal={ICML},
  year={2018},
  volume={abs/1709.05380}
}

@inproceedings{hazan2019maxent,
title	= {Provably Efficient Maximum Entropy Exploration},
author	= {Elad Hazan and Sham Kakade and Karan Singh and Abby Van Soest},
year	= {2019},
journal = {ICML},
URL	= {https://arxiv.org/pdf/1812.02690.pdf}
}


@TECHREPORT{Tsitsiklis97ananalysis,
    author = {John N. Tsitsiklis and Benjamin Van Roy},
    title = {An analysis of temporal-difference learning with function approximation},
    institution = {IEEE Transactions on Automatic Control},
    year = {1997}
}

@inproceedings{rainbow,
  title={Rainbow: Combining improvements in deep reinforcement learning},
  author={Hessel, Matteo and Modayil, Joseph and Van Hasselt, Hado and Schaul, Tom and Ostrovski, Georg and Dabney, Will and Horgan, Dan and Piot, Bilal and Azar, Mohammad and Silver, David},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{zhang2017deeper,
  title={A deeper look at experience replay},
  author={Zhang, Shangtong and Sutton, Richard S},
  journal={arXiv preprint arXiv:1712.01275},
  year={2017}
}

@inproceedings{liu2018effects,
  title={The effects of memory replay in reinforcement learning},
  author={Liu, Ruishan and Zou, James},
  booktitle={2018 56th Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
  year={2018},
  organization={IEEE}
}

@inproceedings{suggala2018connecting,
  title={Connecting optimization and regularization paths},
  author={Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
  booktitle={Advances in Neural Information Processing Systems},
  pages={10608--10619},
  year={2018}
}

@article{ruhe1975closeness,
  title={On the closeness of eigenvalues and singular values for almost normal matrices},
  author={Ruhe, Axel},
  journal={Linear Algebra and its Applications},
  volume={11},
  number={1},
  pages={87--93},
  year={1975},
  publisher={Elsevier}
}

@article{wu2019behavior,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@InProceedings{fujimoto19a,
  title = 	 {Off-Policy Deep Reinforcement Learning without Exploration},
  author = 	 {Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  year = 	 {2019},
}

@incollection{NIPS2019_9015,
title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
booktitle = {Advances in Neural Information Processing Systems 32},
pages = {8026--8037},
year = {2019},
}

@inproceedings{tensorflow,
title	= {TensorFlow: A system for large-scale machine learning},
author	= {Martin Abadi and Paul Barham and Jianmin Chen and Zhifeng Chen and Andy Davis and Jeffrey Dean and Matthieu Devin and Sanjay Ghemawat and Geoffrey Irving and Michael Isard and Manjunath Kudlur and Josh Levenberg and Rajat Monga and Sherry Moore and Derek G. Murray and Benoit Steiner and Paul Tucker and Vijay Vasudevan and Pete Warden and Martin Wicke and Yuan Yu and Xiaoqiang Zheng},
year	= {2016},
URL	= {https://www.usenix.org/system/files/conference/osdi16/osdi16-abadi.pdf},
booktitle	= {12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16)},
pages	= {265--283}
}

@inproceedings{le2019batch,
  title={Batch policy learning under constraints},
  author={Le, Hoang and Voloshin, Cameron and Yue, Yisong},
  booktitle={International Conference on Machine Learning},
  pages={3703--3712},
  year={2019},
  organization={PMLR}
}

@inproceedings{
fu2021benchmarks,
title={Benchmarks for Deep Off-Policy Evaluation},
author={Justin Fu and Mohammad Norouzi and Ofir Nachum and George Tucker and ziyu wang and Alexander Novikov and Mengjiao Yang and Michael R Zhang and Yutian Chen and Aviral Kumar and Cosmin Paduraru and Sergey Levine and Thomas Paine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=kWSeGEeHvF8}
}


@inproceedings{gulcehre2020rl,
  title={Rl unplugged: Benchmarks for offline reinforcement learning},
  author={Gulcehre, Caglar and Wang, Ziyu and Novikov, Alexander and Paine, Tom Le and Colmenarejo, Sergio G{\'o}mez and Zolna, Konrad and Agarwal, Rishabh and Merel, Josh and Mankowitz, Daniel and Paduraru, Cosmin and others},
  journal={Advances in Neural Information Processing Systems},
  year={2020}
}

@book{rummery1994line,
  title={On-line Q-learning using connectionist systems},
  author={Rummery, Gavin A and Niranjan, Mahesan},
  volume={37},
  year={1994}
}

@inproceedings{perkins2002api,
author = {Perkins, Theodore J. and Precup, Doina},
title = {A Convergent Form of Approximate Policy Iteration},
year = {2002},
series = {NIPS’02}
}

@inproceedings{gunasekar2017implicit,
  title={Implicit regularization in matrix factorization},
  author={Gunasekar, Suriya and Woodworth, Blake E and Bhojanapalli, Srinadh and Neyshabur, Behnam and Srebro, Nati},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6151--6159},
  year={2017}
}

@article{lstd,
  title={Linear least-squares algorithms for temporal difference learning},
  author={Bradtke, Steven J and Barto, Andrew G},
  journal={Machine learning},
  volume={22},
  number={1-3},
  pages={33--57},
  year={1996},
  publisher={Springer}
}

@article{bellemare2013ale,
author = {Bellemare, Marc G. and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
title = {The Arcade Learning Environment: An Evaluation Platform for General Agents},
year = {2013},
issue_date = {May 2013},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {47},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
month = may,
pages = {253–279},
numpages = {27}
}
  
@article{yu2020gradient,
  title={Gradient Surgery for Multi-Task Learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={arXiv preprint arXiv:2001.06782},
  year={2020}
}

  
@incollection{ntk,
title = {Neural Tangent Kernel: Convergence and Generalization in Neural Networks},
author = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
booktitle = {Advances in Neural Information Processing Systems 31},
year = {2018},
url = {}
}

@article{lorraine2019optimizing,
  title={Optimizing Millions of Hyperparameters by Implicit Differentiation},
  author={Lorraine, Jonathan and Vicol, Paul and Duvenaud, David},
  journal={arXiv preprint arXiv:1911.02590},
  year={2019}
}


@inproceedings{peters2010reps,
author = {Peters, Jan and M\"{u}lling, Katharina and Alt\"{u}n, Yasemin},
title = {Relative Entropy Policy Search},
year = {2010},
publisher = {AAAI Press},
booktitle = {Proceedings of the Twenty-Fourth AAAI Conference on Artificial Intelligence},
pages = {1607–1612},
numpages = {6},
location = {Atlanta, Georgia},
series = {AAAI’10}
}
  


@article{machado18sticky,
author = {Machado, Marlos C. and Bellemare, Marc G. and Talvitie, Erik and Veness, Joel and Hausknecht, Matthew and Bowling, Michael},
title = {Revisiting the Arcade Learning Environment: Evaluation Protocols and Open Problems for General Agents},
year = {2018},
issue_date = {January 2018},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {61},
number = {1},
issn = {1076-9757},
journal = {J. Artif. Int. Res.},
month = jan,
pages = {523–562},
numpages = {40}
}
  


@inproceedings{bellemare2017distributional,
  title={A distributional perspective on reinforcement learning},
  author={Bellemare, Marc G and Dabney, Will and Munos, R{\'e}mi},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={449--458},
  year={2017},
  organization={JMLR. org}
}


@article{castro18dopamine,
  author    = {Pablo Samuel Castro and
               Subhodeep Moitra and
               Carles Gelada and
               Saurabh Kumar and
               Marc G. Bellemare},
  title     = {Dopamine: {A} {R}esearch {F}ramework for {D}eep {R}einforcement {L}earning},
  year      = {2018},
  url       = {http://arxiv.org/abs/1812.06110},
  archivePrefix = {arXiv}
}

@article{scherrer15a,
  author  = {Bruno Scherrer and Mohammad Ghavamzadeh and Victor Gabillon and Boris Lesner and Matthieu Geist},
  title   = {Approximate Modified Policy Iteration and its Application to the Game of Tetris},
  journal = {Journal of Machine Learning Research},
  year    = {2015},
  volume  = {16},
  number  = {49},
  pages   = {1629-1676},
  url     = {http://jmlr.org/papers/v16/scherrer15a.html}
}

@article{Lesner2013TightPB,
  title={Tight Performance Bounds for Approximate Modified Policy Iteration with Non-Stationary Policies},
  author={Boris Lesner and Bruno Scherrer},
  journal={ArXiv},
  year={2013},
  volume={abs/1304.5610}
}

@inproceedings{scherrer_comparison,
author = {Scherrer, Bruno},
title = {Approximate Policy Iteration Schemes: A Comparison},
year = {2014},
publisher = {JMLR.org},
booktitle = {Proceedings of the 31st International Conference on International Conference on Machine Learning - Volume 32},
pages = {II–1314–II–1322},
numpages = {9},
location = {Beijing, China},
series = {ICML’14}
}
  


@inproceedings{
du2020is,
title={Is a Good Representation Sufficient for Sample Efficient Reinforcement Learning?},
author={Simon S. Du and Sham M. Kakade and Ruosong Wang and Lin F. Yang},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=r1genAVKPB}
}

@inproceedings{munos2003api,
author = {Munos, R\'{e}mi},
title = {Error Bounds for Approximate Policy Iteration},
year = {2003},
isbn = {1577351894},
publisher = {AAAI Press},
booktitle = {Proceedings of the Twentieth International Conference on International Conference on Machine Learning},
pages = {560–567},
numpages = {8},
location = {Washington, DC, USA},
series = {ICML’03}
}
  


@inproceedings{yu2019meta,
  title={Meta-World: A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning},
  author={Tianhe Yu and Deirdre Quillen and Zhanpeng He and Ryan Julian and Karol Hausman and Chelsea Finn and Sergey Levine},
  booktitle={Conference on Robot Learning (CoRL)},
  year={2019},
  eprint={1910.10897},
  archivePrefix={arXiv},
  primaryClass={cs.LG},
  url={https://arxiv.org/abs/1910.10897},
}

@article{kumar19bear,
  author       = {Aviral Kumar and Justin Fu and George Tucker and Sergey Levine},
  title        = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
  conference   = {NeurIPS 2019},
  year = {2019},
  url          = {http://arxiv.org/abs/1906.00949},
}

@article{farias_fixed_points,
author = {Farias, D. and Roy, B.},
year = {2000},
month = {06},
pages = {589-608},
title = {On the Existence of Fixed Points for Approximate Value Iteration and Temporal-Difference Learning},
volume = {105},
journal = {Journal of Optimization Theory and Applications},
doi = {10.1023/A:1004641123405}
}

@inproceedings{Krantz2002TheIF,
  title={The Implicit Function Theorem: History, Theory, and Applications},
  author={Steven G. Krantz and Harold R. Parks},
  year={2002}
}

@InProceedings{ahmed19understanding,
  title = 	 {Understanding the Impact of Entropy on Policy Optimization},
  author = 	 {Ahmed, Zafarali and Le Roux, Nicolas and Norouzi, Mohammad and Schuurmans, Dale},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  publisher = 	 {PMLR},
  year = {2019},
  url = 	 {http://proceedings.mlr.press/v97/ahmed19a.html},
  abstract = 	 {Entropy regularization is commonly used to improve policy optimization in reinforcement learning. It is believed to help with exploration by encouraging the selection of more stochastic policies. In this work, we analyze this claim using new visualizations of the optimization landscape based on randomly perturbing the loss function. We first show that even with access to the exact gradient, policy optimization is difficult due to the geometry of the objective function. We then qualitatively show that in some environments, a policy with higher entropy can make the optimization landscape smoother, thereby connecting local optima and enabling the use of larger learning rates. This paper presents new tools for understanding the optimization landscape, shows that policy entropy serves as a regularizer, and highlights the challenge of designing general-purpose policy optimization algorithms.}
}

@book{rockafellar-1970a,
  added-at = {2008-03-02T02:12:02.000+0100},
  address = {Princeton, N. J.},
  author = {Rockafellar, R. Tyrrell},
  biburl = {https://www.bibsonomy.org/bibtex/223aa07ea525f6dd11585fc2037a0daf1/dmartins},
  callnumber = {UniM Maths 516.08 R59},
  description = {robotica-bib},
  interhash = {30830becb0a2c5ebca5946b895d9740a},
  intrahash = {23aa07ea525f6dd11585fc2037a0daf1},
  keywords = {imported},
  notes = {A SRL reference.},
  publisher = {Princeton University Press},
  series = {Princeton Mathematical Series},
  timestamp = {2008-03-02T02:14:11.000+0100},
  title = {Convex analysis},
  year = 1970
}


@article{Achiam2019TowardsCD,
  title={Towards Characterizing Divergence in Deep Q-Learning},
  author={Joshua Achiam and Ethan Knight and Pieter Abbeel},
  journal={ArXiv},
  year={2019},
  volume={abs/1903.08894}
}

@Article{Tsitsiklis1994,
author="Tsitsiklis, John N.",
title="Asynchronous stochastic approximation and Q-learning",
journal="Machine Learning",
year="1994",
month="Sep",
day="01",
volume="16",
number="3",
pages="185--202",
abstract="We provide some general results on the convergence of a class of stochastic approximation algorithms and their parallel and asynchronous variants. We then use these results to study the Q-learning algorithm, a reinforcement learning method for solving Markov decision problems, and establish its convergence under conditions more general than previously available.",
issn="1573-0565",
doi="10.1007/BF00993306",
url="https://doi.org/10.1007/BF00993306"
}



  @inproceedings{devraj2017zap,
 author = {Devraj, Adithya M. and Meyn, Sean P.},
 title = {Zap Q-Learning},
 year = {2017},
 isbn = {9781510860964},
 publisher = {Curran Associates Inc.},
 address = {Red Hook, NY, USA},
 booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
 pages = {2232–2241},
 numpages = {10},
 location = {Long Beach, California, USA},
 series = {NIPS’17}
}


@inproceedings{maei09nonlineargtd,
 author = {Maei, Hamid R. and Szepesv\'{a}ri, Csaba and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S.},
 title = {Convergent Temporal-Difference Learning with Arbitrary Smooth Function Approximation},
 year = {2009},
 booktitle = {Proceedings of the 22nd International Conference on Neural Information Processing Systems}
}


@article{Hasselt2018DeepRL,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Hado van Hasselt and Yotam Doron and Florian Strub and Matteo Hessel and Nicolas Sonnerat and Joseph Modayil},
  journal={ArXiv},
  year={2018},
  volume={abs/1812.02648}
}

@inproceedings{Kolter2011TheFP,
  title={The Fixed Points of Off-Policy TD},
  author={J. Zico Kolter},
  booktitle={NIPS},
  year={2011}
}

@inproceedings{du2019distributioncheck,
author = {Du, Simon and Luo, Yuping and Wang, Ruosong and Zhang, Hanrui},
year = {2019},
month = {06},
booktitle={NeurIPS},
title = {Provably Efficient $Q$-learning with Function Approximation via Distribution Shift Error Checking Oracle}
}

@article{sutton16emphatic,
author = {Sutton, Richard S. and Mahmood, A. Rupam and White, Martha},
title = {An Emphatic Approach to the Problem of Off-Policy Temporal-Difference Learning},
year = {2016},
issue_date = {January 2016},
publisher = {JMLR.org},
volume = {17},
number = {1},
issn = {1532-4435},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {2603–2631},
numpages = {29},
keywords = {function approximation, temporal-difference learning, off-policy learning, convergence, stability}
}

@InProceedings{fu19diagnosing,
  title = 	 {Diagnosing Bottlenecks in Deep Q-learning Algorithms},
  author = 	 {Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  year = {2019},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  publisher = 	 {PMLR},
}


@phdthesis{konda_ac,
author = {Konda, Vijaymohan and Tsitsiklis, John N.},
title = {Actor-Critic Algorithms},
year = {2002},
publisher = {Massachusetts Institute of Technology},
address = {USA},
note = {AAI0804543}
}


@article{schaul2019ray,
  author    = {Tom Schaul and
               Diana Borsa and
               Joseph Modayil and
               Razvan Pascanu},
  title     = {Ray Interference: a Source of Plateaus in Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1904.11455},
  year      = {2019},
  url       = {http://arxiv.org/abs/1904.11455},
  archivePrefix = {arXiv},
  eprint    = {1904.11455},
  timestamp = {Thu, 02 May 2019 15:13:44 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1904-11455},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
a service of Schloss Dagstuhl - Leibniz Center for Informatics	homebrowsesearchabout


@inproceedings{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  year={2010}
}

@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  number={3},
  pages={185--202},
  year={1994},
  publisher={Springer}
}

@inproceedings{
yaz2018the,
title={The Unusual Effectiveness of Averaging in {GAN} Training},
author={Yasin Yaz{\i}c{\i} and Chuan-Sheng Foo and Stefan Winkler and Kim-Hui Yap and Georgios Piliouras and Vijay Chandrasekhar},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SJgw_sRqFQ},
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2018}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@inproceedings{Kakade2002,
author = {Kakade, Sham and Langford, John},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Approximately Optimal Approximate Reinforcement Learning}},
year = {2002}
}

@inproceedings{Maei2010,
author = {Maei, Hamid Reza and Szepesv{\'{a}}ri, Csaba and Bhatnagar, Shalabh and Sutton, Richard S},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Toward off-policy learning control with function approximation}},
year = {2010}
}

@inproceedings{Baird1995,
annote = {Residual gradient = differentiating through target},
author = {Baird, Leemon},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Residual Algorithms : Reinforcement Learning with Function Approximation}},
year = {1995}
}

@article{Mnih2015,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
issn = {0028-0836},
journal = {Nature},
month = {feb},
number = {7540},
pages = {529--533},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
title = {{Human-level control through deep reinforcement learning}},
volume = {518},
year = {2015}
}

@article{Lillicrap2015,
author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
journal = {International Conference on Learning Representations (ICLR)},
title = {{Continuous control with deep reinforcement learning}},
year = {2015}
}

@inproceedings{Schulman2015,
author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael I. and Abbeel, Pieter},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Trust Region Policy Optimization}},
year = {2015}
}

@inproceedings{Precup2001,
author = {Precup, Doina and Sutton, Richard S. and Dasgupta, Sanjoy},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Off-policy temporal-difference learning with function approximation}},
year = {2001}
}

@article{Schulman2017,
  author    = {John Schulman and
               Pieter Abbeel and
               Xi Chen},
  title     = {Equivalence Between Policy Gradients and Soft Q-Learning},
  journal   = {ArXiv Preprint},
  volume    = {abs/1704.06440},
  year      = {2017},
}

@article{Gu2016,
  author    = {Shixiang Gu and
               Ethan Holly and
               Timothy Lillicrap and
               Sergey Levine},
  title     = {Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  journal   = {IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2017},
}

@article{Watkins92,
  author    = {Christopher J.C.H. Watkins and Peter Dayan},
  title     = {Q-learning},
  journal   = {Machine Learning},
  year      = {1992},
  volume    = {8},
  pages     = {279-292},
  issue     = {3},
}

@incollection{Kakade2001,
title = {A Natural Policy Gradient},
author = {Sham M. Kakade},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2001},
}

@incollection{Munos2016,
title = {Safe and Efficient Off-policy Reinforcement Learning},
author = {Remi Munos and Thomas Stepleton and Anna Harutyunyan and Marc G. Bellemare},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2016},
}

@inproceedings{Sutton09a,
title = {A Convergent O(n) Temporal-difference Algorithm for Off-policy Learning with Linear Function Approximation},
author = {Sutton, Richard S. and Hamid Reza Maei and Csaba Szepesv\'{a}ri},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2009},
}

@inproceedings{Sutton09b,
title = {Fast Gradient-Descent Methods for Temporal-Difference Learning
with Linear Function Approximation},
author = {
Richard S. Sutton and Hamid Reza Maei and Doina Precup and Shalabh Bhatnagar and David Silver and Csaba Szepesv\'{a}ri and
Eric Wiewiora},
booktitle = {International Conference on Machine Learning (ICML)},
year = {2009},
}

@article{Bertsekas96,
title = {Neuro-Dynamic Programming},
author = {Bertsekas, Dimitri P., and Tsitsiklis, John N.},
journal = {Athena Scientific},
year = {1996},
}


@inproceedings{Haarnoja2017,
author = {Tuomas Haarnoja and
               Haoran Tang and
               Pieter Abbeel and
               Sergey Levine},
booktitle = {International Conference on Machine Learning (ICML)},
title = {Reinforcement Learning with Deep Energy-Based Policies},
year = {2017}
}

@inproceedings{Hausknecht2016,
author = {Matthew Hausknecht and Peter Stone},
booktitle = {Deep Reinforcement Learning: Frontiers and Challenges Workshop, IJCAI},
title = {On-Policy vs. Off-Policy Updates for Deep Reinforcement Learning},
year = {2016}
}

@inproceedings{Farrell95,
author = {Jay A. Farrell and T. Berger},
booktitle = {American Control Conference},
title = {On the effects of the training sample density in passive learning control},
year = {1995}
}

@inproceedings{Boyan94,
author = {Justin A. Boyan and Andrew W. Moore},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
title = {Generalization in Reinforcement Learning:
Safely Approximating the Value Function},
year = {1994}
}

@article{Haarnoja18,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
}

@inproceedings{kalashnikov18,
  author    = {Dmitry Kalashnikov and
               Alex Irpan and
               Peter Pastor and
               Julian Ibarz and
               Alexander Herzog and
               Eric Jang and
               Deirdre Quillen and
               Ethan Holly and
               Mrinal Kalakrishnan and
               Vincent Vanhoucke and
               Sergey Levine},
  title     = {QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  booktitle = {CoRL},
  year      = {2018}
}

@article{Ernst05,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@book{suttonrlbook,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  edition = {Second}
}

@inproceedings{Dai2018,
  title={Sbeed: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  booktitle={International Conference on Machine Learning},
  pages={1133--1142},
  year={2018}
}

@article{VanHesselt2018,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@inproceedings{Tsitsiklis1997,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1075--1081},
  year={1997}
}

@article{Hallak2017,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  journal={arXiv preprint arXiv:1702.07121},
  year={2017}
}

@article{Sutton2016,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@article{henderson2017deep,
  title={Deep reinforcement learning that matters},
  author={Henderson, Peter and Islam, Riashat and Bachman, Philip and Pineau, Joelle and Precup, Doina and Meger, David},
  journal={arXiv preprint arXiv:1709.06560},
  year={2017}
}

@article{dalal2017finite,
  title={Finite sample analyses for TD (0) with function approximation},
  author={Dalal, Gal and Sz{\"o}r{\'e}nyi, Bal{\'a}zs and Thoppe, Gugan and Mannor, Shie},
  journal={arXiv preprint arXiv:1704.01161},
  year={2017}
}

@inproceedings{bhatnagar2009convergent,
  title={Convergent temporal-difference learning with arbitrary smooth function approximation},
  author={Maei, Hamid R, and Szepesv{\'a}ri, Csaba, and Bhatnagar, Shalabh and Precup, Doina and Silver, David and Sutton, Richard S },
  booktitle={Advances in Neural Information Processing Systems},
  pages={1204--1212},
  year={2009}
}

@inproceedings{Riedmiller2005,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}

@article{Watkins1992,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{Gu2017,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{fedus2020revisiting,
  title={Revisiting fundamentals of experience replay},
  author={Fedus, William and Ramachandran, Prajit and Agarwal, Rishabh and Bengio, Yoshua and Larochelle, Hugo and Rowland, Mark and Dabney, Will},
  journal={arXiv preprint arXiv:2007.06700},
  year={2020}
}

@misc{gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@misc{approxstack,
  Author = {Robert Johnson},
  Title = {Approximate Irrational Numbers by Rational Numbers},
  Year = {2016},
  url = {https://math.stackexchange.com/questions/1829743/},
}

@article{Schaul2015,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={International Conference on Learning Representations (ICLR)},
  year={2015}
}

@book{Shalev2014,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@incollection{NIPS2017_6913,
title = {Is the Bellman residual a bad proxy?},
author = {Geist, Matthieu and Piot, Bilal and Pietquin, Olivier},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
pages = {3205--3214},
year = {2017},
}

@inproceedings{Pritzel2017,
  title={Neural Episodic Control},
  author={Pritzel, Alexander and Uria, Benigno and Srinivasan, Sriram and Badia, Adri{\`a} Puigdom{\`e}nech and Vinyals, Oriol and Hassabis, Demis and Wierstra, Daan and Blundell, Charles},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2827--2836},
  year={2017}
}

@InProceedings{pmlr-v80-fujimoto18a,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@inproceedings{Gu2017ipg,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={3846--3855},
  year={2017}
}

@inproceedings{maillard2010finite,
  title={Finite-sample analysis of Bellman residual minimization},
  author={Maillard, Odalric-Ambrym and Munos, R{\'e}mi and Lazaric, Alessandro and Ghavamzadeh, Mohammad},
  booktitle={Asian Conference on Machine Learning (ACML)},
  pages={299--314},
  year={2010}
}

@inproceedings{munos2005error,
  title={Error bounds for approximate value iteration},
  author={Munos, R{\'e}mi},
  booktitle={AAAI Conference on Artificial intelligence (AAAI)},
  pages={1006--1011},
  year={2005},
  organization={AAAI Press}
}

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{zhang2018deeper,
  author    = {Shangtong Zhang and
               Richard S. Sutton},
  title     = {A Deeper Look at Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1712.01275},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.01275},
  archivePrefix = {arXiv},
  eprint    = {1712.01275},
  timestamp = {Mon, 13 Aug 2018 16:46:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1712-01275},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{antos2007fitted,
 author = {Antos, Andr\'{a}s and Munos, R{\'e}mi and Szepesv\'{a}ri, Csaba},
 title = {Fitted Q-iteration in Continuous Action-space MDPs},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 series = {NIPS'07},
 year = {2007},
 location = {Vancouver, British Columbia, Canada},
} 

@phdthesis{de2002alp,
  title={The linear programming approach to approximate dynamic programming: Theory and application},
  author={De Farias, Daniela Pucci},
  year={2002}
}

@article{antos2008concentrability,
  title={Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Machine Learning},
  volume={71},
  number={1},
  pages={89--129},
  year={2008},
  publisher={Springer}
}

@article{metelli2018nips,
  author    = {Alberto Maria Metelli and
               Matteo Papini and
               Francesco Faccio and
               Marcello Restelli},
  title     = {Policy Optimization via Importance Sampling},
  journal   = {CoRR},
  volume    = {abs/1809.06098},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.06098},
  archivePrefix = {arXiv},
  eprint    = {1809.06098},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1809-06098},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{pmlr-v70-arjovsky17a,
  title = 	 {{W}asserstein Generative Adversarial Networks},
  author = 	 {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {214--223},
  year = 	 {2017},
}

@techreport{haarnoja2018sacapps,
  title={Soft Actor-Critic Algorithms and Applications},
  author={Tuomas Haarnoja and Aurick Zhou and Kristian Hartikainen and George Tucker and Sehoon Ha and Jie Tan and Vikash Kumar and Henry Zhu and Abhishek Gupta and Pieter Abbeel and Sergey Levine},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{hazan2018,
  title={Provably Efficient Maximum Entropy Exploration},
  author={Hazan, Elad and Kakade, Sham M and Singh, Karan and Van Soest, Abby},
  journal={arXiv preprint arXiv:1812.02690},
  year={2018}
}

@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@inproceedings{scherrer2010residual,
  title={Should one compute the temporal difference fix point or minimize the Bellman Residual? The unified oblique projection view},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={959--966},
  year={2010},
}

@inproceedings{tosatto2017boosted,
  title={Boosted fitted q-iteration},
  author={Tosatto, Samuele and Pirotta, Matteo and D'Eramo, Carlo and Restelli, Marcello},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={3434--3443},
  year={2017},
  organization={JMLR. org}
}

@article{lin1992replay,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1054--1062},
  year={2016}
}

@article{sriperum2009ipms,
  author    = {Bharath K. Sriperumbudur and
               Arthur Gretton and
               Kenji Fukumizu and
               Gert R. G. Lanckriet and
               Bernhard Sch{\"{o}}lkopf},
  title     = {A note on integral probability metrics and {\textdollar}{\textbackslash}phi{\textdollar}-divergences},
  journal   = {CoRR},
  volume    = {abs/0901.2698},
  year      = {2009},
  url       = {http://arxiv.org/abs/0901.2698},
  archivePrefix = {arXiv},
  eprint    = {0901.2698},
  timestamp = {Mon, 13 Aug 2018 16:48:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-0901-2698},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kumar2020discor,
  title={Discor: Corrective feedback in reinforcement learning via distribution correction},
  author={Kumar, Aviral and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2003.07305},
  year={2020}
}

@inproceedings{arora2019implicit,
  title={Implicit regularization in deep matrix factorization},
  author={Arora, Sanjeev and Cohen, Nadav and Hu, Wei and Luo, Yuping},
  booktitle={Advances in Neural Information Processing Systems},
  pages={7413--7424},
  year={2019}
}

@inproceedings{yang2020theoretical,
  title={A theoretical analysis of deep Q-learning},
  author={Yang, Zhuoran and Xie, Yuchen and Wang, Zhaoran},
  booktitle={Learning for Dynamics and Control},
  pages={486--489},
  year={2020},
  organization={PMLR}
}

@article{cai2019neural,
  title={Neural Temporal-Difference and Q-Learning Provably Converge to Global Optima},
  author={Cai, Qi and Yang, Zhuoran and Lee, Jason D and Wang, Zhaoran},
  journal={arXiv preprint arXiv:1905.10027},
  year={2019}
}

@article{mahadevan2007proto,
  title={Proto-value functions: A Laplacian framework for learning representation and control in Markov decision processes},
  author={Mahadevan, Sridhar and Maggioni, Mauro},
  journal={Journal of Machine Learning Research},
  volume={8},
  number={Oct},
  pages={2169--2231},
  year={2007}
}

@article{wu2018laplacian,
  title={The Laplacian in RL: Learning representations with efficient approximations},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1810.04586},
  year={2018}
}

@article{machado2017eigenoption,
  title={Eigenoption discovery through the deep successor representation},
  author={Machado, Marlos C and Rosenbaum, Clemens and Guo, Xiaoxiao and Liu, Miao and Tesauro, Gerald and Campbell, Murray},
  journal={arXiv preprint arXiv:1710.11089},
  year={2017}
}

@article{van2019use,
  title={When to use parametric models in reinforcement learning?},
  author={van Hasselt, Hado and Hessel, Matteo and Aslanides, John},
  journal={arXiv preprint arXiv:1906.05243},
  year={2019}
}

@article{tian2021understanding,
  title={Understanding self-supervised learning dynamics without contrastive pairs},
  author={Tian, Yuandong and Chen, Xinlei and Ganguli, Surya},
  journal={arXiv preprint arXiv:2102.06810},
  year={2021}
}

@article{tian2020understanding,
  title={Understanding self-supervised learning with dual deep networks},
  author={Tian, Yuandong and Yu, Lantao and Chen, Xinlei and Ganguli, Surya},
  journal={arXiv preprint arXiv:2010.00578},
  year={2020}
}

@article{chen2020exploring,
  title={Exploring Simple Siamese Representation Learning},
  author={Chen, Xinlei and He, Kaiming},
  journal={arXiv preprint arXiv:2011.10566},
  year={2020}
}

@article{grill2020bootstrap,
  title={Bootstrap your own latent: A new approach to self-supervised learning},
  author={Grill, Jean-Bastien and Strub, Florian and Altch{\'e}, Florent and Tallec, Corentin and Richemond, Pierre H and Buchatskaya, Elena and Doersch, Carl and Pires, Bernardo Avila and Guo, Zhaohan Daniel and Azar, Mohammad Gheshlaghi and others},
  journal={arXiv preprint arXiv:2006.07733},
  year={2020}
}

@article{fakoor2021continuous,
  title={Continuous Doubly Constrained Batch Reinforcement Learning},
  author={Fakoor, Rasool and Mueller, Jonas and Chaudhari, Pratik and Smola, Alexander J},
  journal={arXiv preprint arXiv:2102.09225},
  year={2021}
}

@article{kaiser2019model,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@article{woodworth2020kernel,
  title={Kernel and rich regimes in overparametrized models},
  author={Woodworth, Blake and Gunasekar, Suriya and Lee, Jason D and Moroshko, Edward and Savarese, Pedro and Golan, Itay and Soudry, Daniel and Srebro, Nathan},
  journal={arXiv preprint arXiv:2002.09277},
  year={2020}
}

@inproceedings{lyle2021effect,
  title={On The Effect of Auxiliary Tasks on Representation Dynamics},
  author={Lyle, Clare and Rowland, Mark and Ostrovski, Georg and Dabney, Will},
  booktitle={International Conference on Artificial Intelligence and Statistics},
  pages={1--9},
  year={2021},
  organization={PMLR}
}

@article{wei2019regularization,
  title={Regularization matters: Generalization and optimization of neural nets vs their induced kernel},
  author={Wei, Colin and Lee, Jason and Liu, Qiang and Ma, Tengyu},
  year={2019}
}

@article{sedghi2018singular,
  title={The singular values of convolutional layers},
  author={Sedghi, Hanie and Gupta, Vineet and Long, Philip M},
  journal={arXiv preprint arXiv:1805.10408},
  year={2018}
}

@article{zhang2020can,
  title={Can Temporal-Difference and Q-Learning Learn Representation? A Mean-Field Theory},
  author={Zhang, Yufeng and Cai, Qi and Yang, Zhuoran and Chen, Yongxin and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2006.04761},
  year={2020}
}

@article{xu2019finite,
  title={A finite-time analysis of Q-learning with neural network function approximation},
  author={Xu, Pan and Gu, Quanquan},
  journal={arXiv preprint arXiv:1912.04511},
  year={2019}
}

@article{voloshin2019empirical,
  title={Empirical study of off-policy policy evaluation for reinforcement learning},
  author={Voloshin, Cameron and Le, Hoang M and Jiang, Nan and Yue, Yisong},
  journal={arXiv preprint arXiv:1911.06854},
  year={2019}
}

@article{ghosh2020representations,
  title={Representations for Stable Off-Policy Reinforcement Learning},
  author={Ghosh, Dibya and Bellemare, Marc G},
  journal={arXiv preprint arXiv:2007.05520},
  year={2020}
}

@article{mobahi2020self,
  title={Self-distillation amplifies regularization in hilbert space},
  author={Mobahi, Hossein and Farajtabar, Mehrdad and Bartlett, Peter L},
  journal={arXiv preprint arXiv:2002.05715},
  year={2020}
}

@inproceedings{agarwal2019optimistic,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{kumar2020conservative,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@article{arora2018optimization,
  title={On the optimization of deep networks: Implicit acceleration by overparameterization},
  author={Arora, Sanjeev and Cohen, Nadav and Hazan, Elad},
  journal={arXiv preprint arXiv:1802.06509},
  year={2018}
}

@inproceedings{boyan1999least,
  title={Least-squares temporal difference learning},
  author={Boyan, Justin A},
  booktitle={ICML},
  pages={49--56},
  year={1999},
  organization={Citeseer}
}

@inproceedings{melo2008analysis,
  title={An analysis of reinforcement learning with function approximation},
  author={Melo, Francisco S and Meyn, Sean P and Ribeiro, M Isabel},
  booktitle={Proceedings of the 25th international conference on Machine learning},
  pages={664--671},
  year={2008}
}

@inproceedings{devraj2017zap,
  title={Zap Q-learning},
  author={Devraj, Adithya M and Meyn, Sean},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2235--2244},
  year={2017}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@article{bengio2020interference,
  title={Interference and Generalization in Temporal Difference Learning},
  author={Bengio, Emmanuel and Pineau, Joelle and Precup, Doina},
  journal={arXiv preprint arXiv:2003.06350},
  year={2020}
}

@inproceedings{precup2001offpol,
  title={Off-Policy Temporal Difference Learning with Function Approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={417--424},
  year={2001},
}

@article{dabney2018implicit,
  title={Implicit quantile networks for distributional reinforcement learning},
  author={Dabney, Will and Ostrovski, Georg and Silver, David and Munos, R{\'e}mi},
  journal={arXiv preprint arXiv:1806.06923},
  year={2018}
}

@inproceedings{hausknecht2016policy,
  title={On-policy vs. off-policy updates for deep reinforcement learning},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={Deep Reinforcement Learning: Frontiers and Challenges, IJCAI},
  year={2016}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{martha2018sparse,
  author    = {Vincent Liu and
               Raksha Kumaraswamy and
               Lei Le and
               Martha White},
  title     = {The Utility of Sparse Representations for Control in Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1811.06626},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.06626},
  archivePrefix = {arXiv},
  eprint    = {1811.06626},
  timestamp = {Sun, 25 Nov 2018 18:57:12 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-06626},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{jaques2019way,
  title={Way off-policy batch deep reinforcement learning of implicit human preferences in dialog},
  author={Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang and Picard, Rosalind},
  journal={arXiv preprint arXiv:1907.00456},
  year={2019}
}

@article{shani2005recommender,
  title={An MDP-based recommender system},
  author={Shani, Guy and Heckerman, David and Brafman, Ronen I},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Sep},
  pages={1265--1295},
  year={2005}
}

@inproceedings{szepesvari1998asymptotic,
  title={The asymptotic convergence-rate of Q-learning},
  author={Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1064--1070},
  year={1998}
}

@inproceedings{ijcai2020-370,
  title     = {I4R: Promoting Deep Reinforcement Learning by the Indicator for Expressive Representations},
  author    = {Luo, Xufang and Meng, Qi and He, Di and Chen, Wei and Wang, Yunhong},
  booktitle = {Proceedings of the Twenty-Ninth International Joint Conference on
               Artificial Intelligence, {IJCAI-20}},
  publisher = {International Joint Conferences on Artificial Intelligence Organization},             
  pages     = {2669--2675},
  year      = {2020},
  month     = {7},
  note      = {Main track},
  doi       = {10.24963/ijcai.2020/370},
  url       = {https://doi.org/10.24963/ijcai.2020/370},
}

@article{yoshida2017spectral,
  title={Spectral norm regularization for improving the generalizability of deep learning},
  author={Yoshida, Yuichi and Miyato, Takeru},
  journal={arXiv preprint arXiv:1705.10941},
  year={2017}
}

@inproceedings{Parr2008AnAO,
  title={An analysis of linear models, linear value-function approximation, and feature selection for reinforcement learning},
  author={Ronald Parr and Lihong Li and Gavin Taylor and Christopher Painter-Wakefield and Michael L. Littman},
  booktitle={ICML '08},
  year={2008}
}


@book{koller_friedman,
 author = {Koller, D. and Friedman, N.},
 title = {Probabilistic Graphical Models: Principles and Techniques},
 year = {2009},
 isbn = {0262013193, 9780262013192},
 publisher = {The MIT Press},
} 

@inproceedings{chebotar2019closing,
  title={Closing the sim-to-real loop: Adapting simulation randomization with real world experience},
  author={Chebotar, Yevgen and Handa, Ankur and Makoviychuk, Viktor and Macklin, Miles and Issac, Jan and Ratliff, Nathan and Fox, Dieter},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8973--8979},
  year={2019},
  organization={IEEE}
}

@article{tan2018sim,
  title={Sim-to-real: Learning agile locomotion for quadruped robots},
  author={Tan, Jie and Zhang, Tingnan and Coumans, Erwin and Iscen, Atil and Bai, Yunfei and Hafner, Danijar and Bohez, Steven and Vanhoucke, Vincent},
  journal={arXiv preprint arXiv:1804.10332},
  year={2018}
}

@inproceedings{sadeghi2016cad2rl,
  title={{CAD2RL}: Real single-image flight without a single real image},
  author={Sadeghi, Fereshteh and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2017}
}

@inproceedings{gae,
title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
author = {J. Schulman and P. Moritz and S. Levine and M. Jordan and P. Abbeel},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2016
}

@misc{kumar_blog,
title = {Data-Driven Deep Reinforcement Learning},
author = {Aviral Kumar},
note = {{BAIR} Blog},
year = {2019},
howpublished  = {\url{https://bair.berkeley.edu/blog/2019/12/05/bear/}}
}

@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{levine2013guided,
  title={Guided policy search},
  author={Levine, Sergey and Koltun, Vladlen},
  booktitle={International Conference on Machine Learning},
  pages={1--9},
  year={2013}
}

@article{luo2019learning,
  title={Learning self-correctable policies and value functions from demonstrations with negative sampling},
  author={Luo, Yuping and Xu, Huazhe and Ma, Tengyu},
  journal={arXiv preprint arXiv:1907.05634},
  year={2019}
}

@inproceedings{mulayoff2020unique,
  title={Unique Properties of Flat Minima in Deep Networks},
  author={Mulayoff, Rotem and Michaeli, Tomer},
  booktitle={International Conference on Machine Learning},
  pages={7108--7118},
  year={2020},
  organization={PMLR}
}

@article{van2018deep,
  title={Deep reinforcement learning and the deadly triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@article{damian2021label,
  title={Label Noise SGD Provably Prefers Flat Global Minimizers},
  author={Damian, Alex and Ma, Tengyu and Lee, Jason},
  journal={arXiv preprint arXiv:2106.06530},
  year={2021}
}

@article{mahmood2015emphatic,
  title={Emphatic temporal-difference learning},
  author={Mahmood, A Rupam and Yu, Huizhen and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1507.01569},
  year={2015}
}

@article{chatterji2019intriguing,
  title={The intriguing role of module criticality in the generalization of deep networks},
  author={Chatterji, Niladri S and Neyshabur, Behnam and Sedghi, Hanie},
  journal={arXiv preprint arXiv:1912.00528},
  year={2019}
}

@article{bjorck2021towards,
  title={Towards Deeper Deep Reinforcement Learning},
  author={Bjorck, Johan and Gomes, Carla P and Weinberger, Kilian Q},
  journal={arXiv preprint arXiv:2106.01151},
  year={2021}
}

@article{ota2021training,
  title={Training Larger Networks for Deep Reinforcement Learning},
  author={Ota, Kei and Jha, Devesh K and Kanezaki, Asako},
  journal={arXiv preprint arXiv:2102.07920},
  year={2021}
}

@article{yang2020feature,
  title={Feature learning in infinite-width neural networks},
  author={Yang, Greg and Hu, Edward J},
  journal={arXiv preprint arXiv:2011.14522},
  year={2020}
}

@article{sinha2020d2rl,
  title={D2rl: Deep dense architectures in reinforcement learning},
  author={Sinha, Samarth and Bharadhwaj, Homanga and Srinivas, Aravind and Garg, Animesh},
  journal={arXiv preprint arXiv:2010.09163},
  year={2020}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354--359},
  year={2017},
  publisher={Nature Publishing Group}
}

@inproceedings{kakade2002natural,
  title={A natural policy gradient},
  author={Kakade, Sham M},
  booktitle={Advances in neural information processing systems},
  pages={1531--1538},
  year={2002}
}


@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in neural information processing systems},
  pages={1057--1063},
  year={2000}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@incollection{lange2012batch,
  title={Batch reinforcement learning},
  author={Lange, Sascha and Gabel, Thomas and Riedmiller, Martin},
  booktitle={Reinforcement learning},
  pages={45--73},
  year={2012},
  publisher={Springer}
}

@InProceedings{thomas,
  title = 	 {Bias in Natural Actor-Critic Algorithms},
  author = 	 {Philip Thomas},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2014},
  month = 	 {22--24 Jun},
}

@inproceedings{toussaint06,
 author = {Toussaint, M. and Storkey, A.},
 title = {Probabilistic Inference for Solving Discrete and Continuous State Markov Decision Processes},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2006},
} 

@INPROCEEDINGS{attias,
    author = {H. Attias},
    title = {Planning by Probabilistic Inference},
    booktitle = {Proceedings of the 9th International Workshop on Artificial Intelligence and Statistics},
    year = {2003}
}

@article{hafner2011reinforcement,
  title={Reinforcement learning in feedback control},
  author={Hafner, Roland and Riedmiller, Martin},
  journal={Machine learning},
  volume={84},
  number={1-2},
  pages={137--169},
  year={2011},
  publisher={Springer}
}

@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{peters2008reinforcement,
  title={Reinforcement learning of motor skills with policy gradients},
  author={Peters, Jan and Schaal, Stefan},
  journal={Neural networks},
  volume={21},
  number={4},
  pages={682--697},
  year={2008},
  publisher={Elsevier}
}

@article{tesauro1994td,
  title={{TD-Gammon}, a self-teaching backgammon program, achieves master-level play},
  author={Tesauro, Gerald},
  journal={Neural computation},
  volume={6},
  number={2},
  pages={215--219},
  year={1994},
  publisher={MIT Press}
}

@InProceedings{ebrl,
  title = 	 {Actor-Critic Reinforcement Learning with Energy-Based Policies},
  author = 	 {N. Heess and D. Silver and Y. W. Teh},
  booktitle = 	 {European Workshop on Reinforcement Learning (EWRL)},
  year = 	 {2013},
}

@inproceedings{ross2011reduction,
  title={A reduction of imitation learning and structured prediction to no-regret online learning},
  author={Ross, St{\'e}phane and Gordon, Geoffrey and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={627--635},
  year={2011}
}

@inproceedings{ross2010efficient,
  title={Efficient reductions for imitation learning},
  author={Ross, St{\'e}phane and Bagnell, Drew},
  booktitle={International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={661--668},
  year={2010}
}

@inproceedings{kakade2002approximately,
  title={Approximately optimal approximate reinforcement learning},
  author={Kakade, Sham and Langford, John},
  booktitle={International Conference on Machine Learning (ICML)},
  volume={2},
  year={2002}
}

@inproceedings{ep,
 author = {Minka, T. P.},
 title = {Expectation Propagation for Approximate Bayesian Inference},
 booktitle = {Uncertainty in Artificial Intelligence (UAI)},
 year = {2001},
}

@inproceedings{mpo,
title = {Maximum a Posteriori Policy Optimisation},
author = {A. Abdolmaleki and J. T. Springenberg and Y. Tassa and R. Munos and N. Heess and M. Riedmiller},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2018
}

@article{williams,
 author = {Williams, R. J.},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 journal = {Machine Learning},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 pages = {229--256}
} 

@article{WilliamsPeng91,
  author = {Williams, R. J. and Peng, J.},
  journal = {Connection Science},
  number = 3,
  pages = {241-268},
  title = {Function optimization using connectionist reinforcement learning
	algorithms},
  volume = 3,
  year = 1991
}

@book{sb-irl-98,
 author = {Sutton, R. S. and Barto, A. G.},
 title = {Introduction to Reinforcement Learning},
 year = {1998},
 isbn = {0262193981},
 edition = {1st},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@INPROCEEDINGS{suttonadp,
    author = {R. S. Sutton},
    title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {1990},
}

@inproceedings{pgq,
author = {O'Donoghue, B. and Munos, R. and Kavukcuoglu, K. and Mnih, V.},
year = {2017},
title = {PGQ: Combining policy gradient and Q-learning},
booktitle = {International Conference on Learning Representations (ICLR)}
}

@article{sallans,
 author = {Sallans, B. and Hinton, G. E.},
 title = {Reinforcement Learning with Factored States and Actions},
 journal = {Journal of Machine Learning Research},
 volume = {5},
 month = dec,
 year = {2004}
 },

@article{KLMSurvey,
    author = "L. P. Kaelbling and M. L. Littman and A. P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
url={http://people.csail.mit.edu/lpk/papers/rl-survey.ps}}

@inproceedings{todorov_kalman_duality, 
author={E. Todorov}, 
booktitle={Conference on Decision and Control (CDC)},
title={General duality between optimal control and estimation}, 
year={2008},
}

@inproceedings{covariant,
author = {J. A. Bagnell and J. Schneider},
title = {Covariant Policy Search},
booktitle = {International Joint Conference on Artifical Intelligence (IJCAI)},
year = {2003},
}

@InProceedings{reps,
  author =       "Peters, J. and  M{\"u}lling, K. and Alt{\"u}n, Y.",
  title =        "Relative Entropy Policy Search",
  booktitle =    "AAAI Conference on Artificial Intelligence (AAAI)",
  year =         "2010",
}

@inproceedings{mfgps,
title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
author = {Levine, S. and Abbeel, P.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{lmdp_policy,
  author    = {E. Todorov},
  title     = {Policy gradients in linearly-solvable MDPs},
  booktitle = {Neural Information Processing Systems (NIPS)},
  year      = {2010},
}

@inproceedings{ldmp_irl,
 author = {Dvijotham, K. and Todorov, E.},
 title = {Inverse Optimal Control with Linearly-solvable MDPs},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2010},
} 

@inproceedings{bear,
title = {Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction},
author = {Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
booktitle = {Neural Information Processing Systems (NeurIPS)},
year = {2019}
}

@article{lerer2016learning,
  title={Learning physical intuition of block towers by example},
  author={Lerer, Adam and Gross, Sam and Fergus, Rob},
  journal={arXiv preprint arXiv:1603.01312},
  year={2016}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@inproceedings{battaglia2016interaction,
  title={Interaction networks for learning about objects, relations and physics},
  author={Battaglia, Peter and Pascanu, Razvan and Lai, Matthew and Rezende, Danilo Jimenez and others},
  booktitle={Advances in neural information processing systems},
  pages={4502--4510},
  year={2016}
}

@inproceedings{sagawa2019distributionally,
  title={Distributionally Robust Neural Networks},
  author={Sagawa, Shiori and Koh, Pang Wei and Hashimoto, Tatsunori B and Liang, Percy},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{arjovsky2019invariant,
  title={Invariant risk minimization},
  author={Arjovsky, Martin and Bottou, L{\'e}on and Gulrajani, Ishaan and Lopez-Paz, David},
  journal={arXiv preprint arXiv:1907.02893},
  year={2019}
}

@article{sinha2017certifying,
  title={Certifying some distributional robustness with principled adversarial training},
  author={Sinha, Aman and Namkoong, Hongseok and Duchi, John},
  journal={arXiv preprint arXiv:1710.10571},
  year={2017}
}

@inproceedings{kingma2014semi,
  title={Semi-supervised learning with deep generative models},
  author={Kingma, Durk P and Mohamed, Shakir and Rezende, Danilo Jimenez and Welling, Max},
  booktitle={Advances in neural information processing systems},
  pages={3581--3589},
  year={2014}
}

@inproceedings{kendall2017uncertainties,
  title={What uncertainties do we need in bayesian deep learning for computer vision?},
  author={Kendall, Alex and Gal, Yarin},
  booktitle={Advances in neural information processing systems},
  pages={5574--5584},
  year={2017}
}

@inproceedings{gal2016dropout,
  title={Dropout as a bayesian approximation: Representing model uncertainty in deep learning},
  author={Gal, Yarin and Ghahramani, Zoubin},
  booktitle={international conference on machine learning},
  pages={1050--1059},
  year={2016}
}

@article{scholkopf2019causality,
  title={Causality for Machine Learning},
  author={Sch{\"o}lkopf, Bernhard},
  journal={arXiv preprint arXiv:1911.10500},
  year={2019}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{pi2,
  title = {Learning Policy Improvements with Path Integrals},
  author = {Theodorou, E. A. and Buchli, J. and Schaal, S.},
  booktitle = {International Conference on  Artificial Intelligence and Statistics (AISTATS 2010)},
  year = {2010},
}

@InProceedings{trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {J. Schulman and S. Levine and P. Moritz and M. I. Jordan and P. Abbeel},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2015},
}

@phdthesis{levine_thesis,
author = {Levine, S.},
title = {Motor skill learning with local trajectory methods},
school = {Stanford University},
year = {2014},
}

@phdthesis{ziebart_thesis,
author = {Ziebart, B.},
title = {Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
school = {Carnegie Mellon University},
year = {2010},
}

@article{kappen_oc,
  author    = {H. J. Kappen},
  title     = {Optimal control theory and the linear bellman equation},
  journal   = {Inference and Learning in Dynamic Models},
  year      = {2011},
  pages     = {363-387},
}

@inproceedings{heess2015learning,
  title={Learning continuous control policies by stochastic value gradients},
  author={Heess, Nicolas and Wayne, Gregory and Silver, David and Lillicrap, Timothy and Erez, Tom and Tassa, Yuval},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2944--2952},
  year={2015}
}

@inproceedings{haarnoja2017reinforcement,
  title={Reinforcement learning with deep energy-based policies},
  author={Haarnoja, Tuomas and Tang, Haoran and Abbeel, Pieter and Levine, Sergey},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1352--1361},
  year={2017},
  organization={JMLR. org}
}

@article{kappen_pgm,
  author    = {H. J. Kappen and
               V. G{\'o}mez and
               M. Opper},
  title     = {Optimal control as a graphical model inference problem},
  journal   = {Machine Learning},
  volume    = {87},
  number    = {2},
  year      = {2012},
  pages     = {159-182},
}

@inproceedings{rawlik_soc,
  author    = {K. Rawlik and
               M. Toussaint and
               S. Vijayakumar},
  title     = {On Stochastic Optimal Control and Reinforcement Learning
               by Approximate Inference},
  year = {2013},
  booktitle = {Robotics: Science and Systems (RSS)},
}

@inproceedings{toussaint_soc,
  author    = {M. Toussaint},
  title     = {Robot trajectory optimization using approximate inference},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2009},
}

@inproceedings{toussaint_pgm,
  title={Hierarchical POMDP Controller Optimization by Likelihood Maximization},
  author={Toussaint, M. and Charlin, L. and Poupart, P.},
  booktitle={Uncertainty in Artificial Intelligence (UAI)},
  volume={24},
  pages={562--570},
  year={2008}
}

@article{kalman_filter,
  author={R. Kalman},
  title={A new approach to linear filtering and prediction problems},
  journal={ASME Transactions journal of basic engineering},
  volume={82},
  number={1},
  pages={35-45},
  year={1960}
}

@inproceedings{konda2000actor,
  title={Actor-critic algorithms},
  author={Konda, Vijay R and Tsitsiklis, John N},
  booktitle={Advances in neural information processing systems},
  pages={1008--1014},
  year={2000}
}

@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{todorov_lmdp,
  author    = {E. Todorov},
  title     = {Linearly-solvable Markov decision problems},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2006},
}

@inproceedings{rwr,
 author = {Peters, J. and Schaal, S.},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2007},
} 


@inproceedings{neumann,
  author    = {G. Neumann},
  title     = {Variational Inference for Policy Search in changing situations},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2011},
}

@inproceedings{levine_vgps,
  author    = {S. Levine and V. Koltun},
  title     = {Variational policy search via trajectory optimization},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2013},
}

@inproceedings{em_policy_search,
  title = {Efficient Sample Reuse in EM-Based Policy Search},
  author = {Hachiya, H. and Peters, J. and Sugiyama, M.},
  booktitle = {European Conference on Machine Learning (ECML)},
  year = {2009},
}

@article{vmp,
    title={Variational message passing},
    author={Winn, J. and Bishop, C.},
    journal={Journal of Machine Learning Research},
    volume={6},
    year={2005},
    pages={661-694}
}

@inproceedings{haarnoja,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, T. and Tang, H. and Abbeel, P. and Levine, S.},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{sac,
title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
author  = {T. Haarnoja and A. Zhou and P. Abbeel and S. Levine},
year  = {2018},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1801.01290.pdf}
}

@inproceedings{d4rl,
title = {D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
author  = {J. Fu and A. Kumar and O. Nachum and G. Tucker and S. Levine},
year  = {2020},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/2004.07219}
}

@inproceedings{pcl,
title = {Bridging the Gap Between Value and Policy Based Reinforcement Learning},
author  = {O. Nachum and M. Norouzi and K. Xu and D. Schuurmans},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1702.08892.pdf}
}

@inproceedings{gps,
 author = {Levine, S. and Koltun, V.},
 title = {Guided Policy Search},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2013},
} 

@inproceedings{maxentirl,
 author = {Ziebart, B. D. and Maas, A. and Bagnell, J. A. and Dey, A. K.},
 title = {Maximum Entropy Inverse Reinforcement Learning},
 booktitle = {International Conference on Artificial Intelligence (AAAI)},
 year = {2008},
} 

@inproceedings{haarnoja_composable,
author = {Haarnjoa, T. and Pong, V. and Zhou, A. and Dalal, M. and Abbeel, P. and Levine, S.},
title = {Composable Deep Reinforcement Learning for Robotic Manipulation},
booktitle = {International Conference on Robotics and Automation (ICRA)},
year = {2018},
}

@article{trust_pcl,
  author    = {O. Nachum and
               M. Norouzi and
               K. Xu and
               D. Schuurmans},
  title     = {Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1707.01891},
  year      = {2017},
}

@inproceedings{gpirl,
 author = {Levine, S. and Popovi\'{c}, Z. and Koltun, V.},
 title = {Nonlinear Inverse Reinforcement Learning with Gaussian Processes},
 booktitle = {Neural Information Processing Systems (NIPS)},
 year = {2011},
}

@inproceedings{localioc,
    author = {S. Levine and V. Koltun},
    title = {Continuous Inverse Optimal Control with Locally Optimal Examples},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2012},
}

@inproceedings{legibility,
  author    = {A. D. Dragan and
               K. C. T. Lee and
               S. S. Srinivasa},
  title     = {Legibility and predictability of robot motion},
  booktitle = {International Conference on Human-Robot Interaction (HRI)},
  year      = {2013},
}

@inproceedings{maxentdeepirl,
author = {M. Wulfmeier and
P. Ondruska and
I. Posner},
title = {Maximum Entropy Deep Inverse Reinforcement Learning},
Booktitle = {Neural Information Processing Systems Conference, Deep Reinforcement Learning Workshop},
year = {2015},
}

@inproceedings{maxcausalent,
  author    = {B. D. Ziebart and
               J. A. Bagnell and
               A. K. Dey},
  title     = {Modeling Interaction via the Principle of Maximum Causal Entropy},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2010},
}

@inproceedings{kitani1,
  author    = {D. Huang and
               K. M. Kitani},
  title     = {Action-Reaction: Forecasting the Dynamics of Human Interaction},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2014},
}

@inproceedings{kitani2,
  author    = {D. Huang and
               A. Farahmand and
               K. M. Kitani and
               J. A. Bagnell},
  title     = {Approximate {MaxEnt} Inverse Optimal Control and Its Application for
               Mental Simulation of Human Interactions},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2015},
}

@article{realnvp,
title={Latent Space Policies for Hierarchical Reinforcement Learning},
author={T. Haarnoja and K. Hartikainen and P. Abbeel and S. Levine},
journal   = {CoRR},
volume    = {abs/1804.02808},
year      = {2018},
}

@inproceedings{Javdani, 
    AUTHOR    = {S. Javdani and S. Srinivasa and J. A. Bagnell}, 
    TITLE     = {Shared Autonomy via Hindsight Optimization}, 
    BOOKTITLE = {Robotics: Science and Systems (RSS)}, 
    YEAR      = {2015}, 
}

@inproceedings{airl,
title={Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
author={Fu, J. and Luo, K. and Levine, S.},
}

@inproceedings{hausman,
title={Learning an Embedding Space for Transferable Robot Skills},
author={K. Hausman and J. T. Springenberg and Z. Wang and N. Heess and M. Riedmiller},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
}

@article{learning_to_explore,
  author    = {A. Gupta and
               R. Mendonca and
               Y. Liu and
               P. Abbeel and
               S. Levine},
  title     = {Meta-Reinforcement Learning of Structured Exploration Strategies},
  journal   = {CoRR},
  volume    = {abs/1802.07245},
  year      = {2018},
}

@article{endtoend,
 author = {Levine, S. and Finn, C. and Darrell, T. and Abbeel, P.},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {Journal of Machine Learning Research},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
} 

@inproceedings{cgps,
    author = {Sergey Levine and Vladlen Koltun},
    title = {Learning Complex Neural Network Policies with Trajectory Optimization},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2014},
}
@inproceedings{schulman,
title = {Equivalence Between Policy Gradients and Soft Q-Learning},
author  = {J. Schulman and X. Chen and P. Abbeel},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1704.06440}
}

@inproceedings{nvil,
  author    = {A. Mnih and
               K. Gregor},
  title     = {Neural Variational Inference and Learning in Belief Networks},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2014}
}

@inproceedings{gcl,
  author    = {Chelsea Finn and
               Sergey Levine and
               Pieter Abbeel},
  title     = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
    booktitle   = {International Conference on Machine Learning (ICML)},
  year      = {2016},
}

@inproceedings{gan,
title = {Generative Adversarial Nets},
author = {Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{gail,
title = {Generative Adversarial Imitation Learning},
author = {Ho, J. and Ermon, S.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2016},
}

@article{finn_adversarial,
  author    = {Chelsea Finn and
               Paul Christiano and
               Pieter Abbeel and
               Sergey Levine},
  title     = {A Connection between Generative Adversarial Networks, Inverse Reinforcement
               Learning, and Energy-Based Models},
  journal   = {CoRR},
  volume    = {abs/1611.03852},
  year      = {2016},
}

@inproceedings{bornschein2016bidirectional,
  title={Bidirectional helmholtz machines},
  author={Bornschein, Jorg and Shabanian, Samira and Fischer, Asja and Bengio, Yoshua},
  booktitle={International Conference on Machine Learning},
  pages={2511--2519},
  year={2016}
}

@article{marino2018iterative,
  title={Iterative amortized inference},
  author={Marino, Joseph and Yue, Yisong and Mandt, Stephan},
  journal={arXiv preprint arXiv:1807.09356},
  year={2018}
}

@inproceedings{rasmus2015semi,
  title={Semi-supervised learning with ladder networks},
  author={Rasmus, Antti and Berglund, Mathias and Honkala, Mikko and Valpola, Harri and Raiko, Tapani},
  booktitle={Advances in neural information processing systems},
  pages={3546--3554},
  year={2015}
}

@inproceedings{sonderby2016ladder,
  title={Ladder variational autoencoders},
  author={S{\o}nderby, Casper Kaae and Raiko, Tapani and Maal{\o}e, Lars and S{\o}nderby, S{\o}ren Kaae and Winther, Ole},
  booktitle={Advances in neural information processing systems},
  pages={3738--3746},
  year={2016}
}

@inproceedings{zhao2017learning,
  title={Learning hierarchical features from deep generative models},
  author={Zhao, Shengjia and Song, Jiaming and Ermon, Stefano},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={4091--4099},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{hsu2017unsupervised,
  title={Unsupervised learning of disentangled and interpretable representations from sequential data},
  author={Hsu, Wei-Ning and Zhang, Yu and Glass, James},
  booktitle={Advances in neural information processing systems},
  pages={1878--1889},
  year={2017}
}


@inproceedings{kalashnikov2018qtopt,
  title={Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  pages={651--673},
  year={2018}
}

@article{cabi2019framework,
  title={A Framework for Data-Driven Robotics},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and {\.Z}o{\l}na, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

 @article{Mo18AdobeIndoorNav,
        Author = {Kaichun Mo and Haoxiang Li and Zhe Lin and Joon-Young Lee},
        Title = {The AdobeIndoorNav Dataset: Towards Deep Reinforcement Learning based Real-world Indoor Robot Visual Navigation},
        Year = {2018},
        Eprint = {arXiv:1802.08824},
    }
    
@article{kandasamy2017batch,
  title={Batch policy gradient methods for improving neural conversation models},
  author={Kandasamy, Kirthevasan and Bachrach, Yoram and Tomioka, Ryota and Tarlow, Daniel and Carter, David},
  journal={arXiv preprint arXiv:1702.03334},
  year={2017}
}

@inproceedings{zhang2018deep,
  title={Deep imitation learning for complex manipulation tasks from virtual reality teleoperation},
  author={Zhang, Tianhao and McCarthy, Zoe and Jow, Owen and Lee, Dennis and Chen, Xi and Goldberg, Ken and Abbeel, Pieter},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={5628--5635},
  year={2018},
  organization={IEEE}
}

@inproceedings{sun2018fast,
  title={A fast integrated planning and control framework for autonomous driving via imitation learning},
  author={Sun, Liting and Peng, Cheng and Zhan, Wei and Tomizuka, Masayoshi},
  booktitle={Dynamic Systems and Control Conference},
  volume={51913},
  pages={V003T37A012},
  year={2018},
  organization={American Society of Mechanical Engineers}
}

@article{zhou2017end,
  title={End-to-end offline goal-oriented dialog policy learning via policy gradient},
  author={Zhou, Li and Small, Kevin and Rokhlenko, Oleg and Elkan, Charles},
  journal={arXiv preprint arXiv:1712.02838},
  year={2017}
}

@article{pan2017agile,
  title={Agile autonomous driving using end-to-end deep imitation learning},
  author={Pan, Yunpeng and Cheng, Ching-An and Saigol, Kamil and Lee, Keuntaek and Yan, Xinyan and Theodorou, Evangelos and Boots, Byron},
  journal={arXiv preprint arXiv:1709.07174},
  year={2017}
}

@article{nie2019learning,
  title={Learning when-to-treat policies},
  author={Nie, Xinkun and Brunskill, Emma and Wager, Stefan},
  journal={arXiv preprint arXiv:1905.09751},
  year={2019}
}

@article{bojarski2016end,
  title={End to end learning for self-driving cars},
  author={Bojarski, Mariusz and Del Testa, Davide and Dworakowski, Daniel and Firner, Bernhard and Flepp, Beat and Goyal, Prasoon and Jackel, Lawrence D and Monfort, Mathew and Muller, Urs and Zhang, Jiakai and others},
  journal={arXiv preprint arXiv:1604.07316},
  year={2016}
}

@article{yu2018bdd100k,
  title={Bdd100k: A diverse driving video database with scalable annotation tooling},
  author={Yu, Fisher and Xian, Wenqi and Chen, Yingying and Liu, Fangchen and Liao, Mike and Madhavan, Vashisht and Darrell, Trevor},
  journal={arXiv preprint arXiv:1805.04687},
  year={2018}
}

@article{sallab2017deep,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}

@article{yurtsever2020survey,
  title={A survey of autonomous driving: Common practices and emerging technologies},
  author={Yurtsever, Ekim and Lambert, Jacob and Carballo, Alexander and Takeda, Kazuya},
  journal={IEEE Access},
  year={2020},
  publisher={IEEE}
}

@inproceedings{kendall2019learning,
  title={Learning to drive in a day},
  author={Kendall, Alex and Hawke, Jeffrey and Janz, David and Mazur, Przemyslaw and Reda, Daniele and Allen, John-Mark and Lam, Vinh-Dieu and Bewley, Alex and Shah, Amar},
  booktitle={2019 International Conference on Robotics and Automation (ICRA)},
  pages={8248--8254},
  year={2019},
  organization={IEEE}
}

@article{maddern2017robotcar,
  title={1 year, 1000 km: The Oxford RobotCar dataset},
  author={Maddern, Will and Pascoe, Geoffrey and Linegar, Chris and Newman, Paul},
  journal={The International Journal of Robotics Research},
  volume={36},
  number={1},
  pages={3--15},
  year={2017},
  publisher={SAGE Publications Sage UK: London, England}
}

@inproceedings{codevilla2018end,
  title={End-to-end driving via conditional imitation learning},
  author={Codevilla, Felipe and Miiller, Matthias and L{\'o}pez, Antonio and Koltun, Vladlen and Dosovitskiy, Alexey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1--9},
  year={2018},
  organization={IEEE}
}

@inproceedings{tassa2012synthesis,
  title={Synthesis and stabilization of complex behaviors through online trajectory optimization},
  author={Tassa, Yuval and Erez, Tom and Todorov, Emanuel},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={4906--4913},
  year={2012},
  organization={IEEE}
}

@inproceedings{pets,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4754--4765},
  year={2018}
}

@inproceedings{nagabandi2018neural,
  title={Neural network dynamics for model-based deep reinforcement learning with model-free fine-tuning},
  author={Nagabandi, Anusha and Kahn, Gregory and Fearing, Ronald S and Levine, Sergey},
  booktitle={2018 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={7559--7566},
  year={2018},
  organization={IEEE}
}

@inproceedings{gu2017deep,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={2017 IEEE international conference on robotics and automation (ICRA)},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@article{pietquin2011sample,
  title={Sample-efficient batch reinforcement learning for dialogue management optimization},
  author={Pietquin, Olivier and Geist, Matthieu and Chandramohan, Senthilkumar and Frezza-Buet, Herv{\'e}},
  journal={ACM Transactions on Speech and Language Processing (TSLP)},
  volume={7},
  number={3},
  pages={1--21},
  year={2011},
  publisher={ACM New York, NY, USA}
}

@article{gottesman2019guidelines,
  title={Guidelines for reinforcement learning in healthcare},
  author={Gottesman, Omer and Johansson, Fredrik and Komorowski, Matthieu and Faisal, Aldo and Sontag, David and Doshi-Velez, Finale and Celi, Leo Anthony},
  journal={Nat Med},
  volume={25},
  number={1},
  pages={16--18},
  year={2019}
}

@inproceedings{swaminathan2015self,
  title={The self-normalized estimator for counterfactual learning},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={advances in neural information processing systems},
  pages={3231--3239},
  year={2015}
}

@book{rockafellar1970convex,
  title={Convex analysis},
  author={Rockafellar, R Tyrrell},
  number={28},
  year={1970},
  publisher={Princeton university press}
}

@article{nachum2020reinforcement,
  title={Reinforcement Learning via Fenchel-Rockafellar Duality},
  author={Nachum, Ofir and Dai, Bo},
  journal={arXiv preprint arXiv:2001.01866},
  year={2020}
}

@inproceedings{nachum2019dualdice,
  title={Dualdice: Behavior-agnostic estimation of discounted stationary distribution corrections},
  author={Nachum, Ofir and Chow, Yinlam and Dai, Bo and Li, Lihong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2315--2325},
  year={2019}
}

@article{eysenbach2017leave,
  title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
  author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.06782},
  year={2017}
}

@article{levine2018reinforcement,
  title={Reinforcement learning and control as probabilistic inference: Tutorial and review},
  author={Levine, Sergey},
  journal={arXiv preprint arXiv:1805.00909},
  year={2018}
}

@inproceedings{osband2018randomized,
  title={Randomized prior functions for deep reinforcement learning},
  author={Osband, Ian and Aslanides, John and Cassirer, Albin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8617--8629},
  year={2018}
}


@inproceedings{lakshminarayanan2017simple,
  title={Simple and scalable predictive uncertainty estimation using deep ensembles},
  author={Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
  booktitle={Advances in neural information processing systems},
  pages={6402--6413},
  year={2017}
}

@article{achiam2019towards,
  title={Towards characterizing divergence in deep q-learning},
  author={Achiam, Joshua and Knight, Ethan and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1903.08894},
  year={2019}
}

@article{gupta2019relay,
  title={Relay Policy Learning: Solving Long-Horizon Tasks via Imitation and Reinforcement Learning},
  author={Gupta, Abhishek and Kumar, Vikash and Lynch, Corey and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:1910.11956},
  year={2019}
}

@inproceedings{osband2016deep,
  title={Deep exploration via bootstrapped DQN},
  author={Osband, Ian and Blundell, Charles and Pritzel, Alexander and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={4026--4034},
  year={2016}
}

@article{lagoudakis2003least,
  title={Least-squares policy iteration},
  author={Lagoudakis, Michail G and Parr, Ronald},
  journal={Journal of machine learning research},
  volume={4},
  number={Dec},
  pages={1107--1149},
  year={2003}
}

@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM Sigart Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011}
}

@article{johnson2016mimic,
  title={MIMIC-III, a freely accessible critical care database},
  author={Johnson, Alistair EW and Pollard, Tom J and Shen, Lu and Li-wei, H Lehman and Feng, Mengling and Ghassemi, Mohammad and Moody, Benjamin and Szolovits, Peter and Celi, Leo Anthony and Mark, Roger G},
  journal={Scientific data},
  volume={3},
  pages={160035},
  year={2016},
  publisher={Nature Publishing Group}
}

@inproceedings{guez2008adaptive,
  title={Adaptive Treatment of Epilepsy via Batch-mode Reinforcement Learning.},
  author={Guez, Arthur and Vincent, Robert D and Avoli, Massimo and Pineau, Joelle},
  booktitle={AAAI},
  pages={1671--1678},
  year={2008}
}

@article{pipps,
  title={PIPPS: Flexible model-based policy search robust to the curse of chaos},
  author={Parmas, Paavo and Rasmussen, Carl Edward and Peters, Jan and Doya, Kenji},
  journal={arXiv preprint arXiv:1902.01240},
  year={2019}
}

@article{simpl,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@inproceedings{mbpo,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12498--12509},
  year={2019}
}

@article{raghu2017deep,
  title={Deep reinforcement learning for sepsis treatment},
  author={Raghu, Aniruddh and Komorowski, Matthieu and Ahmed, Imran and Celi, Leo and Szolovits, Peter and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:1711.09602},
  year={2017}
}

@article{prasad2017reinforcement,
  title={A reinforcement learning approach to weaning of mechanical ventilation in intensive care units},
  author={Prasad, Niranjani and Cheng, Li-Fang and Chivers, Corey and Draugelis, Michael and Engelhardt, Barbara E},
  journal={arXiv preprint arXiv:1704.06300},
  year={2017}
}

@inproceedings{swaminathan2017off,
  title={Off-policy evaluation for slate recommendation},
  author={Swaminathan, Adith and Krishnamurthy, Akshay and Agarwal, Alekh and Dudik, Miro and Langford, John and Jose, Damien and Zitouni, Imed},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3632--3642},
  year={2017}
}

@inproceedings{osband2017posterior,
  title={Why is posterior sampling better than optimism for reinforcement learning?},
  author={Osband, Ian and Van Roy, Benjamin},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={2701--2710},
  year={2017},
  organization={JMLR. org}
}

@article{peng2019awr,
  title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{sriperumbudur2009integral,
  title={On integral probability metrics,$\backslash$phi-divergences and binary classification},
  author={Sriperumbudur, Bharath K and Fukumizu, Kenji and Gretton, Arthur and Sch{\"o}lkopf, Bernhard and Lanckriet, Gert RG},
  journal={arXiv preprint arXiv:0901.2698},
  year={2009}
}

@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}

@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11761--11771},
  year={2019}
}

@article{siegel2020keep,
  title={Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning},
  author={Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Riedmiller, Martin},
  journal={arXiv preprint arXiv:2002.08396},
  year={2020}
}

@inproceedings{nowozin2016f,
  title={f-gan: Training generative neural samplers using variational divergence minimization},
  author={Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
  booktitle={Advances in neural information processing systems},
  pages={271--279},
  year={2016}
}

@article{wu2019domain,
  title={Domain adaptation with asymmetrically-relaxed distribution alignment},
  author={Wu, Yifan and Winston, Ezra and Kaushik, Divyansh and Lipton, Zachary},
  journal={arXiv preprint arXiv:1903.01689},
  year={2019}
}

@inproceedings{sutton2009fastgtd,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S and Maei, Hamid Reza and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={993--1000},
  year={2009}
}


@article{alphastar,
  title={Mastering the Real-Time Strategy Game StarCraft II},
  author={AlphaStar, DeepMind},
  journal={URL: https://deepmind. com/blog/alphastar-mastering-real-time-strategy-game-starcraft-ii}
}

@article{lu2018general,
  title={A General Family of Robust Stochastic Operators for Reinforcement Learning},
  author={Lu, Yingdong and Squillante, Mark S and Wu, Chai Wah},
  journal={arXiv preprint arXiv:1805.08122},
  year={2018}
}

@inproceedings{
Zhang2020GenDICE:,
title={GenDICE: Generalized Offline Estimation of Stationary Values},
author={Ruiyi Zhang and Bo Dai and Lihong Li and Dale Schuurmans},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=HkxlcnVFwB}
}

@inproceedings{imagenet,
  title={Imagenet: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={2009 IEEE conference on computer vision and pattern recognition},
  pages={248--255},
  year={2009},
  organization={Ieee}
}

@inproceedings{resnet,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@article{bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@inproceedings{bellemare2016increasing,
  title={Increasing the action gap: New operators for reinforcement learning},
  author={Bellemare, Marc G and Ostrovski, Georg and Guez, Arthur and Thomas, Philip S and Munos, R{\'e}mi},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{rajeswaran2018dapg,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  booktitle={Robotics: Science and Systems},
  year={2018}
}

@inproceedings{hester2018deep,
  title={Deep q-learning from demonstrations},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Horgan, Dan and Quan, John and Sendonaris, Andrew and Osband, Ian and others},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@article{vecerik2017leveraging,
  title={Leveraging demonstrations for deep reinforcement learning on robotics problems with sparse rewards},
  author={Vecerik, Mel and Hester, Todd and Scholz, Jonathan and Wang, Fumin and Pietquin, Olivier and Piot, Bilal and Heess, Nicolas and Roth{\"o}rl, Thomas and Lampe, Thomas and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1707.08817},
  year={2017}
}

@article{bellemare2013arcade,
  title={The arcade learning environment: An evaluation platform for general agents},
  author={Bellemare, Marc G and Naddaf, Yavar and Veness, Joel and Bowling, Michael},
  journal={Journal of Artificial Intelligence Research},
  volume={47},
  pages={253--279},
  year={2013}
}

@inproceedings{dabney2018distributional,
  title={Distributional reinforcement learning with quantile regression},
  author={Dabney, Will and Rowland, Mark and Bellemare, Marc G and Munos, R{\'e}mi},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@misc{
sachdeva2020offpolicy,
title={Off-policy Bandits with Deficient Support},
author={Noveen Sachdeva and Yi Su and Thorsten Joachims},
year={2020},
url={https://openreview.net/forum?id=SklcyJBtvB}
}

@inproceedings{li2010contextual,
  title={A contextual-bandit approach to personalized news article recommendation},
  author={Li, Lihong and Chu, Wei and Langford, John and Schapire, Robert E},
  booktitle={Proceedings of the 19th international conference on World wide web},
  pages={661--670},
  year={2010}
}

@article{o2018variational,
  title={Variational Bayesian reinforcement learning with regret bounds},
  author={O'Donoghue, Brendan},
  journal={arXiv preprint arXiv:1807.09647},
  year={2018}
}

@inproceedings{hasselt2010double,
  title={Double Q-learning},
  author={Hasselt, Hado V},
  booktitle={Advances in neural information processing systems},
  pages={2613--2621},
  year={2010}
}

@article{burda2018exploration,
  title={Exploration by random network distillation},
  author={Burda, Yuri and Edwards, Harrison and Storkey, Amos and Klimov, Oleg},
  journal={arXiv preprint arXiv:1810.12894},
  year={2018}
}

@InProceedings{fujimoto2018addressing,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@misc{d4rl_repo,
title = {D4RL: Datasets for Data-Driven Deep Reinforcement Learning},
author = {Fu, Justin and Kumar, Aviral and Nachum, Ofir and Tucker, George and Levine, Sergey},
note = {Github repository},
year = {2020},
howpublished  = {\url{https://github.com/rail-berkeley/d4rl/wiki/New-Franka-Kitchen-Tasks}}
}



@inproceedings{blanc2020implicit,
  title={Implicit regularization for deep neural networks driven by an ornstein-uhlenbeck like process},
  author={Blanc, Guy and Gupta, Neha and Valiant, Gregory and Valiant, Paul},
  booktitle={Conference on learning theory},
  pages={483--513},
  year={2020},
  organization={PMLR}
}

@article{furuichi2004fundamental,
  title={Fundamental properties of Tsallis relative entropy},
  author={Furuichi, Shigeru and Yanagi, Kenjiro and Kuriyama, Ken},
  journal={Journal of Mathematical Physics},
  volume={45},
  number={12},
  pages={4868--4877},
  year={2004},
  publisher={American Institute of Physics}
}

@inproceedings{namkoong2017variance,
  title={Variance-based regularization with convex objectives},
  author={Namkoong, Hongseok and Duchi, John C},
  booktitle={Advances in neural information processing systems},
  pages={2971--2980},
  year={2017}
}

@inproceedings{tamar2014scaling,
  title={Scaling up robust MDPs using function approximation},
  author={Tamar, Aviv and Mannor, Shie and Xu, Huan},
  booktitle={International Conference on Machine Learning},
  pages={181--189},
  year={2014}
}

@article{nair2020accelerating,
  title={Accelerating Online Reinforcement Learning with Offline Datasets},
  author={Nair, Ashvin and Dalal, Murtaza and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.09359},
  year={2020}
}

@inproceedings{nilim2004robustness,
  title={Robustness in Markov decision problems with uncertain transition matrices},
  author={Nilim, Arnab and El Ghaoui, Laurent},
  booktitle={Advances in neural information processing systems},
  pages={839--846},
  year={2004}
}

@article{russel2018tight,
  title={Tight bayesian ambiguity sets for robust MDPs},
  author={Russel, Reazul Hasan and Petrik, Marek},
  journal={arXiv preprint arXiv:1811.06512},
  year={2018}
}

@article{iyengar2005robust,
  title={Robust dynamic programming},
  author={Iyengar, Garud N},
  journal={Mathematics of Operations Research},
  volume={30},
  number={2},
  pages={257--280},
  year={2005},
  publisher={INFORMS}
}

@inproceedings{ghavamzadeh2016safe,
  title={Safe policy improvement by minimizing robust baseline regret},
  author={Petrik, Marek and Ghavamzadeh, Mohammad and Chow, Yinlam},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2298--2306},
  year={2016}
}

@inproceedings{strehl2010learning,
  title={Learning from logged implicit exploration data},
  author={Strehl, Alex and Langford, John and Li, Lihong and Kakade, Sham M},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2217--2225},
  year={2010}
}

@article{simao2019safe,
  title={Safe Policy Improvement with an Estimated Baseline Policy},
  author={Sim{\~a}o, Thiago D and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1909.05236},
  year={2019}
}

@article{laroche2017safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1712.06924},
  year={2017}
}

@article{nachum2019algaedice,
  title={AlgaeDICE: Policy Gradient from Arbitrary Experience},
  author={Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1912.02074},
  year={2019}
}

@article{brac,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{jaksch2010near,
  title={Near-optimal regret bounds for reinforcement learning},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={Apr},
  pages={1563--1600},
  year={2010}
}

@inproceedings{o2018uncertainty,
  title={The Uncertainty Bellman Equation and Exploration},
  author={O’Donoghue, Brendan and Osband, Ian and Munos, Remi and Mnih, Volodymyr},
  booktitle={International Conference on Machine Learning},
  pages={3836--3845},
  year={2018}
}

@inproceedings{gilotte2018offline,
  title={Offline a/b testing for recommender systems},
  author={Gilotte, Alexandre and Calauz{\`e}nes, Cl{\'e}ment and Nedelec, Thomas and Abraham, Alexandre and Doll{\'e}, Simon},
  booktitle={Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining},
  pages={198--206},
  year={2018}
}

@article{bottou2013counterfactual,
  title={Counterfactual reasoning and learning systems: The example of computational advertising},
  author={Bottou, L{\'e}on and Peters, Jonas and Qui{\~n}onero-Candela, Joaquin and Charles, Denis X and Chickering, D Max and Portugaly, Elon and Ray, Dipankar and Simard, Patrice and Snelson, Ed},
  journal={The Journal of Machine Learning Research},
  volume={14},
  number={1},
  pages={3207--3260},
  year={2013},
  publisher={JMLR. org}
}

@inproceedings{theocharous2015personalized,
  title={Personalized ad recommendation systems for life-time value optimization with guarantees},
  author={Theocharous, Georgios and Thomas, Philip S and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Fourth International Joint Conference on Artificial Intelligence},
  year={2015}
}


@article{henderson2008hybrid,
  title={Hybrid reinforcement/supervised learning of dialogue policies from fixed data sets},
  author={Henderson, James and Lemon, Oliver and Georgila, Kallirroi},
  journal={Computational Linguistics},
  volume={34},
  number={4},
  pages={487--511},
  year={2008},
  publisher={MIT Press}
}


@inproceedings{tesauro2006hybrid,
  title={A hybrid reinforcement learning approach to autonomic resource allocation},
  author={Tesauro, Gerald and Jong, Nicholas K and Das, Rajarshi and Bennani, Mohamed N},
  booktitle={2006 IEEE International Conference on Autonomic Computing},
  pages={65--73},
  year={2006},
  organization={IEEE}
}

@inproceedings{nazari2018reinforcement,
  title={Reinforcement learning for solving the vehicle routing problem},
  author={Nazari, Mohammadreza and Oroojlooy, Afshin and Snyder, Lawrence and Tak{\'a}c, Martin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={9839--9849},
  year={2018}
}

@article{balaji2010urban,
  title={Urban traffic signal control using reinforcement learning agents},
  author={Balaji, PG and German, X and Srinivasan, Dipti},
  journal={IET Intelligent Transport Systems},
  volume={4},
  number={3},
  pages={177--188},
  year={2010},
  publisher={IET}
}

@inproceedings{hein2017industrial,
  title={Batch reinforcement learning on the industrial benchmark: First experiences},
  author={Hein, Daniel and Udluft, Steffen and Tokic, Michel and Hentschel, Alexander and Runkler, Thomas A and Sterzing, Volkmar},
  booktitle={2017 International Joint Conference on Neural Networks (IJCNN)},
  pages={4214--4221},
  year={2017},
  organization={IEEE}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@article{wang2016sample,
  title={Sample efficient actor-critic with experience replay},
  author={Wang, Ziyu and Bapst, Victor and Heess, Nicolas and Mnih, Volodymyr and Munos, Remi and Kavukcuoglu, Koray and de Freitas, Nando},
  journal={arXiv preprint arXiv:1611.01224},
  year={2016}
}

@inproceedings{achiam2017constrained,
  title={Constrained policy optimization},
  author={Achiam, Joshua and Held, David and Tamar, Aviv and Abbeel, Pieter},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={22--31},
  year={2017},
  organization={JMLR. org}
}


@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@article{fu2019diagnosing,
  title={Diagnosing bottlenecks in deep {Q}-learning algorithms},
  author={Fu, Justin and Kumar, Aviral and Soh, Matthew and Levine, Sergey},
  journal={arXiv preprint arXiv:1902.10250},
  year={2019}
}

@inproceedings{imani2018off,
  title={An off-policy policy gradient theorem using emphatic weightings},
  author={Imani, Ehsan and Graves, Eric and White, Martha},
  booktitle={Advances in Neural Information Processing Systems},
  pages={96--106},
  year={2018}
}

@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year={2014}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@inproceedings{gu2017interpolated,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in neural information processing systems},
  pages={3846--3855},
  year={2017}
}

@inproceedings{gelada2019off,
  title={Off-policy deep reinforcement learning by bootstrapping the covariate shift},
  author={Gelada, Carles and Bellemare, Marc G},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  pages={3647--3655},
  year={2019}
}

@article{gabel2008adaptive,
  title={Adaptive reactive job-shop scheduling with reinforcement learning agents},
  author={Gabel, Thomas and Riedmiller, Martin},
  journal={International Journal of Information Technology and Intelligent Computing},
  volume={24},
  number={4},
  pages={14--18},
  year={2008},
  publisher={Citeseer}
}

@article{precup2000eligibility,
  title={Eligibility traces for off-policy policy evaluation},
  author={Precup, Doina},
  journal={Computer Science Department Faculty Publication Series},
  pages={80},
  year={2000}
}

@article{peshkin2002learning,
  title={Learning from scarce experience},
  author={Peshkin, Leonid and Shelton, Christian R},
  journal={arXiv preprint cs/0204043},
  year={2002}
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={ICML},
  pages={417--424},
  year={2001}
}

@inproceedings{hallak2017consistent,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={1372--1383},
  year={2017},
  organization={JMLR. org}
}

@inproceedings{thomas2016data,
  title={Data-efficient off-policy policy evaluation for reinforcement learning},
  author={Thomas, Philip and Brunskill, Emma},
  booktitle={International Conference on Machine Learning},
  pages={2139--2148},
  year={2016}
}

@inproceedings{wang2017optimal,
  title={Optimal and adaptive off-policy evaluation in contextual bandits},
  author={Wang, Yu-Xiang and Agarwal, Alekh and Dudik, Miroslav},
  booktitle={Proceedings of the 34th International Conference on Machine Learning-Volume 70},
  pages={3589--3597},
  year={2017},
  organization={JMLR. org}
}

@article{jiang2015doubly,
  title={Doubly robust off-policy value evaluation for reinforcement learning},
  author={Jiang, Nan and Li, Lihong},
  journal={arXiv preprint arXiv:1511.03722},
  year={2015}
}

@article{farajtabar2018more,
  title={More robust doubly robust off-policy evaluation},
  author={Farajtabar, Mehrdad and Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1802.03493},
  year={2018}
}

@inproceedings{thomas2015high,
  title={High confidence policy improvement},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={2380--2388},
  year={2015}
}


@inproceedings{scherrer2014approximate,
  title={Approximate policy iteration schemes: a comparison},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning},
  pages={1314--1322},
  year={2014}
}


@article{xie2020q,
  title={Q* Approximation Schemes for Batch Reinforcement Learning: A eoretical Comparison},
  author={Xie, Tengyang and Jiang, Nan},
  year={2020}
}

@inproceedings{hanna2017bootstrapping,
  title={Bootstrapping with models: Confidence intervals for off-policy evaluation},
  author={Hanna, Josiah P and Stone, Peter and Niekum, Scott},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@inproceedings{thomas2015higheval,
  title={High-confidence off-policy evaluation},
  author={Thomas, Philip S and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={Twenty-Ninth AAAI Conference on Artificial Intelligence},
  year={2015}
}


@article{gu2016q,
  title={Q-prop: Sample-efficient policy gradient with an off-policy critic},
  author={Gu, Shixiang and Lillicrap, Timothy and Ghahramani, Zoubin and Turner, Richard E and Levine, Sergey},
  journal={arXiv preprint arXiv:1611.02247},
  year={2016}
}

@article{nadjahi2019safe,
  title={Safe Policy Improvement with Soft Baseline Bootstrapping},
  author={Nadjahi, Kimia and Laroche, Romain and Combes, R{\'e}mi Tachet des},
  journal={arXiv preprint arXiv:1907.05079},
  year={2019}
}

@article{cheng2019trajectory,
  title={Trajectory-wise control variates for variance reduction in policy gradient methods},
  author={Cheng, Ching-An and Yan, Xinyan and Boots, Byron},
  journal={arXiv preprint arXiv:1908.03263},
  year={2019}
}

@article{pankov2018reward,
  title={Reward-estimation variance elimination in sequential decision processes},
  author={Pankov, Sergey},
  journal={arXiv preprint arXiv:1811.06225},
  year={2018}
}

@article{huang2019importance,
  title={From Importance Sampling to Doubly Robust Policy Gradient},
  author={Huang, Jiawei and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.09066},
  year={2019}
}

@article{sutton2016emphatic,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{yu2015convergence,
  title={On convergence of emphatic temporal-difference learning},
  author={Yu, Huizhen},
  booktitle={Conference on Learning Theory},
  pages={1724--1751},
  year={2015}
}

@inproceedings{hallak2016generalized,
  title={Generalized emphatic temporal difference learning: Bias-variance analysis},
  author={Hallak, Assaf and Tamar, Aviv and Munos, R{\'e}mi and Mannor, Shie},
  booktitle={Thirtieth AAAI Conference on Artificial Intelligence},
  year={2016}
}

@inproceedings{zhang2019generalized,
  title={Generalized off-policy actor-critic},
  author={Zhang, Shangtong and Boehmer, Wendelin and Whiteson, Shimon},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1999--2009},
  year={2019}
}

@article{agarwal2021deep,
  title={Deep reinforcement learning at the edge of the statistical precipice},
  author={Agarwal, Rishabh and Schwarzer, Max and Castro, Pablo Samuel and Courville, Aaron C and Bellemare, Marc},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{fu2021benchmarks,
  title={Benchmarks for deep off-policy evaluation},
  author={Fu, Justin and Norouzi, Mohammad and Nachum, Ofir and Tucker, George and Wang, Ziyu and Novikov, Alexander and Yang, Mengjiao and Zhang, Michael R and Chen, Yutian and Kumar, Aviral and others},
  journal={arXiv preprint arXiv:2103.16596},
  year={2021}
}

@inproceedings{ghasemipour2021emaq,
  title={Emaq: Expected-max q-learning operator for simple yet effective offline and online rl},
  author={Ghasemipour, Seyed Kamyar Seyed and Schuurmans, Dale and Gu, Shixiang Shane},
  booktitle={International Conference on Machine Learning},
  pages={3682--3691},
  year={2021},
  organization={PMLR}
}

@article{hallak2015emphatic,
  title={Emphatic TD Bellman Operator is a Contraction},
  author={Hallak, Assaf and Tamar, Aviv and Mannor, Shie},
  journal={arXiv preprint arXiv:1508.03411},
  year={2015}
}

@inproceedings{liu2018breaking,
  title={Breaking the curse of horizon: Infinite-horizon off-policy estimation},
  author={Liu, Qiang and Li, Lihong and Tang, Ziyang and Zhou, Dengyong},
  booktitle={Advances in Neural Information Processing Systems},
  pages={5356--5366},
  year={2018}
}

@article{liu2019off,
  title={Off-policy policy gradient with state distribution correction},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={arXiv preprint arXiv:1904.08473},
  year={2019}
}

@article{mousavi2020black,
  title={Black-box Off-policy Estimation for Infinite-Horizon Reinforcement Learning},
  author={Mousavi, Ali and Li, Lihong and Liu, Qiang and Zhou, Denny},
  journal={arXiv preprint arXiv:2003.11126},
  year={2020}
}

@article{kallus2019efficiently,
  title={Efficiently breaking the curse of horizon: Double reinforcement learning in infinite-horizon processes},
  author={Kallus, Nathan and Uehara, Masatoshi},
  journal={arXiv preprint arXiv:1909.05850},
  year={2019}
}

@inproceedings{kallus2019intrinsically,
  title={Intrinsically efficient, stable, and bounded off-policy evaluation for reinforcement learning},
  author={Kallus, Nathan and Uehara, Masatoshi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={3320--3329},
  year={2019}
}

@article{uehara2019minimax,
  title={Minimax Weight and Q-Function Learning for Off-Policy Evaluation},
  author={Uehara, Masatoshi and Jiang, Nan},
  journal={arXiv preprint arXiv:1910.12809},
  year={2019}
}

@article{tang2019doubly,
  title={Doubly robust bias reduction in infinite horizon off-policy estimation},
  author={Tang, Ziyang and Feng, Yihao and Li, Lihong and Zhou, Dengyong and Liu, Qiang},
  journal={arXiv preprint arXiv:1910.07186},
  year={2019}
}

@book{puterman2014markov,
  title={Markov decision processes: discrete stochastic dynamic programming},
  author={Puterman, Martin L},
  year={2014},
  publisher={John Wiley \& Sons}
}

@article{dai2017boosting,
  title={Boosting the actor with dual critic},
  author={Dai, Bo and Shaw, Albert and He, Niao and Li, Lihong and Song, Le},
  journal={arXiv preprint arXiv:1712.10282},
  year={2017}
}

@article{wang2021instabilities,
  title={Instabilities of Offline RL with Pre-Trained Neural Representation},
  author={Wang, Ruosong and Wu, Yifan and Salakhutdinov, Ruslan and Kakade, Sham M},
  journal={arXiv preprint arXiv:2103.04947},
  year={2021}
}

@article{jin2020pessimism,
  title={Is Pessimism Provably Efficient for Offline RL?},
  author={Jin, Ying and Yang, Zhuoran and Wang, Zhaoran},
  journal={arXiv preprint arXiv:2012.15085},
  year={2020}
}

@article{dai2017sbeed,
  title={SBEED: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  journal={arXiv preprint arXiv:1712.10285},
  year={2017}
}

@article{chen2016stochastic,
  title={Stochastic primal-dual methods and sample complexity of reinforcement learning},
  author={Chen, Yichen and Wang, Mengdi},
  journal={arXiv preprint arXiv:1612.02516},
  year={2016}
}

@inproceedings{wang2016online,
  title={An online primal-dual method for discounted markov decision processes},
  author={Wang, Mengdi and Chen, Yichen},
  booktitle={2016 IEEE 55th Conference on Decision and Control (CDC)},
  pages={4516--4521},
  year={2016},
  organization={IEEE}
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=O9bnihsFfXU}
}

@article{hastie2019surprises,
  title={Surprises in high-dimensional ridgeless least squares interpolation},
  author={Hastie, Trevor and Montanari, Andrea and Rosset, Saharon and Tibshirani, Ryan J},
  journal={arXiv preprint arXiv:1903.08560},
  year={2019}
}

@article{durugkar2018td,
  title={TD learning with constrained gradients},
  author={Durugkar, Ishan and Stone, Peter},
  year={2018}
}

@article{singh2020cog,
  title={COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning},
  author={Singh, Avi and Yu, Albert and Yang, Jonathan and Zhang, Jesse and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2010.14500},
  year={2020}
}

@inproceedings{dong2020expressivity,
  title={On the expressivity of neural networks for deep reinforcement learning},
  author={Dong, Kefan and Luo, Yuping and Yu, Tianhe and Finn, Chelsea and Ma, Tengyu},
  booktitle={International Conference on Machine Learning},
  pages={2627--2637},
  year={2020},
  organization={PMLR}
}

@inproceedings{savarese2019infinite,
  title={How do infinite width bounded norm networks look in function space?},
  author={Savarese, Pedro and Evron, Itay and Soudry, Daniel and Srebro, Nathan},
  booktitle={Conference on Learning Theory},
  pages={2667--2690},
  year={2019},
  organization={PMLR}
}

@article{dosovitskiy2020image,
  title={An image is worth 16x16 words: Transformers for image recognition at scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}

@inproceedings{
kumar2021workflow,
title={A Workflow for Offline Model-Free Robotic Reinforcement Learning},
author={Aviral Kumar and Anikait Singh and Stephen Tian and Chelsea Finn and Sergey Levine},
booktitle={5th Annual Conference on Robot Learning },
year={2021},
url={https://openreview.net/forum?id=fy4ZBWxYbIo}
}

@inproceedings{huang2017densely,
  title={Densely connected convolutional networks},
  author={Huang, Gao and Liu, Zhuang and Van Der Maaten, Laurens and Weinberger, Kilian Q},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4700--4708},
  year={2017}
}

@inproceedings{ghiassian2020gradient,
  title={Gradient temporal-difference learning with regularized corrections},
  author={Ghiassian, Sina and Patterson, Andrew and Garg, Shivam and Gupta, Dhawal and White, Adam and White, Martha},
  booktitle={International Conference on Machine Learning},
  pages={3524--3534},
  year={2020},
  organization={PMLR}
}

@inproceedings{gogianu2021spectral,
  title={Spectral normalisation for deep reinforcement learning: an optimisation perspective},
  author={Gogianu, Florin and Berariu, Tudor and Rosca, Mihaela C and Clopath, Claudia and Busoniu, Lucian and Pascanu, Razvan},
  booktitle={International Conference on Machine Learning},
  pages={3734--3744},
  year={2021},
  organization={PMLR}
}

@article{lee2021versions,
  title={Versions of Gradient Temporal Difference Learning},
  author={Lee, Donghwan and Lim, Han-Dong and Park, Jihoon and Choi, Okyong},
  journal={arXiv preprint arXiv:2109.04033},
  year={2021}
}

@article{cheng2022adversarially,
  title={Adversarially Trained Actor Critic for Offline Reinforcement Learning},
  author={Cheng, Ching-An and Xie, Tengyang and Jiang, Nan and Agarwal, Alekh},
  journal={arXiv preprint arXiv:2202.02446},
  year={2022}
}

@article{xie2021bellman,
  title={Bellman-consistent pessimism for offline reinforcement learning},
  author={Xie, Tengyang and Cheng, Ching-An and Jiang, Nan and Mineiro, Paul and Agarwal, Alekh},
  journal={Advances in neural information processing systems},
  volume={34},
  year={2021}
}

@inproceedings{arora2019fine,
  title={Fine-grained analysis of optimization and generalization for overparameterized two-layer neural networks},
  author={Arora, Sanjeev and Du, Simon and Hu, Wei and Li, Zhiyuan and Wang, Ruosong},
  booktitle={International Conference on Machine Learning},
  pages={322--332},
  year={2019},
  organization={PMLR}
}

@article{du2018gradient,
  title={Gradient descent provably optimizes over-parameterized neural networks},
  author={Du, Simon S and Zhai, Xiyu and Poczos, Barnabas and Singh, Aarti},
  journal={arXiv preprint arXiv:1810.02054},
  year={2018}
}

@article{kostrikov2020image,
  title={Image augmentation is all you need: Regularizing deep reinforcement learning from pixels},
  author={Kostrikov, Ilya and Yarats, Denis and Fergus, Rob},
  journal={arXiv preprint arXiv:2004.13649},
  year={2020}
}

@article{kumar2021dr3,
  title={{DR3: Value-Based Deep Reinforcement Learning Requires Explicit Regularization}},
  author={Kumar, Aviral and Agarwal, Rishabh and Ma, Tengyu and Courville, Aaron and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2112.04716},
  year={2021}
}

@article{pohlen2018observe,
  title={Observe and look further: Achieving consistent performance on atari},
  author={Pohlen, Tobias and Piot, Bilal and Hester, Todd and Azar, Mohammad Gheshlaghi and Horgan, Dan and Budden, David and Barth-Maron, Gabriel and Van Hasselt, Hado and Quan, John and Ve{\v{c}}er{\'\i}k, Mel and others},
  journal={arXiv preprint arXiv:1805.11593},
  year={2018}
}

@article{chowdhery2022palm,
  title={Palm: Scaling language modeling with pathways},
  author={Chowdhery, Aakanksha and Narang, Sharan and Devlin, Jacob and Bosma, Maarten and Mishra, Gaurav and Roberts, Adam and Barham, Paul and Chung, Hyung Won and Sutton, Charles and Gehrmann, Sebastian and others},
  journal={arXiv preprint arXiv:2204.02311},
  year={2022}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{zanette2020exponential,
  title={Exponential Lower Bounds for Batch Reinforcement Learning: Batch RL can be Exponentially Harder than Online RL},
  author={Zanette, Andrea},
  journal={arXiv preprint arXiv:2012.08005},
  year={2020}
}

@article{yu2020mopo,
  title={Mopo: Model-based offline policy optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}

@inproceedings{
wang2021what,
title={What are the Statistical Limits of Offline {\{}RL{\}} with Linear Function Approximation?},
author={Ruosong Wang and Dean Foster and Sham M. Kakade},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=30EvkP2aQLD}
}

@article{liu2020provably,
  title={Provably Good Batch Off-Policy Reinforcement Learning Without Great Exploration},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  year={2020}
}

@inproceedings{duan2020minimax,
  title={Minimax-optimal off-policy evaluation with linear function approximation},
  author={Duan, Yaqi and Jia, Zeyu and Wang, Mengdi},
  booktitle={International Conference on Machine Learning},
  pages={2701--2709},
  year={2020},
  organization={PMLR}
}

@article{lee2018stochastic,
  title={Stochastic primal-dual Q-learning},
  author={Lee, Donghwan and He, Niao},
  journal={arXiv preprint arXiv:1810.08298},
  year={2018}
}

@inproceedings{swaminathan2015counterfactual,
  title={Counterfactual risk minimization: Learning from logged bandit feedback},
  author={Swaminathan, Adith and Joachims, Thorsten},
  booktitle={International Conference on Machine Learning},
  pages={814--823},
  year={2015}
}

@article{hayes2005large,
  title={A large-deviation inequality for vector-valued martingales},
  author={Hayes, Thomas P},
  journal={Combinatorics, Probability and Computing},
  year={2005}
}

@article{McGeer01041990,
  author = {McGeer, Tad}, 
  title = {\href{http://ijr.sagepub.com/content/9/2/62.abstract}{Passive Dynamic Walking}}, 
  volume = {9}, 
  number = {2}, 
  pages = {62-82}, 
  year = {1990}, 
  doi = {10.1177/027836499000900206}, 
  URL = {http://ijr.sagepub.com/content/9/2/62.abstract}, 
  eprint = {http://ijr.sagepub.com/content/9/2/62.full.pdf+html}, 
  journal = {The International Journal of Robotics Research}
}

@article{kalman1960new,
  title={A new approach to linear filtering and prediction problems},
  author={Kalman, R.E.},
  journal={Journal of Basic Engineering},
  volume={82},
  number={1},
  pages={35--45},
  year={1960},
  publisher={Citeseer}
}

@article{ghosh2021generalization,
  title={Why generalization in rl is difficult: Epistemic pomdps and implicit partial observability},
  author={Ghosh, Dibya and Rahme, Jad and Kumar, Aviral and Zhang, Amy and Adams, Ryan P and Levine, Sergey},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@inproceedings{cobbe2020leveraging,
  title={Leveraging procedural generation to benchmark reinforcement learning},
  author={Cobbe, Karl and Hesse, Chris and Hilton, Jacob and Schulman, John},
  booktitle={International conference on machine learning},
  pages={2048--2056},
  year={2020},
  organization={PMLR}
}

@article{sharma2021autonomoussubgoal,
  title={Autonomous Reinforcement Learning via Subgoal Curricula},
  author={Sharma, Archit and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={Advances in Neural Information Processing Systems},
  volume={34},
  year={2021}
}

@article{gupta2021reset,
  title={Reset-Free Reinforcement Learning via Multi-Task Learning: Learning Dexterous Manipulation Behaviors without Human Intervention},
  author={Gupta, Abhishek and Yu, Justin and Zhao, Tony Z and Kumar, Vikash and Rovinsky, Aaron and Xu, Kelvin and Devlin, Thomas and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.11203},
  year={2021}
}

@article{ha2020learning,
  title={Learning to walk in the real world with minimal human effort},
  author={Ha, Sehoon and Xu, Peng and Tan, Zhenyu and Levine, Sergey and Tan, Jie},
  journal={arXiv preprint arXiv:2002.08550},
  year={2020}
}

@article{zhu2020ingredients,
  title={The ingredients of real-world robotic reinforcement learning},
  author={Zhu, Henry and Yu, Justin and Gupta, Abhishek and Shah, Dhruv and Hartikainen, Kristian and Singh, Avi and Kumar, Vikash and Levine, Sergey},
  journal={arXiv preprint arXiv:2004.12570},
  year={2020}
}

@article{ma2022vip,
  title={VIP: Towards Universal Visual Reward and Representation via Value-Implicit Pre-Training},
  author={Ma, Yecheng Jason and Sodhani, Shagun and Jayaraman, Dinesh and Bastani, Osbert and Kumar, Vikash and Zhang, Amy},
  journal={arXiv preprint arXiv:2210.00030},
  year={2022}
}

@article{xiao2022masked,
  title={Masked visual pre-training for motor control},
  author={Xiao, Tete and Radosavovic, Ilija and Darrell, Trevor and Malik, Jitendra},
  journal={arXiv preprint arXiv:2203.06173},
  year={2022}
}

@article{radosavovic2022real,
  title={Real-world robot learning with masked visual pre-training},
  author={Radosavovic, Ilija and Xiao, Tete and James, Stephen and Abbeel, Pieter and Malik, Jitendra and Darrell, Trevor},
  journal={arXiv preprint arXiv:2210.03109},
  year={2022}
}

@article{xu2020continual,
  title={Continual Learning of Control Primitives: Skill Discovery via Reset-Games},
  author={Xu, Kelvin and Verma, Siddharth and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.05286},
  year={2020}
}

@article{eysenbach2017leave,
  title={Leave no trace: Learning to reset for safe and autonomous reinforcement learning},
  author={Eysenbach, Benjamin and Gu, Shixiang and Ibarz, Julian and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.06782},
  year={2017}
}

@inproceedings{han2015learning,
  title={Learning compound multi-step controllers under unknown dynamics},
  author={Han, Weiqiao and Levine, Sergey and Abbeel, Pieter},
  booktitle={2015 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={6435--6442},
  year={2015},
  organization={IEEE}
}

@article{sharma2021autonomous,
  title={Autonomous Reinforcement Learning: Formalism and Benchmarking},
  author={Sharma, Archit and Xu, Kelvin and Sardana, Nikhil and Gupta, Abhishek and Hausman, Karol and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2112.09605},
  year={2021}
}

@article{wang2016learning,
  title={Learning to reinforcement learn},
  author={Wang, Jane X and Kurth-Nelson, Zeb and Tirumala, Dhruva and Soyer, Hubert and Leibo, Joel Z and Munos, Remi and Blundell, Charles and Kumaran, Dharshan and Botvinick, Matt},
  journal={arXiv preprint arXiv:1611.05763},
  year={2016}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{duan2016rl,
  title={R$\mathrm{L}^{2}$: Fast reinforcement learning via slow reinforcement learning},
  author={Duan, Yan and Schulman, John and Chen, Xi and Bartlett, Peter L and Sutskever, Ilya and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1611.02779},
  year={2016}
}

@inproceedings{finn2017model,
  title={Model-agnostic meta-learning for fast adaptation of deep networks},
  author={Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  booktitle={International Conference on Machine Learning},
  pages={1126--1135},
  year={2017},
  organization={PMLR}
}

@inproceedings{rakelly2019efficient,
  title={Efficient off-policy meta-reinforcement learning via probabilistic context variables},
  author={Rakelly, Kate and Zhou, Aurick and Finn, Chelsea and Levine, Sergey and Quillen, Deirdre},
  booktitle={International conference on machine learning},
  pages={5331--5340},
  year={2019},
  organization={PMLR}
}

@article{kalashnikov2021mt,
  title={MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale},
  author={Kalashnikov, Dmitry and Varley, Jacob and Chebotar, Yevgen and Swanson, Benjamin and Jonschkowski, Rico and Finn, Chelsea and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:2104.08212},
  year={2021}
}

@article{yu2021conservative,
  title={Conservative data sharing for multi-task offline reinforcement learning},
  author={Yu, Tianhe and Kumar, Aviral and Chebotar, Yevgen and Hausman, Karol and Levine, Sergey and Finn, Chelsea},
  journal={NeurIPS},
  volume={34},
  year={2021}
}

@article{li2019multi,
  title={Multi-task batch reinforcement learning with metric learning},
  author={Li, Jiachen and Vuong, Quan and Liu, Shuang and Liu, Minghua and Ciosek, Kamil and Ross, Keith and Christensen, Henrik Iskov and Su, Hao},
  journal={arXiv preprint arXiv:1909.11373},
  year={2019}
}

@article{chebotar2021actionable,
  title={Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills},
  author={Chebotar, Yevgen and Hausman, Karol and Lu, Yao and Xiao, Ted and Kalashnikov, Dmitry and Varley, Jake and Irpan, Alex and Eysenbach, Benjamin and Julian, Ryan and Finn, Chelsea and others},
  journal={arXiv preprint arXiv:2104.07749},
  year={2021}
}

@article{yang2021representation,
  title={Representation matters: Offline pretraining for sequential decision making},
  author={Yang, Mengjiao and Nachum, Ofir},
  journal={arXiv preprint arXiv:2102.05815},
  year={2021}
}

@inproceedings{mitchell2021offline,
  title={Offline meta-reinforcement learning with advantage weighting},
  author={Mitchell, Eric and Rafailov, Rafael and Peng, Xue Bin and Levine, Sergey and Finn, Chelsea},
  booktitle={International Conference on Machine Learning},
  pages={7780--7791},
  year={2021},
  organization={PMLR}
}

@article{pong2021offline,
  title={Offline Meta-Reinforcement Learning with Online Self-Supervision},
  author={Pong, Vitchyr H and Nair, Ashvin and Smith, Laura and Huang, Catherine and Levine, Sergey},
  journal={arXiv preprint arXiv:2107.03974},
  year={2021}
}

@article{dorfman2020offline,
  title={Offline meta reinforcement learning},
  author={Dorfman, Ron and Tamar, Aviv},
  journal={arXiv e-prints},
  pages={arXiv--2008},
  year={2020}
}

@article{singh2020parrot,
  title={Parrot: Data-driven behavioral priors for reinforcement learning},
  author={Singh, Avi and Liu, Huihan and Zhou, Gaoyue and Yu, Albert and Rhinehart, Nicholas and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.10024},
  year={2020}
}

@article{ajay2020opal,
  title={Opal: Offline primitive discovery for accelerating offline reinforcement learning},
  author={Ajay, Anurag and Kumar, Aviral and Agrawal, Pulkit and Levine, Sergey and Nachum, Ofir},
  journal={arXiv preprint arXiv:2010.13611},
  year={2020}
}

@inproceedings{nair19ccrig,
    author    = {A. Nair and S. Bahl and A. Khazatsky and V. Pong and G. Berseth and S. Levine},
    title     = {Contextual Imagined Goals for Self-Supervised Robotic Learning},
    booktitle = {Conference on Robot Learning (CoRL)},
    year      = {2019}
}

@article{khazatsky2021can,
  title={What Can I Do Here? Learning New Skills by Imagining Visual Affordances},
  author={Khazatsky, Alexander and Nair, Ashvin and Jing, Daniel and Levine, Sergey},
  journal={arXiv preprint arXiv:2106.00671},
  year={2021}
}

@article{huh2016makes,
  title={What makes ImageNet good for transfer learning?},
  author={Huh, Minyoung and Agrawal, Pulkit and Efros, Alexei A},
  journal={arXiv preprint arXiv:1608.08614},
  year={2016}
}

@article{bommasani2021opportunities,
  title={On the opportunities and risks of foundation models},
  author={Bommasani, Rishi and Hudson, Drew A and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and others},
  journal={arXiv preprint arXiv:2108.07258},
  year={2021}
}

@article{radford2021clip,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  journal={arXiv preprint arXiv:2103.00020},
  year={2021}
}

@inproceedings{pinto2016supersizing,
  title={Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours},
  author={Pinto, Lerrel and Gupta, Abhinav},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={3406--3413},
  year={2016},
  organization={IEEE}
}

@inproceedings{mandlekar2020iris,
  title={Iris: Implicit reinforcement without interaction at scale for learning control from offline robot manipulation data},
  author={Mandlekar, Ajay and Ramos, Fabio and Boots, Byron and Savarese, Silvio and Fei-Fei, Li and Garg, Animesh and Fox, Dieter},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4414--4420},
  year={2020},
  organization={IEEE}
}

@article{julian2020efficient,
  title={Efficient adaptation for end-to-end vision-based robotic manipulation},
  author={Julian, Ryan and Swanson, Benjamin and Sukhatme, Gaurav S and Levine, Sergey and Finn, Chelsea and Hausman, Karol},
  year={2020}
}
@article{cabi2019scaling,
  title={Scaling data-driven robotics with reward sketching and batch reinforcement learning},
  author={Cabi, Serkan and Colmenarejo, Sergio G{\'o}mez and Novikov, Alexander and Konyushkova, Ksenia and Reed, Scott and Jeong, Rae and Zolna, Konrad and Aytar, Yusuf and Budden, David and Vecerik, Mel and others},
  journal={arXiv preprint arXiv:1909.12200},
  year={2019}
}

@inproceedings{hausman2018learning,
  title={Learning an embedding space for transferable robot skills},
  author={Hausman, Karol and Springenberg, Jost Tobias and Wang, Ziyu and Heess, Nicolas and Riedmiller, Martin},
  booktitle={International Conference on Learning Representations},
  year={2018}
}

@article{zintgraf2019varibad,
  title={Varibad: A very good method for bayes-adaptive deep rl via meta-learning},
  author={Zintgraf, Luisa and Shiarlis, Kyriacos and Igl, Maximilian and Schulze, Sebastian and Gal, Yarin and Hofmann, Katja and Whiteson, Shimon},
  journal={arXiv preprint arXiv:1910.08348},
  year={2019}
}

@article{kirk2021survey,
  title={A Survey of Generalisation in Deep Reinforcement Learning},
  author={Kirk, Robert and Zhang, Amy and Grefenstette, Edward and Rockt{\"a}schel, Tim},
  journal={arXiv preprint arXiv:2111.09794},
  year={2021}
}


@article{schaal1997learning,
  title={Learning from demonstration},
  author={Schaal, Stefan and others},
  journal={Advances in neural information processing systems},
  pages={1040--1046},
  year={1997},
  publisher={Citeseer}
}

@article{hester2017learning,
  title={Learning from demonstrations for real world reinforcement learning},
  author={Hester, Todd and Vecerik, Matej and Pietquin, Olivier and Lanctot, Marc and Schaul, Tom and Piot, Bilal and Sendonaris, Andrew and Dulac-Arnold, Gabriel and Osband, Ian and Agapiou, John and others},
  year={2017}
}

@article{rajeswaran2017learning,
  title={Learning complex dexterous manipulation with deep reinforcement learning and demonstrations},
  author={Rajeswaran, Aravind and Kumar, Vikash and Gupta, Abhishek and Vezzani, Giulia and Schulman, John and Todorov, Emanuel and Levine, Sergey},
  journal={arXiv preprint arXiv:1709.10087},
  year={2017}
}

@article{peng2018deepmimic,
  title={Deepmimic: Example-guided deep reinforcement learning of physics-based character skills},
  author={Peng, Xue Bin and Abbeel, Pieter and Levine, Sergey and van de Panne, Michiel},
  journal={ACM Transactions on Graphics (TOG)},
  volume={37},
  number={4},
  pages={1--14},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@inproceedings{kormushev2010robot,
  title={Robot motor skill coordination with EM-based reinforcement learning},
  author={Kormushev, Petar and Calinon, Sylvain and Caldwell, Darwin G},
  booktitle={2010 IEEE/RSJ international conference on intelligent robots and systems},
  pages={3232--3237},
  year={2010},
  organization={IEEE}
}

@article{nair2017overcoming,
  title={Overcoming Exploration in Reinforcement Learning with Demonstrations. CoRR abs/1709.10089 (2017)},
  author={Nair, Ashvin and McGrew, Bob and Andrychowicz, Marcin and Zaremba, Wojciech and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1709.10089},
  year={2017}
}

@article{kalashnikov2018qt,
  title={Qt-opt: Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  journal={arXiv preprint arXiv:1806.10293},
  year={2018}
}

@article{lu2020reset,
  title={Reset-free lifelong learning with skill-space planning},
  author={Lu, Kevin and Grover, Aditya and Abbeel, Pieter and Mordatch, Igor},
  journal={arXiv preprint arXiv:2012.03548},
  year={2020}
}

@inproceedings{fujimoto2019off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  booktitle={International Conference on Machine Learning},
  pages={2052--2062},
  year={2019},
  organization={PMLR}
}

@inproceedings{peters2007reinforcement,
  title={Reinforcement learning by reward-weighted regression for operational space control},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={745--750},
  year={2007}
}

@article{peng2019advantage,
  title={Advantage-weighted regression: Simple and scalable off-policy reinforcement learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{fujimoto2021minimalist,
  title={A Minimalist Approach to Offline Reinforcement Learning},
  author={Fujimoto, Scott and Gu, Shixiang Shane},
  journal={arXiv preprint arXiv:2106.06860},
  year={2021}
}

@inproceedings{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle={International conference on machine learning},
  pages={1861--1870},
  year={2018},
  organization={PMLR}
}

@inproceedings{kostrikov2021offline,
  title={Offline reinforcement learning with fisher divergence critic regularization},
  author={Kostrikov, Ilya and Fergus, Rob and Tompson, Jonathan and Nachum, Ofir},
  booktitle={International Conference on Machine Learning},
  pages={5774--5783},
  year={2021},
  organization={PMLR}
}

@inproceedings{kostrikov2021iql,
  title={Offline reinforcement learning with implicit q-learning},
  author={Kostrikov, Ilya and Nair, Ashvin and Levine, Sergey},
  journal={arXiv preprint arXiv:2110.06169},
  year={2021}
}

@inproceedings{wilson2007multi,
  title={Multi-task reinforcement learning: a hierarchical bayesian approach},
  author={Wilson, Aaron and Fern, Alan and Ray, Soumya and Tadepalli, Prasad},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={1015--1022},
  year={2007}
}

@article{parisotto2015actor,
  title={Actor-mimic: Deep multitask and transfer reinforcement learning},
  author={Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1511.06342},
  year={2015}
}

@article{teh2017distral,
  title={Distral: Robust multitask reinforcement learning},
  author={Teh, Yee Whye and Bapst, Victor and Czarnecki, Wojciech Marian and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  journal={arXiv preprint arXiv:1707.04175},
  year={2017}
}

@inproceedings{espeholt2018impala,
  title={Impala: Scalable distributed deep-rl with importance weighted actor-learner architectures},
  author={Espeholt, Lasse and Soyer, Hubert and Munos, Remi and Simonyan, Karen and Mnih, Vlad and Ward, Tom and Doron, Yotam and Firoiu, Vlad and Harley, Tim and Dunning, Iain and others},
  booktitle={International Conference on Machine Learning},
  pages={1407--1416},
  year={2018},
  organization={PMLR}
}

@inproceedings{hessel2019multi,
  title={Multi-task deep reinforcement learning with popart},
  author={Hessel, Matteo and Soyer, Hubert and Espeholt, Lasse and Czarnecki, Wojciech and Schmitt, Simon and van Hasselt, Hado},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  number={01},
  pages={3796--3803},
  year={2019}
}

@article{xu2020knowledge,
  title={Knowledge transfer in multi-task deep reinforcement learning for continuous control},
  author={Xu, Zhiyuan and Wu, Kun and Che, Zhengping and Tang, Jian and Ye, Jieping},
  journal={arXiv preprint arXiv:2010.07494},
  year={2020}
}

@article{yang2020multi,
  title={Multi-task reinforcement learning with soft modularization},
  author={Yang, Ruihan and Xu, Huazhe and Wu, Yi and Wang, Xiaolong},
  journal={arXiv preprint arXiv:2003.13661},
  year={2020}
}

@article{sodhani2021multi,
  title={Multi-Task Reinforcement Learning with Context-based Representations},
  author={Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
  journal={arXiv preprint arXiv:2102.06177},
  year={2021}
}

@article{lin2021,
  author    = {Yen{-}Chen Lin and
               Andy Zeng and
               Shuran Song and
               Phillip Isola and
               Tsung{-}Yi Lin},
  title     = {Learning to See before Learning to Act: Visual Pre-training for Manipulation},
  journal   = {CoRR},
  volume    = {abs/2107.00646},
  year      = {2021},
  eprint    = {2107.00646},
}

@article{lee2022multi,
  title={Multi-Game Decision Transformers},
  author={Lee, Kuang-Huei and Nachum, Ofir and Yang, Mengjiao and Lee, Lisa and Freeman, Daniel and Xu, Winnie and Guadarrama, Sergio and Fischer, Ian and Jang, Eric and Michalewski, Henryk and others},
  journal={arXiv preprint arXiv:2205.15241},
  year={2022}
}

@article{yang2021trail,
  title={TRAIL: Near-Optimal Imitation Learning with Suboptimal Data},
  author={Yang, Mengjiao and Levine, Sergey and Nachum, Ofir},
  journal={arXiv preprint arXiv:2110.14770},
  year={2021}
}

@article{yu2022leverage,
  title={How to Leverage Unlabeled Data in Offline RL},
  author={Yu, Tianhe and Kumar, Aviral and Chebotar, Yevgen and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  journal={arXiv:2202.01741},
  year={2022}
}

@article{lee2022spend,
  title={How to Spend Your Robot Time: Bridging Kickstarting and Offline Reinforcement Learning for Vision-based Robotic Manipulation},
  author={Lee, Alex X and Devin, Coline and Springenberg, Jost Tobias and Zhou, Yuxiang and Lampe, Thomas and Abdolmaleki, Abbas and Bousmalis, Konstantinos},
  journal={arXiv preprint arXiv:2205.03353},
  year={2022}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Pieter Abbeel, OpenAI and Zaremba, Wojciech},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{julian2020never,
  title={Never stop learning: The effectiveness of fine-tuning in robotic reinforcement learning},
  author={Julian, Ryan and Swanson, Benjamin and Sukhatme, Gaurav S and Levine, Sergey and Finn, Chelsea and Hausman, Karol},
  journal={arXiv preprint arXiv:2004.10190},
  year={2020}
}

@misc{young2020visual,
    title={Visual Imitation Made Easy},
    author={Sarah Young and Dhiraj Gandhi and Shubham Tulsiani and Abhinav Gupta and Pieter Abbeel and Lerrel Pinto},
    year={2020},
    eprint={2008.04899},
    archivePrefix={arXiv},
    primaryClass={cs.RO}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International Conference on Machine Learning},
  pages={8748--8763},
  year={2021},
  organization={PMLR}
}

@article{ahn2022can,
  title={Do as i can, not as i say: Grounding language in robotic affordances},
  author={Ahn, Michael and Brohan, Anthony and Brown, Noah and Chebotar, Yevgen and Cortes, Omar and David, Byron and Finn, Chelsea and Gopalakrishnan, Keerthana and Hausman, Karol and Herzog, Alex and others},
  journal={arXiv preprint arXiv:2204.01691},
  year={2022}
}

@inproceedings{lee2022offline,
  title={Offline-to-Online Reinforcement Learning via Balanced Replay and Pessimistic Q-Ensemble},
  author={Lee, Seunghyun and Seo, Younggyo and Lee, Kimin and Abbeel, Pieter and Shin, Jinwoo},
  booktitle={Conference on Robot Learning},
  pages={1702--1712},
  year={2022},
  organization={PMLR}
}

@article{shapenet,
  author    = {Angel X. Chang and
               Thomas A. Funkhouser and
               Leonidas J. Guibas and
               Pat Hanrahan and
               Qi{-}Xing Huang and
               Zimo Li and
               Silvio Savarese and
               Manolis Savva and
               Shuran Song and
               Hao Su and
               Jianxiong Xiao and
               Li Yi and
               Fisher Yu},
  title     = {ShapeNet: An Information-Rich 3D Model Repository},
  journal   = {CoRR},
  volume    = {abs/1512.03012},
  year      = {2015},
}

@article{coumans2016pybullet,
  title={Pybullet, a python module for physics simulation for games, robotics and machine learning},
  author={Coumans, E and Bai, Y},
  journal={GitHub repository},
  year={2016}
}

@inproceedings{wu2018group,
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}


@article{singh2019,
  title={End-to-End Robotic Reinforcement Learning without Reward Engineering},
  author={Avi Singh and Larry Yang and Kristian Hartikainen and Chelsea Finn and Sergey Levine},
  journal={Robotics: Science and Systems},
  year={2019}
}

@unpublished{        
anonymous2023calql,        
title={{Cal-QL: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning}},      
author={Anonymous},        
year={2023},        
note={anonymous paper under review}    
}

@article{nakamoto2023calql,
      title={Cal-{QL}: Calibrated Offline RL Pre-Training for Efficient Online Fine-Tuning}, 
      author={Mitsuhiko Nakamoto and Yuexiang Zhai and Anikait Singh and Max Sobol Mark and Yi Ma and Chelsea Finn and Aviral Kumar and Sergey Levine},
      year={2023},
    journal={arXiv preprint arXiv:2303.05479},

}

% (iii) “Sequence Transduction with Recurrent Neural Networks” Graves 2012.

% (iv) “Streaming End-to-End Speech Recognition for Mobile Devices” He et al. 2018.

% (v) “A streaming on-device end-to-end model surpassing server-side conventional model quality and latency” Sainath et al. 2020.

% (vi) “A Better and Faster end-to-end Model for Streaming ASR” Li et al. 2021

@article{dmazerunner,
  title={{DMazeRunner: Executing Perfectly Nested Loops on Dataflow Accelerators}},
  author={Dave, Shail and Kim, Youngbin and Avancha, Sasikanth and Lee, Kyoungwoo and Shrivastava, Aviral},
  journal={TECS},
  year={2019}
}

@inproceedings{magnet,
  title={{MAGNet: A Modular Accelerator Generator for Neural Networks}},
  author={Venkatesan, Rangharajan and Shao, Yakun Sophia and Wang, Miaorong and Clemons, Jason and Dai, Steve and Fojtik, Matthew and Keller, Ben and Klinefelter, Alicia and Pinckney, Nathaniel and Raina, Priyanka and others},
  booktitle={ICCAD},
  year={2019},
}

@inproceedings{autodnnchip,
  title={{AutoDNNchip: An Automated DNN Chip Predictor and Builder for both FPGAs and ASICs}},
  author={Xu, Pengfei and Zhang, Xiaofan and Hao, Cong and Zhao, Yang and Zhang, Yongan and Wang, Yue and Li, Chaojian and Guan, Zetong and Chen, Deming and Lin, Yingyan},
  booktitle={FPGA},
  year={2020}
}


@inproceedings{maestro,
  title={{Understanding Reuse, Performance, and Hardware Cost of DNN Dataflow: A Data-Centric Approach}},
  author={Kwon, Hyoukjun and Chatarasi, Prasanth and Pellauer, Michael and Parashar, Angshuman and Sarkar, Vivek and Krishna, Tushar},
  booktitle={MICRO},
  year={2019}
}

@article{marvel,
  title={{MARVEL: A Decoupled Model-driven Approach for Efficiently Mapping Convolutions on Spatial DNN Accelerators}},
  author={Chatarasi, Prasanth and Kwon, Hyoukjun and Raina, Natesh and Malik, Saurabh and Haridas, Vaisakh and Krishna, Tushar and Sarkar, Vivek},
  journal={arXiv preprint arXiv:2002.07752},
  year={2020}
}

@misc{nvdla,
  title={{NVDLA} Deep Learning Accelerator},
  author={Nvidia},
  howpublished = {\url{http://nvdla.org}},
  year={2021},
  note = {Accessed: 2021-10-01}
}

@article{fast,
  title={A full-stack accelerator search technique for vision applications},
  author={Zhang, Dan and Huda, Safeen and Songhori, Ebrahim and Le, Quoc and Goldie, Anna and Mirhoseini, Azalia},
  journal={arXiv preprint arXiv:2105.12842},
  year={2021}
}



@inproceedings{shidiannao,
  title={{ShiDianNao: Shifting Vision Processing Closer to the Sensor}},
  author={Du, Zidong and Fasthuber, Robert and Chen, Tianshi and Ienne, Paolo and Li, Ling and Luo, Tao and Feng, Xiaobing and Chen, Yunji and Temam, Olivier},
  booktitle={ISCA},
  year={2015}
}

@article{trnn01,
  title={{Sequence Transduction with Recurrent Neural Networks}},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1211.3711},
  year={2012}
}
@inproceedings{trnn02,
  title={{Streaming End-to-End Speech Recognition for Mobile Devices}},
  author={He, Yanzhang and Sainath, Tara N and Prabhavalkar, Rohit and McGraw, Ian and Alvarez, Raziel and Zhao, Ding and Rybach, David and Kannan, Anjuli and Wu, Yonghui and Pang, Ruoming and others},
  booktitle={ICASSP},
  year={2019},
}

@inproceedings{trnn03,
  title={{A Streaming On-Device End-to-End Model Surpassing Server-Side Conventional Model Quality and Latency}},
  author={Sainath, Tara N and He, Yanzhang and Li, Bo and Narayanan, Arun and Pang, Ruoming and Bruguier, Antoine and Chang, Shuo-yiin and Li, Wei and Alvarez, Raziel and Chen, Zhifeng and others},
  booktitle={ICASSP},
  year={2020},
}

@inproceedings{trnn04,
  title={{A Better and Faster end-to-end Model for Streaming ASR}},
  author={Li, Bo and Gulati, Anmol and Yu, Jiahui and Sainath, Tara N and Chiu, Chung-Cheng and Narayanan, Arun and Chang, Shuo-Yiin and Pang, Ruoming and He, Yanzhang and Qin, James and others},
  booktitle={ICASSP},
  year={2021},
}

@inproceedings{unet,
  title={{U-Net: Convolutional Networks for Biomedical Image Segmentation}},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={MICCAI},
  year={2015},
  organization={Springer}
}


@inproceedings{esmaeilzadeh2011dark,
  title={{Dark Silicon and the End of Multicore Scaling}},
  author={Esmaeilzadeh, Hadi and Blem, Emily and Amant, Renee St and Sankaralingam, Karthikeyan and Burger, Doug},
  booktitle={ISCA},
  year={2011},
}

@article{yang2019machine,
  title={Machine-learning-guided directed evolution for protein engineering},
  author={Yang, Kevin K and Wu, Zachary and Arnold, Frances H},
  journal={Nature methods},
  volume={16},
  number={8},
  pages={687--694},
  year={2019},
  publisher={Nature Publishing Group}
}

@inproceedings{trabucco2021conservative,
  title={{Conservative Objective Models for Effective Offline Model-Based Optimization}},
  author={Trabucco, Brandon and Kumar, Aviral and Geng, Xinyang and Levine, Sergey},
  booktitle={ICML},
  year={2021},
}

@inproceedings{kao2020confuciux,
  title={{ConfuciuX: Autonomous Hardware Resource Assignment for DNN Accelerators using Reinforcement Learning}},
  author={Kao, Sheng-Chun and Jeong, Geonhwa and Krishna, Tushar},
  booktitle={MICRO},
  year={2020},
}

@inproceedings{
fu2021offline,
title={{Offline Model-Based Optimization via Normalized Maximum Likelihood Estimation}},
author={Justin Fu and Sergey Levine},
booktitle={ICLR},
year={2021}
}

@article{mazurenko2019machine,
  title={Machine learning in enzyme engineering},
  author={Mazurenko, Stanislav and Prokop, Zbynek and Damborsky, Jiri},
  journal={ACS Catalysis},
  volume={10},
  number={2},
  pages={1210--1223},
  year={2019},
  publisher={ACS Publications}
}

@article{duris2020bayesian,
  title={Bayesian optimization of a free-electron laser},
  author={Duris, Joseph and Kennedy, Dylan and Hanuka, Adi and Shtalenkova, Jane and Edelen, Auralee and Baxevanis, P and Egger, Adam and Cope, T and McIntire, M and Ermon, S and others},
  journal={Physical review letters},
  volume={124},
  number={12},
  pages={124801},
  year={2020},
  publisher={APS}
}

@inproceedings{jouppi2017datacenter,
  title={{In-Datacenter Performance Analysis of a Tensor Processing Unit}},
  author={Jouppi, Norman P and Young, Cliff and Patil, Nishant and Patterson, David and Agrawal, Gaurav and Bajwa, Raminder and Bates, Sarah and Bhatia, Suresh and Boden, Nan and Borchers, Al and others},
  booktitle={ISCA},
  year={2017}
}

@article{ ,
  title={Bayesian optimization for materials design with mixed quantitative and qualitative variables},
  author={Zhang, Yichi and Apley, Daniel W and Chen, Wei},
  journal={Scientific reports},
  volume={10},
  number={1},
  pages={1--13},
  year={2020},
  publisher={Nature Publishing Group}
}

@article{yazdanbakhsh2021apollo,
  title={{Apollo: Transferable Architecture Exploration}},
  author={Yazdanbakhsh, Amir and Angermueller, Christof and Akin, Berkin and Zhou, Yanqi and Jones, Albin and Hashemi, Milad and Swersky, Kevin and Chatterjee, Satrajit and Narayanaswami, Ravi and Laudon, James},
  journal={arXiv preprint arXiv:2102.01723},
  year={2021}
}

@inproceedings{reagen2017case,
  title={{A Case for Efficient Accelerator Design Space Exploration via Bayesian Optimization}},
  author={Reagen, Brandon and Hern{\'a}ndez-Lobato, Jos{\'e} Miguel and Adolf, Robert and Gelbart, Michael and Whatmough, Paul and Wei, Gu-Yeon and Brooks, David},
  booktitle={ISLPED},
  year={2017},
}

@article{shi2020learned,
      title={{Learned Hardware/Software Co-Design of Neural Accelerators}}, 
      author={Zhan Shi and Chirag Sakhuja and Milad Hashemi and Kevin Swersky and Calvin Lin},
      journal={arXiv preprint arXiv:2010.02075},
  year={2020}
}

@article{yazdanbakhsh2021evaluation,
  title={{An Evaluation of Edge TPU Accelerators for Convolutional Neural Networks}},
  author={Yazdanbakhsh, Amir and Seshadri, Kiran and Akin, Berkin and Laudon, James and Narayanaswami, Ravi},
  journal={arXiv preprint arXiv:2102.10423},
  year={2021}
}

@inproceedings{razavi2019preventing,
  title={{Preventing Posterior Collapse with Delta-VAEs}},
  author={Razavi, Ali and Oord, A{\"a}ron van den and Poole, Ben and Vinyals, Oriol},
  booktitle={ICLR},
  year={2018}
}

@inproceedings{hegdemind,
  title={{Mind Mappings: Enabling Efficient Algorithm-Accelerator Mapping Space Search}},
  author={Hegde, Kartik and Tsai, Po-An and Huang, Sitao and Chandra, Vikas and Parashar, Angshuman and Fletcher, Christopher W},
  booktitle={ASPLOS},
  year={2021}
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Models
@inproceedings{mnv2:arxiv:2018,
  title={{MobileNetV2: Inverted Residuals and Linear Bottlenecks}},
  author={Sandler, Mark and Howard, Andrew and Zhu, Menglong and Zhmoginov, Andrey and Chen, Liang-Chieh},
  booktitle={CVPR},
  year={2018}
}
@inproceedings{mnv3:cvpr:2019,
  title={{Searching for MobileNetV3}},
  author={Howard, Andrew and Sandler, Mark and Chu, Grace and Chen, Liang-Chieh and Chen, Bo and Tan, Mingxing and Wang, Weijun and Zhu, Yukun and Pang, Ruoming and Vasudevan, Vijay and others},
  booktitle={CVPR},
  year={2019}
}

@misc{efficientnet:2020,
  title = {{Introducing the Next Generation of On-Device Vision Models: MobileNetV3 and MobileNetEdgeTPU}},
  year = {2020},
  author = {Andrew Howard and Suyog Gupta},
  publisher = {Google},
  journal = {Google AI Blog},
  howpublished = {\url{https://ai.googleblog.com/2019/11/introducing-next-generation-on-device.html}}
}

@book{dfo:siam:2009,
  title={Introduction to derivative-free optimization},
  author={Conn, Andrew R and Scheinberg, Katya and Vicente, Luis N},
  year={2009},
  publisher={SIAM}
}

@inproceedings{timeloop,
  title={{Timeloop: A Systematic Approach to DNN Accelerator Evaluation}},
  author={Parashar, Angshuman and Raina, Priyanka and Shao, Yakun Sophia and Chen, Yu-Hsin and Ying, Victor A and Mukkara, Anurag and Venkatesan, Rangharajan and Khailany, Brucek and Keckler, Stephen W and Emer, Joel},
  booktitle={ISPASS},
  year={2019},
  organization={IEEE}
}

@misc{menger:blog:2020,
  title = {{Menger: Massively Large-Scale Distributed Reinforcement Learning}},
  month = {October},
  year = {2020},
  author = {Amir Yazdanbakhsh and Junchao Chen, and Yu Zheng},
  publisher = {Google},
  journal = {Google AI Blog},
  howpublished = {\url{https://ai.googleblog.com/2020/10/massively-large-scale-distributed.html}}
}


@article{edgetpu:arxiv:2020,
  title={{Accelerator-Aware Neural Network Design using AutoML}},
  author={Gupta, Suyog and Akin, Berkin},
  journal={arXiv preprint arXiv:2003.02838},
  year={2020}
}
@inproceedings{vizier:sigkdd:2017,
  title={{Google Vizier: A Service for Black-box Optimization}},
  author={Golovin, Daniel and Solnik, Benjamin and Moitra, Subhodeep and Kochanski, Greg and Karro, John and Sculley, D},
  booktitle={SIGKDD},
  year={2017}
}

@article{brown2020language,
  title={{Language Models are Few-Shot Learners}},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={arXiv preprint arXiv:2005.14165},
  year={2020}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Derivative-free
@book{intro_derivative:siam:2009,
  title={Introduction to derivative-free optimization},
  author={Conn, Andrew R and Scheinberg, Katya and Vicente, Luis N},
  year={2009},
  publisher={SIAM}
}
@article{derivative_review:jgo:2013,
  title={Derivative-free optimization: a review of algorithms and comparison of software implementations},
  author={Rios, Luis Miguel and Sahinidis, Nikolaos V},
  journal={Journal of Global Optimization},
  volume={56},
  number={3},
  pages={1247--1293},
  year={2013},
  publisher={Springer}
}
@article{derivative_methods:arxiv:2019,
  title={Derivative-free optimization methods},
  author={Larson, Jeffrey and Menickelly, Matt and Wild, Stefan M},
  journal={arXiv preprint arXiv:1904.11585},
  year={2019}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bandit
@article{surface:jrss:1995,
  title={Response surface bandits},
  author={Ginebra, Josep and Clayton, Murray K},
  journal={Journal of the Royal Statistical Society: Series B (Methodological)},
  volume={57},
  number={4},
  pages={771--784},
  year={1995},
  publisher={Wiley Online Library}
}
@article{hyperband:jmlr:2017,
  title={Hyperband: A novel bandit-based approach to hyperparameter optimization},
  author={Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={6765--6816},
  year={2017},
  publisher={JMLR. org}
}
@article{gauss_bandit:arxiv:2009,
  title={Gaussian process optimization in the bandit setting: No regret and experimental design},
  author={Srinivas, Niranjan and Krause, Andreas and Kakade, Sham M and Seeger, Matthias},
  journal={arXiv preprint arXiv:0912.3995},
  year={2009}
}
@article{bouneffouf:arxiv:2019,
  title={A survey on practical applications of multi-armed and contextual bandits},
  author={Bouneffouf, Djallel and Rish, Irina},
  journal={arXiv preprint arXiv:1904.10040},
  year={2019}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bayesian and Evolutionary
@inproceedings{p3bo:arxiv:2020,
  title={{Population-Based Black-Box Optimization for Biological Sequence Design}},
  author={Angermueller, Christof and Belanger, David and Gane, Andreea and Mariet, Zelda and Dohan, David and Murphy, Kevin and Colwell, Lucy and Sculley, D},
  booktitle={ICML},
  year={2020}
}
@inproceedings{angermueller2019model,
  title={{Model-based Reinforcement Learning for Biological Sequence Design}},
  author={Angermueller, Christof and Dohan, David and Belanger, David and Deshpande, Ramya and Murphy, Kevin and Colwell, Lucy},
  booktitle={ICLR},
  year={2019}
}
@article{pbo:arxiv:2020,
  title={Prior-guided Bayesian Optimization},
  author={Souza, Artur and Nardi, Luigi and Oliveira, Leonardo B and Olukotun, Kunle and Lindauer, Marius and Hutter, Frank},
  journal={arXiv preprint arXiv:2006.14608},
  year={2020}
}
@article{population:is:2014,
  title={{Population-based Algorithm Portfolios with Automated Constituent Algorithms Selection}},
  author={Tang, Ke and Peng, Fei and Chen, Guoliang and Yao, Xin},
  journal={Information Sciences},
  volume={279},
  pages={94--104},
  year={2014},
  publisher={Elsevier}
}

@article{eff_global:jgo:1998,
  title={Efficient global optimization of expensive black-box functions},
  author={Jones, Donald R and Schonlau, Matthias and Welch, William J},
  journal={Journal of Global optimization},
  volume={13},
  number={4},
  pages={455--492},
  year={1998},
  publisher={Springer}
}

@article{bo_tutorial:arxiv:2010,
  title={A tutorial on Bayesian optimization of expensive cost functions, with application to active user modeling and hierarchical reinforcement learning},
  author={Brochu, Eric and Cora, Vlad M and De Freitas, Nando},
  journal={arXiv preprint arXiv:1012.2599},
  year={2010}
}
@inproceedings{practical_bo:nips:2012,
  title={Practical bayesian optimization of machine learning algorithms},
  author={Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P},
  booktitle={Advances in neural information processing systems},
  pages={2951--2959},
  year={2012}
}
@inproceedings{seq_mbo:lio:2011,
  title={Sequential model-based optimization for general algorithm configuration},
  author={Hutter, Frank and Hoos, Holger H and Leyton-Brown, Kevin},
  booktitle={International conference on learning and intelligent optimization},
  pages={507--523},
  year={2011},
  organization={Springer}
}
@article{con_bo:ba:2019,
  title={Constrained Bayesian optimization with noisy experiments},
  author={Letham, Benjamin and Karrer, Brian and Ottoni, Guilherme and Bakshy, Eytan and others},
  journal={Bayesian Analysis},
  volume={14},
  number={2},
  pages={495--519},
  year={2019},
  publisher={International Society for Bayesian Analysis}
}
@article{survey_gen:jrs:2019,
  title={A survey on evolutionary machine learning},
  author={Al-Sahaf, Harith and Bi, Ying and Chen, Qi and Lensen, Andrew and Mei, Yi and Sun, Yanan and Tran, Binh and Xue, Bing and Zhang, Mengjie},
  journal={Journal of the Royal Society of New Zealand},
  volume={49},
  number={2},
  pages={205--228},
  year={2019},
  publisher={Taylor \& Francis}
}
@inproceedings{ssl_pso:gec:2018,
  title={Semi-supervised learning assisted particle swarm optimization of computationally expensive problems},
  author={Sun, Chaoli and Jin, Yaochu and Tan, Ying},
  booktitle={Proceedings of the Genetic and Evolutionary Computation Conference},
  pages={45--52},
  year={2018}
}
@inproceedings{tpe:nips:2011,
  title={Algorithms for hyper-parameter optimization},
  author={Bergstra, James S and Bardenet, R{\'e}mi and Bengio, Yoshua and K{\'e}gl, Bal{\'a}zs},
  booktitle={Advances in neural information processing systems},
  pages={2546--2554},
  year={2011}
}
@inproceedings{real2019regularized,
  title={Regularized evolution for image classifier architecture search},
  author={Real, Esteban and Aggarwal, Alok and Huang, Yanping and Le, Quoc V},
  booktitle={Proceedings of the aaai conference on artificial intelligence},
  volume={33},
  pages={4780--4789},
  year={2019}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Architecture Exploration
@inproceedings{opentuner:pact:2014,
  title={{OpenTuner: An Extensible Framework for Program Autotuning}},
  author={Ansel, Jason and Kamil, Shoaib and Veeramachaneni, Kalyan and Ragan-Kelley, Jonathan and Bosboom, Jeffrey and O'Reilly, Una-May and Amarasinghe, Saman},
  booktitle={PACT},
  year={2014}
}
@inproceedings{automomml:hpc:2016,
  title={{AutoMOMML: Automatic Multi-Objective Modeling with Machine Learning}},
  author={Balaprakash, Prasanna and Tiwari, Ananta and Wild, Stefan M and Carrington, Laura and Hovland, Paul D},
  booktitle={HiPC},
  year={2016},
}
@inproceedings{prac_dse:mascots:2019,
  title={{Practical Design Space Exploration}},
  author={Nardi, Luigi and Koeplinger, David and Olukotun, Kunle},
  booktitle={MASCOTS},
  year={2019},
}
@article{bo:frontiers:2020,
  title={{Bayesian Multi-objective Hyperparameter Optimization for Accurate, Fast, and Efficient Neural Network Accelerator Design}},
  author={Parsa, Maryam and Mitchell, John P and Schuman, Catherine D and Patton, Robert M and Potok, Thomas E and Roy, Kaushik},
  journal={Frontiers in Neuroscience},
  volume={14},
  pages={667},
  year={2020},
  publisher={Frontiers}
}
@inproceedings{accel_gen:dac:2018,
  title={{Automated Accelerator Generation and Optimization with Composable, Parallel and Pipeline Architecture}},
  author={Cong, Jason and Wei, Peng and Yu, Cody Hao and Zhang, Peng},
  booktitle={DAC},
  year={2018},
}
@article{flexibo:arxiv:2020,
  title={{FlexiBO: Cost-Aware Multi-Objective Optimization of Deep Neural Networks}},
  author={Iqbal, Md Shahriar and Su, Jianhai and Kotthoff, Lars and Jamshidi, Pooyan},
  journal={arXiv preprint arXiv:2001.06588},
  year={2020}
}
@inproceedings{spatial:pldi:2018,
  title={{Spatial: A Language and Compiler for Application Accelerators}},
  author={Koeplinger, David and Feldman, Matthew and Prabhakar, Raghu and Zhang, Yaqi and Hadjis, Stefan and Fiszel, Ruben and Zhao, Tian and Nardi, Luigi and Pedram, Ardavan and Kozyrakis, Christos and others},
  booktitle={PLDI},
  year={2018},
}

@article{cnn_gen:cyber:2020,
  title={{Automatically Designing CNN Architectures Using the Genetic Algorithm for Image Classification}},
  author={Sun, Yanan and Xue, Bing and Zhang, Mengjie and Yen, Gary G and Lv, Jiancheng},
  journal={IEEE Transactions on Cybernetics},
  year={2020},
}


@article{ding_hardware_2020,
	title = {Hardware design and the competency awareness of a neural network},
	volume = {3},
	language = {en},
	author = {Ding, Yukun},
	year = {2020},
	pages = {10},
}

@article{colangelo_evolutionary_2019,
	title = {Evolutionary {Cell} {Aided} {Design} for {Neural} {Network} {Architectures}},
	url = {http://arxiv.org/abs/1903.02130},
	urldate = {2020-09-20},
	journal = {arXiv:1903.02130 [cs]},
	author = {Colangelo, Philip and Segal, Oren and Speicher, Alexander and Margala, Martin},
	month = may,
	year = {2019},
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Transfer Learning
@inproceedings{trans_evol:cvprw:2017,
  author={T. {Chugh} and M. {Singh} and S. {Nagpal} and R. {Singh} and M. {Vatsa}},
  booktitle={2017 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={Transfer Learning Based Evolutionary Algorithm for Composite Face Sketch Recognition}, 
  year={2017},
  volume={},
  number={},
  pages={619-627},}
@article{transfer_mobj:ec:2017,
  title={Transfer learning-based dynamic multiobjective optimization algorithms},
  author={Jiang, Min and Huang, Zhongqiang and Qiu, Liming and Huang, Wenzhen and Yen, Gary G},
  journal={IEEE Transactions on Evolutionary Computation},
  volume={22},
  number={4},
  pages={501--514},
  year={2017},
  publisher={IEEE}
}
@book{aml:springer:2019,
	series = {The {Springer} {Series} on {Challenges} in {Machine} {Learning}},
	title = {Automated {Machine} {Learning}: {Methods}, {Systems}, {Challenges}},
	editor = {Hutter, Frank, Kotthoff, Lars, Vanschoren, Joaquin},
	publisher = {Springer International Publishing},
	year = {2019},
}
@article{transfer:expert:2019,
	title = {A flexible transfer learning framework for {Bayesian} optimization with convergence guarantee},
	volume = {115},
	journal = {Expert Systems with Applications},
	author = {Theckel Joy, Tinu and Rana, Santu and Gupta, Sunil and Venkatesh, Svetha},
	month = jan,
	year = {2019},
	pages = {656--672},
}
@article{metalearn:arxiv:2020,
	title = {Meta-{Learning} {Acquisition} {Functions} for {Transfer} {Learning} in {Bayesian} {Optimization}},
	journal = {arXiv:1904.02642 [cs, stat]},
	author = {Volpp, Michael and Fröhlich, Lukas P. and Fischer, Kirsten and Doerr, Andreas and Falkner, Stefan and Hutter, Frank and Daniel, Christian},
	month = feb,
	year = {2020},
}
@inproceedings{regret_transfer:aistats:2017,
  title={Regret bounds for transfer learning in Bayesian optimisation},
  author={Shilton, Alistair and Gupta, Sunil and Rana, Santu and Venkatesh, Svetha},
  booktitle={Machine Learning Research: Proceedings of the 20th Artificial Intelligence and Statistics International Conference},
  pages={1--9},
  year={2017},
  organization={Journal of Machine Learning Research (JMLR)}
}
@article{genetic_transfer:expert:2010,
	title = {Genetic transfer learning},
	volume = {37},
	number = {10},
	journal = {Expert Systems with Applications},
	author = {Koçer, Barış and Arslan, Ahmet},
	month = oct,
	year = {2010},
	pages = {6997--7002},
}
@article{transfer_ci_survery:know:2015,
	title = {Transfer learning using computational intelligence: {A} survey},
	volume = {80},
	journal = {Knowledge-Based Systems},
	author = {Lu, Jie and Behbood, Vahid and Hao, Peng and Zuo, Hua and Xue, Shan and Zhang, Guangquan},
	month = may,
	year = {2015},
	pages = {14--23},
}
@article{min_multiproblem:ec:2020,
	title = {Multiproblem {Surrogates}: {Transfer} {Evolutionary} {Multiobjective} {Optimization} of {Computationally} {Expensive} {Problems}},
	volume = {23},
	number = {1},
	journal = {IEEE Transactions on Evolutionary Computation},
	author = {Min, Alan Tan Wei and Ong, Yew-Soon and Gupta, Abhishek and Goh, Chi-Keong},
	month = feb,
	year = {2019},
	pages = {15--28},
}

@inproceedings{swersky2013multi,
  title={Multi-task bayesian optimization},
  author={Swersky, Kevin and Snoek, Jasper and Adams, Ryan P},
  booktitle={Advances in neural information processing systems},
  pages={2004--2012},
  year={2013}
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@misc{simd,
  title={{Multi-Processor Reconfigurable in Single Instruction Multiple Data (SIMD) and Multiple Instruction Multiple Data (MIMD) Modes and Method of Operation}},
  author={Gove, Robert J and Balmer, Keith and Ing-Simmons, Nicholas K and Guttag, Karl M},
  year={1993},
  publisher={Google Patents},
  note={US Patent 5,212,777}
}

@inproceedings{
brock2018large,
title={Large Scale {GAN} Training for High Fidelity Natural Image Synthesis},
author={Andrew Brock and Jeff Donahue and Karen Simonyan},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=B1xsqj09Fm},
}

@inproceedings{
peng2018variational,
title={Variational Discriminator Bottleneck: Improving Imitation Learning, Inverse {RL}, and {GAN}s by Constraining Information Flow},
author={Xue Bin Peng and Angjoo Kanazawa and Sam Toyer and Pieter Abbeel and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=HyxPx3R9tm},
}

@inproceedings{mescheder2017numerics,
  title={The numerics of gans},
  author={Mescheder, Lars and Nowozin, Sebastian and Geiger, Andreas},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1825--1835},
  year={2017}
}

@misc{gym,
  Author = {Greg Brockman and Vicki Cheung and Ludwig Pettersson and Jonas Schneider and John Schulman and Jie Tang and Wojciech Zaremba},
  Title = {OpenAI Gym},
  Year = {2016},
  Eprint = {arXiv:1606.01540},
}

@inproceedings{krizhevsky2012imagenet,
  title={Imagenet classification with deep convolutional neural networks},
  author={Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
  booktitle={Advances in neural information processing systems},
  pages={1097--1105},
  year={2012}
}

@article{gumbelsoftmax,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Jang, Eric and Gu, Shixiang and Poole, Ben},
  biburl = {https://www.bibsonomy.org/bibtex/2af59bb3d69f11385bd14932dc93c5abd/dblp},
  ee = {http://arxiv.org/abs/1611.01144},
  interhash = {157733069613834cff7c133ed27aae43},
  intrahash = {af59bb3d69f11385bd14932dc93c5abd},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T14:41:37.000+0200},
  title = {Categorical Reparameterization with Gumbel-Softmax.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1611.html#JangGP16},
  volume = {abs/1611.01144},
  year = 2016
}

@misc{banditnetcode,
    author       = {Noveen Sachdeva},
    title        = {{BanditNet}},
    url          = {https://github.com/noveens/banditnet}
}

@misc{pytorch-gan,
    author       = {Erik Linder-Norén},
    title        = {{PyTorch GAN}},
    url          = {https://github.com/eriklindernoren/PyTorch-GAN}
}

@incollection{russo13eluder,
title = {Eluder Dimension and the Sample Complexity of Optimistic Exploration},
author = {Russo, Daniel and Van Roy, Benjamin},
booktitle = {Advances in Neural Information Processing Systems 26},
year = {2013},
}


@inproceedings{Srinivas2010gaussian,
 author = {Srinivas, Niranjan and Krause, Andreas and Kakade, Sham and Seeger, Matthias},
 title = {Gaussian Process Optimization in the Bandit Setting: No Regret and Experimental Design},
 booktitle = {Proceedings of the 27th International Conference on International Conference on Machine Learning},
 series = {ICML'10},
 acmid = {3104451},
 year = {2010},
} 

@inproceedings{Metelli2018policy,
 author = {Metelli, Alberto Maria and Papini, Matteo and Faccio, Francesco and Restelli, Marcello},
 title = {Policy Optimization via Importance Sampling},
 series = {NIPS'18},
 year = {2018},
 url = {http://dl.acm.org/citation.cfm?id=3327345.3327449},
} 


@inproceedings{Christiano2017DeepRL,
  title={Deep reinforcement learning from human preferences},
  author={Paul F. Christiano and Jan Leike and Tom B. Brown and Miljan Martic and Shane Legg and Dario Amodei},
  booktitle={NIPS},
  year={2017}
}

@article{Rothe2016Deep,
  author = {Rasmus Rothe and Radu Timofte and Luc Van Gool},
  title = {Deep expectation of real and apparent age from a single image without facial landmarks},
  journal = {International Journal of Computer Vision (IJCV)},
  year = {2016},
  month = {July},
}

@inproceedings{liu2015faceattributes,
 title = {Deep Learning Face Attributes in the Wild},
 author = {Liu, Ziwei and Luo, Ping and Wang, Xiaogang and Tang, Xiaoou},
 booktitle = {Proceedings of International Conference on Computer Vision (ICCV)},
 month = {December},
 year = {2015} 
}

@inproceedings{
ma2018characterizing,
title={Characterizing Adversarial Subspaces Using Local Intrinsic Dimensionality},
author={Xingjun Ma and Bo Li and Yisen Wang and Sarah M. Erfani and Sudanthi Wijewickrema and Grant Schoenebeck and Michael E. Houle and Dawn Song and James Bailey},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=B1gJ1L2aW},
}

@article{Lake2015HumanlevelCL,
  title={Human-level concept learning through probabilistic program induction},
  author={Brenden M. Lake and Ruslan Salakhutdinov and Joshua B. Tenenbaum},
  journal={Science},
  year={2015},
  volume={350},
  pages={1332-1338}
}

@TECHREPORT{Krizhevsky09learningmultiple,
    author = {Alex Krizhevsky},
    title = {Learning multiple layers of features from tiny images},
    institution = {},
    year = {2009}
}

@misc{mirza2014conditional,
  abstract = {Generative Adversarial Nets [8] were recently introduced as a novel way to
train generative models. In this work we introduce the conditional version of
generative adversarial nets, which can be constructed by simply feeding the
data, y, we wish to condition on to both the generator and discriminator. We
show that this model can generate MNIST digits conditioned on class labels. We
also illustrate how this model could be used to learn a multi-modal model, and
provide preliminary examples of an application to image tagging in which we
demonstrate how this approach can generate descriptive tags which are not part
of training labels.},
  added-at = {2017-10-04T17:14:40.000+0200},
  author = {Mirza, Mehdi and Osindero, Simon},
  biburl = {https://www.bibsonomy.org/bibtex/2a4426d639ebb30270839ad347bcfb999/achakraborty},
  description = {Conditional Generative Adversarial Nets},
  interhash = {efbbaeaebb1ea8d88264d258624d364c},
  intrahash = {a4426d639ebb30270839ad347bcfb999},
  keywords = {2014 GAN deep-learning machine-learning neural-networks},
  note = {cite arxiv:1411.1784},
  timestamp = {2017-10-04T17:14:40.000+0200},
  title = {Conditional Generative Adversarial Nets},
  url = {http://arxiv.org/abs/1411.1784},
  year = 2014
}

@article{lecun2010mnisthandwrittendigit,
  added-at = {2010-06-28T21:16:30.000+0200},
  author = {LeCun, Yann and Cortes, Corinna},
  biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
  groups = {public},
  howpublished = {http://yann.lecun.com/exdb/mnist/},
  interhash = {21b9d0558bd66279df9452562df6e6f3},
  intrahash = {935bad99fa1f65e03c25b315aa3c1032},
  keywords = {MSc _checked character_recognition mnist network neural},
  lastchecked = {2016-01-14 14:24:11},
  timestamp = {2016-07-12T19:25:30.000+0200},
  title = {{MNIST} handwritten digit database},
  url = {http://yann.lecun.com/exdb/mnist/},
  username = {mhwombat},
  year = 2010
}




@misc{kingma2013autoencoding,
  abstract = {How can we perform efficient inference and learning in directed probabilistic
models, in the presence of continuous latent variables with intractable
posterior distributions, and large datasets? We introduce a stochastic
variational inference and learning algorithm that scales to large datasets and,
under some mild differentiability conditions, even works in the intractable
case. Our contributions is two-fold. First, we show that a reparameterization
of the variational lower bound yields a lower bound estimator that can be
straightforwardly optimized using standard stochastic gradient methods. Second,
we show that for i.i.d. datasets with continuous latent variables per
datapoint, posterior inference can be made especially efficient by fitting an
approximate inference model (also called a recognition model) to the
intractable posterior using the proposed lower bound estimator. Theoretical
advantages are reflected in experimental results.},
  added-at = {2018-09-01T00:55:48.000+0200},
  author = {Kingma, Diederik P and Welling, Max},
  biburl = {https://www.bibsonomy.org/bibtex/2d5418945b5a08cf2ad018a9d593364ed/gonzalob90},
  description = {[1312.6114] Auto-Encoding Variational Bayes},
  interhash = {85731e0fbdb10b8543ea9f55301b37a5},
  intrahash = {d5418945b5a08cf2ad018a9d593364ed},
  keywords = {VAE},
  note = {cite arxiv:1312.6114},
  timestamp = {2018-09-01T00:57:30.000+0200},
  title = {Auto-Encoding Variational Bayes},
  url = {http://arxiv.org/abs/1312.6114},
  year = 2013
}




@inproceedings{yu2017seqgan,
 author = {Yu, Lantao and Zhang, Weinan and Wang, Jun and Yu, Yong},
 title = {SeqGAN: Sequence Generative Adversarial Nets with Policy Gradient},
 booktitle = {Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence},
 series = {AAAI'17},
 year = {2017},
} 

@article{russo2016information,
 author = {Russo, Daniel and Van Roy, Benjamin},
 title = {An Information-theoretic Analysis of Thompson Sampling},
 journal = {J. Mach. Learn. Res.},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1532-4435},
 pages = {2442--2471},
 numpages = {30},
 url = {http://dl.acm.org/citation.cfm?id=2946645.3007021},
 acmid = {3007021},
 publisher = {JMLR.org},
 keywords = {Thompson sampling, information theory, mutli-armed bandit, online optimization, regret bounds},
} 


@InProceedings{oord2018parallel,
  title = 	 {Parallel {W}ave{N}et: Fast High-Fidelity Speech Synthesis},
  author = 	 {van den Oord, Aaron and Li, Yazhe and Babuschkin, Igor and et.al.},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  year = 	 {2018},
  publisher = 	 {PMLR},
  abstract = 	 {The recently-developed WaveNet architecture is the current state of the art in realistic speech synthesis, consistently rated as more natural sounding for many different languages than any previous system. However, because WaveNet relies on sequential generation of one audio sample at a time, it is poorly suited to today’s massively parallel computers, and therefore hard to deploy in a real-time production setting. This paper introduces Probability Density Distillation, a new method for training a parallel feed-forward network from a trained WaveNet with no significant difference in quality. The resulting system is capable of generating high-fidelity speech samples at more than 20 times faster than real-time, a 1000x speed up relative to the original WaveNet, and capable of serving multiple English and Japanese voices in a production setting.}
}

@article{dinh2016density,
  added-at = {2018-08-13T00:00:00.000+0200},
  author = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  biburl = {https://www.bibsonomy.org/bibtex/2859fa3b8f19792c99866c25bb7929c7d/dblp},
  ee = {http://arxiv.org/abs/1605.08803},
  interhash = {c0077430b328ea1f29e79319529e865a},
  intrahash = {859fa3b8f19792c99866c25bb7929c7d},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2018-08-14T14:21:24.000+0200},
  title = {Density estimation using Real NVP.},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1605.html#DinhSB16},
  volume = {abs/1605.08803},
  year = 2016
}


@inproceedings{oord2016pixelrnn,
 author = {Van Den Oord, A\"{a}ron and Kalchbrenner, Nal and Kavukcuoglu, Koray},
 title = {Pixel Recurrent Neural Networks},
 booktitle = {Proceedings of the 33rd International Conference on International Conference on Machine Learning - Volume 48},
 series = {ICML'16},
 year = {2016},
} 

@article{ghavamzadeh2015bayesian,
 author = {Ghavamzadeh, Mohammad and Mannor, Shie and Pineau, Joelle and Tamar, Aviv},
 title = {Bayesian Reinforcement Learning: A Survey},
 journal = {Found. Trends Mach. Learn.},
 issue_date = {11 2015},
 volume = {8},
 number = {5-6},
 month = nov,
 year = {2015},
 issn = {1935-8237},
 pages = {359--483},
 numpages = {125},
 url = {http://dx.doi.org/10.1561/2200000049},
 doi = {10.1561/2200000049},
 acmid = {2858996},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
} 


@article{russo2018tutorialthompson,
 author = {Russo, Daniel J. and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng},
 title = {A Tutorial on Thompson Sampling},
 journal = {Found. Trends Mach. Learn.},
 issue_date = {12 7 2018},
 volume = {11},
 number = {1},
 month = jul,
 year = {2018},
 issn = {1935-8237},
 pages = {1--96},
 numpages = {96},
 url = {https://doi.org/10.1561/2200000070},
 doi = {10.1561/2200000070},
 acmid = {3283246},
 publisher = {Now Publishers Inc.},
 address = {Hanover, MA, USA},
 keywords = {Bandit learning, Exploration},
} 


@inproceedings{swaminathan2015selfnormalized,
 author = {Swaminathan, Adith and Joachims, Thorsten},
 title = {The Self-normalized Estimator for Counterfactual Learning},
 booktitle = {Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2},
 series = {NIPS'15},
 year = {2015},
} 


@InProceedings{garnelo18conditional,
  title = 	 {{Conditional Neural Processes}},
  author = 	 {Garnelo, Marta and Rosenbaum, Dan and Maddison, Christopher and Ramalho, Tiago and Saxton, David and Shanahan, Murray and Teh, Yee Whye and Rezende, Danilo and Eslami, S. M. Ali},
  booktitle = 	 {ICML},
  year = 	 {2018},
}

@article{garnelo18neural,
  author    = {Marta Garnelo and
               Jonathan Schwarz and
               Dan Rosenbaum and
               Fabio Viola and
               Danilo J. Rezende and
               S. M. Ali Eslami and
               Yee Whye Teh},
  title     = {{Neural Processes}},
  journal={arXiv preprint arXiv:1807.01622},
  year={2018}
}

@inproceedings{
kim2018attentive,
title={{Attentive Neural Processes}},
author={Hyunjik Kim and Andriy Mnih and Jonathan Schwarz and Marta Garnelo and Ali Eslami and Dan Rosenbaum and Oriol Vinyals and Yee Whye Teh},
booktitle={ICLR},
year={2019},
}

@article{shahriari2016TakingTH,
  title={{Taking the Human Out of the Loop: A Review of Bayesian Optimization}},
  author={Bobak Shahriari and Kevin Swersky and Ziyu Wang and Ryan P. Adams and Nando de Freitas},
  journal={Proceedings of the IEEE},
  year={2016},
}

@ARTICLE{rubinstein96optimizationof,
    author = {Reuven Y. Rubinstein},
    title = {Optimization of Computer Simulation Models with Rare Events},
    journal = {European Journal of Operations Research},
    year = {1996},
    volume = {99},
    pages = {89--112}
}

@book{rubinstein2004cross,
 author = {Rubinstein, Reuven Y. and Kroese, Dirk P.},
 title = {The Cross Entropy Method: A Unified Approach To Combinatorial Optimization, Monte-carlo Simulation (Information Science and Statistics)},
 year = {2004},
 isbn = {038721240X},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
} 


@inproceedings{
joachims2018deep,
title={Deep Learning with Logged Bandit Feedback},
author={Thorsten Joachims and Adith Swaminathan and Maarten de Rijke},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJaP_-xAb},
}

@inproceedings{swaminathan2015counterfactual,
 author = {Swaminathan, Adith and Joachims, Thorsten},
 title = {Counterfactual Risk Minimization: Learning from Logged Bandit Feedback},
 booktitle = {Proceedings of the 32Nd International Conference on International Conference on Machine Learning - Volume 37},
 series = {ICML'15},
 year = {2015},
} 

@article{goodfellow2014generative,
  title={Generative adversarial networks},
  author={Goodfellow, Ian J and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1406.2661},
  year={2014}
}

@InProceedings{snoek15scalable,
  title = 	 {{Scalable Bayesian Optimization Using Deep Neural Networks}},
  author = 	 {Jasper Snoek and Oren Rippel and Kevin Swersky and Ryan Kiros and Nadathur Satish and Narayanan Sundaram and Mostofa Patwary and Mr Prabhat and Ryan Adams},
  booktitle = 	 {ICML},
  year = 	 {2015},
}

@inproceedings{zhu2016generative,
  title={Generative Visual Manipulation on the Natural Image Manifold},
  author={Zhu, Jun-Yan and Kr{\"a}henb{\"u}hl, Philipp and Shechtman, Eli and Efros, Alexei A.},
  booktitle={Proceedings of European Conference on Computer Vision (ECCV)},
  year={2016}
}

@inproceedings{peters2012reinforcement,
 author = {Peters, Jan and Schaal, Stefan},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {Proceedings of the 24th International Conference on Machine Learning},
 series = {ICML '07},
 year = {2007},
} 

@inproceedings{snoek2012practical,
 author = {Snoek, Jasper and Larochelle, Hugo and Adams, Ryan P.},
 title = {{Practical Bayesian Optimization of Machine Learning Algorithms}},
 booktitle = {NIPS},
 year = {2012},
} 

@inproceedings{zoph2017,
title	= {Neural Architecture Search with Reinforcement Learning},
author	= {Barret Zoph and Quoc V. Le},
year	= {2017},
URL	= {https://arxiv.org/abs/1611.01578}
}

@inproceedings{liao2019,
  title                 = {Data-efficient Learning of Morphology and Controller for a Microrobot},
  author                = {Liao, Thomas and Wang, Grant and Yang, Brian and Lee, Rene and Pister, Kristofer and Levine, Sergey and Calandra, Roberto},
  booktitle             = {2019 IEEE International Conference on Robotics and Automation},
  year                  = {2019},
  url                   = {https://arxiv.org/abs/1905.01334}
}

@inproceedings{hoburg2012,
author = {Hoburg, Warren and Abbeel, Pieter},
year = {2012},
month = {04},
pages = {},
title = {Geometric Programming for Aircraft Design Optimization},
volume = {52},
isbn = {978-1-60086-937-2},
journal = {AIAA Journal},
doi = {10.2514/6.2012-1680}
}

@InProceedings{brookes19a,
  title = 	 {{Conditioning by Adaptive Sampling for Robust Design}},
  author = 	 {Brookes, David and Park, Hahnbeom and Listgarten, Jennifer},
  booktitle = 	 {ICML},
  year = 	 {2019},
}


@book{koller_friedman,
 author = {Koller, D. and Friedman, N.},
 title = {Probabilistic Graphical Models: Principles and Techniques},
 year = {2009},
 isbn = {0262013193, 9780262013192},
 publisher = {The MIT Press},
} 

@inproceedings{gae,
title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
author = {J. Schulman and P. Moritz and S. Levine and M. Jordan and P. Abbeel},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2016
}

@inproceedings{toussaint06,
 author = {Toussaint, M. and Storkey, A.},
 title = {Probabilistic Inference for Solving Discrete and Continuous State Markov Decision Processes},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2006},
} 

@INPROCEEDINGS{attias,
    author = {H. Attias},
    title = {Planning by Probabilistic Inference},
    booktitle = {Proceedings of the 9th International Workshop on Artificial Intelligence and Statistics},
    year = {2003}
}

@InProceedings{ebrl,
  title = 	 {Actor-Critic Reinforcement Learning with Energy-Based Policies},
  author = 	 {N. Heess and D. Silver and Y. W. Teh},
  booktitle = 	 {European Workshop on Reinforcement Learning (EWRL)},
  year = 	 {2013},
}

@inproceedings{ep,
 author = {Minka, T. P.},
 title = {Expectation Propagation for Approximate Bayesian Inference},
 booktitle = {Uncertainty in Artificial Intelligence (UAI)},
 year = {2001},
}

@inproceedings{mpo,
title = {Maximum a Posteriori Policy Optimisation},
author = {A. Abdolmaleki and J. T. Springenberg and Y. Tassa and R. Munos and N. Heess and M. Riedmiller},
booktitle = {International Conference on Learning Representations (ICLR)},
year  = 2018
}

@article{williams,
 author = {Williams, R. J.},
 title = {Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning},
 journal = {Machine Learning},
 issue_date = {May 1992},
 volume = {8},
 number = {3-4},
 month = may,
 year = {1992},
 pages = {229--256}
} 

@article{WilliamsPeng91,
  author = {Williams, R. J. and Peng, J.},
  journal = {Connection Science},
  number = 3,
  pages = {241-268},
  title = {Function optimization using connectionist reinforcement learning
	algorithms},
  volume = 3,
  year = 1991
}

@INPROCEEDINGS{suttonadp,
    author = {R. S. Sutton},
    title = {Integrated Architectures for Learning, Planning, and Reacting Based on Approximating Dynamic Programming},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {1990},
}

@inproceedings{pgq,
author = {O'Donoghue, B. and Munos, R. and Kavukcuoglu, K. and Mnih, V.},
year = {2017},
title = {PGQ: Combining policy gradient and Q-learning},
booktitle = {International Conference on Learning Representations (ICLR)}
}

@article{sallans,
 author = {Sallans, B. and Hinton, G. E.},
 title = {Reinforcement Learning with Factored States and Actions},
 journal = {Journal of Machine Learning Research},
 volume = {5},
 month = dec,
 year = {2004}
 },

@article{KLMSurvey,
    author = "L. P. Kaelbling and M. L. Littman and A. P. Moore",
    title = "Reinforcement Learning: A Survey",
    journal = "Journal of Artificial Intelligence Research",
    volume = "4",
    pages = "237-285",
    year = "1996",
url={http://people.csail.mit.edu/lpk/papers/rl-survey.ps}}

@inproceedings{todorov_kalman_duality, 
author={E. Todorov}, 
booktitle={Conference on Decision and Control (CDC)},
title={General duality between optimal control and estimation}, 
year={2008},
}

@inproceedings{covariant,
author = {J. A. Bagnell and J. Schneider},
title = {Covariant Policy Search},
booktitle = {International Joint Conference on Artifical Intelligence (IJCAI)},
year = {2003},
}

@InProceedings{reps,
  author =       "Peters, J. and  M{\"u}lling, K. and Alt{\"u}n, Y.",
  title =        "Relative Entropy Policy Search",
  booktitle =    "AAAI Conference on Artificial Intelligence (AAAI)",
  year =         "2010",
}

@inproceedings{mfgps,
title = {Learning Neural Network Policies with Guided Policy Search under Unknown Dynamics},
author = {Levine, S. and Abbeel, P.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{lmdp_policy,
  author    = {E. Todorov},
  title     = {Policy gradients in linearly-solvable MDPs},
  booktitle = {Neural Information Processing Systems (NIPS)},
  year      = {2010},
}

@inproceedings{ldmp_irl,
 author = {Dvijotham, K. and Todorov, E.},
 title = {Inverse Optimal Control with Linearly-solvable MDPs},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2010},
} 

@inproceedings{pi2,
  title = {Learning Policy Improvements with Path Integrals},
  author = {Theodorou, E. A. and Buchli, J. and Schaal, S.},
  booktitle = {International Conference on  Artificial Intelligence and Statistics (AISTATS 2010)},
  year = {2010},
}

@InProceedings{trpo,
  title = 	 {Trust Region Policy Optimization},
  author = 	 {J. Schulman and S. Levine and P. Moritz and M. I. Jordan and P. Abbeel},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  year = 	 {2015},
}

@phdthesis{levine_thesis,
author = {Levine, S.},
title = {Motor skill learning with local trajectory methods},
school = {Stanford University},
year = {2014},
}

@phdthesis{ziebart_thesis,
author = {Ziebart, B.},
title = {Modeling purposeful adaptive behavior with the principle of maximum causal entropy},
school = {Carnegie Mellon University},
year = {2010},
}

@article{kappen_oc,
  author    = {H. J. Kappen},
  title     = {Optimal control theory and the linear bellman equation},
  journal   = {Inference and Learning in Dynamic Models},
  year      = {2011},
  pages     = {363-387},
}

@article{kappen_pgm,
  author    = {H. J. Kappen and
               V. G{\'o}mez and
               M. Opper},
  title     = {Optimal control as a graphical model inference problem},
  journal   = {Machine Learning},
  volume    = {87},
  number    = {2},
  year      = {2012},
  pages     = {159-182},
}

@inproceedings{rawlik_soc,
  author    = {K. Rawlik and
               M. Toussaint and
               S. Vijayakumar},
  title     = {On Stochastic Optimal Control and Reinforcement Learning
               by Approximate Inference},
  year = {2013},
  booktitle = {Robotics: Science and Systems (RSS)},
}

@inproceedings{toussaint_soc,
  author    = {M. Toussaint},
  title     = {Robot trajectory optimization using approximate inference},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2009},
}

@inproceedings{toussaint_pgm,
  title={Hierarchical POMDP Controller Optimization by Likelihood Maximization},
  author={Toussaint, M. and Charlin, L. and Poupart, P.},
  booktitle={Uncertainty in Artificial Intelligence (UAI)},
  volume={24},
  pages={562--570},
  year={2008}
}

@article{kalman_filter,
  author={R. Kalman},
  title={A new approach to linear filtering and prediction problems},
  journal={ASME Transactions journal of basic engineering},
  volume={82},
  number={1},
  pages={35-45},
  year={1960}
}

@inproceedings{todorov_lmdp,
  author    = {E. Todorov},
  title     = {Linearly-solvable Markov decision problems},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2006},
}

@inproceedings{rwr,
 author = {Peters, J. and Schaal, S.},
 title = {Reinforcement Learning by Reward-weighted Regression for Operational Space Control},
 booktitle = {International Conference on Machine Learning (ICML)},
 year = {2007},
} 


@inproceedings{neumann,
  author    = {G. Neumann},
  title     = {Variational Inference for Policy Search in changing situations},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2011},
}

@inproceedings{levine_vgps,
  author    = {S. Levine and V. Koltun},
  title     = {Variational policy search via trajectory optimization},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  year      = {2013},
}

@inproceedings{em_policy_search,
  title = {Efficient Sample Reuse in EM-Based Policy Search},
  author = {Hachiya, H. and Peters, J. and Sugiyama, M.},
  booktitle = {European Conference on Machine Learning (ECML)},
  year = {2009},
}

@article{vmp,
    title={Variational message passing},
    author={Winn, J. and Bishop, C.},
    journal={Journal of Machine Learning Research},
    volume={6},
    year={2005},
    pages={661-694}
}

@inproceedings{haarnoja,
  title={Reinforcement Learning with Deep Energy-Based Policies},
  author={Haarnoja, T. and Tang, H. and Abbeel, P. and Levine, S.},
  booktitle={International Conference on Machine Learning (ICML)},
  year={2017}
}

@inproceedings{sac,
title = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
author  = {T. Haarnoja and A. Zhou and P. Abbeel and S. Levine},
year  = {2018},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1801.01290.pdf}
}

@inproceedings{pcl,
title = {Bridging the Gap Between Value and Policy Based Reinforcement Learning},
author  = {O. Nachum and M. Norouzi and K. Xu and D. Schuurmans},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1702.08892.pdf}
}

@inproceedings{gps,
 author = {Levine, S. and Koltun, V.},
 title = {Guided Policy Search},
 booktitle = {International Conference on International Conference on Machine Learning (ICML)},
 year = {2013},
} 

@inproceedings{maxentirl,
 author = {Ziebart, B. D. and Maas, A. and Bagnell, J. A. and Dey, A. K.},
 title = {Maximum Entropy Inverse Reinforcement Learning},
 booktitle = {International Conference on Artificial Intelligence (AAAI)},
 year = {2008},
} 

@inproceedings{haarnoja_composable,
author = {Haarnjoa, T. and Pong, V. and Zhou, A. and Dalal, M. and Abbeel, P. and Levine, S.},
title = {Composable Deep Reinforcement Learning for Robotic Manipulation},
booktitle = {International Conference on Robotics and Automation (ICRA)},
year = {2018},
}

@article{Gupta2018FeedbackG,
  title={Feedback GAN (FBGAN) for DNA: a Novel Feedback-Loop Architecture for Optimizing Protein Functions},
  author={Anvita Gupta and James Zou},
  journal={ArXiv},
  year={2018},
  volume={abs/1804.01694}
}

@misc{nvidia,
  title = {{Nvidia}},
  howpublished = {\url{https://www.nvidia.com/en-us/}},
  author={Nvidia},
  note = {Accessed: 2021-05-16},
  year={2021}
}

@misc{graphcore,
  title = {{GraphCore}},
  howpublished = {\url{https://www.graphcore.ai/}},
  author={GraphCore},
  note = {Accessed: 2021-05-16},
  year={2021}
}


@inproceedings{GmezBombarelli2018AutomaticCD,
  title={Automatic Chemical Design Using a Data-Driven Continuous
Representation of Molecules},
  author={Rafael G{\'o}mez-Bombarelli and David Duvenaud and Jos{\'e} Miguel Hern{\'a}ndez-Lobato and Jorge Aguilera-Iparraguirre and Timothy D. Hirzel and Ryan P. Adams and Al{\'a}n Aspuru-Guzik},
  booktitle={ACS central science},
  year={2018}
}

@inbook{ngyuen_rebuttal,
author = {Phuoc Nguyen and Truyen Tran and Sunil Gupta and Santu Rana and Matthew Barnett and Svetha Venkatesh},
title = {Incomplete Conditional Density Estimation for Fast Materials Discovery},
booktitle = {Proceedings of the 2019 SIAM International Conference on Data Mining},
chapter = {},
pages = {549-557},
doi = {10.1137/1.9781611975673.62},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611975673.62},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611975673.62}
}


@article{trust_pcl,
  author    = {O. Nachum and
               M. Norouzi and
               K. Xu and
               D. Schuurmans},
  title     = {Trust-PCL: An Off-Policy Trust Region Method for Continuous Control},
  journal   = {CoRR},
  volume    = {abs/1707.01891},
  year      = {2017},
}

@inproceedings{gpirl,
 author = {Levine, S. and Popovi\'{c}, Z. and Koltun, V.},
 title = {Nonlinear Inverse Reinforcement Learning with Gaussian Processes},
 booktitle = {Neural Information Processing Systems (NIPS)},
 year = {2011},
}

@inproceedings{localioc,
    author = {S. Levine and V. Koltun},
    title = {Continuous Inverse Optimal Control with Locally Optimal Examples},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2012},
}

@inproceedings{legibility,
  author    = {A. D. Dragan and
               K. C. T. Lee and
               S. S. Srinivasa},
  title     = {Legibility and predictability of robot motion},
  booktitle = {International Conference on Human-Robot Interaction (HRI)},
  year      = {2013},
}

@inproceedings{maxentdeepirl,
author = {M. Wulfmeier and
P. Ondruska and
I. Posner},
title = {Maximum Entropy Deep Inverse Reinforcement Learning},
Booktitle = {Neural Information Processing Systems Conference, Deep Reinforcement Learning Workshop},
year = {2015},
}

@inproceedings{maxcausalent,
  author    = {B. D. Ziebart and
               J. A. Bagnell and
               A. K. Dey},
  title     = {Modeling Interaction via the Principle of Maximum Causal Entropy},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2010},
}

@inproceedings{kitani1,
  author    = {D. Huang and
               K. M. Kitani},
  title     = {Action-Reaction: Forecasting the Dynamics of Human Interaction},
  booktitle = {European Conference on Computer Vision (ECCV)},
  year      = {2014},
}

@inproceedings{kitani2,
  author    = {D. Huang and
               A. Farahmand and
               K. M. Kitani and
               J. A. Bagnell},
  title     = {Approximate {MaxEnt} Inverse Optimal Control and Its Application for
               Mental Simulation of Human Interactions},
  booktitle = {AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2015},
}

@article{realnvp,
title={Latent Space Policies for Hierarchical Reinforcement Learning},
author={T. Haarnoja and K. Hartikainen and P. Abbeel and S. Levine},
journal   = {CoRR},
volume    = {abs/1804.02808},
year      = {2018},
}

@inproceedings{Javdani, 
    AUTHOR    = {S. Javdani and S. Srinivasa and J. A. Bagnell}, 
    TITLE     = {Shared Autonomy via Hindsight Optimization}, 
    BOOKTITLE = {Robotics: Science and Systems (RSS)}, 
    YEAR      = {2015}, 
}

@inproceedings{airl,
title={Learning Robust Rewards with Adversarial Inverse Reinforcement Learning},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
author={Fu, J. and Luo, K. and Levine, S.},
}

@inproceedings{hausman,
title={Learning an Embedding Space for Transferable Robot Skills},
author={K. Hausman and J. T. Springenberg and Z. Wang and N. Heess and M. Riedmiller},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
}

@article{learning_to_explore,
  author    = {A. Gupta and
               R. Mendonca and
               Y. Liu and
               P. Abbeel and
               S. Levine},
  title     = {Meta-Reinforcement Learning of Structured Exploration Strategies},
  journal   = {CoRR},
  volume    = {abs/1802.07245},
  year      = {2018},
}

@article{endtoend,
 author = {Levine, S. and Finn, C. and Darrell, T. and Abbeel, P.},
 title = {End-to-end Training of Deep Visuomotor Policies},
 journal = {Journal of Machine Learning Research},
 issue_date = {January 2016},
 volume = {17},
 number = {1},
 month = jan,
 year = {2016},
} 

@inproceedings{cgps,
    author = {Sergey Levine and Vladlen Koltun},
    title = {Learning Complex Neural Network Policies with Trajectory Optimization},
    booktitle = {International Conference on Machine Learning (ICML)},
    year = {2014},
}
@inproceedings{schulman,
title = {Equivalence Between Policy Gradients and Soft Q-Learning},
author  = {J. Schulman and X. Chen and P. Abbeel},
year  = {2017},
booktitle = {arXiv},
URL = {https://arxiv.org/pdf/1704.06440}
}

@article{gelbart2014bayesian,
  title={{Bayesian Optimization with Unknown Constraints}},
  author={Gelbart, Michael A and Snoek, Jasper and Adams, Ryan P},
  journal={arXiv preprint arXiv:1403.5607},
  year={2014}
}

@article{gaulton2012chembl,
  title={ChEMBL: a large-scale bioactivity database for drug discovery},
  author={Gaulton, Anna and Bellis, Louisa J and Bento, A Patricia and Chambers, Jon and Davies, Mark and Hersey, Anne and Light, Yvonne and McGlinchey, Shaun and Michalovich, David and Al-Lazikani, Bissan and others},
  journal={Nucleic acids research},
  volume={40},
  number={D1},
  pages={D1100--D1107},
  year={2012},
  publisher={Oxford University Press}
}


@article{shazeer2017outrageously,
  title={{Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer}},
  author={Shazeer, Noam and Mirhoseini, Azalia and Maziarz, Krzysztof and Davis, Andy and Le, Quoc and Hinton, Geoffrey and Dean, Jeff},
  journal={arXiv preprint arXiv:1701.06538},
  year={2017}
}

@book{yang2010nature,
  title={{Nature-Inspired Metaheuristic Algorithms}},
  author={Yang, Xin-She},
  year={2010},
  publisher={Luniver press},
}

@incollection{yang2010eagle,
  title={{Eagle Strategy Using L{\'e}vy Walk and Firefly Algorithms for Stochastic Optimization}},
  author={Yang, Xin-She and Deb, Suash},
  booktitle={NICSO},
    publisher={Springer},
  year={2010},
}

@inproceedings{liu2013adaptive,
  title={{Adaptive Firefly Optimization Algorithm Based on Stochastic Inertia Weight}},
  author={Liu, Changnian and Tian, Yafei and Zhang, Qiang and Yuan, Jie and Xue, Binbin},
  booktitle={ISCID},
  year={2013},
}


@book{flynn2011computer,
  title={{Computer System Design: System-on-Chip}},
  author={Flynn, Michael J and Luk, Wayne},
  year={2011},
  publisher={John Wiley \& Sons},
}

@misc{trabucco2021designbench,
title={{Design-Bench: Benchmarks for Data-Driven Offline Model-Based Optimization}},
author={Brandon Trabucco and Aviral Kumar and Xinyang Geng and Sergey Levine},
year={2021},
url={https://openreview.net/forum?id=cQzf26aA3vM}
}

@article{jacot2018neural,
  title={Neural tangent kernel: Convergence and generalization in neural networks},
  author={Jacot, Arthur and Gabriel, Franck and Hongler, Cl{\'e}ment},
  journal={arXiv preprint arXiv:1806.07572},
  year={2018}
}

@article{suggala2018connecting,
  title={Connecting optimization and regularization paths},
  author={Suggala, Arun and Prasad, Adarsh and Ravikumar, Pradeep K},
  journal={Advances in Neural Information Processing Systems},
  volume={31},
  pages={10608--10619},
  year={2018}
}

@article{goodfellow2014explaining,
  title={{Explaining and Harnessing Adversarial Examples}},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={ICLR},
  year={2015}
}

@article{mirhoseini2020chip,
  title={{A Graph Placement Methodology for Fast Chip Design}},
  author={Mirhoseini, Azalia and Goldie, Anna and Yazgan, Mustafa and Jiang, Joe Wenjie and Songhori, Ebrahim and Wang, Shen and Lee, Young-Joon and Johnson, Eric and Pathak, Omkar and Nazi, Azade and others},
  journal={Nature},
  year={2021},
}

@article{kumar2020conservative,
  title={{Conservative Q-Learning for Offline Reinforcement Learning}},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={NeurIPS},
  year={2020}
}

@inproceedings{thomas2015high,
  title={High-confidence off-policy evaluation},
  author={Thomas, Philip and Theocharous, Georgios and Ghavamzadeh, Mohammad},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={29},
  number={1},
  year={2015}
}

@article{voloshin2019empirical,
  title={Empirical Study of Off-Policy Policy Evaluation for Reinforcement Learning},
  author={Voloshin, Cameron and Le, Hoang M and Jiang, Nan and Yue, Yisong},
  journal={arXiv preprint arXiv:1911.06854},
  year={2019}
}


@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@article{fannjiang2020autofocused,
  title={{Autofocused Oracles for Model-Based Design}},
  author={Fannjiang, Clara and Listgarten, Jennifer},
  journal={arXiv preprint arXiv:2006.08052},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@inproceedings{berkenkamp2016safe,
  title={Safe controller optimization for quadrotors with Gaussian processes},
  author={Berkenkamp, Felix and Schoellig, Angela P and Krause, Andreas},
  booktitle={2016 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={491--496},
  year={2016},
  organization={IEEE}
} 

@article{kumar2019model,
  title={{Model Inversion Networks for Model-Based Optimization}},
  author={Kumar, Aviral and Levine, Sergey},
  journal={NeurIPS},
  year={2020}
}

@inproceedings{nvil,
  author    = {A. Mnih and
               K. Gregor},
  title     = {Neural Variational Inference and Learning in Belief Networks},
  booktitle = {International Conference on Machine Learning (ICML)},
  year      = {2014}
}

@inproceedings{gcl,
  author    = {Chelsea Finn and
               Sergey Levine and
               Pieter Abbeel},
  title     = {Guided Cost Learning: Deep Inverse Optimal Control via Policy Optimization},
    booktitle   = {International Conference on Machine Learning (ICML)},
  year      = {2016},
}

@inproceedings{gan,
title = {Generative Adversarial Nets},
author = {Goodfellow, I. and Pouget-Abadie, J. and Mirza, M. and Xu, B. and Warde-Farley, D. and Ozair, S. and Courville, A. and Bengio, Y.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2014},
}

@inproceedings{gail,
title = {Generative Adversarial Imitation Learning},
author = {Ho, J. and Ermon, S.},
booktitle = {Neural Information Processing Systems (NIPS)},
year = {2016},
}

@article{finn_adversarial,
  author    = {Chelsea Finn and
               Paul Christiano and
               Pieter Abbeel and
               Sergey Levine},
  title     = {A Connection between Generative Adversarial Networks, Inverse Reinforcement
               Learning, and Energy-Based Models},
  journal   = {CoRR},
  volume    = {abs/1611.03852},
  year      = {2016},
}

﻿@Article{gfp,
author={Sarkisyan, Karen S.
and Bolotin, Dmitry A.
and Meer, Margarita V.
and Usmanova, Dinara R.
and Mishin, Alexander S.
and Sharonov, George V.
and Ivankov, Dmitry N.
and Bozhanova, Nina G.
and Baranov, Mikhail S.
and Soylemez, Onuralp
and Bogatyreva, Natalya S.
and Vlasov, Peter K.
and Egorov, Evgeny S.
and Logacheva, Maria D.
and Kondrashov, Alexey S.
and Chudakov, Dmitry M.
and Putintseva, Ekaterina V.
and Mamedov, Ilgar Z.
and Tawfik, Dan S.
and Lukyanov, Konstantin A.
and Kondrashov, Fyodor A.},
title={Local fitness landscape of the green fluorescent protein},
journal={Nature},
year={2016},
month={May},
day={01},
volume={533},
number={7603},
pages={397-401},
abstract={Comprehensive genotype--phenotype mapping of the green fluorescent protein shows that the local fitness peak is narrow, shaped by a high prevalence of epistatic interactions, providing for the loss of fluorescence when the joint effect of mutations exceeds a threshold.},
issn={1476-4687},
doi={10.1038/nature17995},
url={https://doi.org/10.1038/nature17995}
}

@article{martin2019molecule,
    author = {Martin, Eric J. and Polyakov, Valery R. and Zhu, Xiang-Wei and Tian, Li and Mukherjee, Prasenjit and Liu, Xin},
    title = {All-Assay-Max2 pQSAR: Activity Predictions as Accurate as Four-Concentration IC50s for 8558 Novartis Assays},
    journal = {Journal of Chemical Information and Modeling},
    volume = {59},
    number = {10},
    pages = {4450-4459},
    year = {2019},
    doi = {10.1021/acs.jcim.9b00375},
    note ={PMID: 31518124},
    URL = {https://doi.org/10.1021/acs.jcim.9b00375},
    eprint = {https://doi.org/10.1021/acs.jcim.9b00375}
}

@inproceedings{kingma2014adam,
  author    = {Diederik P. Kingma and
               Jimmy Ba},
  title     = {{Adam: {A} Method for Stochastic Optimization}},
  booktitle = {ICLR},
  year      = {2015},
}


@inproceedings{Florian2018,
  author    = {Florian Tram{\`{e}}r and
               Alexey Kurakin and
               Nicolas Papernot and
               Ian J. Goodfellow and
               Dan Boneh and
               Patrick D. McDaniel},
  title     = {Ensemble Adversarial Training: Attacks and Defenses},
  booktitle = {6th International Conference on Learning Representations, {ICLR} 2018,
               Vancouver, BC, Canada, April 30 - May 3, 2018, Conference Track Proceedings},
  publisher = {OpenReview.net},
  year      = {2018},
  url       = {https://openreview.net/forum?id=rkZvSe-RZ},
  timestamp = {Thu, 25 Jul 2019 14:25:44 +0200},
  biburl    = {https://dblp.org/rec/conf/iclr/TramerKPGBM18.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{Santurkar19RobustClassifier,
  author    = {Shibani Santurkar and
               Andrew Ilyas and
               Dimitris Tsipras and
               Logan Engstrom and
               Brandon Tran and
               Aleksander Madry},
  editor    = {Hanna M. Wallach and
               Hugo Larochelle and
               Alina Beygelzimer and
               Florence d'Alch{\'{e}}{-}Buc and
               Emily B. Fox and
               Roman Garnett},
  title     = {Image Synthesis with a Single (Robust) Classifier},
  booktitle = {Advances in Neural Information Processing Systems 32: Annual Conference
               on Neural Information Processing Systems 2019, NeurIPS 2019, 8-14
               December 2019, Vancouver, BC, Canada},
  pages     = {1260--1271},
  year      = {2019},
  url       = {http://papers.nips.cc/paper/8409-image-synthesis-with-a-single-robust-classifier},
  timestamp = {Fri, 06 Mar 2020 16:59:09 +0100},
  biburl    = {https://dblp.org/rec/conf/nips/SanturkarITETM19.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{kirkpatrick1983optimization,
  title={Optimization by simulated annealing},
  author={Kirkpatrick, Scott and Gelatt, C Daniel and Vecchi, Mario P},
  journal={science},
  volume={220},
  number={4598},
  pages={671--680},
  year={1983},
  publisher={American association for the advancement of science}
}

@incollection{van1987simulated,
  title={Simulated annealing},
  author={Van Laarhoven, Peter JM and Aarts, Emile HL},
  booktitle={Simulated annealing: Theory and applications},
  pages={7--15},
  year={1987},
  publisher={Springer}
}

@article{kolda2003optimization,
  title={Optimization by direct search: New perspectives on some classical and modern methods},
  author={Kolda, Tamara G and Lewis, Robert Michael and Torczon, Virginia},
  journal={SIAM review},
  volume={45},
  number={3},
  pages={385--482},
  year={2003},
  publisher={SIAM}
}

@article{powell1998direct,
  title={Direct search algorithms for optimization calculations},
  author={Powell, Michael JD},
  journal={Acta numerica},
  pages={287--336},
  year={1998},
  publisher={Cambridge University Press}
}

@book{rubinstein2013cross,
  title={The cross-entropy method: a unified approach to combinatorial optimization, Monte-Carlo simulation and machine learning},
  author={Rubinstein, Reuven Y and Kroese, Dirk P},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@article{whitley1994genetic,
  title={A genetic algorithm tutorial},
  author={Whitley, Darrell},
  journal={Statistics and computing},
  volume={4},
  number={2},
  pages={65--85},
  year={1994},
  publisher={Springer}
}

@inproceedings{welling2011bayesian,
  title={Bayesian learning via stochastic gradient Langevin dynamics},
  author={Welling, Max and Teh, Yee W},
  booktitle={Proceedings of the 28th international conference on machine learning (ICML-11)},
  pages={681--688},
  year={2011}
}

@book{williams2006gaussian,
  title={Gaussian processes for machine learning},
  author={Williams, Christopher KI and Rasmussen, Carl Edward},
  volume={2},
  number={3},
  year={2006},
  publisher={MIT press Cambridge, MA}
}

@inproceedings{gonzalez2016batch,
  title={Batch bayesian optimization via local penalization},
  author={Gonz{\'a}lez, Javier and Dai, Zhenwen and Hennig, Philipp and Lawrence, Neil},
  booktitle={Artificial intelligence and statistics},
  pages={648--657},
  year={2016}
}

@article{qin2008differential,
  title={Differential evolution algorithm with strategy adaptation for global numerical optimization},
  author={Qin, A Kai and Huang, Vicky Ling and Suganthan, Ponnuthurai N},
  journal={IEEE transactions on Evolutionary Computation},
  volume={13},
  number={2},
  pages={398--417},
  year={2008},
  publisher={IEEE}
}

@inproceedings{snoek2015scalable,
  title={Scalable bayesian optimization using deep neural networks},
  author={Snoek, Jasper and Rippel, Oren and Swersky, Kevin and Kiros, Ryan and Satish, Nadathur and Sundaram, Narayanan and Patwary, Mostofa and Prabhat, Mr and Adams, Ryan},
  booktitle={International conference on machine learning},
  pages={2171--2180},
  year={2015}
}
@article{wang2005hybrid,
  title={A hybrid genetic algorithm--neural network strategy for simulation optimization},
  author={Wang, Ling},
  journal={Applied Mathematics and Computation},
  volume={170},
  number={2},
  pages={1329--1343},
  year={2005},
  publisher={Elsevier}
}

@article{brookes2019conditioning,
  title={Conditioning by adaptive sampling for robust design},
  author={Brookes, David H and Park, Hahnbeom and Listgarten, Jennifer},
  journal={arXiv preprint arXiv:1901.10060},
  year={2019}
}

@article{kingma2013auto,
  title={{Auto-Encoding Variational Bayes}},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013}
}

@Article{sarkisyan2016GFP,
    author={Sarkisyan, Karen S.
    and Bolotin, Dmitry A.
    and Meer, Margarita V.
    and Usmanova, Dinara R.
    and Mishin, Alexander S.
    and Sharonov, George V.
    and Ivankov, Dmitry N.
    and Bozhanova, Nina G.
    and Baranov, Mikhail S.
    and Soylemez, Onuralp
    and Bogatyreva, Natalya S.
    and Vlasov, Peter K.
    and Egorov, Evgeny S.
    and Logacheva, Maria D.
    and Kondrashov, Alexey S.
    and Chudakov, Dmitry M.
    and Putintseva, Ekaterina V.
    and Mamedov, Ilgar Z.
    and Tawfik, Dan S.
    and Lukyanov, Konstantin A.
    and Kondrashov, Fyodor A.},
    title={Local fitness landscape of the green fluorescent protein},
    journal={Nature},
    year={2016},
    month={May},
    day={01},
    volume={533},
    number={7603},
    pages={397-401},
    abstract={Comprehensive genotype--phenotype mapping of the green fluorescent protein shows that the local fitness peak is narrow, shaped by a high prevalence of epistatic interactions, providing for the loss of fluorescence when the joint effect of mutations exceeds a threshold.},
    issn={1476-4687},
    doi={10.1038/nature17995},
    url={https://doi.org/10.1038/nature17995}
    }
    
@article{hamidieh2018superconductor,
    title = "A data-driven statistical model for predicting the critical temperature of a superconductor",
    journal = "Computational Materials Science",
    volume = "154",
    pages = "346 - 354",
    year = "2018",
    issn = "0927-0256",
    doi = "https://doi.org/10.1016/j.commatsci.2018.07.052",
    url = "http://www.sciencedirect.com/science/article/pii/S0927025618304877",
    author = "Kam Hamidieh",
    keywords = "Superconductivity, Superconductor, Machine learning, Statistical learning, Data mining, Critical temperature",
    abstract = "We estimate a statistical model to predict the superconducting critical temperature based on the features extracted from the superconductor’s chemical formula. The statistical model gives reasonable out-of-sample predictions: ±9.5 K based on root-mean-squared-error. Features extracted based on thermal conductivity, atomic radius, valence, electron affinity, and atomic mass contribute the most to the model’s predictive accuracy. It is crucial to note that our model does not predict whether a material is a superconductor or not; it only gives predictions for superconductors."
}

@article{martin2019molecule,
    author = {Martin, Eric J. and Polyakov, Valery R. and Zhu, Xiang-Wei and Tian, Li and Mukherjee, Prasenjit and Liu, Xin},
    title = {All-Assay-Max2 pQSAR: Activity Predictions as Accurate as Four-Concentration IC50s for 8558 Novartis Assays},
    journal = {Journal of Chemical Information and Modeling},
    volume = {59},
    number = {10},
    pages = {4450-4459},
    year = {2019},
    doi = {10.1021/acs.jcim.9b00375},
    note ={PMID: 31518124},
    URL = {https://doi.org/10.1021/acs.jcim.9b00375},
    eprint = {https://doi.org/10.1021/acs.jcim.9b00375}
}

@article{yao2020SupportSet,
  author    = {Huaxiu Yao and
               Longkai Huang and
               Ying Wei and
               Li Tian and
               Junzhou Huang and
               Zhenhui Li},
  title     = {Don't Overlook the Support Set: Towards Improving Generalization in
               Meta-learning},
  journal   = {CoRR},
  volume    = {abs/2007.13040},
  year      = {2020},
  url       = {https://arxiv.org/abs/2007.13040},
  archivePrefix = {arXiv},
  eprint    = {2007.13040},
  timestamp = {Sun, 02 Aug 2020 19:55:03 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-2007-13040.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@Article{Shen2014,
author={Shen, Wen-Jun
and Wong, Hau-San
and Xiao, Quan-Wu
and Guo, Xin
and Smale, Stephen},
title={Introduction to the Peptide Binding Problem of Computational Immunology: New Results},
journal={Foundations of Computational Mathematics},
year={2014},
month={Oct},
day={01},
volume={14},
number={5},
pages={951-984},
abstract={We attempt to establish geometrical methods for amino acid sequences. To measure the similarities of these sequences, a kernel on strings is defined using only the sequence structure and a good amino acid substitution matrix (e.g. BLOSUM62). The kernel is used in learning machines to predict binding affinities of peptides to human leukocyte antigen DR (HLA-DR) molecules. On both fixed allele (Nielsen and Lund in BMC Bioinform. 10:296, 2009) and pan-allele (Nielsen et al. in Immunome Res. 6(1):9, 2010) benchmark databases, our algorithm achieves the state-of-the-art performance. The kernel is also used to define a distance on an HLA-DR allele set based on which a clustering analysis precisely recovers the serotype classifications assigned by WHO (Holdsworth et al. in Tissue Antigens 73(2):95--170, 2009; Marsh et al. in Tissue Antigens 75(4):291--455, 2010). These results suggest that our kernel relates well the sequence structure of both peptides and HLA-DR molecules to their biological functions, and that it offers a simple, powerful and promising methodology to immunology and amino acid sequence studies.},
issn={1615-3383},
doi={10.1007/s10208-013-9173-9},
url={https://doi.org/10.1007/s10208-013-9173-9}
}

@Article{Gaulton2012ChEMBL,
author={Gaulton, Anna
and Bellis, Louisa J.
and Bento, A. Patricia
and Chambers, Jon
and Davies, Mark
and Hersey, Anne
and Light, Yvonne
and McGlinchey, Shaun
and Michalovich, David
and Al-Lazikani, Bissan
and Overington, John P.},
title={ChEMBL: a large-scale bioactivity database for drug discovery},
journal={Nucleic acids research},
year={2012},
month={Jan},
edition={2011/09/23},
publisher={Oxford University Press},
volume={40},
number={Database issue},
pages={D1100-D1107},
keywords={*Databases, Factual; Databases, Protein; *Drug Discovery; Humans; Pharmaceutical Preparations/chemistry; Proteins/chemistry/metabolism; User-Computer Interface},
abstract={ChEMBL is an Open Data database containing binding, functional and ADMET information for a large number of drug-like bioactive compounds. These data are manually abstracted from the primary published literature on a regular basis, then further curated and standardized to maximize their quality and utility across a wide range of chemical biology and drug-discovery research problems. Currently, the database contains 5.4 million bioactivity measurements for more than 1 million compounds and 5200 protein targets. Access is available through a web-based interface, data downloads and web services at: https://www.ebi.ac.uk/chembldb.},
note={21948594[pmid]},
note={PMC3245175[pmcid]},
note={gkr777[PII]},
issn={1362-4962},
doi={10.1093/nar/gkr777},
url={https://pubmed.ncbi.nlm.nih.gov/21948594},
url={https://doi.org/10.1093/nar/gkr777},
language={eng}
}

@article{hoburg2014geometric,
  title={Geometric programming for aircraft design optimization},
  author={Hoburg, Warren and Abbeel, Pieter},
  journal={AIAA Journal},
  volume={52},
  number={11},
  pages={2414--2426},
  year={2014},
  publisher={American Institute of Aeronautics and Astronautics}
}



@book{lizotte2008practical,
  title={Practical bayesian optimization},
  author={Lizotte, Daniel James},
  year={2008},
  publisher={University of Alberta}
}

@INPROCEEDINGS{Kumar_ROBEL, 
 AUTHOR = {Michael Ahn AND Henry Zhu AND Kristian Hartikainen AND Hugo Ponte AND Abhishek Gupta AND Sergey Levine AND Vikash Kumar}, 
 TITLE = "{ROBEL: RObotics BEnchmarks for Learning with low-cost robots}", 
 BOOKTITLE = {Conference on Robot Learning (CoRL)}, 
 YEAR = {2019},
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}

@article{Schulman2017ppo,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06347},
  archivePrefix = {arXiv},
  eprint    = {1707.06347},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{stable-baselines,
  author = {Hill, Ashley and Raffin, Antonin and Ernestus, Maximilian and Gleave, Adam and Kanervisto, Anssi and Traore, Rene and Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai},
  title = {Stable Baselines},
  year = {2018},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/hill-a/stable-baselines}},
}

@article{vaswani2017attention,
  title={{Attention is All you Need}},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, Lukasz and Polosukhin, Illia},
  journal={arXiv preprint arXiv:1706.03762},
  year={2017}
}

@inproceedings{Haarnoja2018SoftAO,
  title={Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author={T. Haarnoja and Aurick Zhou and P. Abbeel and S. Levine},
  booktitle={ICML},
  year={2018}
}

@article{haarnoja2018soft,
  title={Soft actor-critic algorithms and applications},
  author={Haarnoja, Tuomas and Zhou, Aurick and Hartikainen, Kristian and Tucker, George and Ha, Sehoon and Tan, Jie and Kumar, Vikash and Zhu, Henry and Gupta, Abhishek and Abbeel, Pieter and others},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{reparameterization2017,
  author    = {James T. Wilson and
               Riccardo Moriconi and
               Frank Hutter and
               Marc Peter Deisenroth},
  title     = {The reparameterization trick for acquisition functions},
  journal   = {CoRR},
  volume    = {abs/1712.00424},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.00424},
  archivePrefix = {arXiv},
  eprint    = {1712.00424},
  timestamp = {Mon, 13 Aug 2018 16:47:25 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1712-00424.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}



@incollection{Hansen06,
  author    = {Nikolaus Hansen},
  editor    = {Jos{\'{e}} Antonio Lozano and
               Pedro Larra{\~{n}}aga and
               I{\~{n}}aki Inza and
               Endika Bengoetxea},
  title     = {The {CMA} Evolution Strategy: {A} Comparing Review},
  booktitle = {Towards a New Evolutionary Computation - Advances in the Estimation
               of Distribution Algorithms},
  series    = {Studies in Fuzziness and Soft Computing},
  volume    = {192},
  pages     = {75--102},
  publisher = {Springer},
  year      = {2006},
  url       = {https://doi.org/10.1007/3-540-32494-1\_4},
  doi       = {10.1007/3-540-32494-1\_4},
  timestamp = {Mon, 16 Sep 2019 14:43:19 +0200},
  biburl    = {https://dblp.org/rec/books/sp/06/Hansen06.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Williams92,
  author    = {Ronald J. Williams},
  title     = {Simple Statistical Gradient-Following Algorithms for Connectionist
               Reinforcement Learning},
  journal   = {Mach. Learn.},
  volume    = {8},
  pages     = {229--256},
  year      = {1992},
  url       = {https://doi.org/10.1007/BF00992696},
  doi       = {10.1007/BF00992696},
  timestamp = {Mon, 02 Mar 2020 16:28:58 +0100},
  biburl    = {https://dblp.org/rec/journals/ml/Williams92.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
