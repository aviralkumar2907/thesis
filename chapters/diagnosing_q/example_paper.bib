@inproceedings{
daskalakis2018training,
title={Training {GAN}s with Optimism},
author={Constantinos Daskalakis and Andrew Ilyas and Vasilis Syrgkanis and Haoyang Zeng},
booktitle={International Conference on Learning Representations},
year={2018},
url={https://openreview.net/forum?id=SJJySbbAZ},
}

@inproceedings{farahmand2010error,
  title={Error propagation for approximate policy and value iteration},
  author={Farahmand, Amir-massoud and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  year={2010}
}

@article{tsitsiklis1994asynchronous,
  title={Asynchronous stochastic approximation and Q-learning},
  author={Tsitsiklis, John N},
  journal={Machine learning},
  volume={16},
  number={3},
  pages={185--202},
  year={1994},
  publisher={Springer}
}

@inproceedings{
yaz2018the,
title={The Unusual Effectiveness of Averaging in {GAN} Training},
author={Yasin Yaz{\i}c{\i} and Chuan-Sheng Foo and Stefan Winkler and Kim-Hui Yap and Georgios Piliouras and Vijay Chandrasekhar},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=SJgw_sRqFQ},
}

@inproceedings{langley00,
 author    = {P. Langley},
 title     = {Crafting Papers on Machine Learning},
 year      = {2000},
 pages     = {1207--1216},
 editor    = {Pat Langley},
 booktitle     = {Proceedings of the 17th International Conference
              on Machine Learning (ICML 2000)},
 address   = {Stanford, CA},
 publisher = {Morgan Kaufmann}
}

@TechReport{mitchell80,
  author = 	 "T. M. Mitchell",
  title = 	 "The Need for Biases in Learning Generalizations",
  institution =  "Computer Science Department, Rutgers University",
  year = 	 "1980",
  address =	 "New Brunswick, MA",
}

@phdthesis{kearns89,
  author = {M. J. Kearns},
  title =  {Computational Complexity of Machine Learning},
  school = {Department of Computer Science, Harvard University},
  year =   {1989}
}

@Book{MachineLearningI,
  editor = 	 "R. S. Michalski and J. G. Carbonell and T.
		  M. Mitchell",
  title = 	 "Machine Learning: An Artificial Intelligence
		  Approach, Vol. I",
  publisher = 	 "Tioga",
  year = 	 "1983",
  address =	 "Palo Alto, CA"
}

@Book{DudaHart2nd,
  author =       "R. O. Duda and P. E. Hart and D. G. Stork",
  title =        "Pattern Classification",
  publisher =    "John Wiley and Sons",
  edition =      "2nd",
  year =         "2000"
}

@misc{anonymous,
  title= {Suppressed for Anonymity},
  author= {Author, N. N.},
  year= {2018}
}

@InCollection{Newell81,
  author =       "A. Newell and P. S. Rosenbloom",
  title =        "Mechanisms of Skill Acquisition and the Law of
                  Practice", 
  booktitle =    "Cognitive Skills and Their Acquisition",
  pages =        "1--51",
  publisher =    "Lawrence Erlbaum Associates, Inc.",
  year =         "1981",
  editor =       "J. R. Anderson",
  chapter =      "1",
  address =      "Hillsdale, NJ"
}


@Article{Samuel59,
  author = 	 "A. L. Samuel",
  title = 	 "Some Studies in Machine Learning Using the Game of
		  Checkers",
  journal =	 "IBM Journal of Research and Development",
  year =	 "1959",
  volume =	 "3",
  number =	 "3",
  pages =	 "211--229"
}


@inproceedings{Kakade2002,
author = {Kakade, Sham and Langford, John},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Approximately Optimal Approximate Reinforcement Learning}},
year = {2002}
}

@inproceedings{Maei2010,
author = {Maei, Hamid Reza and Szepesv{\'{a}}ri, Csaba and Bhatnagar, Shalabh and Sutton, Richard S},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Toward off-policy learning control with function approximation}},
year = {2010}
}

@inproceedings{Baird1995,
annote = {Residual gradient = differentiating through target},
author = {Baird, Leemon},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Residual Algorithms : Reinforcement Learning with Function Approximation}},
year = {1995}
}

@article{Mnih2015,
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis},
issn = {0028-0836},
journal = {Nature},
month = {feb},
number = {7540},
pages = {529--533},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
title = {{Human-level control through deep reinforcement learning}},
volume = {518},
year = {2015}
}

@article{Lillicrap2015,
author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
journal = {International Conference on Learning Representations (ICLR)},
title = {{Continuous control with deep reinforcement learning}},
year = {2015}
}

@inproceedings{Schulman2015,
author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael I. and Abbeel, Pieter},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Trust Region Policy Optimization}},
year = {2015}
}

@inproceedings{Precup2001,
author = {Precup, Doina and Sutton, Richard S. and Dasgupta, Sanjoy},
booktitle = {International Conference on Machine Learning (ICML)},
title = {{Off-policy temporal-difference learning with function approximation}},
year = {2001}
}

@article{Schulman2017,
  author    = {John Schulman and
               Pieter Abbeel and
               Xi Chen},
  title     = {Equivalence Between Policy Gradients and Soft Q-Learning},
  journal   = {ArXiv Preprint},
  volume    = {abs/1704.06440},
  year      = {2017},
}

@article{Gu2016,
  author    = {Shixiang Gu and
               Ethan Holly and
               Timothy Lillicrap and
               Sergey Levine},
  title     = {Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  journal   = {IEEE International Conference on Robotics and Automation (ICRA)},
  year      = {2017},
}

@article{Watkins92,
  author    = {Christopher J.C.H. Watkins and Peter Dayan},
  title     = {Q-learning},
  journal   = {Machine Learning},
  year      = {1992},
  volume    = {8},
  pages     = {279-292},
  issue     = {3},
}

@incollection{Kakade2001,
title = {A Natural Policy Gradient},
author = {Sham M. Kakade},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2001},
}

@incollection{Munos2016,
title = {Safe and Efficient Off-policy Reinforcement Learning},
author = {Remi Munos and Thomas Stepleton and Anna Harutyunyan and Marc G. Bellemare},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2016},
}

@inproceedings{Sutton09a,
title = {A Convergent O(n) Temporal-difference Algorithm for Off-policy Learning with Linear Function Approximation},
author = {Sutton, Richard S. and Hamid Reza Maei and Csaba Szepesv\'{a}ri},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
year = {2009},
}

@inproceedings{Sutton09b,
title = {Fast Gradient-Descent Methods for Temporal-Difference Learning
with Linear Function Approximation},
author = {
Richard S. Sutton and Hamid Reza Maei and Doina Precup and Shalabh Bhatnagar and David Silver and Csaba Szepesv\'{a}ri and
Eric Wiewiora},
booktitle = {International Conference on Machine Learning (ICML)},
year = {2009},
}

@article{Bertsekas96,
title = {Neuro-Dynamic Programming},
author = {Bertsekas, Dimitri P., and Tsitsiklis, John N.},
journal = {Athena Scientific},
year = {1996},
}


@inproceedings{Haarnoja2017,
author = {Tuomas Haarnoja and
               Haoran Tang and
               Pieter Abbeel and
               Sergey Levine},
booktitle = {International Conference on Machine Learning (ICML)},
title = {Reinforcement Learning with Deep Energy-Based Policies},
year = {2017}
}

@inproceedings{Hausknecht2016,
author = {Matthew Hausknecht and Peter Stone},
booktitle = {Deep Reinforcement Learning: Frontiers and Challenges Workshop, IJCAI},
title = {On-Policy vs. Off-Policy Updates for Deep Reinforcement Learning},
year = {2016}
}

@inproceedings{Farrell95,
author = {Jay A. Farrell and T. Berger},
booktitle = {American Control Conference},
title = {On the effects of the training sample density in passive learning control},
year = {1995}
}

@inproceedings{Boyan94,
author = {Justin A. Boyan and Andrew W. Moore},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
title = {Generalization in Reinforcement Learning:
Safely Approximating the Value Function},
year = {1994}
}

@article{Haarnoja18,
  author    = {Tuomas Haarnoja and
               Aurick Zhou and
               Pieter Abbeel and
               Sergey Levine},
  title     = {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning
               with a Stochastic Actor},
  journal   = {CoRR},
  volume    = {abs/1801.01290},
  year      = {2018},
  url       = {http://arxiv.org/abs/1801.01290},
  archivePrefix = {arXiv},
  eprint    = {1801.01290},
}

@inproceedings{kalashnikov18,
  author    = {Dmitry Kalashnikov and
               Alex Irpan and
               Peter Pastor and
               Julian Ibarz and
               Alexander Herzog and
               Eric Jang and
               Deirdre Quillen and
               Ethan Holly and
               Mrinal Kalakrishnan and
               Vincent Vanhoucke and
               Sergey Levine},
  title     = {QT-Opt: Scalable Deep Reinforcement Learning for Vision-Based Robotic Manipulation},
  booktitle = {CoRL},
  series    = {Proceedings of Machine Learning Research},
  volume    = {87},
  pages     = {651--673},
  publisher = {{PMLR}},
  year      = {2018}
}

@article{Ernst05,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Apr},
  pages={503--556},
  year={2005}
}

@book{suttonrlbook,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  edition = {Second}
}

@inproceedings{Dai2018,
  title={Sbeed: Convergent reinforcement learning with nonlinear function approximation},
  author={Dai, Bo and Shaw, Albert and Li, Lihong and Xiao, Lin and He, Niao and Liu, Zhen and Chen, Jianshu and Song, Le},
  booktitle={International Conference on Machine Learning},
  pages={1133--1142},
  year={2018}
}

@article{VanHesselt2018,
  title={Deep Reinforcement Learning and the Deadly Triad},
  author={Van Hasselt, Hado and Doron, Yotam and Strub, Florian and Hessel, Matteo and Sonnerat, Nicolas and Modayil, Joseph},
  journal={arXiv preprint arXiv:1812.02648},
  year={2018}
}

@inproceedings{Tsitsiklis1997,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1075--1081},
  year={1997}
}

@article{Hallak2017,
  title={Consistent on-line off-policy evaluation},
  author={Hallak, Assaf and Mannor, Shie},
  journal={arXiv preprint arXiv:1702.07121},
  year={2017}
}

@article{Sutton2016,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@inproceedings{Riedmiller2005,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}

@article{Watkins1992,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={279--292},
  year={1992},
  publisher={Springer}
}

@inproceedings{Gu2017,
  title={Deep reinforcement learning for robotic manipulation with asynchronous off-policy updates},
  author={Gu, Shixiang and Holly, Ethan and Lillicrap, Timothy and Levine, Sergey},
  booktitle={Robotics and Automation (ICRA), 2017 IEEE International Conference on},
  pages={3389--3396},
  year={2017},
  organization={IEEE}
}

@misc{gym,
  Author = {Matthias Plappert and Marcin Andrychowicz and Alex Ray and Bob McGrew and Bowen Baker and Glenn Powell and Jonas Schneider and Josh Tobin and Maciek Chociej and Peter Welinder and Vikash Kumar and Wojciech Zaremba},
  Title = {Multi-Goal Reinforcement Learning: Challenging Robotics Environments and Request for Research},
  Year = {2018},
  Eprint = {arXiv:1802.09464},
}

@article{Schaul2015,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={International Conference on Learning Representations (ICLR)},
  year={2015}
}

@book{Shalev2014,
  title={Understanding machine learning: From theory to algorithms},
  author={Shalev-Shwartz, Shai and Ben-David, Shai},
  year={2014},
  publisher={Cambridge university press}
}

@incollection{NIPS2017_6913,
title = {Is the Bellman residual a bad proxy?},
author = {Geist, Matthieu and Piot, Bilal and Pietquin, Olivier},
booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
pages = {3205--3214},
year = {2017},
}

@inproceedings{Pritzel2017,
  title={Neural Episodic Control},
  author={Pritzel, Alexander and Uria, Benigno and Srinivasan, Sriram and Badia, Adri{\`a} Puigdom{\`e}nech and Vinyals, Oriol and Hassabis, Demis and Wierstra, Daan and Blundell, Charles},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={2827--2836},
  year={2017}
}

@InProceedings{pmlr-v80-fujimoto18a,
  title = 	 {Addressing Function Approximation Error in Actor-Critic Methods},
  author = 	 {Fujimoto, Scott and van Hoof, Herke and Meger, David},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {1587--1596},
  year = 	 {2018},
}

@inproceedings{Gu2017ipg,
  title={Interpolated policy gradient: Merging on-policy and off-policy gradient estimation for deep reinforcement learning},
  author={Gu, Shixiang Shane and Lillicrap, Timothy and Turner, Richard E and Ghahramani, Zoubin and Sch{\"o}lkopf, Bernhard and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={3846--3855},
  year={2017}
}

@inproceedings{maillard2010finite,
  title={Finite-sample analysis of Bellman residual minimization},
  author={Maillard, Odalric-Ambrym and Munos, R{\'e}mi and Lazaric, Alessandro and Ghavamzadeh, Mohammad},
  booktitle={Asian Conference on Machine Learning (ACML)},
  pages={299--314},
  year={2010}
}

@inproceedings{munos2005error,
  title={Error bounds for approximate value iteration},
  author={Munos, R{\'e}mi},
  booktitle={AAAI Conference on Artificial intelligence (AAAI)},
  pages={1006--1011},
  year={2005},
  organization={AAAI Press}
}

@article{munos2008finite,
  title={Finite-time bounds for fitted value iteration},
  author={Munos, R{\'e}mi and Szepesv{\'a}ri, Csaba},
  journal={Journal of Machine Learning Research},
  volume={9},
  number={May},
  pages={815--857},
  year={2008}
}

@article{zhang2018deeper,
  author    = {Shangtong Zhang and
               Richard S. Sutton},
  title     = {A Deeper Look at Experience Replay},
  journal   = {CoRR},
  volume    = {abs/1712.01275},
  year      = {2017},
  url       = {http://arxiv.org/abs/1712.01275},
  archivePrefix = {arXiv},
  eprint    = {1712.01275},
  timestamp = {Mon, 13 Aug 2018 16:46:10 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1712-01275},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{antos2007fitted,
 author = {Antos, Andr\'{a}s and Munos, R{\'e}mi and Szepesv\'{a}ri, Csaba},
 title = {Fitted Q-iteration in Continuous Action-space MDPs},
 booktitle = {Advances in Neural Information Processing Systems (NeurIPS)},
 series = {NIPS'07},
 year = {2007},
 location = {Vancouver, British Columbia, Canada},
} 

@phdthesis{de2002alp,
  title={The linear programming approach to approximate dynamic programming: Theory and application},
  author={De Farias, Daniela Pucci},
  year={2002}
}

@article{antos2008concentrability,
  title={Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path},
  author={Antos, Andr{\'a}s and Szepesv{\'a}ri, Csaba and Munos, R{\'e}mi},
  journal={Machine Learning},
  volume={71},
  number={1},
  pages={89--129},
  year={2008},
  publisher={Springer}
}

@inproceedings{munos2005erroravi,
  title={Error bounds for approximate value iteration},
  author={Munos, R{\'e}mi},
  booktitle={AAI Conference on Artificial intelligence (AAAI)},
  pages={1006--1011},
  year={2005},
  organization={AAAI Press}
}

@article{metelli2018nips,
  author    = {Alberto Maria Metelli and
               Matteo Papini and
               Francesco Faccio and
               Marcello Restelli},
  title     = {Policy Optimization via Importance Sampling},
  journal   = {CoRR},
  volume    = {abs/1809.06098},
  year      = {2018},
  url       = {http://arxiv.org/abs/1809.06098},
  archivePrefix = {arXiv},
  eprint    = {1809.06098},
  timestamp = {Fri, 05 Oct 2018 11:34:52 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1809-06098},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@InProceedings{pmlr-v70-arjovsky17a,
  title = 	 {{W}asserstein Generative Adversarial Networks},
  author = 	 {Martin Arjovsky and Soumith Chintala and L{\'e}on Bottou},
  booktitle = 	 {International Conference on Machine Learning (ICML)},
  pages = 	 {214--223},
  year = 	 {2017},
}

@techreport{haarnoja2018sacapps,
  title={Soft Actor-Critic Algorithms and Applications},
  author={Tuomas Haarnoja, Aurick Zhou, Kristian Hartikainen, George Tucker, Sehoon Ha, Jie Tan, Vikash Kumar, Henry Zhu, Abhishek Gupta, Pieter Abbeel, and Sergey Levine},
  journal={arXiv preprint arXiv:1812.05905},
  year={2018}
}

@article{hazan2018,
  title={Provably Efficient Maximum Entropy Exploration},
  author={Hazan, Elad and Kakade, Sham M and Singh, Karan and Van Soest, Abby},
  journal={arXiv preprint arXiv:1812.02690},
  year={2018}
}

@misc{baselines,
  author = {Dhariwal, Prafulla and Hesse, Christopher and Klimov, Oleg and Nichol, Alex and Plappert, Matthias and Radford, Alec and Schulman, John and Sidor, Szymon and Wu, Yuhuai and Zhokhov, Peter},
  title = {OpenAI Baselines},
  year = {2017},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/openai/baselines}},
}

@inproceedings{scherrer2010residual,
  title={Should one compute the temporal difference fix point or minimize the Bellman Residual? The unified oblique projection view},
  author={Scherrer, Bruno},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={959--966},
  year={2010},
}

@inproceedings{tosatto2017boosted,
  title={Boosted fitted q-iteration},
  author={Tosatto, Samuele and Pirotta, Matteo and D'Eramo, Carlo and Restelli, Marcello},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={3434--3443},
  year={2017},
  organization={JMLR. org}
}

@article{lin1992replay,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems (NeurIPS)},
  pages={1054--1062},
  year={2016}
}

@article{sriperum2009ipms,
  author    = {Bharath K. Sriperumbudur and
               Arthur Gretton and
               Kenji Fukumizu and
               Gert R. G. Lanckriet and
               Bernhard Sch{\"{o}}lkopf},
  title     = {A note on integral probability metrics and {\textdollar}{\textbackslash}phi{\textdollar}-divergences},
  journal   = {CoRR},
  volume    = {abs/0901.2698},
  year      = {2009},
  url       = {http://arxiv.org/abs/0901.2698},
  archivePrefix = {arXiv},
  eprint    = {0901.2698},
  timestamp = {Mon, 13 Aug 2018 16:48:04 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-0901-2698},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{precup2001offpol,
  title={Off-Policy Temporal Difference Learning with Function Approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={417--424},
  year={2001},
}

@inproceedings{hausknecht2016policy,
  title={On-policy vs. off-policy updates for deep reinforcement learning},
  author={Hausknecht, Matthew and Stone, Peter},
  booktitle={Deep Reinforcement Learning: Frontiers and Challenges, IJCAI},
  year={2016}
}

@article{martha2018sparse,
  author    = {Vincent Liu and
               Raksha Kumaraswamy and
               Lei Le and
               Martha White},
  title     = {The Utility of Sparse Representations for Control in Reinforcement
               Learning},
  journal   = {CoRR},
  volume    = {abs/1811.06626},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.06626},
  archivePrefix = {arXiv},
  eprint    = {1811.06626},
  timestamp = {Sun, 25 Nov 2018 18:57:12 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1811-06626},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{shani2005recommender,
  title={An MDP-based recommender system},
  author={Shani, Guy and Heckerman, David and Brafman, Ronen I},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Sep},
  pages={1265--1295},
  year={2005}
}

@inproceedings{szepesvari1998asymptotic,
  title={The asymptotic convergence-rate of Q-learning},
  author={Szepesv{\'a}ri, Csaba},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1064--1070},
  year={1998}
}