\section{Related Work}


Hoiem et al \cite{hoiem2008putting} studied the interaction between object detection and scene layout estimation and showed that reasoning over object sizes within their 3D environment, as opposed to within the image, had a positive impact on detection performance. 

The work Lalonde et al \cite{lalonde2007photo} is close to ours. It estimates average real world sizes of many object categories in the 3D world, from annotated LabelMe data.

This was still in the HOG age  \cite{dalal2005histograms} -- here we leverage the more powerful feature extraction technology we have now to be able to widthstand occlusions and recover metric information.

Building a database of 3d scenes from user annotations \cite{russell2009building}. This is a heavy duty system with quite a broad model, that classifies pairwise relationships into support, attachment, occlusion, etc. On the bright side it assumes every pixel is annotated as belonging in a region. It also does not perform completion and it's not clear  exactly how they recover depth of occluded objects, probably using familiarity, etc.. ?
 
 Other references:
-  Are Cars Just 3D Boxes? â€“ Jointly Estimating the 3D Shape of Multiple Objects. Schindler
-  Towards Scene Understanding with Detailed 3D Object Representations. Schindler
------------------------------------------------------

Psychology:
Do Artists See Their Retinas? Cavanagh

Amodal completion:
Amodal volume completion: 3D visual completion. Fisher


Organization in vision: Essays on Gestalt perception. Kanizsa 1979

%