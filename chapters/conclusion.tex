\documentclass[../thesis.tex]{subfiles}
\begin{document}
In this thesis, we have presented a number of advances towards learning based 3D object reconstruction. In Chapter \ref{chapter:CategoryShapes}, we presented an algorithm to learn category-specific deformable 3D models for diverse object categories and showed how to use them in conjunction with recognition systems to achieve fully automatic object localization and reconstruction from a single image. In Chapter \ref{chapter:Amodal}, we worked towards calibrating the size of the reconstructed objects by inferring their relative sizes and depths from a single image. We did this by leveraging amodal bounding boxes and reasoning about object co-occurences in image collections. We worked towards unifying single and multi-view reconstruction with a CNN in Chapter \ref{chapter:LSM} with Learnt Stereo Machines.

We have still just scratched the tip of the iceberg as alluded to in the limitations of current works in the chapters above. A number of challenges remain in tightly integrating semantic reasoning and 3D reconstruction (some of which we summarize below) and present for exciting directions for future work. 

\paragraph{Shape Representations:} In our works, we have explored using deformable meshes, voxel occupancy grids and depth maps as representations for shape. While each presents its own benefits, it is still unclear whether one has all the desirable properties for shape representations. For example, part compositionality plays a crucial role in the human visual system which none of the above representations exhibit. There have been promising works towards modelling shapes with primitives such as planes and simple shapes~\cite{abstractionTulsiani17} (cubes, cylinders \etc). Automatic discovery of such primitives which can be shared across object categories would allow for greater interpretability in reconstructions.

\paragraph{Learning without explicit supervision:} We, as humans, almost never have ``ground truth'' data to learn from - especially for 3D shapes. Our mental models are built from observing objects from different viewpoints, in various lighting conditions, by interacting with them \etc This remains a critical problem to solve for current learning systems to scale beyond available 3D datasets. Some recent works~\cite{tulsiani2017multi,zhou2017unsupervised} have investigated using motion and projection into novel views as a proxy for learning shapes. An exciting direction to investigate would be coupling active exploration with 3D shape inference. For example, a robot could derive shape cues for an object by trying to grasp/poke/manipulate it in certain ways.

\paragraph{Quality of reconstructions:} A common issue with current methods for learning-based shape inference methods is that they dont produce high quality outputs (in terms of accuracy, fidelity and resolution). This is in contrast with classical systems which produce extremely detailed models, albeit from far more images. Recent attempts at modelling high resolution grids with CNNs~\cite{hane2017hierarchical} present a promising direction towards detailed reconstructions with learning-based cues. A related task is modelling large spaces with such systems which couples with the question of what shape representations are amenable to such problems.

\paragraph{Related tasks:} While inferring 3D shape from 2D views is an end in itself, it can be especially useful for a number of complementary and upstream tasks. For example, estimating lighting and reflectance in scenes could benefit from learning-based 3D inference systems, particularly when learnt jointly~\cite{barronPAMI13}. More examples of properties for which are difficult to \textit{ground-truth} and tightly coupled with 3D reasoning are optical flow and scene flow. Learning systems could provide a very natural way of jointly modelling these variety of tasks with strong inter-dependencies. Implicit 3D reasoning could also play a critical role in end-to-end learning of policies in robotics~\cite{finn2016end}, \eg for navigating in 3D scenes or manipulating objects.

\end{document}