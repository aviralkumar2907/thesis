% Ever since the dawn of computer vision, 3D reconstruction has been a core problem, inspiring early seminal works and leading to numerous real world applications. Much recent progress in the field has been driven by visual recognition systems powered by statistical learning techniques - more recently with convolutional neural networks (CNNs). In this thesis, we attempt to bridge the worlds of geometric 3D reconstruction and learning based recognition by leveraging 3D perception cues from image collections for the task of reconstructing 3D objects.

% In Chapter \ref{chapter:CategoryShapes}, we present a system which is able to learn category-specific deformable 3D models for objects from 2D recognition datasets enabling single view 3D reconstruction for novel instances. In Chapter \ref{chapter:Amodal}, we demonstrate how predicting the amodal extent of objects in images can help us infer their real world heights. Finally, in Chapter \ref{chapter:LSM}, we present Learnt Stereo Machines (LSM), which unify a number of paradigms in 3D object reconstruction - single and multi-view, coarse and dense reconstruction, geometric and semantic reasoning- within an end-to-end learnt framework using convolutional neural networks.

Reinforcement learning (RL) provides a formalism for learning-based control. By attempting to learn behavioral policies that can optimize a user-specified reward function, RL methods have been able to acquire novel decision-making strategies that can outperform the best humans even with highly complex dynamics and even when the space of all possible outcomes is huge (e.g., robotic manipulation, chip floorplanning). Yet RL has had a limited applicability compared to standard machine learning (ML) in real-world scenarios. Why? The central issue with RL is that it relies crucially on running large amounts of trial-and-error active data collection for learning policies. Unfortunately though, in the real world, active data collection is generally very expensive (e.g., running wet lab experiments for drug design), and/or dangerous (e.g., robots operating around humans), and accurate simulators are hard to build. Overall, this means that while RL carries the potential to broadly unlock ML in real-world decision-making problems, we are unable to realize this potential via current RL techniques.           

To realize this potential of RL, in this dissertation, we develop an alternate paradigm that aims to utilizes static datasets of experience for learning policies.
% , i.e., we aim to answer: How can we learn policies from an offline dataset of historically-executed sequences of decisions and their corresponding outcomes, without any active interaction with the environment? 
Such a ``dataset-driven'' paradigm broadens the applicability of RL to a variety of decision-making problems where historical datasets already exist or can be collected via domain-specific strategies. It also brings the scalability and reliability benefits that modern supervised and unsupervised ML methods enjoy into RL. That said, instantiating this paradigm is challenging as it requires reconciling the {static} nature of learning from a dataset with the traditionally active nature of RL, which results in challenges of distributional shift, generalization, and optimization.
After theoretically and empirically understanding these challenges, we develop algorithmic ideas for addressing thee challenges and discuss several extensions to convert these ideas into practical methods that can train modern high-capacity neural network function approximators on large and diverse datasets. Finally, we show how the techniques can enable us to pre-train generalist policies for real robots and video games and enable fast and efficient hardware accelerator design. 
% Category specific deformable 3D models - Learning shape statistics from annotations in image collections
% Amodal Completion and Size constancy - Learning relative size of objects by observing object co-occurence in image collections
% Learnt Stereo Machines - Unifying single and multi-view resconstruction, geometric and semantic reasoning for 3D reconstruction and coarse and dense prediction by leveraging recent advances in learning based systems (deep neural networks).