\begin{table*}[t!]
\small
\centering
\renewcommand{\arraystretch}{1.1}
\vspace*{-0.05cm}
\caption{\label{table:dla_shi}Optimized objective values (i.e. total number of cycles) for two different dataflow architectures, NVDLA-style~\citep{nvdla} and ShiDianNao-style~\citep{shidiannao}, across three classes of applications. The maximum search space for the studied accelerators are $\approx$~2.5$\times$10$^{114}$. \primemethodname\ generalizes to other classes of accelerators with larger search space and outperforms the best online method by 1.06$\times$ and the best data seen in training by 3.75$\times$ (last column). The best accelerator configurations is highlighted in bold.}
\resizebox{0.95\textwidth}{!}{\begin{tabular}{l|l|l|l|l}
\toprule
\textbf{Applications}&\textbf{Dataflow}&\textbf{\primemethodname}&\textbf{Evolutionary ~(Online)}&\textbf{$\mathcal{D}$ (Best in Training)}\\\midrule
% MobileNetV2
MobileNetV2&NVDLA&\textbf{2.51$\times$10$^7$}&2.70$\times$10$^7$&1.32$\times$10$^8$\\\hline
MobileNetV2&ShiDianNao&\textbf{2.65$\times$10$^7$}&2.84$\times$10$^7$&1.27$\times$10$^8$\\\bottomrule
% ResNet50
ResNet50&NVDLA&\textbf{2.83$\times$10$^8$}&3.13$\times$10$^8$&1.63$\times$10$^9$\\\hline
ResNet50&ShiDianNao&\textbf{3.44$\times$10$^8$}&3.74$\times$10$^8$&2.05$\times$10$^9$\\\bottomrule
% Transformer
Transformer&NVDLA&\textbf{7.8$\times$10$^8$}&\textbf{7.8$\times$10$^8$}&1.3$\times$10$^9$\\\hline
Transformer&ShiDianNao&\textbf{7.8$\times$10$^8$}&\textbf{7.8$\times$10$^8$}&1.5$\times$10$^9$\\\bottomrule
\CC \textbf{Geomean of \primemethodname's Improvement}&\CC---&\CC~\texttt{\textbf{1.0$\times$}}&\CC~\texttt{\textbf{1.06$\times$}}&\CC~\texttt{\textbf{3.75$\times$}}\\
\bottomrule
\end{tabular}}
\vspace{-0.4cm}
\end{table*}