\documentclass[../thesis.tex]{subfiles}

\usepackage{wrapfig}
\usepackage{cite}
% \usepackage{natbib}
% \usepackage[round]{natbib}

\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{amsthm}
\usepackage{amssymb}
\usetikzlibrary{positioning}
\usepackage{mathtools}
\usepackage{fleqn, tabularx}
\usepackage{multirow}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{assumption}{Assumption}[section]
\newtheorem{proposition}{Proposition}[section]
\newtheorem{definition}{Definition}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}{Lemma}[theorem]
% \newtheorem{corollary}{Corollary}[proposition]
\newtheorem{definition1}{Definition}[section]



\begin{document}

% \blfootnote{This chapter is based on \cite{fu2019diagnosing}, published at ICML 2019, which is joint work with Justin Fu, Matthew Soh, and Sergey Levine.}

% \input{chapters/bear/text/abstract.tex}

% \input{chapters/bear/text/introduction.tex}
% \input{chapters/bear/text/related.tex}
% \input{chapters/bear/text/background.tex}
% \input{chapters/bear/text/method.tex}
% \input{chapters/bear/text/experiments.tex}
% \input{chapters/bear/text/conclusions.tex}

\vspace{-0.4cm}
\begin{AIbox}{\large{\textbf{Abstract}}}
\vspace{4mm}
In this chapter, we present an application of offline RL to the problem of designing hardware accelerators, i.e., designing hardware with the goal of improving the performance of specific applications. To attain higher efficiency, the industry has gradually reformed towards application-specific hardware accelerators. For instance, TPU accelerators aim to optimize the performance of machine learning models. While such a paradigm shift is already starting to show promising results, designers need to spend considerable manual effort and perform large number of time-consuming simulations to find accelerators that can accelerate multiple target applications while obeying design constraints. Moreover, such a ``simulation-driven'' approach must be re-run from scratch every time the set of target applications or design constraints change. An alternative paradigm is to use a an offline approach that utilizes logged simulation data, to architect hardware accelerators, without needing active simulations. In the context of this problem, this not only alleviates the need to run time-consuming simulation, but also enables data reuse and applies even when set of target applications changes. In this chapter, we develop an offline RL paradigm for designing hardware accelerators, dubbed \primemethodname, which utilizes conservative value estimation.
% Our approach learns a conservative estimate of the desired reward function, utilizes infeasible points and optimizes the design against this estimate without any additional simulator queries during optimization.
\primemethodname\ architects accelerators for both single and multiple applications, improving performance upon state-of-the-art simulation-driven methods by about 1.54$\times$ and 1.20$\times$, while reducing the required total simulation time by 93\% and 99\%, respectively.
In addition, \primemethodname\ architects accelerators for unseen applications in a zero-shot setting, outperforming simulation-based methods by 1.26$\times$.
\vspace{2mm}
\end{AIbox}


\input{chapters/prime/body/01_intro}
\input{chapters/prime/body/02_background}
\input{chapters/prime/body/03_problem}
\input{chapters/prime/body/04_method}
\input{chapters/prime/body/05_related}
\input{chapters/prime/body/06_ablation}
\input{chapters/prime/body/07_discussion}


\end{document}