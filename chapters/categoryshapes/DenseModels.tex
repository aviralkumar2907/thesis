\label{densemodels}
Equipped with camera projection parameters and keypoint correspondences (now lifted to 3D by \nrsfm) on the whole training set, we proceed to build morphable 3D models for object categories from our major source of information in this paper - object silhouettes. This problem of reconstructing the 3D shape of a single object from its projected silhouettes in multiple calibrated images has been widely studied in the computer vision literature. Two prominent approaches are \textit{visual hulls} \cite{laurentini1994hull} and variational methods derived from \textit{snakes} e.g \cite{esteban2004snake,yusuf2006snake} which deform a surface mesh iteratively until convergence. Some recent papers have also extended variational approaches to the case of category shape reconstruction \cite{cashman2013dolphins,chen20123d}. While demonstrating accurate results on a limited number of categories, they typically require some form of 3D annotations to bootstrap the model and are computationally expensive. A recent work \cite{carvi14} has proposed a visual-hull based data-driven approach for class-based reconstruction for the first time on challenging real world datasets like PASCAL VOC. In contrast, we build parametric shape models for categories that compactly capture intra class shape variations. The benefits of having a model of 3D shape are manifold: 1) we are more robust to noisy inputs (silhouettes and pose) allowing us to pursue reconstruction in a fully automatic setting and 2) we forego the need for having continuous access to a large corpus of data. \RED{add points here.}

We propose an algorithm to learn class-specific 3D shape models given silhouette information and camera viewpoints estimated in the previous section. Our shape models inherently capture the intraclass variations in object categories and can be used to recover a 3D shape given an object's approximate silhouette and viewpoint in a new image.
