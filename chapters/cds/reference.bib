@inproceedings{lee2019SLAC,
  title={Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model
},
  author={Alex X. Lee and Anusha Nagabandi and Pieter Abbeel and Sergey Levine},
  booktitle={Advances in Neural Information Processing Systems},
  year={2020}
}


@inproceedings{Hafner2019PlanNet,
  title={International Conference on Machine
Learning},
  author={Danijar Hafner and Timothy Lillicrap and Ian Fischer and Ruben Villegas and David Ha and Honglak Lee and James Davidson},
  booktitle={ International Conference on Machine
Learning},
  year={2019}
}

@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}

@article{liu2020provably,
  title={Provably good batch reinforcement learning without great exploration},
  author={Liu, Yao and Swaminathan, Adith and Agarwal, Alekh and Brunskill, Emma},
  journal={arXiv preprint arXiv:2007.08202},
  year={2020}
}

@article{christiano2017deep,
  title={Deep reinforcement learning from human preferences},
  author={Christiano, Paul and Leike, Jan and Brown, Tom B and Martic, Miljan and Legg, Shane and Amodei, Dario},
  journal={arXiv preprint arXiv:1706.03741},
  year={2017}
}

@article{fujimoto2018addressing,
  title={Addressing function approximation error in actor-critic methods},
  author={Fujimoto, Scott and Van Hoof, Herke and Meger, David},
  journal={arXiv preprint arXiv:1802.09477},
  year={2018}
}

@article{fujimoto2018off,
  title={Off-policy deep reinforcement learning without exploration},
  author={Fujimoto, Scott and Meger, David and Precup, Doina},
  journal={arXiv preprint arXiv:1812.02900},
  year={2018}
}

@inproceedings{kumar2019stabilizing,
  title={Stabilizing off-policy q-learning via bootstrapping error reduction},
  author={Kumar, Aviral and Fu, Justin and Soh, Matthew and Tucker, George and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={11761--11771},
  year={2019}
}

@article{wu2019behavior,
  title={Behavior Regularized Offline Reinforcement Learning},
  author={Wu, Yifan and Tucker, George and Nachum, Ofir},
  journal={arXiv preprint arXiv:1911.11361},
  year={2019}
}

@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}

@article{jaques2019way,
  title={Way off-policy batch deep reinforcement learning of implicit human preferences in dialog},
  author={Jaques, Natasha and Ghandeharioun, Asma and Shen, Judy Hanwen and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang and Picard, Rosalind},
  journal={arXiv preprint arXiv:1907.00456},
  year={2019}
}

@article{nachum2019algaedice,
  title={AlgaeDICE: Policy Gradient from Arbitrary Experience},
  author={Nachum, Ofir and Dai, Bo and Kostrikov, Ilya and Chow, Yinlam and Li, Lihong and Schuurmans, Dale},
  journal={arXiv preprint arXiv:1912.02074},
  year={2019}
}

@article{peng2019advantage,
  title={Advantage-Weighted Regression: Simple and Scalable Off-Policy Reinforcement Learning},
  author={Peng, Xue Bin and Kumar, Aviral and Zhang, Grace and Levine, Sergey},
  journal={arXiv preprint arXiv:1910.00177},
  year={2019}
}

@article{siegel2020keep,
  title={Keep Doing What Worked: Behavioral Modelling Priors for Offline Reinforcement Learning},
  author={Siegel, Noah Y and Springenberg, Jost Tobias and Berkenkamp, Felix and Abdolmaleki, Abbas and Neunert, Michael and Lampe, Thomas and Hafner, Roland and Riedmiller, Martin},
  journal={arXiv preprint arXiv:2002.08396},
  year={2020}
}

@inproceedings{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12498--12509},
  year={2019}
}

@article{luo2018algorithmic,
  title={Algorithmic framework for model-based deep reinforcement learning with theoretical guarantees},
  author={Luo, Yuping and Xu, Huazhe and Li, Yuanzhi and Tian, Yuandong and Darrell, Trevor and Ma, Tengyu},
  journal={arXiv preprint arXiv:1807.03858},
  year={2018}
}

@article{agarwal2019striving,
  title={Striving for simplicity in off-policy deep reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  journal={arXiv preprint arXiv:1907.04543},
  year={2019}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={Nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}

@inproceedings{balaji2017ensemble,
author = {Lakshminarayanan, Balaji and Pritzel, Alexander and Blundell, Charles},
title = {Simple and Scalable Predictive Uncertainty Estimation Using Deep Ensembles},
year = {2017},
isbn = {9781510860964},
publisher = {Curran Associates Inc.},
address = {Red Hook, NY, USA},
booktitle = {Proceedings of the 31st International Conference on Neural Information Processing Systems},
pages = {6405–6416},
numpages = {12},
location = {Long Beach, California, USA},
series = {NIPS’17}
}

@inproceedings{precup2001off,
  title={Off-policy temporal-difference learning with function approximation},
  author={Precup, Doina and Sutton, Richard S and Dasgupta, Sanjoy},
  booktitle={ICML},
  pages={417--424},
  year={2001}
}

@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1054--1062},
  year={2016}
}

@article{ajksbook,
  title={Reinforcement learning: Theory and algorithms},
  author={Agarwal, Alekh and Jiang, Nan and Kakade, Sham M},
  journal={CS Dept., UW Seattle, Seattle, WA, USA, Tech. Rep},
  year={2019}
}

@misc{fu2020d4rl,
    title={D4RL: Datasets for Deep Data-Driven Reinforcement Learning},
    author={Justin Fu and Aviral Kumar and Ofir Nachum and George Tucker and Sergey Levine},
    year={2020},
    eprint={2004.07219},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@article{fujimoto2019benchmarking,
  title={Benchmarking Batch Deep Reinforcement Learning Algorithms},
  author={Fujimoto, Scott and Conti, Edoardo and Ghavamzadeh, Mohammad and Pineau, Joelle},
  journal={arXiv preprint arXiv:1910.01708},
  year={2019}
}

@article{sutton1991dyna,
  title={Dyna, an integrated architecture for learning, planning, and reacting},
  author={Sutton, Richard S},
  journal={ACM Sigart Bulletin},
  volume={2},
  number={4},
  pages={160--163},
  year={1991},
  publisher={ACM New York, NY, USA}
}

@InCollection{LangeGR12,
	title =	"Batch Reinforcement Learning",
	author =	"Sascha Lange and Thomas Gabel and Martin A.
	Riedmiller",
	booktitle =	"Reinforcement Learning",
	publisher =	"Springer",
	year = 	"2012",
	volume =	"12",
}

@Article{LiuSAB19,
  title =	"Off-Policy Policy Gradient with State Distribution
		 Correction",
  author =	"Yao Liu and Adith Swaminathan and Alekh Agarwal
		 and Emma Brunskill",
  journal =	"CoRR",
  year = 	"2019",
  volume =	"abs/1904.08473",
}

@Article{SwaminathanJ15,
	title =	"Batch learning from logged bandit feedback through
	counterfactual risk minimization",
	author =	"Adith Swaminathan and Thorsten Joachims",
	journal =	"J. Mach. Learn. Res",
	year = 	"2015",
	volume =	"16",
	pages =	"1731--1755",
}

@article{Liu2020ProvablyGB,
  title={Provably Good Batch Reinforcement Learning Without Great Exploration},
  author={Yao Liu and A. Swaminathan and A. Agarwal and Emma Brunskill},
  journal={ArXiv},
  year={2020},
  volume={abs/2007.08202}
}

@article{argenson2020model,
  title={Model-Based Offline Planning},
  author={Argenson, Arthur and Dulac-Arnold, Gabriel},
  journal={arXiv preprint arXiv:2008.05556},
  year={2020}
}

@article{levine2020offline,
  title={Offline reinforcement learning: Tutorial, review, and perspectives on open problems},
  author={Levine, Sergey and Kumar, Aviral and Tucker, George and Fu, Justin},
  journal={arXiv preprint arXiv:2005.01643},
  year={2020}
}

@article{kumar2020conservative,
  title={Conservative Q-Learning for Offline Reinforcement Learning},
  author={Kumar, Aviral and Zhou, Aurick and Tucker, George and Levine, Sergey},
  journal={arXiv preprint arXiv:2006.04779},
  year={2020}
}

@article{kidambi2020morel,
  title={MOReL: Model-Based Offline Reinforcement Learning},
  author={Kidambi, Rahul and Rajeswaran, Aravind and Netrapalli, Praneeth and Joachims, Thorsten},
  journal={arXiv preprint arXiv:2005.05951},
  year={2020}
}

@article{matsushima2020deployment,
  title={Deployment-Efficient Reinforcement Learning via Model-Based Offline Optimization},
  author={Matsushima, Tatsuya and Furuta, Hiroki and Matsuo, Yutaka and Nachum, Ofir and Gu, Shixiang},
  journal={arXiv preprint arXiv:2006.03647},
  year={2020}
}

@article{wang2020critic,
  title={Critic regularized regression},
  author={Wang, Ziyu and Novikov, Alexander and {\.Z}o{\l}na, Konrad and Springenberg, Jost Tobias and Reed, Scott and Shahriari, Bobak and Siegel, Noah and Merel, Josh and Gulcehre, Caglar and Heess, Nicolas and others},
  journal={arXiv preprint arXiv:2006.15134},
  year={2020}
}

@article{yu2020mopo,
  title={MOPO: Model-based Offline Policy Optimization},
  author={Yu, Tianhe and Thomas, Garrett and Yu, Lantao and Ermon, Stefano and Zou, James and Levine, Sergey and Finn, Chelsea and Ma, Tengyu},
  journal={arXiv preprint arXiv:2005.13239},
  year={2020}
}

@article{zhanggendice,
  title={GenDICE: Generalized offline estimation of stationary values, 2020},
  author={Zhang, Ruiyi and Dai, Bo and Lihong, Li and Schuurmans, Dale},
  journal={Preprint}
}

@inproceedings{chua2018deep,
  title={Deep reinforcement learning in a handful of trials using probabilistic dynamics models},
  author={Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={4754--4765},
  year={2018}
}

@inproceedings{schulman2015trust,
  title={Trust region policy optimization},
  author={Schulman, John and Levine, Sergey and Abbeel, Pieter and Jordan, Michael and Moritz, Philipp},
  booktitle={International conference on machine learning},
  pages={1889--1897},
  year={2015}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@inproceedings{mnih2016asynchronous,
  title={Asynchronous methods for deep reinforcement learning},
  author={Mnih, Volodymyr and Badia, Adria Puigdomenech and Mirza, Mehdi and Graves, Alex and Lillicrap, Timothy and Harley, Tim and Silver, David and Kavukcuoglu, Koray},
  booktitle={International conference on machine learning},
  pages={1928--1937},
  year={2016}
}

@phdthesis{thomas2015safe,
  title={Safe reinforcement learning},
  author={Thomas, Philip S},
  year={2015},
  school={University of Massachusetts Libraries}
}

@inproceedings{agarwal2020optimistic,
  title={An optimistic perspective on offline reinforcement learning},
  author={Agarwal, Rishabh and Schuurmans, Dale and Norouzi, Mohammad},
  booktitle={International Conference on Machine Learning},
  pages={104--114},
  year={2020},
  organization={PMLR}
}

@article{Wang2018SupervisedRL,
  title={Supervised Reinforcement Learning with Recurrent Neural Network for Dynamic Treatment Recommendation},
  author={L. Wang and Wei Zhang and Xiaofeng He and H. Zha},
  journal={Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  year={2018}
}

@article{Rafailov2020LOMPO,
  title={Offline Reinforcement Learning from Images with Latent Space Models},
  author={Rafael Rafailov and Tianhe Yu and A. Rajeswaran and Chelsea Finn},
  journal={Learning for Decision Making and Control (L4DC)},
  year={2021},
}

@article{Buckman2020TheIO,
  title={The Importance of Pessimism in Fixed-Dataset Policy Optimization},
  author={J. Buckman and Carles Gelada and Marc G. Bellemare},
  journal={ArXiv},
  year={2020},
  volume={abs/2009.06799}
}

@article{ernst2005tree,
  title={Tree-based batch mode reinforcement learning},
  author={Ernst, Damien and Geurts, Pierre and Wehenkel, Louis},
  journal={Journal of Machine Learning Research},
  volume={6},
  pages={503--556},
  year={2005},
  publisher={Microtome Publishing}
}

@inproceedings{riedmiller2005neural,
  title={Neural fitted Q iteration--first experiences with a data efficient neural reinforcement learning method},
  author={Riedmiller, Martin},
  booktitle={European Conference on Machine Learning},
  pages={317--328},
  year={2005},
  organization={Springer}
}

@article{rafailov2020offline,
  title={Offline Reinforcement Learning from Images with Latent Space Models},
  author={Rafailov, Rafael and Yu, Tianhe and Rajeswaran, Aravind and Finn, Chelsea},
  journal={arXiv preprint arXiv:2012.11547},
  year={2020}
}

@article{singh2020parrot,
  title={Parrot: Data-Driven Behavioral Priors for Reinforcement Learning},
  author={Singh, Avi and Liu, Huihan and Zhou, Gaoyue and Yu, Albert and Rhinehart, Nicholas and Levine, Sergey},
  journal={arXiv preprint arXiv:2011.10024},
  year={2020}
}

@article{xie2019improvisation,
  title={Improvisation through physical understanding: Using novel objects as tools with visual foresight},
  author={Xie, Annie and Ebert, Frederik and Levine, Sergey and Finn, Chelsea},
  journal={Robotics: Science and Systems (RSS)},
  year={2019}
}

@article{jaques2020human,
  title={Human-centric dialog training via offline reinforcement learning},
  author={Jaques, Natasha and Shen, Judy Hanwen and Ghandeharioun, Asma and Ferguson, Craig and Lapedriza, Agata and Jones, Noah and Gu, Shixiang Shane and Picard, Rosalind},
  journal={arXiv preprint arXiv:2010.05848},
  year={2020}
}

@article{kumar2020discor,
  title={DisCor: Corrective Feedback in Reinforcement Learning via Distribution Correction},
  author={Kumar, Aviral and Gupta, Abhishek and Levine, Sergey},
  journal={arXiv preprint arXiv:2003.07305},
  year={2020}
}

@article{dorfman2020offline,
  title={Offline meta reinforcement learning},
  author={Dorfman, Ron and Tamar, Aviv},
  journal={arXiv preprint arXiv:2008.02598},
  year={2020}
}

@article{singh2020cog,
  title={COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning},
  author={Singh, Avi and Yu, Albert and Yang, Jonathan and Zhang, Jesse and Kumar, Aviral and Levine, Sergey},
  journal={arXiv preprint arXiv:2010.14500},
  year={2020}
}

@article{sutton2016emphatic,
  title={An emphatic approach to the problem of off-policy temporal-difference learning},
  author={Sutton, Richard S and Mahmood, A Rupam and White, Martha},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={2603--2631},
  year={2016},
  publisher={JMLR. org}
}

@article{raghu2017deep,
  title={Deep reinforcement learning for sepsis treatment},
  author={Raghu, Aniruddh and Komorowski, Matthieu and Ahmed, Imran and Celi, Leo and Szolovits, Peter and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:1711.09602},
  year={2017}
}

@article{shortreed2011informing,
  title={Informing sequential clinical decision-making through reinforcement learning: an empirical study},
  author={Shortreed, Susan M and Laber, Eric and Lizotte, Daniel J and Stroup, T Scott and Pineau, Joelle and Murphy, Susan A},
  journal={Machine learning},
  volume={84},
  number={1-2},
  pages={109--136},
  year={2011},
  publisher={Springer}
}

@inproceedings{pinto2016supersizing,
  title={Supersizing self-supervision: Learning to grasp from 50k tries and 700 robot hours},
  author={Pinto, Lerrel and Gupta, Abhinav},
  booktitle={2016 IEEE international conference on robotics and automation (ICRA)},
  pages={3406--3413},
  year={2016},
  organization={IEEE}
}

@inproceedings{kalashnikov2018scalable,
  title={Scalable deep reinforcement learning for vision-based robotic manipulation},
  author={Kalashnikov, Dmitry and Irpan, Alex and Pastor, Peter and Ibarz, Julian and Herzog, Alexander and Jang, Eric and Quillen, Deirdre and Holly, Ethan and Kalakrishnan, Mrinal and Vanhoucke, Vincent and others},
  booktitle={Conference on Robot Learning},
  pages={651--673},
  year={2018},
  organization={PMLR}
}

@inproceedings{finn2017deep,
  title={Deep visual foresight for planning robot motion},
  author={Finn, Chelsea and Levine, Sergey},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={2786--2793},
  year={2017},
  organization={IEEE}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@article{oh2015action,
  title={Action-conditional video prediction using deep networks in atari games},
  author={Oh, Junhyuk and Guo, Xiaoxiao and Lee, Honglak and Lewis, Richard and Singh, Satinder},
  journal={arXiv preprint arXiv:1507.08750},
  year={2015}
}

@article{kaiser2019model,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}

@InProceedings{RossB12,
  title =	"Agnostic System Identification for Model-Based Reinforcement Learning",
  author =	"Stephane Ross and Drew Bagnell",
  year = 	"2012",
  booktitle =	"ICML",
}

@INPROCEEDINGS{Rajeswaran-Game-MBRL,
    AUTHOR    = {Aravind Rajeswaran AND Igor Mordatch AND Vikash Kumar},
    TITLE     = "{A Game Theoretic Framework for
Model-Based Reinforcement Learning}",
    BOOKTITLE = {ICML},
    YEAR      = {2020},
}

@article{Abdolmaleki2018MaximumAP,
  title={Maximum a Posteriori Policy Optimisation},
  author={Abbas Abdolmaleki and Jost Tobias Springenberg and Y. Tassa and R. Munos and N. Heess and Martin A. Riedmiller},
  journal={ArXiv},
  year={2018},
  volume={abs/1806.06920}
}

@INPROCEEDINGS{POLO,
    AUTHOR  = {Kendall Lowrey AND Aravind Rajeswaran AND Sham Kakade AND 
             Emanuel Todorov AND Igor Mordatch},
    TITLE   = "{Plan Online, Learn Offline: Efficient Learning and Exploration via Model-Based Control}",
    BOOKTITLE = "{International Conference on Learning Representations (ICLR)}",
    YEAR      = {2019},
}

@inproceedings{Todorov2005,
  title={A generalized iterative LQG method for locally-optimal feedback control of constrained nonlinear stochastic systems},
  author={Emanuel Todorov and Weiwei Li},
  booktitle={ACC},
  year={2005},
}

@article{WilliamsMPPI,
  title={Information theoretic MPC for model-based reinforcement learning},
  author={Grady Williams and Nolan Wagener and Brian Goldfain and Paul Drews and James M. Rehg and Byron Boots and Evangelos Theodorou},
  journal={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  year={2017},
  pages={1714-1721}
}

@Misc{RRT,
  title =	"Rapidly-Exploring Random Trees: A New Tool for Path Planning",
  author =	"Steven M. Lavalle",
  year = 	"1998",
}

@article{Nagabandi2019DeepDM,
  title={Deep Dynamics Models for Learning Dexterous Manipulation},
  author={Anusha Nagabandi and K. Konolige and S. Levine and V. Kumar},
  journal={ArXiv},
  year={2019},
  volume={abs/1909.11652}
}

@Article{OsbandAC18,
  title =	"Randomized Prior Functions for Deep Reinforcement Learning",
  author =	"Ian Osband and John Aslanides and Albin Cassirer",
  journal =	"CoRR",
  year = 	"2018",
  volume =	"abs/1806.03335",
}

@InProceedings{Azizzadenesheli18,
  title =	"Efficient Exploration Through Bayesian Deep
		 Q-Networks",
  author =	"Kamyar Azizzadenesheli and Emma Brunskill and
		 Animashree Anandkumar",
  publisher =	"IEEE",
  year = 	"2018",
  booktitle =	"ITA",
  pages =	"1--9",
}

@InProceedings{BurdaESK19,
  title =	"Exploration by random network distillation",
  author =	"Yuri Burda and Harrison Edwards and Amos J. Storkey and Oleg Klimov",
  publisher =	"OpenReview.net",
  year = 	"2019",
  booktitle =	"ICLR",
}

@article{Chen2019InformationTheoreticCI,
  title={Information-Theoretic Considerations in Batch Reinforcement Learning},
  author={J. Chen and Nan Jiang},
  journal={ArXiv},
  year={2019},
  volume={abs/1905.00360}
}

@Book{BertsekasBook,
  author =	"Dimitri P. Bertsekas and John N. Tsitsiklis",
  title =	"Neuro-Dynamic Programming",
  publisher =	"Athena Scientific",
  year = 	"1996",
  address =	"Belmont, MA",
}

@Book{SuttonBook,
  author =	"R. S. Sutton and A. G. Barto",
  title =	"Reinforcement Learning: An Introduction",
  year = 	"1998",
  publisher =	"MIT Press",
  address =	"Cambridge, MA",
}

@article{Munos2008FiniteTimeBF,
  title={Finite-Time Bounds for Fitted Value Iteration},
  author={R{\'e}mi Munos and Csaba Szepesvari},
  journal={J. Mach. Learn. Res.},
  year={2008},
  volume={9},
  pages={815-857}
}

@article{brockman2016openai,
  title={Openai gym},
  author={Brockman, Greg and Cheung, Vicki and Pettersson, Ludwig and Schneider, Jonas and Schulman, John and Tang, Jie and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1606.01540},
  year={2016}
}

@inproceedings{mandlekar2020iris,
  title={Iris: Implicit reinforcement without interaction at scale for learning control from offline robot manipulation data},
  author={Mandlekar, Ajay and Ramos, Fabio and Boots, Byron and Savarese, Silvio and Fei-Fei, Li and Garg, Animesh and Fox, Dieter},
  booktitle={2020 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4414--4420},
  year={2020},
  organization={IEEE}
}

@article{zhou2020plas,
  title={PLAS: Latent Action Space for Offline Reinforcement Learning},
  author={Zhou, Wenxuan and Bajracharya, Sujay and Held, David},
  journal={arXiv preprint arXiv:2011.07213},
  year={2020}
}

@inproceedings{kahn2018composable,
  title={Composable action-conditioned predictors: Flexible off-policy learning for robot navigation},
  author={Kahn, Gregory and Villaflor, Adam and Abbeel, Pieter and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={806--816},
  year={2018},
  organization={PMLR}
}

@article{Yu2020BDD100KAD,
  title={BDD100K: A Diverse Driving Dataset for Heterogeneous Multitask Learning},
  author={F. Yu and H. Chen and X. Wang and Wenqi Xian and Yingying Chen and Fangchen Liu and V. Madhavan and Trevor Darrell},
  journal={2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year={2020},
  pages={2633-2642}
}

@inproceedings{
lee2021representation,
title={Representation Balancing Offline Model-based Reinforcement Learning},
author={Byung-Jun Lee and Jongmin Lee and Kee-Eung Kim},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=QpNz8r_Ri2Y}
}

@article{swazinna2020overcoming,
  title={Overcoming Model Bias for Robust Offline Deep Reinforcement Learning},
  author={Swazinna, Phillip and Udluft, Steffen and Runkler, Thomas},
  journal={arXiv preprint arXiv:2008.05533},
  year={2020}
}

@article{tassa2018deepmind,
  title={Deepmind control suite},
  author={Tassa, Yuval and Doron, Yotam and Muldal, Alistair and Erez, Tom and Li, Yazhe and Casas, Diego de Las and Budden, David and Abdolmaleki, Abbas and Merel, Josh and Lefrancq, Andrew and others},
  journal={arXiv preprint arXiv:1801.00690},
  year={2018}
}

@article{ovadia2019can,
  title={Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift},
  author={Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, David and Nowozin, Sebastian and Dillon, Joshua V and Lakshminarayanan, Balaji and Snoek, Jasper},
  journal={arXiv preprint arXiv:1906.02530},
  year={2019}
}

@article{degris2012off,
  title={Off-policy actor-critic},
  author={Degris, Thomas and White, Martha and Sutton, Richard S},
  journal={arXiv preprint arXiv:1205.4839},
  year={2012}
}

@inproceedings{laroche2019safe,
  title={Safe policy improvement with baseline bootstrapping},
  author={Laroche, Romain and Trichelair, Paul and Des Combes, Remi Tachet},
  booktitle={International Conference on Machine Learning},
  pages={3652--3661},
  year={2019},
  organization={PMLR}
}

@article{petrik2016safe,
  title={Safe policy improvement by minimizing robust baseline regret},
  author={Petrik, Marek and Chow, Yinlam and Ghavamzadeh, Mohammad},
  journal={arXiv preprint arXiv:1607.03842},
  year={2016}
}

@inproceedings{osband2017posterior,
  title={Why is posterior sampling better than optimism for reinforcement learning?},
  author={Osband, Ian and Van Roy, Benjamin},
  booktitle={International Conference on Machine Learning},
  pages={2701--2710},
  year={2017},
  organization={PMLR}
}

@article{jaksch2010near,
  title={Near-optimal Regret Bounds for Reinforcement Learning.},
  author={Jaksch, Thomas and Ortner, Ronald and Auer, Peter},
  journal={Journal of Machine Learning Research},
  volume={11},
  number={4},
  year={2010}
}

@misc{dasari2020robonet,
      title={RoboNet: Large-Scale Multi-Robot Learning}, 
      author={Sudeep Dasari and Frederik Ebert and Stephen Tian and Suraj Nair and Bernadette Bucher and Karl Schmeckpeper and Siddharth Singh and Sergey Levine and Chelsea Finn},
      year={2020},
      eprint={1910.11215},
      archivePrefix={arXiv},
      primaryClass={cs.RO}
}

@article{kostrikov2021offline,
  title={Offline Reinforcement Learning with Fisher Divergence Critic Regularization},
  author={Kostrikov, Ilya and Tompson, Jonathan and Fergus, Rob and Nachum, Ofir},
  journal={arXiv preprint arXiv:2103.08050},
  year={2021}
}

@inproceedings{
kumar2021implicit,
title={Implicit Under-Parameterization Inhibits Data-Efficient Deep Reinforcement Learning},
author={Aviral Kumar and Rishabh Agarwal and Dibya Ghosh and Sergey Levine},
booktitle={International Conference on Learning Representations},
year={2021},
url={https://openreview.net/forum?id=O9bnihsFfXU}
}

@article{kalashnikov2021mt,
  title={MT-Opt: Continuous Multi-Task Robotic Reinforcement Learning at Scale},
  author={Kalashnikov, Dmitry and Varley, Jacob and Chebotar, Yevgen and Swanson, Benjamin and Jonschkowski, Rico and Finn, Chelsea and Levine, Sergey and Hausman, Karol},
  journal={arXiv preprint arXiv:2104.08212},
  year={2021}
}

@article{eysenbach2020rewriting,
  title={Rewriting history with inverse rl: Hindsight inference for policy improvement},
  author={Eysenbach, Benjamin and Geng, Xinyang and Levine, Sergey and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:2002.11089},
  year={2020}
}

@article{li2020generalized,
  title={Generalized hindsight for reinforcement learning},
  author={Li, Alexander C and Pinto, Lerrel and Abbeel, Pieter},
  journal={arXiv preprint arXiv:2002.11708},
  year={2020}
}

@article{andrychowicz2017hindsight,
  title={Hindsight experience replay},
  author={Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1707.01495},
  year={2017}
}

@article{caruana1997multitask,
  title={Multitask learning},
  author={Caruana, Rich},
  journal={Machine learning},
  volume={28},
  number={1},
  pages={41--75},
  year={1997},
  publisher={Springer}
}

@inproceedings{schaul2015universal,
  title={Universal value function approximators},
  author={Schaul, Tom and Horgan, Daniel and Gregor, Karol and Silver, David},
  booktitle={International conference on machine learning},
  pages={1312--1320},
  year={2015},
  organization={PMLR}
}

@article{pong2018temporal,
  title={Temporal difference models: Model-free deep rl for model-based control},
  author={Pong, Vitchyr and Gu, Shixiang and Dalal, Murtaza and Levine, Sergey},
  journal={arXiv preprint arXiv:1802.09081},
  year={2018}
}

@inproceedings{kaelbling1993learning,
  title={Learning to achieve goals},
  author={Kaelbling, Leslie Pack},
  booktitle={IJCAI},
  pages={1094--1099},
  year={1993},
  organization={Citeseer}
}

@inproceedings{espeholt2018impala,
  author    = {Lasse Espeholt and
               Hubert Soyer and
               R{\'{e}}mi Munos and
               Karen Simonyan and
               Volodymyr Mnih and
               Tom Ward and
               Yotam Doron and
               Vlad Firoiu and
               Tim Harley and
               Iain Dunning and
               Shane Legg and
               Koray Kavukcuoglu},
  title     = {{IMPALA:} Scalable Distributed Deep-RL with Importance Weighted Actor-Learner
               Architectures},
  booktitle = { International Conference on Machine Learning},
  year      = {2018},
}

@inproceedings{hessel2019popart,
  title={Multi-task deep reinforcement learning with popart},
  author={Hessel, Matteo and Soyer, Hubert and Espeholt, Lasse and Czarnecki, Wojciech and Schmitt, Simon and van Hasselt, Hado},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={33},
  year={2019}
}

@inproceedings{riedmiller2018learning,
  title={Learning by playing solving sparse reward tasks from scratch},
  author={Riedmiller, Martin and Hafner, Roland and Lampe, Thomas and Neunert, Michael and Degrave, Jonas and Wiele, Tom and Mnih, Vlad and Heess, Nicolas and Springenberg, Jost Tobias},
  booktitle={International Conference on Machine Learning},
  pages={4344--4353},
  year={2018},
  organization={PMLR}
}

@article{teh2017distral,
  title={Distral: Robust multitask reinforcement learning},
  author={Teh, Yee Whye and Bapst, Victor and Czarnecki, Wojciech Marian and Quan, John and Kirkpatrick, James and Hadsell, Raia and Heess, Nicolas and Pascanu, Razvan},
  journal={arXiv preprint arXiv:1707.04175},
  year={2017}
}

@inproceedings{wilson2007multi,
  title={Multi-task reinforcement learning: a hierarchical bayesian approach},
  author={Wilson, Aaron and Fern, Alan and Ray, Soumya and Tadepalli, Prasad},
  booktitle={Proceedings of the 24th international conference on Machine learning},
  pages={1015--1022},
  year={2007}
}

@article{rusu2015policy,
  title={Policy distillation},
  author={Rusu, Andrei A and Colmenarejo, Sergio Gomez and Gulcehre, Caglar and Desjardins, Guillaume and Kirkpatrick, James and Pascanu, Razvan and Mnih, Volodymyr and Kavukcuoglu, Koray and Hadsell, Raia},
  journal={arXiv preprint arXiv:1511.06295},
  year={2015}
}

@article{ghosh2017divide,
  title={Divide-and-conquer reinforcement learning},
  author={Ghosh, Dibya and Singh, Avi and Rajeswaran, Aravind and Kumar, Vikash and Levine, Sergey},
  journal={arXiv preprint arXiv:1711.09874},
  year={2017}
}

@article{yu2020gradient,
  title={Gradient surgery for multi-task learning},
  author={Yu, Tianhe and Kumar, Saurabh and Gupta, Abhishek and Levine, Sergey and Hausman, Karol and Finn, Chelsea},
  journal={arXiv preprint arXiv:2001.06782},
  year={2020}
}

@article{yu2021combo,
  title={Combo: Conservative offline model-based policy optimization},
  author={Yu, Tianhe and Kumar, Aviral and Rafailov, Rafael and Rajeswaran, Aravind and Levine, Sergey and Finn, Chelsea},
  journal={arXiv preprint arXiv:2102.08363},
  year={2021}
}

@article{strehl2010learning,
  title={Learning from logged implicit exploration data},
  author={Strehl, Alex and Langford, John and Kakade, Sham and Li, Lihong},
  journal={arXiv preprint arXiv:1003.0120},
  year={2010}
}

@inproceedings{garcin2014offline,
  title={Offline and online evaluation of news recommender systems at swissinfo. ch},
  author={Garcin, Florent and Faltings, Boi and Donatsch, Olivier and Alazzawi, Ayar and Bruttin, Christophe and Huber, Amr},
  booktitle={Proceedings of the 8th ACM Conference on Recommender systems},
  pages={169--176},
  year={2014}
}

@article{charles2013counterfactual,
  title={Counterfactual reasoning and learning systems: The example of computational advertising},
  author={Charles, Denis and Chickering, Max and Simard, Patrice},
  journal={Journal of Machine Learning Research},
  volume={14},
  year={2013}
}

@inproceedings{theocharous2015ad,
  title={Ad recommendation systems for life-time value optimization},
  author={Theocharous, Georgios and Thomas, Philip S and Ghavamzadeh, Mohammad},
  booktitle={Proceedings of the 24th International Conference on World Wide Web},
  pages={1305--1310},
  year={2015}
}

@inproceedings{thomas2017predictive,
  title={Predictive Off-Policy Policy Evaluation for Nonstationary Decision Problems, with Applications to Digital Marketing.},
  author={Thomas, Philip S and Theocharous, Georgios and Ghavamzadeh, Mohammad and Durugkar, Ishan and Brunskill, Emma},
  booktitle={AAAI},
  pages={4740--4745},
  year={2017}
}

@article{parisotto2015actor,
  title={Actor-mimic: Deep multitask and transfer reinforcement learning},
  author={Parisotto, Emilio and Ba, Jimmy Lei and Salakhutdinov, Ruslan},
  journal={arXiv preprint arXiv:1511.06342},
  year={2015}
}

@article{schaul2019ray,
  title={Ray interference: a source of plateaus in deep reinforcement learning},
  author={Schaul, Tom and Borsa, Diana and Modayil, Joseph and Pascanu, Razvan},
  journal={arXiv preprint arXiv:1904.11455},
  year={2019}
}

@inproceedings{yu2020metaworld,
  title={Meta-world: A benchmark and evaluation for multi-task and meta reinforcement learning},
  author={Yu, Tianhe and Quillen, Deirdre and He, Zhanpeng and Julian, Ryan and Hausman, Karol and Finn, Chelsea and Levine, Sergey},
  booktitle={Conference on Robot Learning},
  pages={1094--1100},
  year={2020},
  organization={PMLR}
}

@article{sodhani2021multi,
  title={Multi-Task Reinforcement Learning with Context-based Representations},
  author={Sodhani, Shagun and Zhang, Amy and Pineau, Joelle},
  journal={arXiv preprint arXiv:2102.06177},
  year={2021}
}

@article{xu2020knowledge,
  title={Knowledge Transfer in Multi-Task Deep Reinforcement Learning for Continuous Control},
  author={Xu, Zhiyuan and Wu, Kun and Che, Zhengping and Tang, Jian and Ye, Jieping},
  year={2020}
}

@inproceedings{guez2008adaptive,
  title={Adaptive Treatment of Epilepsy via Batch-mode Reinforcement Learning.},
  author={Guez, Arthur and Vincent, Robert D and Avoli, Massimo and Pineau, Joelle},
  booktitle={AAAI},
  pages={1671--1678},
  year={2008}
}

@inproceedings{d2019sharing,
  title={Sharing knowledge in multi-task deep reinforcement learning},
  author={D'Eramo, Carlo and Tateo, Davide and Bonarini, Andrea and Restelli, Marcello and Peters, Jan},
  booktitle={International Conference on Learning Representations},
  year={2019}
}

@article{gulcehre2020rl,
  title={Rl unplugged: Benchmarks for offline reinforcement learning},
  author={Gulcehre, Caglar and Wang, Ziyu and Novikov, Alexander and Paine, Tom Le and Colmenarejo, Sergio G{\'o}mez and Zolna, Konrad and Agarwal, Rishabh and Merel, Josh and Mankowitz, Daniel and Paduraru, Cosmin and others},
  journal={arXiv preprint arXiv:2006.13888},
  year={2020}
}

@article{yang2020multi,
  title={Multi-task reinforcement learning with soft modularization},
  author={Yang, Ruihan and Xu, Huazhe and Wu, Yi and Wang, Xiaolong},
  journal={arXiv preprint arXiv:2003.13661},
  year={2020}
}

@article{tao2020repaint,
  title={REPAINT: Knowledge Transfer in Deep Reinforcement Learning},
  author={Tao, Yunzhe and Genc, Sahika and Chung, Jonathan and Sun, Tao and Mallya, Sunil},
  journal={arXiv preprint arXiv:2011.11827},
  year={2020}
}

@article{ebert2018visual,
  title={Visual foresight: Model-based deep reinforcement learning for vision-based robotic control},
  author={Ebert, Frederik and Finn, Chelsea and Dasari, Sudeep and Xie, Annie and Lee, Alex and Levine, Sergey},
  journal={arXiv preprint arXiv:1812.00568},
  year={2018}
}

@article{tian2020model,
  title={Model-Based Visual Planning with Self-Supervised Functional Distances},
  author={Tian, Stephen and Nair, Suraj and Ebert, Frederik and Dasari, Sudeep and Eysenbach, Benjamin and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2012.15373},
  year={2020}
}

@article{chebotar2021actionable,
  title={Actionable Models: Unsupervised Offline Reinforcement Learning of Robotic Skills},
  author={Chebotar, Yevgen and Hausman, Karol and Lu, Yao and Xiao, Ted and Kalashnikov, Dmitry and Varley, Jake and Irpan, Alex and Eysenbach, Benjamin and Julian, Ryan and Finn, Chelsea and Levine, Sergey},
  journal={arXiv preprint arXiv:2104.07749},
  year={2021}
}

@article{sun2019policy,
  title={Policy continuation with hindsight inverse dynamics},
  author={Sun, Hao and Li, Zhizhong and Liu, Xiaotong and Lin, Dahua and Zhou, Bolei},
  journal={arXiv preprint arXiv:1910.14055},
  year={2019}
}

@article{pitis2020counterfactual,
  title={Counterfactual Data Augmentation using Locally Factored Dynamics},
  author={Pitis, Silviu and Creager, Elliot and Garg, Animesh},
  journal={arXiv preprint arXiv:2007.02863},
  year={2020}
}

@article{liu2019competitive,
  title={Competitive experience replay},
  author={Liu, Hao and Trott, Alexander and Socher, Richard and Xiong, Caiming},
  journal={arXiv preprint arXiv:1902.00528},
  year={2019}
}

@article{yang2021bias,
  title={Bias-reduced multi-step hindsight experience replay},
  author={Yang, Rui and Lyu, Jiafei and Yang, Yu and Ya, Jiangpeng and Luo, Feng and Luo, Dijun and Li, Lanqing and Li, Xiu},
  journal={arXiv preprint arXiv:2102.12962},
  year={2021}
}

@article{lynch2020grounding,
  title={Grounding language in play},
  author={Lynch, Corey and Sermanet, Pierre},
  journal={arXiv preprint arXiv:2005.07648},
  year={2020}
}

@article{lin2019reinforcement,
  title={Reinforcement learning without ground-truth state},
  author={Lin, Xingyu and Baweja, Harjatin Singh and Held, David},
  journal={arXiv preprint arXiv:1905.07866},
  year={2019}
}

@article{huang2019mapping,
  title={Mapping state space using landmarks for universal goal reaching},
  author={Huang, Zhiao and Liu, Fangchen and Su, Hao},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  pages={1942--1952},
  year={2019}
}

@article{nair2018visual,
  title={Visual reinforcement learning with imagined goals},
  author={Nair, Ashvin and Pong, Vitchyr and Dalal, Murtaza and Bahl, Shikhar and Lin, Steven and Levine, Sergey},
  journal={arXiv preprint arXiv:1807.04742},
  year={2018}
}

@inproceedings{xie2018few,
  title={Few-shot goal inference for visuomotor learning and planning},
  author={Xie, Annie and Singh, Avi and Levine, Sergey and Finn, Chelsea},
  booktitle={Conference on Robot Learning},
  pages={40--52},
  year={2018},
  organization={PMLR}
}

@article{fu2018variational,
  title={Variational inverse control with events: A general framework for data-driven reward definition},
  author={Fu, Justin and Singh, Avi and Ghosh, Dibya and Yang, Larry and Levine, Sergey},
  journal={arXiv preprint arXiv:1805.11686},
  year={2018}
}

@article{chen2021learning,
  title={Learning Generalizable Robotic Reward Functions from" In-The-Wild" Human Videos},
  author={Chen, Annie S and Nair, Suraj and Finn, Chelsea},
  journal={arXiv preprint arXiv:2103.16817},
  year={2021}
}

@article{yang2021representation,
  title={Representation matters: Offline pretraining for sequential decision making},
  author={Yang, Mengjiao and Nachum, Ofir},
  journal={arXiv preprint arXiv:2102.05815},
  year={2021}
}

@article{li2019multi,
  title={Multi-task batch reinforcement learning with metric learning},
  author={Li, Jiachen and Vuong, Quan and Liu, Shuang and Liu, Minghua and Ciosek, Kamil and Ross, Keith and Christensen, Henrik Iskov and Su, Hao},
  journal={arXiv preprint arXiv:1909.11373},
  year={2019}
}

@article{killian2020empirical,
  title={An Empirical Study of Representation Learning for Reinforcement Learning in Healthcare},
  author={Killian, Taylor W and Zhang, Haoran and Subramanian, Jayakumar and Fatemi, Mehdi and Ghassemi, Marzyeh},
  journal={arXiv preprint arXiv:2011.11235},
  year={2020}
}

@inproceedings{sharma2018multiple,
  title={Multiple interactions made easy (mime): Large scale demonstrations data for imitation},
  author={Sharma, Pratyusha and Mohan, Lekha and Pinto, Lerrel and Gupta, Abhinav},
  booktitle={Conference on robot learning},
  pages={906--915},
  year={2018},
  organization={PMLR}
}